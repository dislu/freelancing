---
title: "Neural Networks"
author: "Charles Lang"
date: "10/05/2021"
output: html_document
---

## Part I - Introduction to Using Neural Nets

In the attached data sets attention1.csv and attention2.csv, you will find data that describe features assocaited with webcam images of 100 students' faces as they particpate in an online discussion. The variables are:

eyes - student has their eyes open (1 = yes, 0 = no)
face.forward - student is facing the camera (1 = yes, 0 = no)
chin.up - student's chin is raised above 45 degrees (1 = yes, 0 = no)
squint - eyes are squinting
hunch - shoulders are hunched over
mouth1 - mouth is smiling
mouth2 - mouth is frowning
mouth3 - mouth is open
attention - whether the student was paying attention when asked (1 = yes, 0 = no)

We will use the webcam data to build a neural net to predict whether or not a student is attending.

First install and load the neuralnet package
```{r}
install.packages("neuralnet")
library(neuralnet)
```

Now upload your data
```{r}
D1 <- read.csv("/Users/arvind tomar/Documents/neural-networks-master/attention1.csv", head=TRUE)
  
D2 <-read.csv("/Users/arvind tomar/Documents/neural-networks-master/attention2.csv",head=TRUE)

```

Now you can build a neural net that predicts attention based on webcam images. The command "neuralnet" sets up the model. It is composed of four basic arguments:

- A formula that describes the inputs and outputs of the neural net (attention is our output)
- The data frame that the model will use
- How many nodes are in the hidden layer
- A threshold that tells the model when to stop adjusting weights to find a better fit. If error does not change more than the threshold from one iteration to the next, the algorithm will stop (We will use 0.01, so if prediction error does not change by more than 1% from one iteration to the next the algorithm will halt)

```{r}
nn <- neuralnet(attention == 1 ~ eyes + face.forward + chin.up + squint + hunch + mouth1 + mouth2 + mouth3, D1, hidden = c(2,2), learningrate = 0.2)

plot(nn)
nn$result.matrix
#The option "hidden" allows you to change the number of hiddden layers and number of nodes within the hidden layers c(1,1) = one hidden layer with 1 node, 0 = zero hidden layers, etc

#The option "learningrate" alters the size of the steps the model takes every time it adjusts the weights.

#Change the hidden layers and learningrate options and check both the prediction accuracy 
```

You have now trained a neural network! The plot shows you the layers of your newtork as black nodes and edges with the calculated weights on each edge. The blue nodes and edges are the bias/threshold terms - it is a little bit confusing that they are represented as nodes, they are not nodes in the sense that the black nodes are. The bias anchors the activation function, the weights change the shape of the activation function while the bias term changes the overall position of the activation function - if you have used linear regression the bias term is like the intercept of the regression equation, it shifts the trend line up and down the y axis, while the other parameters change the angle of the line. The plot also reports the final error rate and the number of iterations ("steps") that it took to reach these weights.

What happens if you increase the number of hidden layers in the neural net? Build a second neural net with more or fewer layers in it and determine if this improves your predictions or not? How can you tell if your new neural network is doing a better job than your first?
```{r}
nn1 <- neuralnet(attention == 1 ~ eyes + face.forward + chin.up + squint + hunch + mouth1 + mouth2 + mouth3, D1, hidden = c(3,2), learningrate = 0.2)

plot(nn1)
```
#####################################################
If we increase the number of hidden layers, number of steps goes up, but error and accuracy have almost no change. Here, if we build a neural net with 3 hidden layers and 2 nodes, it doesn't improve our prediction. The prediction remains the same at 98%, but the steps in neural net goes up. If our second neural net is improving the error and accuracy on test data, we can say it is performing better than first one.
####################################################

Now use your preferred neural net to predict the second data set. You will need to create a new data frame (D3) that only includes the input layers to use this command.

```{r}
D3 <- subset(D2, select=-c(4)) # remove attention the outcome variable from the test set
#nn_result<-compute(nn,D3)
#results <- data.frame(actual = D2$attention,                    prediction = nn_result$net.result)
```

Now you can create predictions using your neural net
```{r}
#The code below will use your model to predict the outcome using D3 data
pred <- predict(nn, D3)

#The code below will tell you how accurate your model is att predicting the unseen data
table(D2$attention == 1, pred[, 1] > 0.5)

#Adjust both the hidden layer and lerarning rate and see if that has an impact on error, steps and prediction accuracy


```

## Please answer the following questions:

1. How accurate is your neural net? How can you tell?
####################################################
from the confusion matrix accuracy = (TP+TN)/total
accuracy = (33+65)/33+65+1+1 = 98/100=98%
We can say that our neural net a doing outstanding job with accuracy of 98%
####################################################
2. How would you explain your model to the students whose behavior you are predicting? 

3. This is a very simple example of a neural network. Real facial recognition is very complex though. Would a neural network be a good solution for predicting real facial movements? Why, why not? 

####################################################
Yes, neural networks is a good solution for predicting real facial movements. We have seen a lot of development in artificial neural networks in recent time. Convolution neural network (a type of Neural networks) performs better on unstructured data like images and videos. There are already many types of CNN model in market which are doing great job in predicting real facial movements. The main advantage of CNN compared to its algorithm is that it automatically detects the important features without any human supervision.  
####################################################
## Repeat with your own data

Either synthesize a data set or find a data set online and build a neural net to predict a binary outcome from several inputs. Split your data into two sets and use one set to train the neural net and the other set to make predictions. Change the hidden layers and learning rate until you get the most accurate model you can.
####################################################
Classification problwm: Predict 5-Year Career Longevity for NBA Rookies
y = 0 if career years played < 5
y = 1 if career years played >= 5

Here, I am using caret package to train and tune neural network model. Caret package have inbuilt mechanism to build and tune model with less effort
####################################################

```{r}
# import required packages
library(caret)
library(doParallel) # package for parallel processing

registerDoParallel(cores = 2) # two cores at a time
```
```{r}
# Read data.
Data <- read.csv("/Users/arvind tomar/Documents/neural-networks-master/Own_data/nba_logreg.csv",sep=",",head = TRUE)
#test <- read.csv('test.csv')
```
# Set classification column to factor.
#y <- as.factor(make.names(Data$TARGET_5Yrs))


```{r}
library('RANN')
sum(is.na(Data)) # checking for NAs
#removing missing values using KNN. 
Data<-na.omit(Data)
sum(is.na(Data)) # checking again if there are NAs
traindata<-createDataPartition(
  y=Data$TARGET_5Yrs # the outcome data are needed
  ,p=0.75 # The percentage of data in training set
  ,list=FALSE)

#Generates a list of index numbers for the sample
training<-Data[traindata,]
testing<- Data[-traindata,]
#TRAIN <- training[,c(2:10)] #Remove the student_id variable that we do not want to use in the model
```
#pre-processing steps

Training the nnet model 
```{r}
#create outcome variable as factor
training$TARGET_5Yrs<-ifelse(training$TARGET_5Yrs==1,"yes","no")
training$TARGET_5Yrs<-factor(training$TARGET_5Yrs )
numFolds <- trainControl(method = 'cv', number = 10, classProbs = TRUE, verboseIter = TRUE, summaryFunction = twoClassSummary, preProcOptions = list(thresh = 0.75, ICAcomp = 3, k = 5))
fit <- train(TARGET_5Yrs ~ . -TARGET_5Yrs, data = training[,-1], method = 'nnet', preProcess = c('center', 'scale'), trControl = numFolds, tuneGrid=expand.grid(size=c(10), decay=c(0.1)))
fit
```
```{r}
# accuracy measures on training data set
results1 <- predict(fit, newdata=training)
conf1 <- confusionMatrix(results1, training$TARGET_5Yrs)
conf1
# testing the model on testing data set
testing$TARGET_5Yrs<-ifelse(testing$TARGET_5Yrs==1,"yes","no")
testing$TARGET_5Yrs<-factor(testing$TARGET_5Yrs )
results2 <- predict(fit, newdata=testing)
conf2 <- confusionMatrix(results2, testing$TARGET_5Yrs)
conf2
#probs <- predict(fit, newdata=testing, type='prob')
#probs
```
