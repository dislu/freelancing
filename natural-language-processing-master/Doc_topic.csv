"","Title","Notes","positive","negative","score","topic"
"1","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","While Learning Analytics and Educational Data Mining have evolved and formed into two separate communities of research, they have some similarities and should work together more often. Promotes shared communication and collaboration. Both EDM and LAK want to improve education analysis and data. They are becoming more important in data-driven decision making. Table 1 (p.2)highlights key differences between the fields. LAK: systems; more focused on empowering teachers/learners EDM: reducing components/individual relationships; focused on automated adaptation Healthy competition helps fuel the fields but they have to communicate to provide the greatest educational benefits.",3,0,3,2
"2","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","distinction between exploratory and presentation graphs writing about static presentation graphs Purpose of graphic display (p7) 1. Graphics are for the qualitative/descriptive—conceivably the semiquantitative—never for the carefully quantitative (tables do that better).2. Graphics are for comparison—comparison of one kind or another—not for access to individual amounts.3. Graphics are for impact—interocular impact if possible, swinging-finger impact if that is the best one can do, or impact for the unexpected as a minimum—but almost never for something that has to be worked at hard to be perceived.4. Finally, graphics should report the results of careful data analysis—rather than be an attempt to replace it. (Exploration—to guide data analysis—can make essential interim use of graphics, but unless we are describing the exploration process rather than its results, the final graphic should build on the data analysis rather than the reverse.) discovery goals v communication goals making graphics attractive can motivate people to understand them help with recall of information statistical data visualization: focused on facilitating understanding of patterns infographcis: attractive, tell a story, encourage viewer to look/think about the data best visualization projects: wordle, decision tree (obama-clinton divide), radiohead video(uses graphics technology but is not a data visualization), box office streamgraphs not very useful graphics: florence nightingale's celebrated circualr plot of crimean war mortality shows different goals of statistical graphics which in modern day would use time-series plots and information visualization which attracts people who wouldn't likely be interested otherwise  solution is to do both, draw people in and give precise plots that describe data well  example baby name wizard graphs: ""Less constraint -&gt; more diffuse distribution of names -&gt; more concentrated distribution of lastletters. And we gained this bit of social science insight from a powerful combination of high-tech interactive visualization, exploratory data analysis, and static statistical graphics to crisply summarize the result."" (p36)",9,6,3,2
"3","Data wranglers: human interpreters to help close the feedback loop","LA seen as a feedback loop...but how do we close the loop of actionable intelligence and learning data? Need to pair actionable intelligence with intelligent action. Learning is a complex social activity that requires sense-making in order to take action Need to support LA by establishing a contextual framework and increasing a culture of data use -&gt; creating community of practice Data wranglers - goal to engage in sense-making and create actionable intelligence; theory-&gt;practice -how data can be improved (double-loop learning) -act as human sense-makers -facilitate action -develop community of practice Large-scale student bodies and data sets can create gaps in systems between knowledge and practice While all data DW use is available, their purpose is to go beyond analytics to increase familiarity and capacity Found examples of good practice in online learning: -students focus on assessed activities but are likely to ignore optional ones -many students enjoy learning though reading print but fewer like text online (audio and video are about as popular as print), but these balances can be changed with certain types of activities anecdotal evidence of success increasing data use among faculty issue of data quality/organization ",9,1,8,1
"4","Saturday Morning Breakfast Cereal","Comic: starts w/ 90% of elite engineers were observed disassembling and reassembling clocks as children -- through panicked policy change about failure to teach clocks -- progresses to kids being 'over clocked' -- everything is 'clock' now ",1,1,0,2
"5","Translating Learning into Numbers: A Generic Framework for Learning Analytics","There has been an explosion of available data, much of which is promising in its use in education Hopes to reduce delivery costs, improve learning effectiveness, accelerate development, etc.  Data mining is more economical than past collection strategies which makes is more common, reflects real user behavior proliferation of interactive learning platforms etc. produces significant quantities of tracking data questions of data ownership and openness, compatibility of education data sets&; 6 critical dimensions of LA 1. internal limitations -competences and acceptance 2. external constrains -conventions and norms, laws/policies/standards -ethical policies of the field, legal protections of individual data, institutional constraints&; 3. stakeholders -data clients and data subjects; requires hierarchical data flow 4. objectives -reflection and prediction 5. data -challenge of public availability of data -problem with the common assumption that data sets consist of only meaningful, context-free data 6. instruments -utilize different techs to retrieve information -includes conceptual instruments all 6 elements critical to have a fully formulated LA framework technologies are not pedagologically neutral so evaluation will be influenced by analytical approach chosen  &;",4,5,-1,1
"6","Chapter 12: Learning Analytics Dashboards","Types of dashboards 1. support traditional face-to-face lectures, allow teacher to engage students during lecture 2. support face-to-face group work such as visualizing for individual learners and groups of students 3. support online or blended learning What can be incorporated into dashboards: 1. artifacts produced by learners 2. social interaction 3. resources use (documents, videos, etc.) 4. time spent 5. test and self-assessment Goal to support awareness about learning process and foster discussion. can include color cues and diagrams. Need to understand why, for whom, what, and how before you start working with your data set to create a dashboard. Choose a representation that best answers the questions that people are going to want answered. Think of what students, teachers, or other audiences might want to know/ask. Make sure to document your rationale and decision-making process throughout to show alternative and evolution of your design. Interaction techniques are useful in visual analytics. Make sure to evaluate continuously to reference your goals and your audience and make sure your dashboard is accomplishing what it needs to through the most appropriate techniques.",9,0,9,2
"7","Zotero Quick Start Guide","Welcome to Zotero!View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.Thanks for installing Zotero.",0,0,0,1
"8","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","research has not paid enough attention to teacher assigned grades and has relied on standardized test scores An emerging line of research has begun to ask whyteacher-assigned grades are predictive of overall studentoutcomes, but are a weak indicator of academicknowledge when compared to standardized test scores (2) The broader data mining literature provides a wayto bring order and a means to analyze all of the datawithout aggregating the data, displaying each individual’sinformation patterned and displayed in a way that allowsfor interpretation of large longitudinal datasets (3)  Hierarchical cluster analysis - cluster trees or dendograms - provides a way of organizing cases based on how similar the values for the list ofvariables are for each case (5) Thus, when complete, cases that were previouslyorganized just as a pseudo-random descriptive list,organized alphabetically or by student numbers, wereplaced nearby other cases in the list with which they had a high similarity, aiding in visualization and identificationof empirically defined patterns previously unknownwithin the dataset. This does not change the data foreach case, but merely reorders the cases into clustersbased on the similarity of each case’s data vector (5-6)",1,1,0,3
"9","k-Means Clustering","k-means clustering algorithm classifies n points into k clusters through these steps: 1. assigns each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. 2. computes these assignments iteratively, until reassigning points and recomputing averages (over all points in a cluster) produces no changes. creates 2D cutting planes that separate clusters  need to design the algorithm properly because it can give you clusters even when they don't exist in the data, can be manipulated to give patterns that we want to see ",1,0,1,1
"10","RStudio Cheat Sheets","Data Wrangling &; tidyr::gather()Specify:• dataframe• key: the variable that the reshape will be based on• value: new variable names that will generated for new dataframe• gather_cols: the variables that are reshaped toaccommodate the new structure example from swirl  res&lt;- gather(students2, sex_class, count, -grade) gathers sex_class and count but not grade from data students2 gather(data, key = ""key"", value = ""value"", ..., na.rm = FALSE, convert = FALSE, factor_key = FALSE) &; tidyr::spread()Specify:• dataframe• key: the variable that the reshape will be based on• value: column whose values will populate the cells spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE, sep = NULL); R Markdown &; ```{}put code in here. ``` R markdown doesn't let you do shortcuts to run so you have to highlight and click run selected or click the run button",0,4,-4,1
"11","Chapter 1: Social Network Data","first major emphasis of network analysis: seeing how actors are located or ""embedded"" in the overall network second major emphasis of network analysis: seeing how the wholepattern of individual choices gives rise to more holistic patterns Rather than thinking about how an actor's ties with other actors describes the attributes of ""ego,"" network analysts instead see a structure of connections, within which the actor is embedded. Actors are described by their relations, not by their attributes. (2) Nodes/Actors - not sampled independently because it is their relationships that are important to the analysis SNA rarely uses samples from data but instead conducts census actors cannot be selected independently - must also select actors they are tied to boundaries are a priori/naturally occuring or imposed in aggregates by the investigator think of individuals as embedded in hierarchical or nested designs The ability of network methods to map such multi-modal relations is, at least potentially, a step forward in rigor (5) sampling ties: full network methods (complete picture of relations in a pop), snowball (focal actor or set of actors and ties spread from there), ego-centric (selection of focal nodes and connectors, good for large populations) multiple relations If we do not know what relations to examine, how might we decide? material and informational. Material things are ""conserved"" in the sense that they can only be located at one node of the network at a time. Movements of people between organizations, money between people, automobiles between cities, and the like are all examples of material things which move between nodes -- and hence establish a network of material relations. Informational things, to the systems theorist, are ""non-conserved"" in the sense that they can be inmore than one place at the same time. (8) scales of measurement  binary measures of relations multiple category nominal measures of relations grouped ordinal measures of relations full rank ordinal measures of relations interval measures of relations",2,0,2,4
"12","Statistical graphics: making information clear – and beautiful","&;&;&; <U+2043>&;&; &;A well-designed graph can make clear what an ill-thought-out one conceals.&;&; &;<U+2043>&;&; &;When producing-quality figures, every decision needs to be made consciously and with intent.&;&; &;<U+2043>&;&; &;Who is your target audience? &;&;&; &;<U+2043>&;&; &;What are you trying to show?&;&; &;<U+2043>&;&; &;In the example, show the timing of the WHO’s mass vaccination campaign relative to the outbreak in order to provide public health officials with a retrospective view of the policy decision&;&; &;<U+2043>&;&; &;number of infected individuals at a given time is more important than the total number of cases = plot confirmed cases&;&; &;<U+2043>&;&; &;2-types of audiences: 1) officials into those who are interested in this particular outbreak and 2) hose who are interested in lessons learned from this outbreak that will inform future policy = two things to show&;&; &;<U+2043>&;&; &;Guiding principles along for graphs:&;&; &;<U+2043>&;&; &;Avoid distracting elements.&;&; &;<U+2043>&;&; &;Use informative colour to visually associate elements.&;&; &;<U+2043>&;&; &;Keep the figure simple (and therefore interpretable)&;&; &;<U+2043>&;&; &;A successful chart “conveys information as well as containing it”&;&; &;<U+2043>&;&; &;A second set of guiding principles:&;&; &;<U+2043>&;&; &;Keep the x- and y-axes on the same scale. &;&;&; &;<U+2043>&;&; &;Eliminate repetitive information.&;&; &;<U+2043>&;&; &;Maintain consistency across plots.&;&; &;<U+2043>&;&; &;generally speaking, start with exploratory plots and then move towards presentation-quality graphs. But in some cases the visually attractive overview sets the stage for more focused data exploration",3,6,-3,2
"13","Junkcharts Trifecta Checkup: The Definitive Guide","junkcharts trifecta is a framework for visual data criticism 3 questions: 1. what is the question? 2. what does the data say? 3. what does the visual say? ideally, these should all have the same results. typologies 0. the trifecta - everything in sync 1. the singles - 1a) type Q - poorly defined objective 1b) Type D - data fail to illuminate the question 1c) Type V - visual design hides or confuses the message 2. doubles - 2a) Tupe QD - poor data quality and unclear objective 2b) Type QV - undefined question and poor graphic design 2c) Type DV - unconvincing data and poor graphics 3. triple - Type QDV - nothing right &;",2,9,-7,2
"14","Big Data in Education","Video 1 clustering and factor analysis clustering: type of structure discovery element-large # data points-want to find structure of data points-don’t know anything about structure beforehand tries to find data points that group together centroids represent center of space -usually chosen randomly then refined convergence-repeating refining process until centroids stop moving; Video 2 how do we choose which clusters to choose after randomized restarts?-distortion/mean squared deviation &;&; &;-take each point P&;&; &;-find centroid of P’s cluster C&;&; &;-find distance D from C to P&;&; &;-square D to get D’&;&; &;-sum all D’ to get Distortion -doesn’t work for choosing cluster size b.c more clusters almost always leads to smaller Distortion",2,2,0,1
"15","Chapter 3: Measurement and its Uses in Learning Analytics","Psychological measurement typically comprises: 1. defining a construct -term construct used interchangeably with latent variable while trait is a construct stable over time -Operationalist view: measurement requires comparison with a reference point - forces redefinition of the construct for every instrument used to measure it -model-based reasoning accepts simplified representations of a system -examples are SAT which we know is a flawed measurement system but it is designed and accepted to measure something 2. specifying a measurement model and (developing) a reliable instrument -typically tests or questionnaires made up of indicators -balancing efficiency and standardization 3. analyzing and accounting for various sources of error -not consistent and may not accurately reflect someone's abilities etc. -systematic, user, and latent error all possible -measurement models are formal mathematical relationships b/w latent and observable variables 4. framing a valid argument for uses of the outcome Measuring knowledge/skills/feeling difficult but increasingly discussed High-stakes consequences like tracking based on psychological measurement What error can be tolerated when stakes are so high? What ways can we avoid misunderstanding learning or diminishing learner experiences? 4 types of latent variable models: 1. factor analysis: latent continuous/observed continuous -models linear relationships 2. latent mixture: latent categorical/observed continuous -understanding distributions 3. item response: latent continuous/observed categorical -models individual person-item interactions rather than total test scores 4. latent class: latent categorical/observed categorical -understanding distributions Use of a model depends on the error, use goodness of fit tests to evaluate consistency b/w observed data and model  explanatory power plays the role of determining the truer model, but does not always point in the same direction as predictive power -- LA occupies the middle space between these two ideas &;",2,7,-5,5
"16","Chapter 4: Ethics and Learning Analytics: Charting the (Un)Charted","Fears and realities about privacy/surveillance often lead people to be hesitant about data collection Because the field is emerging, ethics standards need to be developed/maintained as the field grows to encourage good practice General consensus that education will be increasingly influenced by data collection and advanced machine learning/human learning analysis/support There are a lot of economic benefits to educational benefits of data harvesting so ethical implications come up for managing interests of different stakeholders with the risk/harm resulting from the collection and analysis of student data  Issues affecting ethical use of LA: 1. location and interpretation of data 2. informed consent, privacy, and de-identification of data 3. management, classification, and storage of data Development of a thorough understanding of the stakeholders and the conditions under which they would benefit; issues around vulnerability; systems of redress; storage; governance are some of the practical considerations LA proposes theoretical opportunities for institutions to mitigate risks but resources are limited Increasing awareness of LA being used to do something to the student without that student's knowledge triggers issues of accountability -challenged assumptions of objectivity and accuracy -raised need to focus on building appropriate framework for student-centered LA: output subject to student review, students able to ensure security of their personal data, full knowledge of its collection and use, no harm to student progress How do these issues align with the perceptions about how people share their personal information as a cultural norm?  Importance of 'informed consent' to data collection/use and transparency &;",6,5,1,2
"17","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Network concepts social network basics: SNA aims to understand the determinants,structure, and consequences of relationships between actors network types: unipartite (or sometimes monopartite or one-mode)/ bipartite (or sometimes two-mode); undirected/directed; binary/valued network data collection: Network data collection(and subsequent analyses) can be categorized, then,by whether it considers a static network, a cross-sectionalrealization of an implicitly dynamic network, or an explicitlydynamic network-ego centric, whole, census  network level concepts and measures: density (how many ties are present); patterns of who is connected with whom; homophily; patterns of social selection and social influence diads/triads transitivity: likelihood of student A being tied to C, giventhat A is tied to B and B is tied to C. -transitive triads/ cyclical triads actor-level variables: centrality, degree, betweeness, eigenvecotr centrality, indegree, outdegree, In performing SNA, visualizing the network is often the firststep taken. Using sociographs, with nodal attributes representedby different colors, shapes, and sizes, we will be ableto begin qualitatively assessing a priori hypotheses and derivingnew hypotheses (8)",0,1,-1,4
"18","Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult? Learning is very multidimensional: what do you count as noise and what do you count as signal? sometimes you have to simplify learning too much in order to analyze it it is very personal difficult to define/measure as cultural construct can measure particular behavioral outputs no trusted reliable proxies we often don't know what people's competencies are coming into places like MOOCs  analytics should reveal something to the learner; be a doorway to suggest what else is possible ",2,2,0,1
"19","Why Students Should Own Their Educational Data","most learners have ""jagged profile"" of learning traits (i.e. high science interest w/ low reading skill) standardized teaching does not account for these patterns but assumes average skill across learners suggests detailed data on students can help customize individual learning experience to account for these jagged profiles learning style theory comes from analyzing learning over a population but doesn't necessarily hold when applied to the individual - highly contextual MOOCs understand that data is important for this purpose (contextualizing ed) but they hoard it as part of their business model - there needs to be more transparency in the education market ",2,1,1,2
"20","How to Display Data Badly","balance too much and too little data (method for figuring this out was called ddi -data density index- and was the number of numbers plotted per square inch) rule 1 - minimize data density -- demonstrates efficiency and clarity  rule 2 - minimize data-ink ratio -- ration of the amount of ink used in graphing the data to the total amount of ink to the page, closer to 0 the worse the graph rule 3 - ignore the visual metaphor rule 4 - only order matters -- use length as the visual metaphor when area is what is being perceived rule 5 - graph data out of context rule 6 - change scales mid axis rule 7 - emphasize the trivial and ignore the important rule 8 - jiggle the baseline -- can always make the graph worse by starting from different bases rule 9 - austria first rule 10 - label a. illegibly, b. incompetently, c. incorrectly, and d. ambiguously rule 11 - more is murkier: a. more decimal places and b. more dimensions  rule 12 - if it has been done well in the past, think of another way to do it &;",1,4,-3,3
"21","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Key Notes: Network analysis can inform our understanding of student network formation in classrooms and the types of impacts these networks have on students. This set of theoretical and methodological approaches can help to answer questions about pedagogy, equity, learning, and educational policy and organization.     Network analysis entails two broad classes of hypotheses: those that seek to understand what influences the formation of relational ties in a given population (e.g., having the same major, having relational partners in common), and those that consider the influence that the structure of ties has on shaping outcomes, at either the individual level (e.g., grade point average [GPA] or socioeco- nomic status) or the population level (e.g., graduation rates or retention in science, technology, engineering, and mathe- matics [STEM] disciplines).     The importance of relationships and emergent structures formed by relationships makes SNA different from other re- search paradigms, which often focus solely on the attributes of actors.      Networks that consist of only one type of actor (e.g., students) are referred to as unipartite (or sometimes monopartite or one-mode). While not discussed in detail here, bipartite (or sometimes two-mode) networks are also possible, linking actors with the groups to which they belong.     Ties can also be binary or valued. Binary ties represent whether or not a relation exists, while valued ties include additional quantitative information about the relation. For example, a binary network of student study relations would indicate whether or not student A studied with student B, while a valued network would include the number of hours they studied together.     Degree centrality is often useful for examining the equity or inequity in the number of ties be- tween individuals and can be done by looking at the degree distribution, which shows the distribution of degrees over an entire network. Betweenness centrality focuses on whether actors serve as bridges in the shortest paths between two actors. Actors with high betweenness centrality have a high probability of existing as a link on the shortest path (geodesic) between any two actors in a network.     Closeness centrality focuses on how close one actor is to other actors on average, measured along geodesics. It is important to keep in mind that closeness centrality is poorly suited for discon- nected networks (networks in which many actors have zero ties or groups of actors have no connection to other groups). Eigenvector centrality places importance on being connected to other well-connected individual.    Our main interest in these analy- ses will be how study networks form in a classroom and the impacts these networks have on students.                      ",0,1,-1,4
"22","Why Students Should Own Their Educational Data","Key notes: ""What we need to know about you is your contextualized profile of your performance and what kind of support you’ll need to be able to model your learner profile across contexts.""   ""you’ve got to have a third party who is responsible for protecting learner data. Then the student could have, say, a decade of data about the way that they’re learning.""",2,0,2,2
"23","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Key notes: ""The EDM community brings together  an inter-disciplinary community of computer scientists,  learning scientists, psychometricians, and researchers from other traditions. "" ""“Educational Data Mining is an emerging discipline,  concerned  with developing methods for exploring  the  unique types of data that come from educational  settings, and  using those methods to better understand students, and the settings which they learn in.”   “... the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning  and the environments in which it occurs.”  ""EDM has a considerably greater focus  on  automated discovery, and LAK  has a considerably greater focus on  leveraging human judgment. "" ""EDM models are more often used as the basis of automated  adaptation, conducted by a computer system such as an intelligent tutoring system. By  contrast, LAK models are more often designed to  inform and empower instructors and learners."" ""A third difference, and an important one, is the   distinction between  holistic and reductionistic   frameworks. It is much  more  typical  in EDM research to see research which reduces phenomena  to components  and  an alyzing  individual components  and  relationships  between  them. The  “discovery  with  models” paradigm for EDM research discussed in is a clear example of this paradigm. By  contrast, L AK  researchers  typically  place a stronger emphasis on attempting to understand systems as wholes, in their full complexity.""",3,1,2,2
"24","Evaluating Machine Learning Models","Key Notes: Classification is about predicting class labels given input data. accuracy = # correct predictions/# total data points Accuracy is an example of what’s known  as  a  micro-average,  and  average  per-class  accuracy  is  a macro-average. Precision  answers  the  question,  “Out  of  the  items  that  the ranker/classifier  predicted  to  be  relevant,  how  many  are  truly  relevant?”  Whereas,  recall  answers  the  question,  “Out  of  all  the  items that  are  truly  relevant,  how  many  are  found  by  the  ranker/classifier?”",1,0,1,5
"25","Why Is Measuring Learning So Difficult?","Key Notes: Education is personal, hard to define, and hard to measure.  ",0,2,-2,1
"26","Saturday Morning Breakfast Cereal","Key Notes: Information gets diffuse and misconstrued  ",0,0,0,2
"27","Data wranglers: human interpreters to help close the feedback loop","Key notes: ""Learning  Design  can  provide an account of pedagogical  intent that can provide useful context  for  interpreting learning analytics, and earning   analytics can provide particularly useful insight to  underpin the  process of Learning Design. So, for instance, some Data Wranglers  were  able to  attend  or even facilitate Learning  Design workshops, to help the process of closing the feedback loop."" ""A  less  positive  theme was the unevenness of the  process  across Faculties. The reports were all produced to the same template, and  based on the same  data  sources, but the  analysis and recommendations varied, as  did  the  quality of the  conversation between the Data Wrangler and Faculty members. Other concerns  raised  included the  timing of the  reports and  which courses were included"" ""Perhaps  the  largest  issue  was  data  quality. One  serious  misinterpretation of VLE/LMS  activity  data arose  during  the  project,  and  the  quality  and  resolution  of  the  delivery data was  perceived as a serious  obstacle""",1,4,-3,1
"28","Zuckerberg is ploughing billions into 'personalised learning' – why?","Key Notes: Zuckerberg has a clear definition in mind, however. For him, personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”. Although the Chan Zuckerberg Initiative’s Personalized Learning Platform is not part of Facebook, the underlying principles are the same: human work is replaced by technology, algorithms provide users with content based on an analysis of their past behavior and demonstrated interests Too specialized of a focus- not well rounded Children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalized learning, and classrooms with little conversation between student and teacher.    ",5,0,5,2
"29","The R Markdown Cheat sheet","Key Notes: Good for embedded code and rendering Shows workflow process  ",1,0,1,1
"30","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Key Notes: ""The proliferation of interactive learning environments, learning management systems (LMS), intelligent tutoring systems, e-portfolio systems, and personal learning environments (PLE) in all sectors of education produces vast amounts of tracking data. But, although these e-learning environments store user data automatically, exploitation of the data for learning and teaching is still very limited. These educational datasets offer unused opportunities for the evaluation of learning theories, learner feedback and support, early warning systems, learning technology, and the development of future learning applications. This leads to the importance of Learning Analytics (LA) being increasingly recognised by governments, educators, funding agencies, research institutes, and software providers.""""   ""By soft issues we mean challenges that depend on assumptions being made about humans or the society in general, e.g., competences or ethics. They are opposed by the hard challenges of the fact-based world of data and algorithm""    ""Apart from support for reflective practice, LA can also be used for predicting and modelling learner activities (Siemens, 2011; Verbert et al., 2011). This can lead to earlier intervention (e.g., to prevent drop-out), or to adaptive services and curricula.""   ""With respect to pedagogic theories, we would like to argue that LA does neither support nor ignore specific pedagogic theories, and as an abstract concept is pedagogically neutral. Indeed, we are of the opinion that LA can be used to evaluate different pedagogic strategies and their effects on learning and teaching through the analysis of learner data.""   ""LA strongly relies on data about learners and one of the major challenges LA researchers are facing is the availability of publicly available datasets to evaluate their LA methods. Most of the data produced in institutions is protected, and the protection of student data and created learning artefacts is a high priority for IT services departments.""   ""Like in related research domains, LA datasets create a new set of challenges for research and practice. These include:       <U+0010FC00>  A lack of common dataset formats like the suggested one from the CEN/ISSS PT social data group (cf. CAM Schema at: https://sites.google.com/site/camschema/home; and Wolpers et al., 2007).    <U+0010FC00>  The need for version control and a common reference system to distinguish and point to different datasets.    <U+0010FC00>  Methods to anonymise and pre-process data according to privacy and legal protection rights (Drachsler et al., 2010).    <U+0010FC00>  A standardised documentation of datasets so that others can make proper use of it like that promoted by the data-seal-of-approval initiative (cf. http://www.datasealofapproval.org).    <U+0010FC00>  Data policies (licences) that regulate how users can use and share certain datasets. For instance, the Creative  Commons licensing rights could be considered as a standard way to grant permissions to datasets. DataCite (Brase, 2009) is an organization that enables to register research datasets and to assign licensing rights to them, so that the datasets can be referenced similar to academic articles. From a technical point of view, idealised datasets probably remain the biggest challenge for analytics. This is to say that the assumption that datasets consist of context-free, meaningful and only meaningful data, is highly optimistic. In most natural settings, users “pollute” databases by producing erroneous or incomplete datasets.""   ""Similarly, data collection often leads to “enmeshed identities” being used for analytics and prediction. A dataset cannot typically distinguish between a single individual and a shared presence in the learning space (group work on a single device). Students who often work together with others on shared devices (laptops, smartphone, lab space, etc.) produce enmeshed fingerprints in their educational data.""   ""Additionally, from a pedagogic perspective, it remains an on-going challenge to formulate indicators from the available datasets that bear relevance for the evaluation of the learning process. The selection of specific data and their weighting (under the methods applied in the “instruments” dimension) against the real behaviour of students is of greatest importance, as is the process of relating behaviour pattern data to cognitive developments.""   ""Further research on LA can contribute to decrease the drop-out rate by developing e.g., a Drop-out Analyser that notifies the teacher of a course in time which students are in danger of falling behind or dropping out. This could be done by using LMS datasets and train a certain information retrieval technology (e.g., a Bayesian classifier) on the datasets to learn behavioural patterns of students that dropped out.""   ""Many different kinds of constraints can limit the beneficial application of LA processes, some being “softer” than others. It has been suggested to us to identify them as ethical, legal, and social constraints, but also to feature organisational, managerial, and process constraints. This we find a useful subdivision of external limitations, but other divisions look equally logical. In the abstraction of the diagram above (cf. Figure 1), we propose the preliminary distinction of conventions, under which we count ethics, personal privacy, and similar socially motivated limitations, and, norms that are restricted by laws or specific mandated policies or standards.""   ""On institutional level, educational and student data was traditionally handled separately, and is legally something of a blind spot. Registration data was kept and maintained by registry staff, IT data by IT staff, and learning data by academic staff. To use LA to its full potential, integration of available institutional datasets needs to happen.""   ""Another ethical consideration is the acceptance of divergence in the data constituency (AoIR, 2002). We already touched upon the danger that the result of algorithmic analysis, consequent policies and exercised pressures may aim at uniformity and at mainstreaming learning and teaching processes, thereby greatly harming creative processes and innovation that diverge from the statistical mean.""   ""In order to make LA an effective tool for educational practice, it is important to recognise that LA ends with the presentation of algorithmically attained results that require interpretation (Reffay &amp; Chanier, 2003; Mazza &amp; Milani, 2005). There are innumerable ways to present and to interpret data and base consecutive decisions and actions on it, but only some of them will lead to benefits and to improved learning"" ""LA has been effectively used for behaviourist-instructivist style approaches (but see the critical reflection by Pardo &amp; Kloos, 2011), but there is as yet little evidence for the support of constructivist approaches to learning (Duffy &amp; Cunningham, 2001), where learning is seen as an active cognitive process in which learners construct their own concepts of the world around them. In LA, the latter is mostly inferred indirectly, by relating grades of learning outcomes with activities during the learning process (Dawson, 2012). In these correlations, it emerges that active students get better results.""   ""In our model, LA can work in support of a multitude of pedagogic strategies and learning activities as manifested and represented by the available data. This means we can only see pedagogies through the data. Because of this, we do not include them as part of the analytics process (Figure 1) but as implicitly contained in the input datasets that encapsulate the pedagogic behaviour of users.""   ""Additionally, pedagogy can be explicitly addressed in the goals and objectives that the LA designer sets (“objectives” dimension). The LA method (“instruments” dimension) will determine the outcome of the analysis and together with the interpretation applied may lead to a large variety of options for consequences and interventions""    ""It is therefore our conviction that only the consideration of all six dimensions in the design process can lead to optimal exploitation of LA. Additionally, substantial work on new ethical guidance, data curation, and ownership needs to happen at universities and in legislation to reduce the risks connected to the application of LA and to protect the data subject, usually the learner.""   ""In its most optimistic outlook, learners will be provided with personal information about their current needs, while, at the same time, the educational system will be evolved from a “one- size-fits-all” approach into a highly personal competence-driven educational experience. But this view is not without flaws, because of the real dangers that the extended and organised collection of learner data may not so much bring added benefits to the individual, but instead provides a tool for HEIs, companies, or governments to increase manipulative control over students, employees, and citizens, thereby abusing LA as a means to reinforce segregation, peer pressure, and conformism rather than to help construct a needs-driven learning society. We therefore believe that it will be of critical importance for its acceptance that the development of LA takes a bottom-up approach focused on the interests of the learners as the main driving force.""   ",38,20,18,1
"31","Chapter 4: Handbook of Learning Analytics","Key Notes: ""Tools can be used in many ways, and should not"" ""Learning analytics, as a new form of assessment instrument, have potential to support current educational practices, or to challenge them and reshape education; considering their theoretic positioning is important in understanding the kind of education"" ""This question regards the desire for analytic insights at multiple levels of a system, and the ability of indi- vidual analytic approaches (including their outputs in various forms, such as dashboards) to support the following: 1) individual students in developing their learning; 2) educators in developing their own practice and in targeting their support at individual student needs; and 3) administrators in understanding""  ""First, analytics that require particular forms of technology or participation may create new divides between student cohorts, or - entrench existing divides. Second, there is an ethical concern regarding the use of student data by not given, where no direct learning gain is directed to those students.""",6,1,5,2
"32","Chapter 1 Handbook of Learning Analytics","Key Notes:  ""by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices"" "" That is the question of epistemology: it concerns the nature of the constructs, why they kind required for a claim of knowledge to be made"" ""This question regards the desire for analytic insights at multiple levels of a system, and the ability of individual analytic approaches (including their outputs in various forms, such as dashboards) to support the following: 1) individual students in developing their learning; 2) educators in developing their own practice and in targeting their support at individual student needs; and 3) administrators in understanding""",3,1,2,2
"33","How to Display Data Badly","Key Notes: Good displays of data show data, show data accurately, and show data clearly.   Bad data displays: 1) show as few data as possible 2) Hide what data you do show 3) Ignore visual metaphor 4) Only order matters 5) Graph data out of context 6) Change scales in mid-axis 7) Emphasize trivial and ignore the important 8) Jiggle the baseline 9) Austra first (alphabetically ordering) 10) Label illegibly, incompletely, incorrectly, and ambiguously 11) More decimal places and more dimensions",3,3,0,3
"34","Statistical graphics: making information clear – and beautiful, Significance","Key Notes: Information visuals = infovis Avoid distracting elements. Use informative color to visually associate  elements. Keep the figure simple (and  therefore interpretable) Keep the  x - and  y -axes on the same scale.  Eliminate repetitive information. Maintain consistency across plots.",0,1,-1,2
"35","Chapter 12: Handbook of Learning Analytics","Key Notes:          Data mining plays to the strengths of computers to do the number crunching, while visualization techniques play to the remarkable perceptual abilities that humans possess.   A very useful goal in information visualization is to rely on human perceptual abilities for pattern discovery (trends, gaps, outliers, clusters). These patterns often become more apparent visually than numerically.      Adding  dynamic interaction techniques to the visualization. therefore, is often necessary to design meaningful visualization tools that encourage exploratory data analysis.        Artefacts produced by learners, including blog posts, shared documents, software, and other artefacts that would often end up in a student project portfolio.    Social interaction, including speech in face-to-face group work, blog comments, Twitter or discussion forum interactions.    Resource use can include consultation of documents (manuals, web pages, slides), views of videos, ecetera. Techniques like software trackers and eye-tracking can provide detailed information  used and how.   Time spent can be useful for teachers to identify students at risk and for students to compare their own efforts with those of their peers.   Test and self-assessment results can provide an indication of learning progress.          In both cases, we deliberately only list questions that start with what, when, how much, and how often which can be directly mapped in a data set.                 ",3,1,2,2
"36","Junk Charts Trifecta Checkup: The Definitive Guide - Junk Charts","Key Notes: The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?   ",0,0,0,2
"37","Infovis and Statistical Graphics:  Different Goals, Different Looks","Key Notes: Try not to  cram into a single graph what can be better displayed in two or more. With presentation graphics you prepare some small number of graphs, which may be viewed by  thousands, and with exploratory graphics you prepare thousands of graphs, which are viewed by  one person, yourself.  Exploratory graphics is  all about speed and flexibility and alternative  views.  Presentation graphics is all about care and specifics and a single view.  Presentation  graphics can really benefit from a graphic designer's contribution; for exploratory graphics it's  not so relevant. 1. Graphics are for the qualitative/descriptive — conceivably the semiquantitative — never  for the carefully quantitative (tables do that better). 2. Graphics are for comparison — comparison of one kind or another — not for access to  individual amounts. 3. Graphics are for impact — interocular impact if possible, swinging - finger impact if that  is the best one can do, or impact for the unexpected as a minimum — but almost never for  something that has to be worked at hard to be perceived. 4. Finally, graphics should report the results of careful data analysis — rather than be an  attempt to replace it.  (Exploration — to guide data analysis — can make essential interim  use of graphics, but unless we are describing the exploration process rather than its  results, the final graphic should build on t he data analysis rather than the reverse.) (1) Statistical data visualization, which is focused not on visual appeal but on facilitating an  understanding of  patterns in an  applied problem (recall the Discovery goals listed above), both in directing  reader s to specific information and allowing the reader s to see for themselves. (2) Infographics, which ideally should be attractive, grab one’s attention, tell a story and  encourage the viewer to think about a particular dataset, both as individual measurements and as  a representation of larger patterns ( as in our Communication goals). Eye - catching data graphics tend to use designs that are unique (or nearly so) without being  strongly focused on the data being displayed. Recognizability is  important: every novel graph requires more work and without experience we may miss some of  the secondary features. On the other hand novelty attracts attention.",12,3,9,2
"38","Introduction to Social Network Methods:  Chapter 1: Social Network Data","Key Notes: ""Network"" data (in their purest form) consist of a square array of measurements. The rows of the array are the cases, or subjects, or observations. The columns of the array are -- and note the key difference from conventional data -- the same set of cases, subjects, or observations. In each cell of the array describes a relationship between the actors This is the first major emphasis of network analysis: seeing how actors are located or ""embedded"" in the overall network. This is the second major emphasis of network analysis: seeing how the whole pattern of individual choices gives rise to more holistic patterns. The major difference between conventional and network data is that conventional data focuses on actors and attributes; network data focus on actors and relations. nodes (or actors) and edges (or relations) Because network methods focus on relations among actors, actors cannot be sampled independently to be included as observations. If one actor happens to be selected, then we must also include all other actors to whom our ego has (or could have) ties. As a result, network approaches tend to study whole populations by means of census, rather than by sample  Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal."" In our school example, individual students and teachers form one mode, classrooms a second, schools a third, and so on. A data set that contains information about two types of social entities (say persons and organizations) is a two mode network. Full network methods require that we collect information about each actor's ties with all other actors. In essence, this approach is taking a census of ties in a population of actors -- rather than a sample. Snowball methods begin with a focal actor or set of actors. Each of these actors is asked to name some or all of their ties to other actors. Then, all the actors named (who were not part of the original list) are tracked down and asked for some or all of their ties. The process continues until no new actors are identified, or until we decide to stop (usually for reasons of time and resources, or because the new actors being named are very marginal to the group we are trying to study). If we do not know what relations to examine, how might we decide? There are a number of conceptual approaches that might be of assistance. Systems theory, for example, suggests two domains: material and informational. Material things are ""conserved"" in the sense that they can only be located at one node of the network at a time. Movements of people between organizations, money between people, automobiles between cities, and the like are all examples of material things which move between nodes -- and hence establish a network of material relations. Informational things, to the systems theorist, are ""non-conserved"" in the sense that they can be in more than one place at the same time. If I know something and share it with you, we both now know it. In a sense, the commonality that is shared by the exchange of information may also be said to establish a tie between two nodes. One needs to be cautious here, however, not to confuse the simple possession of a common attribute (e.g. gender) with the presence of a tie (e.g. the exchange of views between two persons on issues of gender). Binary measures of relations: By far the most common approach to scaling (assigning numbers to) relations is to simply distinguish between relations being absent (coded zero), and ties being present (coded one). If we ask respondents in a survey to tell us ""which other people on this list do you like?"" we are doing binary measurement. Each person from the list that is selected is coded one. Those who are not selected are coded zero. Multiple-category nominal measures of relations: In collecting data we might ask our respondents to look at a list of other people and tell us: ""for each person on this list, select the category that describes your relationship with them the best: friend, lover, business relationship, kin, or no relationship."" We might score each person on the list as having a relationship of type ""1"" type ""2"" etc. This kind of a scale is nominal or qualitative -- each person's relationship to the subject is coded by its type, rather than its strength. Unlike the binary nominal (true-false) data, the multiple category nominal measure is multiple choice. Grouped ordinal measures of relations: One of the earliest traditions in the study of social networks asked respondents to rate each of a set of others as ""liked"" ""disliked"" or ""neutral."" The result is a grouped ordinal scale (i.e., there can be more than one ""liked"" person, and the categories reflect an underlying rank order of intensity). Usually, this kind of three point scale was coded -1, 0, and +1 to reflect negative liking, indifference, and positive liking. When scored this way, the pluses and minuses make it fairly easy to write algorithms that will count and describe various network properties (e.g. the structural balance of the graph).  ",9,2,7,4
"39","assignment-3-brumuly created by GitHub Classroom","Key Notes: Indeed, while  administrators have indicated that they privilege standardized test scores over other forms of data (Guskey,  2007),  little  criterion  validity  has  been  shown   for test scores as they relate  to overall student school or  life  outcomes  (Rumberger  &amp;  Palardy,  2005),  whereas   teacher-assigned grades have a  long history of predicting  overall   student   outcomes, such as graduating or  dropping out (Bowers, 2010).  The  goal  should  be  to  interrupt  a   decline  in  achievement  early,  before  it  results  in  future   course failure, especially if an early but small decline is  predictive of major future challenges with school years  later   HCA  also  provides a means  to  draw  what  is   known  as  a  cluster tree, or a dendrogram  (“dendro”  from the Greek meaning “root s or tree”). Thus,  the  central  aim  of  this  study  is  to  adapt   hierarchical  cluster  analysis  and  heatmaps  for  use  with   teacher assigned grades for data driven decision-making.  The  method  will  be  tested  and  demonstrated  with  a   small sample of data, and the study will explore what the  analysis and visualization method can and cannot do for  3DM in schools. The research question of interest here  is  that  as  just  one  example  of  the  usefulness  of  the   method  for  3DM,  to  what  extent  do  student  grades   cluster  through  HCA  into  patterns  that  identify  which   students are most at risk of dropping out of school. Supervised  clustering  begins  with  a  defined  set  of  assumptions about the categorization of the data, while  unsupervised   clustering   assumes   nothing   about   the    categorization and is designed to statistically discover the  underlying    structure    patterns within  the dataset (Kohonen, 1997), a procedure well suited to discovering  the underlying patterns within  student data in education. For  cluster  analysis  in   fields  such  as  the  natural  sciences,  it  has  become   standard to pattern analyze large sets of data and display  both a heatmap together with a dendrogram to visualize  the  patterns  within  the  data   and  determine  if  specific   patterns  align  with  overall  participant  outcomes student   grade   patterns   are   somewhat  unstable  prior  to  grade  four.  However,  the  period between grade 4 and grade 8 seem s to be critical in terms  of   grade patterns when examining overall student  performance, such as dropout. Much  like  a  medical  x-ray,  the  clustergram   provides  a  unique  way  to  “look  inside”  each  student’s   entire history of achievemen t, and examine that history  in context with other students who have performed in a  similar manner through pattern analysis. The interpretation  of  these  data  patterns  for  3DM  is  then   aided  through  this  type  of  pattern  analysis,  and  helps   point    to    possible areas and timing for future interventions. ",2,5,-3,3
"40","Cluster","Key Notes: The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. The algorithm computes these assignments iteratively, until reassigning points and recomputing averages (over all points in a cluster) produces no changes. K is number of cluster points that are defined by you. We need to know k to find clusters and we need to identify clusters to determine k. Hartigan gives an approximate F statistic that can be used to test the ""significance"" of this reduction, but a simple method that works well for most datasets is to look for a proportional reduction in error (PRE) of about .4 or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares. You should expect to see only one color for Uniform or Normal data (except occasionally for the smaller samples, where it is possible to get a blobby pattern by chance). And you should expect to see different colored clusters wherever they appear separated in the Lumpy display. In some cases you will see the straight cutting planes (lines) between clusters when overlapping blobs of points are cut apart. The applet also illustrates that k-means is most suited for separating convex clusters (clusters in which any line passing through a cluster intersects its boundary only twice). If your data contain doughnut-shaped or wormy-shaped clusters, don't expect k-means to find them.  ",3,2,1,1
"41","Big Data in Education 7.1 Clustering","Key Notes: Want large data set for clustering",0,0,0,1
"42","Analyzing the Longitudinal K-12 Gradin g Histories of Entire Cohorts of  Students: Grades, Data Driven Decision Making, Dropping Out and  Hierarchical Cluster Analysis","Key Notes: Indeed, while  administrators have indicated that they privilege standardized test scores over other forms of data (Guskey,  2007),  little  criterion  validity  has  been  shown   for test scores as they relate  to overall student school or  life  outcomes  (Rumberger  &amp;  Palardy,  2005),  whereas   teacher-assigned grades have a  long history of predicting  overall   student   outcomes, such as graduating or  dropping out (Bowers, 2010).  The  goal  should  be  to  interrupt  a   decline  in  achievement  early,  before  it  results  in  future   course failure, especially if an early but small decline is  predictive of major future challenges with school years  later   HCA  also  provides a means  to  draw  what  is   known  as  a  cluster tree, or a dendrogram  (“dendro”  from the Greek meaning “root s or tree”). Thus,  the  central  aim  of  this  study  is  to  adapt   hierarchical  cluster  analysis  and  heatmaps  for  use  with   teacher assigned grades for data driven decision-making.  The  method  will  be  tested  and  demonstrated  with  a   small sample of data, and the study will explore what the  analysis and visualization method can and cannot do for  3DM in schools. The research question of interest here  is  that  as  just  one  example  of  the  usefulness  of  the   method  for  3DM,  to  what  extent  do  student  grades   cluster  through  HCA  into  patterns  that  identify  which   students are most at risk of dropping out of school. Supervised  clustering  begins  with  a  defined  set  of  assumptions about the categorization of the data, while  unsupervised   clustering   assumes   nothing   about   the    categorization and is designed to statistically discover the  underlying    structure    patterns within  the dataset (Kohonen, 1997), a procedure well suited to discovering  the underlying patterns within  student data in education. For  cluster  analysis  in   fields  such  as  the  natural  sciences,  it  has  become   standard to pattern analyze large sets of data and display  both a heatmap together with a dendrogram to visualize  the  patterns  within  the  data   and  determine  if  specific   patterns  align  with  overall  participant  outcomes student   grade   patterns   are   somewhat  unstable  prior  to  grade  four.  However,  the  period between grade 4 and grade 8 seem s to be critical in terms  of   grade patterns when examining overall student  performance, such as dropout. Much  like  a  medical  x-ray,  the  clustergram   provides  a  unique  way  to  “look  inside”  each  student’s   entire history of achievemen t, and examine that history  in context with other students who have performed in a  similar manner through pattern analysis. The interpretation  of  these  data  patterns  for  3DM  is  then   aided  through  this  type  of  pattern  analysis,  and  helps   point    to    possible areas and timing for future interventions. ",2,5,-3,3
"43","Big Data in Education 7.1 Clustering","Key Notes: Want large data set for clustering Move centroids around after picking them until they stop moving around aka convergence",0,0,0,1
"44","Big Data in Education 7.2 Validation and Selection","Key Notes: Distortion = mean squared deviation More clusters = smaller distortion",0,2,-2,1
"45","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Key Notes: Goal is to create a high-quality MOOC on recommender systems Programs vs concepts: can two tracks work? Why researching MOOC's is hard: diverse student pop, lack of information on students’ background,  aptitude, and knowledge prior to the course, non-random attrition Long format actually does work (14 weeks,  longer lectures) and many students preferred it Face-to-face students overwhelmingly preferred  the MOOC approach Better time management Better able to pace learning; rewind; language issues The two-track approach worked!  Possible to  learn the concepts well alongside programmers",9,3,6,4
"46","Feature Selection - Georgia Tech - Machine Learning","Key Notes: As you add more features- the amount of data needed grows exponentially Knowledge discovery -interpretability and insight",0,0,0,1
"47","Machine beats experts: Automatic discovery of skill models for data-driven online course refinement","Key Notes: Large-scale  online  courses  (e.g.,  MOOCs)  often  contain  a  broad   range of contents frequently intended to be a semester’s worth of  materials;  this  breadth  often  makes  it  difficult  to  articulate  an   accurate set of skills and knowledge (i.e., a skill model, or the Q- Matrix).    EPIPANY - combination of the matrix factorization to analyze students’ response data and bag-of- words techniques to analyze course content data. mapping   between   a   single   skill   and   multiple    assessment items in the skill map is called a  skill-item association Our  study  showed  that  using  student  response  data  (i.e.,  the   number  of  attempts  made  on  assessment  items  before  a  student   finally  made  their  first  correct  response)  always  yields  a  better   skill model than using the bag-of-words with item stems. We also  found  that   even only using the bag-of-words, eEPIPHANY always  yields  a  better  skill  model  than  the  default  skill  model  that  is   hand-crafted by human experts .     Even   though    eEPIPHANY  requires  human  labor  to  interpret  the  discovered   skill  models  (with  the  aid  of  DoE),  it  is  arguably  still  less  time   consuming  than  creating  skill  models  by  hand. ",13,1,12,5
"48","Big Data in Education 7.6 Knowledge Inference: Q-Matrix Knowledge Structure","Key Notes: Every item in Q matrix must involve a skill The algorithm on the Q matrix will be run a certain number of times with a different (random) initial assignment of skills  ",2,0,2,1
"49","Chapter 5: Handbook of Learning Analytics","Key Notes:     Predictive analytics are a group of techniques used to make inferences about uncertain future events. In the educational domain, one may be interested in predicting a measurement of learning (e.g., student academic success or skill acquisition), teaching (e.g.,  of value for administrations (e.g., predictions of re-       Explanatory modeling is a post-hoc and reflective activity aimed at generating an understanding of a phenomenon.       Predictive modeling is an in situ activity intended to make systems responsive to changes in the underlying data.     In statistical modelling, there are generally four types of data considered: categorical, ordinal, interval, and ratio.          Applying a learning algorithm that naively assumes independence of the attributes can result in predictions with an over-emphasis on the repeated or correlated features.      By determining an informative subset of the features,  predictive model, reduce data storage and collection requirements, and aid in simplifying predictive models      After collecting a dataset and performing attribute selection, a predictive model can be built from historical data. In the most general terms, the purpose of a predictive model is to make a prediction of some unknown quantity or attribute, given some related  several such methods for building predictive models. A fundamental assumption of predictive modelling is that the relationship that exists in the data gathered in the past will exist in the future.                          ",2,3,-1,3
"50","Chapter 6: Handbook of Learning Analytics","Key Notes:             The field could benefit from more focus on developing explanatory models Explanatory models seek to identify interpretable constructs that are causally related to outcomes and thus provide an explanation of the data that can be connected to existing theory      LFA searches across hypothesized  knowledge components drawn from existing KC models, evaluates different models based on their  fit to data, and outputs the best-fitting KC model in the form of a symbolic model. As such, LFA greatly reduces demands on human effort while simultaneously easing the burden of interpretation, even if it does not automatically accomplish it.                   ",3,1,2,5
"51","Big Data in Education 2.2 Diagnostic Metrics Part 1","Key Notes: Accuracy also called agreement when measuring inter-rater reliability Accuracy not a good unit of measurement Kapp .3-.5 ideal value",2,0,2,1
"52","Big Data in Education 2.3  Diagnostic Metrics Part 2","Key Notes: ROC Curves predict two values Prediction model puts out real value",0,0,0,5
"53","Big Data in Education 2.4 Diagnostic Metrics: Correlation - YouTube","Key Notes: Linear corelation = pearson correlation (-1 to 1); high = good r2 = correlation squared",1,0,1,3
"54","Big Data in Education 2.5 Cross-Validation and Over-Fitting","Key Notes: Over fit - not good for future data Cannot eliminate over fit  ",1,0,1,2
"55","Cross Validation","Key Notes: goal is to generalize data is expected to be Independently Identically Distributed  ",0,0,0,2
"56","Knowledge Tracing: Modeling  the  Acquisition  of  Procedural  Knowledge","Key Notes: This  model  allows  the  tutor  to  solve  exercises  along  with  the  student  and  provide  assistance  as  necessary.  As  the  student  works,  the  tutor  also  maintains  an  estimate  of  the  probability  that  the  student  has  learned  each  of  the  rules  in  the  ideal  model,  in  a  process  called  knowledge  tracing. Virtually  all  students  can  achieve  expertise  in  a  domain  if  two  conditions  are  met:  (1)  the  domain  knowledge  is  appropriately  analyzed  into  a  hierarchy  of  component  skills  and  (2)  learning  experiences  are  structured  to  ensure  that  students  master  prerequisite  skills  before  tackling  higher  level  skills  in  the  hierarchy. One  of  the  primary  goals  in  our  tutoring  research  has  been  to  evaluate  the  ACT-R  assumption  that  procedural  knowledge  maps  onto  independent  production  rules.  Three  types  of  results  provide  support  for  this  assumption:  1.  A  production  rule  model  provides  a  regular  analysis  of  learning  trends. 2.  Production  rule  analyses  have  proven  successful  in  predicting  transfer  among  programming  languages  and  across  text  editors 3.  A  variety  of  results  support  the  assumption  that  procedural  knowledge  is  goal-specific. In  model  tracing  the  cognitive  model  is  used  to  interpret  each  student  action  and  follow  the  student's  step-by-step  path  through  the  problem  space.  The  primary  goal  in  this  process  is  to  provide  whatever  guidance  is  needed  for  the  student  to  reach  a  successful  conclusion  to  problem  solving.  By  contrast,  in  knowledge  tracing  we  attempt  to  monitor  the  student's  changing  knowledge  state  during  practice.  ",11,2,9,3
"57","Big Data in Education 1.1 Introduction","Key Notes: In prediction - develop a model which can infer a single aspect of the data from some combination of others aspects of the data PSLC DataShop - world's leading public repository for Ed software interaction data",1,0,1,2
"58","data-wrangling-cheatsheet.pdf","Key Notes: Helpful quick tool for tidy data with dplyr",0,0,0,1
"59","rmarkdown-cheatsheet-2.0.pdf","Key Notes: Handy tool for understanding R Markdown Sheets and chunk options",0,0,0,1
"60","Measurement and its Uses in Learning Analytics","Measurement  defining the construct  construct - latent variable   specifying a measurement model and developing a reliable instrument  measurement model: formal mathematical relationship between a latent variables or set of variables and an observable variable or set of variable  distribution for latent variable distribution for the observed variable functional relationship between them   instruments: measurement scale eg. tests/questionnaires  efficiency and standardization   reliability: measurement of the consistency of the score alpha(0,1) OR test-retest reliability: correlation/ inter-rater reliability: kappa   analyzing and accounting for various sources of error  measurement error: any variance in the data not attributed to the construct   framing a valid argument for particular uses of the outcome  validity: degree to which evidence and theory support the interpretations of test scores for proposed used of tests    Latent variable Models  factor model: L-con, O-con  correlations exploratory factor analysis:  determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development; requires decision confirmatory factor analysis: complementary set of techniques to test a theoretically proposed factor model byexamining residuals between expected and observed correlation   item response model: L-con, O-cate  modelling individual person-item interactions   latent mixture model: L-cate, O-con latent class models: L-cate, O-cate ",2,2,0,5
"61","Ethics and Learning Analytics: Charting the (Un)Charted","Ethical issues:  the location and interpretation of data informed consent, privacy, and the de-identification of data the management, classification, and storage of data  Six principles ( Slade and Prinsloo, 2013)  learning analytics as moral practice-effective+appropriate,morally necessary students as agents-engaged as collaborators student identity and performance as temporal dynamic constructs student success as a complex, multidimensional phenomenon transparency as important higher education cannot afford not to use data  practical considerations  development of a thorough understanding of who benefits establishment of institutional positions on consent, de-identification and opting out issues around vulnerability and harm systems of redress data collection, analyses, access, and storage governance and resource allocation  six elements-basis for a student-centred learning analytics  aggregated, non-personalized data full knowledge of which data is collected and how it is used personal data records are complete and up to date surveillance of activities and harvesting of data must not harm student progress output should be subject to human review algorithms should eb frequently reviewed and validated  8 principles (OU, 2014)  ethical practice responsibility to all stakeholders to use and extract meaning from data students should not be wholly defined by the data purpose and boundaries should be will defined university is transparent regarding data collection engaged as active agents modelling and interventions should be sound and free from bias adoption requires broad acceptance of the value and benefit  4 principles (Engelfriest et al., 2015)  info only used in the context and purpose subsequent use of data should be reconcilable with the original context carefully collected and analyzed only collected when the purpose is explicitly clear  future consideration  potential conflicts between students' concern their right to opt-out balancing optimism around AI, machine learning, and big data critical approach to consider the ethical implications of learning analytics ",9,8,1,2
"62","Predictive Modelling in Teaching and Learning","process, practice, challenges of using predictive modelling in teaching and learning EDM &amp; LA - predict student success -&gt; academic achievement steps must consider + most popular techniques in the field predictive modelling workflow  problem identification data collection classification &amp; regression feature selection methods for building predictive models  linear regression logistic regression nearest neighbors classifiers decision trees naive bayes classifiers bayesian networks support vector machines neural networks ensemble methods   evaluating a model practice  identify students at risk detect learners who are engaging in off-task behavior   challenges and opportunities  support non-computer scientists in predictive modelling activities creating community-led educational data science challenge initiatives engaging in second order predictive modelling   ",4,5,-1,3
"63","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Predictive VS explanatory model  predictive models aim to find a combination of features that best predict outcomes - accuracy  that it fits well   explanatory model seek to identify interpretable causal relationships between constructs that can be either observed/inferred from the data  why it fits well   educational data mining research  statistical model  outer loop of intelligent tutoring system - based on performance   cognitive model  representations of the knowledge space (facts, concepts, skills..) underlying a particular educational domain basis-&gt;better prediction discover &amp; refine cognitive model -&gt; alleviate expert bias+reduce load on human input  difficulty factors assessment(DFA)  to identify and validate cognitive model improvements   Learning Factors Analysis  further alleviate demands on human time   SimStudent - state-of-theart machine-learning agent   discover cognitive models automatically without requiring existing ones     modelling student-specific variability -&gt; better predictive accuracies + inform instruction  grouping students   importance of interpretability and actionability educational data mining effort  clean maps well fewer estimated parameters (independent variables/features)       ",6,0,6,5
"64","Statistical graphics: making information clear – and beautiful","two decision  who is your target audience what are you trying to show  guiding principles  avoid distracting elements use informative color to visually associate element keep the figure simple ",0,1,-1,2
"65","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Graphical displays  statistical side: find effective and precise ways of representing data infovis: grab the readers' attention and tell them a story  Goal  discovery goals communication goals  5 best data visualization project  Wordle decision tree radiohead music video box office streamgraphs I want you to want me video  stats problem  plane crashes florence nightingale's coxcomb health spending and life expectancy how to win in afganistan   ",2,2,0,2
"66","Junkcharts Trifecta Checkup: The Definitive Guide","Junk charts trifecta checkup - general framework for data visualization crticism  what is the QUESTION what does the DATA say what does the VISUAL say  eight types of critiques  trifecta the singles: type Q, D, V doubles: QD, QV, DV triple:QDV ",0,1,-1,2
"67","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","3DM - Data driven decision making  powerful means flooded with data one purpose: help drive decisions on improving specific school, teacher and student outcomes  Teacher-Assigned Gardes  long history of predicting overall student outcomes(graduating/dropping out) 25%-assess academic knowledge+75% assess student ability to negotiate the social processes of school overall student outcomes  Purpose: combine 3DM and teacher-assigned grades by hierarchical cluster analysis(HCA) + heatmaps  dropout by grades  overly concentrated on course failures in core courses - all subjects capture the pattern require using of multiple variables in addition to grades, attendance, unsatisfactory behavior - score alone is useful overly focused on single grade level - over time overly relied on achievement in core courses - all courses    Hierarchical Cluster Analysis: descriptive statistical analysis that brings empirical defined organization to a set of previously unorganized data  supervised  begin with a defined set of assumptions about categorization of the data   unsupervised  assume nothing about the categorization&amp;designed to statistically discover the underlying structure patterns within the dataset    HCA  each case is first defined as an individual cluster, a series of numbers for each variable on that case all data standardized into z-score distance measure -&gt; similarity/dissimilarity matrix e.g. uncentered correlation iterated clustering algorithm at each level: 2 most similar cases join first reorder the cases into clusters visualization: cluster tree/dendrogram  Heatmap: convert the table into blocks of color missing data  not all students take all of the same subjects many students drop out of the school before the end of grade 12|transfer into/out to this district   ",0,2,-2,3
"68","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social network Analysis (SNA)  social network basics  group of actors and their connections between makes a network   network types  unipartite bipartite undirected vs directed binary/valued   network data collection  Egocentric  focus on a sample of individuals   census/whole  collect data from an entire bounded population of actors     network level concepts and measures  density: how many ties are present   actor-level variables  centrality: degree, closeness, betweenness, eigenvector centrality   ",0,0,0,4
"69","Why Students Should Own Their Educational Data"," technology - give educators data on students and ability to customize teaching materials -&gt; nurture every single individual average learner: groups vs individuals; average not most personal pattern, contextualized profile of the performance and need user should own their data   ",0,0,0,2
"70","Knowledge tracing: Modeling the acquisition of procedural knowledge","model - changing knowledge state during skill acquisition achieve expertise  the domain knowledge is appropriately analyzed into a hierarchy of component skills learning experiences are structured to ensure that students master prerequisite skills before tackling higher level skills in the hierarchy  cognitive model of skill acquisition -&gt; mastery learning  monitor students' changing knowledge state as they practice a complex cognitive skill individualize the practice sequence to enable students to master the skill efficiently accurately predict students' performance  intelligent tutoring environment ACT programming tutor(APT) - a practice environment/a production rule cognitive model of programming knowledge  ideal student model  complete, executable model of procedural knowledge in the domain   knowledge tracing  tutor solve exercises along with student provide assistance as necessary estimate of the probability of learning    curriculum underlying cognitive model  ACT-R theory of skill knowledge  learning&amp;performance assumption  assume a fundamental distinction between declarative knowledge(factual/experiential) &amp; procedural knowledge(goal-oriented and mediates problems-solving behavior)  Evaluation  abandon an initial ideal student model and to model a sufficient set of rules to model differences in rule difficulty model individual differences among students in learning and performance     ",12,1,11,3
"71","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","LAK VS EDM similarity  define reflect the emergence of data-intensive approaches to educ prominent for gaining insight into organizational activities goal of improving education by improving assessment, how problem in educ are understood, how interventions are planned and select goal of improving quality og analysis of large-scale educational data to support both basic research and practice in education  distinction  discovery  automated discovery vs leveraging human judgement   reduction and holism  individual vs whole   origins adaption and personalization  basis of automated adaption vs inform and empower instructor   technique and methods ",2,1,1,2
"72","Evaluating Machine Learning Models","confusion matrix  true positive false positive-type I true negative false negative-typeII accuracy = (true positive+true negative)/ (true positive+false positive+true negative+false negative) ",0,2,-2,5
"73","Why Opting Out of Student Data Collection Isn’t the Solution","? right to opt-out ? when and how  Fair Information Privacy Principles - basis of most privacy laws  specify the purpose informed consent additional permissions for unrelated use   Help?  primary use -&gt; operate cafeterias, school buses, data storage systems, etc.  record grades subsidized lunch special learning needs   assess performance through data analysis  opt-out -&gt; affect accuracy   secondary use of data  parents marketing/survey - informed     opt-out isn't the solution  not an opportunity to avoid resolution of education policy issues that affect all students   ",2,0,2,2
"74","Why Is Measuring Learning So Difficult?","Difficult in measuring learning  simplify - capture broad, contextual personal thing, motivation measure: reliable, symbol, proxy - imagination, understanding  teaching   cultural, social implication competent psychological construct or achievement connection ",1,1,0,1
"75","Saturday Morning Breakfast Cereal","'WHY A KINDERGARTENER NEEDS 6 HOURS A DAY OF CLOCK HOMEWORK""",0,0,0,2
"76","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers  sense-making activity facilitate action on feedback from learners make better sense of what that feedback means &amp; how the data can be improved (double-loop learning) help to develop the Community of Practice around the use of LA  Data sources  survey from students activity data delivery data aggregated completion, pass rate, and demographic data  Evaluation  overall performance worsened slightly - substantial change in funding regime at the same time increase direct use of the data sources by faculty member feedback - generally positive desire for more data unevenness of the process across faculties data quality(largest issue) ",1,3,-2,1
"77","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning  philanthropic act/shrewd business strategy definition  modify learning materials and teaching styles to accommodate the different ways pupils learn work with students to customize instruction to meet the student's individual needs and interests   similar to Facebook  human work is replaced by technology, algorithms provide users with content based on an analysis of their past behavior and demonstrated interests   dangers  education includes acquire knowledge and skills relevant to a profession + general knowledge real world life will not always be so accommodating children's preferences are not fixed-change as immediate responses to the environment data misuse   help  ownership and relevance -&gt; motivation   compromise approach  adaptive study plans  adapts all topics to a learners' pace   customized study plans  course modifies according to the teacher's knowledge of what fits the students best     ",5,1,4,2
"78","Feature Selection","feature selection  knowledge discovery  interpretability insight e.g. spam   curse of dimensionality  2^N   ",0,0,0,5
"79","Chapter 1: Social Network Data","Major difference between conventional &amp; network data  conventional data: focuses on actors and attributes network data: actors and relations ( nodes and edges)  identify some population and conduct a census full network methods: collect info about each actor's ties with all other actors snowball methods: begin with a focal actor or set of actors, then asked to name some/all their ties to other actors. ego-centric networks  with alter connection ego only      scale of measurement  binary measures of relation ( absent vs present) multiple-catergory nominal measures of relations grouped ordinal measures of relations(negative, indifference, positive liking) full rank ordinal measures of relations(1st, 2nd, 3rd) interval measures of relations ",1,1,0,4
"80","RStudio Cheat Sheets","Data Wrangling (dplyr + tidyr) most used in this course:  spread unite count mutate bind_cols     ",0,0,0,1
"81","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","detector (ASSISRment system) -&gt; college attendance successful+potentially more actionable",0,0,0,3
"82","Translating Learning into Numbers: A Generic Framework for Learning Analytics","key dimensions of LA  stakeholder  data subjects - suppliers data clients - beneficiaries eg. institution, teachers, learners, etc   objective  reflection: self-evaluation prediction: predict and model learner activities   data  protected dataset vs open relevant indicators time scale   instruments  pedagogic theory technology algorithm presentation others   external limitations  convention norms  privacy ethics   internal limitations  competences &amp; acceptance interpretation critical thinking     ",1,4,-3,1
"83","The Big Five and Visualisations of Team Work Activity"," group learning = task-work+teamwork what: processes, components; how -&gt; effective  big five components of teamwork  team leadership-ticket actions  facilitate team problem solving provide performance expectations and acceptable interaction patterns synchronize and combine individual team member contributions see and evaluate information that affects team functioning   mutual performance monitoring-INs  identifying mistakes and lapses in other team members' actions   backup behavior-IN/T  recognition of a workload distribution problem in the team shifting work to underutilized members   adaptability  identify cues of changes, assign meaning to it, develop new plan to deal with it   team orientation-wattle tree  increase task involvement, information sharing, strategizing and goal setting     three coordinating mechanisms  shared mental models mutual trust closed-loop communication     set of novel visualization  mirror activity of individual and interactions  activity radar interaction network wattle tree   powerful and valuable mirroring role     ",2,2,0,2
"84","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Introduction to Recommender Systems: hybrid online course  online VS graduate-level course at university intent: to explore the medium of massive-scale online education as a vehicle for delivering in-depth advanced technical content at a level normally associated with a  graduate-credit course concept(basic mathematics) VS concepts+programming  completion &amp; retention     intention predicts completion recommender systems knowledge     student knowledge increased     limited data suggests that face-to-face students learned at least as much as online-only students     students at all incoming knowledge levels benefited similarly from the course     students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge factors predicting learning and students success     normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest     predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking knowledge retention over time     among students who responded to a 5-month follow-up, most student learning gains were retained after 5 months. Programming students retained more than concepts students; very limited data on face-to-face students suggests their retention is at least as high as that of online-only students student evaluation and survey results &amp; qualitative results and anecdotes   useful lessons  generation of a class-specific dataset used for the assignment personal test data-provide both interest and a barrier to cheating by passing around correct datasets use if open-source infrastructure better hiding the tool implementation or having a complete mapping between concepts and grading options   ",11,6,5,4
"85","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","A data driven, matrix factorization approach  two mapping items to skills  expert matrix factorization - slightly better - valid   comparison  discrepancies performance   visual analysis  similar pattern      Skills modeling, Q-Matrices, and Matrix Factorization  linear models results matrix R ~= QS alternate Least-Square Factorization(ALS ",3,0,3,5
"86","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Our method-eEPUPHANY: assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course  better than human-engineered skill models skill models discovered by ours are interpretable ours is remarkably faster than existing methods  goal: to provide constructive feedback to online course designers and developers for iterative course improvement eEPIPHANY  collection of data mining techniques for automatic discovery of skill models from online course daa input: matrix representing a chronological record of students' responses to assessment items ( A-matirx) find a skill model(Q-matrix) the produces the best prediction of the A-matrix. the predictive power is measured bu cross-validation steps  clustering assessment items with latent features proposing a new skill model searching for the best skill model by comparing multiple skill model candidates    Discussion  strategy comparison  yields a better skill model than the default skill model that is hand-crafted by human experts can actually find a better skill model completely automatically without human interaction (which is what the replace strategy does) from real online course data   interpretability  this hybrid technique allows course designers to make meaningful interpretations of the proposed refinements of the skill model   Implication for evidence-based online course refinement  authors of online courses would not need to create a default skill model at all eEPIPHANY can find the default model by itself using the bag-of-words method   ",20,0,20,5
"87","Using data mining to predict secondary school student performance","high failure rates in Math and Portuguese language - Business Intelligence/Data Mining help  aim at extracting high-level knowledge from raw data, offer interesting automated tools modeled under binary/five-level classification and regression tasks 4 DM models : Decision Trees, Random Forest, Neural Networks and Support Vector Machines 3 input selections results: a good predictive accuracy achievement is highly influenced by past evaluation  explanatory analysis - other relevant features   ",2,1,1,3
"88","Developing a generalizable detector of when students game the system","Game the system VS Learn the material  gaming the system: attempting to succeed in an educational environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly Baker et al.'s Gaming Detector  data  4 lessons geometry, percents, probability 4-6 classrooms/year 2 school districts observation, pre/post-test   evidence distinguish types generalize to new tutor lessons  Leave-One-Out-Cross-Validation Strube's Adjusted Z     gaming behavior  quickly and repeatedly asking for help until the correct answer inputting answers quickly and systematically   detector structure  latent response models Fast Correlation-Based Filtering Forward Selection linear correlation   comparison  criteria  accurately identify a category of behavior which is known to be associated with a meaningful difference in student experience or outcomes predict not only which students engage in the behavior, but when they do so. not only detects student behaviors but can help researchers understand those behaviors better generalize     ",5,1,4,5
"89","Big Data in Education","novel visualization  individual &amp; interaction activity (e.g. teamwork) evaluated - theoretical analysis - ""Big 5"" + qualitative study of visualization + reflective report powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness   ",1,0,1,2
"90","Cross Validation","cross validation  train -&gt; test generalization, representative IID - independent identically distributed fundamental assumption model that is complex enough to fit the data without causing problems on the test set use part of training set as testing set folds  123-&gt;4 234-&gt;1 341-&gt;2 412-&gt;3 average error together (goodness of fit)  pick the lowest error     ",2,4,-2,5
"91","Hands-On Programming with R"," die &lt;- 1:6  die*c(1,2) - 1 4 3 8 5 12 die*die - 1 4 9 16 25 36   %*% inner multiplication %o% outer multiplication function  roll &lt;- function(input) {}   double(4), integer(4L), character(""Hello""), logic(TRUE). complex(1+2i),raw(raw(3)) as.logical(1) - ""TRUE"", as.numeric(FALSE)-0 now &lt;- sys.time() df &lt;- data.frame(face=c(),suit=c(),value=c()) ",1,1,0,1
"92","Principal Component Analysis explained visually","principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It is used to make data easy to explore and visualized. PCA is used for eliminating dimensions.  ",1,0,1,2
"93","Measurement and its Uses in Learning Analytics","Psychological measurement Composition: Define a construct; specify measurement models and develop reliable instruments; analyze and explain various sources of error, including operator errors; and build valid justifications for specific uses of the results. Construction Construction can be used interchangeably with latent variables, and features are used to imply that construction is stable over time. (For example, a tape measure provides a scale)Psychological constructions, such as mathematical abilities and extraversion, make constructs equivalent to the scores of the instruments used to measure them.We can infer an extremely local list of structures related to learning analysis from the analysis tools that have been developed for metric learning. Measuring Instruments Tests, questionnaires, items or indicators. Errors Models used Latent Category and Potential Hybrid Models Project Response Theory Interpretation and / or prediction Learning analytics has been described as an intermediate space between learning science and analysis, so the field may benefit from an understanding of the nuances of the two perspectives. ",1,3,-2,5
"94","Ethics and Learning Analytics: Charting the (Un)Charted","Ethics Persuasive surveillance, algorithmic effects and unintended consequences. Ethics and privacy are key drivers in learning analytics. Will people inevitably realize the importance of ethics after a series of misconducts and even catastrophic consequences? Just like in other fields?  As in the financial field, the CFA certificate occupies a large proportion of ethics and aims to solve the ethics in the financial field. Although Edtech can adopt some similar methods, he said that “inventing” Certificate exams emphasize the importance of ethics, but in the real world, because transparency and market regulations increase trust in data users.  The question is, who and which entity has the right to regulate? How can we deal with the monopoly of large companies or any unnecessary intervention by the state, or the unavoidable controversy, better than nothing?It attracted me, and even the right to draft and draw up a code of ethics, suggests that there is some kind of sovereignty and power relationship in the field? ",5,1,4,2
"95","Predictive Modelling in Teaching and Learning","Predict students' academic achievements. Predictive models in education. Unlike the interpretation model, this model aims to provide an explanation of the results and implies causality. The purpose of modeling is to create a model that predicts new data values <U+200B><U+200B>based on observations. Intuitively, training data can be used to predict the value of new data. And implementation in education, including identifying vulnerable students in areas such as learning outcomes. Problem identification, Data collection, Classification and regression, Feature selection, Model construction (linear regression, logistic regression, KNN, decision tree, naive Bayes classifier, Bayesian network, support vector machine, neutral network, set method) 6. Model evaluation ",2,4,-2,3
"96","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","1. Educational data mining research focuses on developing two types of models: statistical models and cognitive models. The statistical model drives the outer loop of the intelligent tutoring system based on the observable characteristics of students' performance during learning (VanLehn, 2006). Cognitive models are representations of the knowledge space (facts, concepts, skills, etc.) in a particular education field.  2. Difficult factor assessment (DFA; for example, Koedinger &amp; Nathan, 2004) goes beyond the intuition of experts by using a data-driven knowledge decomposition process to identify problematic elements of a defined task. In other words, when a task is much harder than a closely related task, the difference means an understanding of the harder tasks that do not exist.",0,1,-1,5
"97","Statistical graphics: making information clear – and beautiful","Build more beautiful and useful data and inference summaries: Who is your target audience?  What do you want to display? Avoid distractions.  Use information colors to visually associate elements.  keeps the graphics simple (and therefore explainable).  Keep the x-axis and y-axis ratios the same. Consistency between plots. ",0,0,0,2
"98","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","One of the main differences between the two approaches is that Infovis rewards unique, unique displays, while statisticians have been trying to develop generics that have similar appearances in various applications method. . Few statisticians try to develop new things. They are using standard trial tools. Infovis attaches great importance to creativity and diversity, while statistics are centered on objectivity and reproducibility.  Another important difference is the intended audience. Statisticians think that their audience is already interested and want to provide structured information, often a carefully prepared argument. For statisticians, graphics are part of the explanation. Even exploratory analysis often has a clear structure. Instead, Infovis designers want to draw attention to their graphics, and thus to the subject matter. For them, the graphics are more like a door opener.",4,1,3,2
"99","Junkcharts Trifecta Checkup: The Definitive Guide","Trifecta Checkup is a universal framework for data visualization criticism. It documents the way people like to organize thinking behind the critique of their work. It's a clear framework that shows whether the charts in question, data, and visualization are correct and well constructed. ",5,1,4,2
"100","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","I should read this at the beginning of this semester, as most of the information covered in this article is relevant to what we have learned this semester. I'm glad to read a real case when analyzing education data for k-12 schools to help reform education policies and understand the situation of students before deciding whether to drop out. After completing all tasks and familiarizing myself with all the code, I am now familiar with the diagrams mentioned in this article and all the analysis methods used by researchers. Although many questions still need to be answered in the future development of educational data analysis, the current development trend marks a bright future in this field.",3,0,3,2
"101","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Living in an age where people cannot live without social media. Researchers are very cautious to take into account changes in relationships over time. I think this research is very valuable to both teachers and students. For teachers, they can help students form study groups to help them get the best learning results. For students, with the help of this research, they can find partners who can best help them.",2,0,2,2
"102","Why Students Should Own Their Educational Data","In my opinion, based on extensive research, the most effective teaching method is still based on your own pace and individual guidance strategy (ie apprenticeship or tutoring mode). However, this model is too expensive and impractical for all models except 1%. Perhaps with enough data and design, the model can be replicated through technology, and no teachers are needed at this time.",1,0,1,2
"103","Knowledge tracing: Modeling the acquisition of procedural knowledge","In this article, the Bayesian cognitive model in the APT tutoring system is introduced. This model allows the tutor to interact with the students during the learning process and judge the quality and progress of the students. As described herein, the system has high internal and external effectiveness.",2,0,2,3
"104","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This article make me understand learning analytics; This article summarizes the similarities and differences between educational data mining and learning analysis. The author's point is that researchers should learn from each other and improve their research in various fields.",0,0,0,2
"105","Evaluating Machine Learning Models","He introduced diagnostic measures for three types of algorithms in data mining, including classification, ranking, and regression. The author points out that each type has its advantages and disadvantages, and recommends selecting the type for the appropriate purpose.",1,2,-1,5
"106","Why Opting Out of Student Data Collection Isn’t the Solution","Use the data to understand how students perform over time, how the school system provides services to different populations, and how successful different education strategies have been.",1,0,1,2
"107","Why Is Measuring Learning So Difficult?","In this video, they point out that despite measuring learning difficulties, they still measure learning well, such as social structure. Finding reliable measurements is important for the measurement process. Through the longitudinal model, students can measure the learning progress of educational achievements.",3,1,2,1
"108","Saturday Morning Breakfast Cereal","Comics suggest a phenomenon in which current education focuses more on results than on process and education itself. It is still doubtful whether educational achievements such as grades are more important than the improvement of learning ability. ",0,1,-1,2
"109","Data wranglers: human interpreters to help close the feedback loop","This article highlights the point that data brawlers are very helpful in interpreting educational data. I believe that when educators make education policies, data brawlers are very important to interpret educational data.",0,0,0,2
"110","Zuckerberg is ploughing billions into 'personalised learning' – why?","in this article, the author introduces Zuckerberg's personalized learning plan, and discusses the status and dangers of personalized learning. They suspect the potential for personalized learning development due to current conditions. First, it is difficult to determine whether personalized learning is truly personalized. Second, the high cost of personalization does not really help improve the quality of education for all.",1,3,-2,2
"111","Feature Selection","A short introduction to this feature selection discusses two main reasons why we performed this process. One reason is interpretation and insight (knowledge discovery), and the other is solving the curse of dimensionality. ",0,0,0,5
"112","Chapter 1: Social Network Data","Network data and regular data &lt;/ <U+200B><U+200B>p&gt; &lt;p&gt; Unlike conventional data that emphasizes participants and attributes, network data focuses more on participants and relationships, which leads to the combination of nodes and edges in network data. A key point in the emergence of network data is that we are interested in both participants and found different participants The relationship between them. Therefore, when we design a sample to address the population we are interested in, we usually cannot include a single observation, that is, if an observation is selected, the relevant ""neighbors"" and their relationships should also be included in Data is being collected. ",1,0,1,4
"113","RStudio Cheat Sheets","The most useful information in this cheat sheet relates to the shiny R and format. I used to know about Rmarkdown, but it was limited to basic commands and formats. This cheat sheet tells me how to generate stories in Rmarkdown and generate Latex formatted text. This is very useful for people who may need to produce clean mathematical equations in a dissertation. ",1,3,-2,1
"114","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Predicting coellege enrollment is a good way in 21 century, but it is not accurt all the time.",1,0,1,4
"115","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This article provides a general framework for learning analytics, which includes six dimensions, such as data, stakeholders, and goals. The significance of this framework is that it connects interested parties in education and illustrates how these parties are linked in the field of learning analytics. As the author mentioned, the framework is not intended to be perfect and applicable to every situation in education, but rather it can be modified by educators to make them useful for their specific purpose. ",1,0,1,2
"116","The Big Five and Visualisations of Team Work Activity","In methods that support online (learning) teams, we track student interactionsBehavior in these dimensions and provides a visual mirrorTo groups.",1,0,1,1
"117","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This is a comprehensive study of MOOC recommendation system courses at the Department of Computer Science at the University of Minnesota. The PCA analysis was limited to Section 4.4 ""Preliminary Analysis"", in which the author explored the reasons why students enrolled in this course and found four factors with eigenvalues <U+200B><U+200B>exceeding 1. &lt;/ p&gt; &lt;p&gt; But this article is not limited to PCA. It has performed many regression analyses in an attempt to find variables that significantly predict outcomes such as final grade and retention (five months after the course ends). The authors also compared face-to-face and online students, with the former generally prevailing in their learning outcomes. However, the authors caution that the small number of students in the previous group may make the results statistically unconvincing. &lt;/ p&gt; &lt;p&gt; This article not only provides detailed information for studying PCA or even MOOC courses. It also discusses student interaction, the qualitative part. Some students apply what they have learned to their own business in a class or work immediately. This shows the usefulness of this recommendation system course. ",3,4,-1,4
"118","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Linear models of skills are important. Weighted sums of individual score items broken down by topic skill.",3,1,2,5
"119","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Skill models for online courses to better evaluate and improve courses. ""Our method assumes that online courses have a pre-defined skill map that is relevant to the formative assessment items embedded throughout the online course &lt;/ p&gt; &lt;p&gt; The limitation of interpretability is that ""The obvious limitation of current technology is its reliance on manual inspections. "" The article introduces the analysis of eEPIPHANY's performance better than humans. A sophisticated skill model,"" eEPIPHANY is an efficient, practical and fast method that can be automatically discovered from online course data without human intervention Skill model. ""&lt;/ P&gt;",8,2,6,5
"120","Using data mining to predict secondary school student performance","Although there is a trendIncrease IT investmentFrom the government, most PortuguesePublic school information systems are very poor, relying mainly on paper",0,1,-1,2
"121","Developing a generalizable detector of when students game the system","In this article, we will discuss the work of detecting games in cognitive mentors.Cognitive tutor learning environments are designed to promote learning by doing.In the cognitive mentor environment discussed in this article, each studentComplete the math problem alone. Cognitive tutor environmentBreak down each mathematical problem into steps for the process used to solve itQuestions that make students' ideas clearly visible.",2,2,0,2
"122","Big Data in Education","Big data is useful in education.",0,0,0,2
"123","Cross Validation","I don't understand this video.",0,0,0,1
"124","Hands-On Programming with R","By reading this article, I know how to programming by R.",0,0,0,2
"125","Principal Component Analysis explained visually","I don't understand what the different between 3D and 2D....",0,0,0,4
"126","Why Students Should Own Their Educational Data","In order to answer this question, the article discussed several question: What’s wrong with the idea of the average learner? -For 150 years, we’ve thought we could understand individuals by studying groups of people and patterns in the population. So every time we say we’re studying this application of learning, what we’re really saying is there are groups of people, and we look for statistical patterns in the people. but it turns out that much to our chagrin, we know now that you can’t actually tell anything in population studies about any individual in that group. How does that apply to learning? I prefer visual information over other kinds. [Learning style theory] comes from analyzing a population and trying to parse out different ways of learning over a population. But when you apply it to one individual it doesn’t hold. You can’t start with averages, it doesn’t work. We couldn’t do better approaches to individuals back in the day because we just didn’t have enough data. -So that aggregate data was all we had? It’s all we had. You had to draw inferences about a population from a sample because you couldn’t get the population data. When we start talking about the ability to create some kind of personalized learning, you have to be able to model the individual. -The argument by some MOOC proponents is that artificial intelligence can transform education, and that what they do today is just the beginning of what will become a more personalized learning experience.  What we need to know about you is your contextualized profile of your performance and what kind of support you’ll need to be able to model your learner profile across contexts. If I had to push for one thing that I think is super important, that is that the user should own their data. There’s this default thing right now which is that everybody but the user owns their data. My vision that we’re going to push for in my organization is you’ve got to have a third party who is responsible for protecting learner data. Then the student could have, say, a decade of data about the way that they’re learning.  In conclusion, we need a market solution. The market only works if you have a functional market. And education is decidedly not a functional market right now. There’s not enough transparency.",12,3,9,2
"127","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","With the development of our society, there is growing interest in data analytic of education. we call for communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.",0,0,0,2
"128","Why Is Measuring Learning So Difficult?","Reasons:1. Learning is very contextual and broad.             2.Because we have to simplify it in order to capture date and understanding of it that we can use.             3. Learning is very personal and actually nobody else can do it for us. Without being presented with conditions and motivations and being very attentive about what is going on, then measuring learning will be very difficult.           4.In terms of the ways to measure learning, we think it's difficult, because there is no reliable indicators that we can trust           5 Because learning is very complex. There are cultural things and individual psychological things people might not notice.            6 we don't know people's competences were coming into learning environment.",1,3,-2,1
"129","Saturday Morning Breakfast Cereal","The comic mainly showed that children were undercolocked and they want to make children to work harder so that they can exceed other countries. The sentence in the comic is very ironic. Science is dead. Engineering is static. The humanities are unknown. All is clock.",2,4,-2,2
"130","The Data Wrangling Cheatsheet","Tidy data-a foundation for wrangling in R -In a tidy data set: Each variable is saved in its own column and each observation is saved in its own row. -Reshaping data-change the layout of a data set gather():gather one column into rows separate():Separate one column into several spread(): spread rows into columns unite(): unite several columns into one data_frame():Combine vectors into data frame (optimized) arrange():Order rows by values of a column (low to high). arrange(mtcars, desc(mpg)):Order rows by values of a column (high to low) rename(tb, y = year):Rename the columns of a data frame -Subset Observations dplyr::filter(iris, Sepal.Length &gt; 7) Extract rows that meet logical criteria. dplyr::distinct(iris) Remove duplicate rows. dplyr::sample_frac(iris, 0.5, replace = TRUE) Randomly select fraction of rows. dplyr::sample_n(iris, 10, replace = TRUE) Randomly select n rows. dplyr::slice(iris, 10:15) Select rows by position. dplyr::top_n(storms, 2, date) Select and order top n entries (by group if grouped data). In conclusion, learned a lot of operations in R.",1,2,-1,1
"131","Data wranglers: human interpreters to help close the feedback loop","Previous work in the literature has emphasized the need for and value of human meaning-making in the process of interpretation of data to transform it in to actionable intelligence. This paper describes a program of human Data Wranglers deployed at the Open University, UK, charged with making sense of a range of data sources related to learning, analyzing that data in the light of their understanding of practice in individual faculties/departments, and producing reports that summarize the key points and make actionable recommendations. Learning analytics is widely seen as entailing a feedback loop, where ‘actionable intelligence’ is produced from data about learners and their contexts, and interventions are made with the aim of improving learning. This paper has presented an account of Data Wranglers. Substantial progress has been made in establishing a Community of Practice in learning analytics, by analyzing and presenting learning analytics data to academics who are in a position to take action, and through extensive engagement. Progress has also been made in improving institutional learning about the quality and interpretation of the available data, and how better data can be captured and made available. A structurally similar project – large scale and with senior management engagement – is discussed McFadden &amp; Dawson’s analysis of LMS use at a large research-intensive university. In that project, technical discussions swamped more meaningful change processes. In contrast, the Data Wrangler work detailed in this current paper was perhaps better placed to present data “to those involved in strategic institutional planning in ways that have the power to motivate organizational adoption and cultural change”. The analysts were well embedded within the organization to begin with, and they were able to facilitate conversations about pedagogical issues through finer-grained analyses. This project was able to pay “greater attention […] to the accessibility and presentation of analytics processes and findings so that learning analytics discoveries also have the capacity to surprise and compel, and thus motivate behavioral change” – although it is not yet a runaway success.",11,1,10,1
"132","The Quantified Student: An App That Predicts GPA","After finishing reading this article, I am fascinated with the power of technology that can facilitate the development of education. If there is an APP which can help predict students learning habits and GPA, then probably we could use that to collect data which can help students to know their study habits so they can achieve higher scores. However, every coin has two sides. Like what the author has mentioned at the end of the article, we have to think about the privacy and also put the sensitive data in right people's hand, then we can make the best use of it.",3,0,3,2
"133","The R Markdown Cheat sheet","Some basic knowledge about R markdown. Narration formatted with markdown, mixed with: TextChunks of embedded code. Each chunk: • Begins with ```{r} • ends with ``` R Markdown will run the code and append the results to the doc. It will use the location of the .Rmd file  as the working directory.",1,0,1,1
"134","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","-Teacher-Assigned Grades as Useful Data in Schools This research has suggested that about 25% of the variance in grades is attributable to assessing academic knowledge (grades and test scores historically correlate at 0.5), but that the other 75% of teacher-assigned grades appear to assess a student’s ability to negotiate the social processes of school (Bowers, 2009).   -Visualizing Data for 3DM in Schools  while much of the 3DM literature has focused on the use of data systems, data rooms, and discussion of student scores.few studies to date have proposed and tested methods that would allow schools to not only inspect their student’s data, but allow practitioners to understand the complexities of the data, analyze longitudinal trends, and make predictions based on their school’s past performance. In this study, I adapt innovations from the broader data mining literature to propose the use of hierarchical cluster analysis (HCA) and heatmaps as a novel means to pattern and interpret longitudinal trends in student data. -Central Aim of the Study  Thus, the central aim of this study is to adapt hierarchical cluster analysis and heatmaps for use with teacher assigned grades for data driven decision-making. The method will be tested and demonstrated with a small sample of data, and the study will explore what the analysis and visualization method can and cannot do for 3DM in schools. The research question of interest here is that as just one example of the usefulness of the method for 3DM, to what extent do student grades cluster through HCA into patterns that identify which students are most at risk of dropping out of school. Methods: Sample and District Context--Data Collection-Hierarchical Cluster Analysis --Missing Data --Clustergrams --Clustergram X-Axis Subject Order   Findings: First,the study design consists first of a hierarchical cluster analysis and display of a large number of different assessments on each case in the dataset. Here, teacher assigned grades for each student in two cohorts from every subject and every grade level. Second, the cluster pattern is compared to an overall outcome of interest, here student dropout, to assess if the cluster patterns of the assessment align with the overall outcome patterns. Third, other categorical covariates are compared to the cluster pattern, such as gender. Fourth, the hypothesis is that when clustered using the entire longitudinal K-12 grading histories of entire cohorts of students, teacher assigned grades should predict overall student outcomes, such as dropping out or taking the ACT, by clustering students into identifiable clusters based only on their grades.              ",0,4,-4,3
"135","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","-Social network basic concepts Social network analysis (SNA) helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of actors, and what, if any, the impacts are of these relationships on actors. -Network Types. One way to categorize networks is by the number of types of actors they contain. Networks that consist of only one type of actor (e.g., students) are referred to as unipartite (or sometimes monopartite or one-mode). -Network Data Collection. Collecting network data requiresdeciding on a time frame for the relationships of interest.Real worldnetworks are rarely static; ties form, break, strengthen and weaken over time. -Network Level Concepts and Measures. The density of a network is a measurement of how many links are observed in a whole network divided by the total number of links that could exist if every actor were connected to every other actor. -Network Methods: Data Collection -Timing of Survey Administration -IRB and Consent.The nature of network data not only allows subjects toreport information on other subjects but may allow recognizabilityof even anonymized data (called deductive disclosure),especially in small networks. Future direction: Correlating student performance (on any number ofmeasures) to network position is one clear area of researchpossibility. Summary: We have discussed collection of both nodaland relational data, and we specifically focused on keepingsurveys brief and simple to process. We transitioned thesedata to a sociomatrix form for use with SNA software in astatistical package. We analyzed and interpreted these databy visualizing network data with sociographs, looking atsome basic network measurements, and testing for associationsbetween network position and a nodal attribute. Datawere interpreted both as a description of a single networkand as a longitudinal time lapse of community change.",1,3,-2,4
"136","Feature Selection","Reading Notes Feature selection 1 Knowledge discovery Interpretability insights 2 The curse of dimensionality: the amount of data you need to grow in the number of features you have.  ",0,0,0,5
"137","Chapter 1: Social Network Data","Introduction to social network methods -What's different about social network data?  On one hand,network data can also be described and understood using the ideas and concepts of more familiar methods, like cross-sectional survey research. On the other hand, the data sets that social network analysts develop usually end up looking quite different from the conventional rectangular data array so familiar to survey researchers and statistical analysts. The differences are quite important because they lead us to look at our data in a different way -- and even lead us to think differently about how to apply statistics. -Nodes Populations, samples, and boundaries Network analysts will identify some population and conduct a census (i.e. include all elements of the population as units of observation). A network analyst might examine all of the nouns and objects occurring in a text, all of the persons at a birthday party, all members of a kinship group, of an organization, neighborhood, or social class Modality and levels of analysis Often network data sets describe the nodes and relations among nodes for a single bounded population. Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Having claimed that social network methods are particularly well suited for dealing with multiple levels of analysis and multi-modal data structures, it must immediately be admitted that social network analysis rarely actually takes much advantage. Relation Sampling ties Given a set of actors or nodes, there are several strategies for deciding how to go about collecting measurements on the relations among them. Full network methods require that we collect information about each actor's ties with all other actors. Snowball methods begin with a focal actor or set of actors. Ego-centric networks, this kind of approach can be quite effective for collecting a form of relational data from very large populations, and can be combined with attribute-based approaches. Scales of measurement: Binary measures of relations--Multiple-category nominal measures of relations--Grouped ordinal measures of relations--Full-rank ordinal measures of relations--Interval measures of relations      ",5,2,3,4
"138","niemi.pdf","10.10(2) reading The outline of the article The obvious way to present information is in a graph. But not all graphs are created equal. A well-designed graph can make clear what an ill-thought-out one conceals. And then it illustrates how to make information clear and beautiful. -Constructing a more beautiful and informative summary of data and inferences Improving figures requires two key decisions: Who is your target audience?  What are you trying to show?   when presenting data, some guiding principles along the way: Avoid distracting elements. Use informative colour to visually associateelements. Keep the figure simple (and therefore interpretable).   -Further graphs for data exploration Diving one more layer down would produce the data table from which both the statistical graphic and the InfoVis were produced. Each layer would be interactive, allowing the reader to present the data in the way they felt most appropriate for their needs. In this way, we view InfoVis and statistical graphics as complementary tools for understanding data.",3,1,2,2
"139","Chapter 12","10.10(1) reading  Learning Analytics Dashboards The goal of this chapter is to provide a guide to practitioners and researchers who want to get started with the development and evaluation of learning analytics dashboards. what is information visualization? Information visualization is the use of interactive visual representation to amplify cognition. -different kinds of dashboards 1. Dashboards that support traditional face-to face lectures, so as to enable the teacher to adapt the teaching, or to engage students during lecture sessions. 2. Dashboards that support face-to-face group work and classroom orchestration, for instance by visualizing activities of both individual learners and groups of learners. 3 Dashboards that support online or blended learning. -How to get started: acquire and (pre-) process your data-mapping,mapping design, documentation, add interaction techniques, evaluate continuously. -Conclusion Information visualization concepts and methodologies are key enablers for  Learners to gain insight into their learning actions and the effects these have. Teachers to stay aware of the subtle interactions in their courses. Researchers to discover patterns in large data sets of user traces and to communicate these  data to their peers.              ",5,0,5,2
"140","wainer.pdf","10.10(3) Reading -The definition of categorizing methods of bad data display: (a) showing data, (b) showing data accurately, and (c) showing data clearly. -The rules of guiding these three methods: rule 1, show as few data as possible(minimize the data density); rule 2, hide what data you do show( minimize the date-ink ratio); rule 3, ignore the visual metaphor altogether; rule 4, only order matters; rule 5, graph data out of context; rule 6, change scales in mid-axis; rule 7, emphasize the trivial (Ignore the important); rule 8, jiggle the baseline; rule 9, austria first; rule 10, label (a) illegibly,(b) incompletely,(c) incorrectly and(d) ambiguously; rule 11, more is murkier:(a) more decimal places and (b) more dimensions; rule 12, if it has been done well in the past, think of another way to do it. -Conclusion There are many paths that one can follow that will cause deteriorating quality of our data displays; the 12 rules that we described were only the beginning. The rules for good display are quite simple. Examine the data carefully enough to know what they have to say, and then let them say it with a minimum of adornment. Do this while following reasonable regularity practices in the depiction of scale, and label clearly and fully. Last, probably the most important part, spend some time looking at the work of the masters of the craft.",9,3,6,3
"141","vis14.pdf","10.12 (1) reading The purpose of the present article is to start a conversation between practitioners in statistical graphics and information visualization. We hope that by identifying the different goals that motivate work in these two areas, we can get the best researchers in these fields to learn from each other. Difficulties: Our difficulties with some popular visualizations arose from an insufficient understanding—by ourselves and others—of the multiplicity of goals involved in data display. True purpose of graphic display  Graphics are for the qualitative/descriptive—conceivably the semiquantitative—never  for the carefully quantitative (tables do that better).  Graphics are for comparison—comparison of one kind or another—not for access to  individual amounts.  Graphics are for impact—interocular impact if possible, swinging-finger impact if that  is the best one can do, or impact for the unexpected as a minimum—but almost never for something that has to be worked at hard to be perceived.  Finally, graphics should report the results of careful data analysis—rather than be an  attempt to replace it.   (1) Statistical data visualization, which is focused not on visual appeal but on facilitating an understanding of patterns in an applied problem (recall the Discovery goals listed above), both in directing readers to specific information and allowing the readers to see for themselves. (2) Infographics, which ideally should be attractive, grab one’s attention, tell a story and encourage the viewer to think about a particular dataset, both as individual measurements and as a representation of larger patterns (as in our Communication goals).",9,3,6,2
"142","Junk Charts Trifecta Checkup: The Definitive Guide - Junk Charts","10.12 (2) reading What is Junk Charts Trifecta? The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how I like to organize the thinking behind my critique pieces. It has three investigations:what is the questions?,what does the data say?;what does the visual say? The trifecta Everything is in sync, and the chart has no weaknesses   The singles  1a. Type Q Some charts use a good source of data effectively presented in a visual display. However, the effort fails because of a poorly defined objective, or an unengaging premise.   1b. Type D Some designs emerge from well posed and interesting questions, and the graph is well executed. The problem here is the data, which fail to illuminate the question.   1c. Type V Despite having a good data source and an interesting, well-posed problem, the visual design hides or confuses the message. These charts have long provided fodder for Tufte, Wainer and the like     Doubles  2a. Type QD The graphical elements follow best practices, and present the data well. This effort is in vain, because of poor data quality, and an unclear objective.   2b. Type QV The data has been properly collected and processed. However, the question being addressed has not been clearly defined, and the graphical design fails to bring out the key features of the data.    Triple (Type QDV)  These graphical disasters do not get anything right.",12,13,-1,2
"143","Purchase: Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","10.31 notes The main idea for the article: students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.",9,4,5,4
"144","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Reading notes This article said the team has developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability.",11,1,10,5
"145","Zuckerberg is ploughing billions into 'personalised learning' – why?","Reading notes -Chan Zuckerberg initiative -Personalized learning is what all good teachers do as a matter of course – modifying learning materials and teaching styles to accommodate the different ways pupils learn. Zuckerberg thought personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. -The danger of personalized learning Zuckerberg’s idea of personalised learning has three major flaws. First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. Finally, children’s preferences are not fixed – in fact they often change as immediate responses to the environment.",3,5,-2,2
"146","Chapter 5","Reading notes of Predictive Modelling in Teaching and Learning Predictive Modelling Workflow -problem identification In the domain of teaching and learning, predictive modelling tends to sit within a larger action-oriented educational policy and educational contexts, where institutions use these models to react to student needs in real-time. -Data collection In predictive modelling, historical data is used to generate models of relationships between features. One of the first activities for a researcher to identify the outcome variable (e.g., grade or achievement level) as well as the suspected correlates of this variable.  -Classification and Regression In statistical modelling, there are generally four types of data considered: categorical, ordinal, interval, and ratio. Each type of data differs with respect to the kinds of relationships, and thus mathematical operations, which can be derived from individual elements. -Feature Selection In order to build and apply a predictive model, features that correlate with the value to predict must be created. When choosing what data to collect, the practitioner should err on the side of collecting more information rather than less, as it may be difficult or impossible to add additional data later, but removing information is typically much easier.",3,5,-2,3
"147","Chapter 6","Reading notes:Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data -Cognitive Model Discovery Cognitive models map knowledge components (i.e., concepts, skills, and facts; Koedinger, Corbett, &amp; Perfetti) to problem steps or tasks on which student performance can be observed. This mapping provides a way for statistical models to make inferences about students’ underlying knowledge based on their observable performance on different problem steps. -Data-Driven Cognitive Model when one task is much harder than a closely related task, the difference implies a knowledge demand of the harder task that is not present in the easier one. Stamper and Koedinger (2011) illustrated a method that use DFA, along with freely accessible educational data and built in visualization tools on datashop to identify and validate cognitive model improvements.  -Learning Factors Analysis -Automated Cognitive Model Discovery  -Comparison to Other Work put the data into real situations",4,2,2,5
"148","Evaluating Machine Learning Models - O'Reilly Media","Reading notes for machine learning  In this overview, Zheng first introduces the machine-learning workflow, and then dives into evaluation metrics and model selection. The latter half of the report focuses on hyperparameter tuning and A/B testing, which may benefit more seasoned machine-learning practitioners. With this report, I learned the following:  Learn the stages involved when developing a machine-learning model for use in a software application Understand the metrics used for supervised learning models, including classification, regression, and ranking Walk through evaluation mechanisms, such as hold?out validation, cross-validation, and bootstrapping Explore hyperparameter tuning in detail, and discover why it’s so difficult Learn the pitfalls of A/B testing, and examine a promising alternative: multi-armed bandits Get suggestions for further reading, as well as useful software packages ",2,2,0,5
"149","Knowledge tracing: Modeling the acquisition of procedural knowledge","reading notes 11.30 The paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.",5,0,5,3
"150","Big Data in Education 2.2 Diagnostic Metrics Part 1","Diagnostiic metrics -Accuracy does poorly when there is non even assignment to categories -Kappa: expected agreement comparing Kappa values between two data sets, in a principled fashion, is highly difficult It is OK to compare Kappa values within a data set A lot of work went into statistical methods for comparing Kappa values in the 1990s Informally, you can compare two data sets if the proportion of esch category are ""similar"".",1,2,-1,1
"151","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","NOTE:   There are two types of clustering, supervised and unsupervised. Supervised clustering begins with a defined set of assumptions about the categorization of the data, while unsupervised clustering assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the dataset (Kohonen, 1997) Past methods of identifying students who may drop out of school have been overly reliant on regression analysis, which inherently aggregates data to the overall means within the dataset. Rather than collect different types of data, the results of this study suggests that through the use of these types of pattern analysis and visualization techniques, data that we currently collect in schools but often ignore can be repurposed for 3DM and examined longitudinally to aid in identifying early which students are most challenged by school. HCA is in stark contrast to regression analyses that aggregate data and report overall parameter estimates. Much like a medical x-ray, the clustergram provides a unique way to “look inside” each student’s entire history of achievement, and examine that history in context with other students who have performed in a similar manner through pattern analysis.",2,3,-1,3
"152","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","NOTE: Nodes within a network also have their own set of measurements. These include the exogenously defined attributes with which we are generally familiar (e.g., age, race, major), but they also include measures of position of nodes in the network. Several ways of measuring centrality have been proposed, including degree (Nieminen, 1974), closeness (Sabidussi, 1966), betweenness (Freeman, 1977), and eigenvector centrality (Bonacich, 1987) Degree centrality represents the total number of connections a node has. In networks in which relations are directional, this includes measures ofindegree and outdegree, or the number of edges pointing to or away from an actor, respectively. If one were to look at an airport network (airports connected by flights), airports serving as main hubs, such as Chicago O’Hare and London Heathrow, would have high betweenness, as they connect many cities with no direct flights between them. Closeness centrality focuses on how close one actor is to other actors on average, measured along geodesics. It is important to keep in mind that closeness centrality is poorly suited for disconnected networks (networks in which many actors have zero ties or groups of actors have no connection to other groups). Eigenvector centrality places importance on being connected to other well-connected individuals; having well-connected neighbors gives a higher eigenvector centrality than having the same number of neighbors who are less well connected.",1,2,-1,4
"153","Why Students Should Own Their Educational Data","NOTE:  Students, with help from a third party, should have the rights of and access to their own learning data.  The reason is that they could understand their own learning paths and take action on with their data Many online learning are hoarding students' data because of their business model. But the lack of transparency due to this doing makes it harder to individualize learning Our textbooks, lessons, tests are based on the average students and doing that people focus on averages of a group of people but not individuals. Learning styles are similar to aptitude tests, they are contextual could reflect only certain aspects of a person during a given specific time period. Therefore, a jagged profile of traits is better than the aggregate averages they they are applied to educational interventions. ",2,2,0,2
"154","Knowledge tracing: Modeling the acquisition of procedural knowledge","NOTE: 1.As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process called knowledge tracing. 2.ACT-R theory of skill knowledge (Anderson 1993). This theory assumes a fundamental distinction between declarative knowledge and procedural knowledge. Declarative knowledge is factual or experiential. For example, the following sentence and example in the Lisp text would be encoded declaratively: 3.Procedural knowledge, in contrast, is goal-oriented and mediates problemsolving behavior. ACT-R assumes that skill knowledge is encoded initially in declarative form through experiences such as reading. Early in practice the student solves problems by applying general procedural rules to this domain-specific knowledge. As a consequence of this early activity, domain-specific procedural knowledge is acquired. With subsequent practice, both declarative and procedural knowledge are strengthened so that performance grows more rapid and reliable. ",6,1,5,3
"155","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","NOTE: 1. Comparison between LAK &amp;  EDM Discovery: Leveraging human judgement is key; automated discovery is a tool to accomplish this goal (LAK) Automated discovery is key; leveraging human judgment is a tool to accomplish this goal (EDM) Reduction &amp; Holism: Stronger emphasis on understanding systems as wholes, in their full complexity(LAK) Stronger emphasis on reducing to components and analyzing individual components and relationships between them(EDM) Origins: LAK has stronger origins in semantic web, ""intelligent curriculum,"" outcome prediction, and systemic interventions EDM has strong origins in educational software and student modeling, with a siginficiant community in predicting course outcomes Adapation &amp; Personalization: Greater focus on informing and empowering instructors and learners(LAK) Greater focus on automated adaption (e.g. by the computer with no human in the loop)(EDM) Techniques &amp; Methods: Social network analysis, sentiment analysis, influence analytics, discourse analysis, learner success prediction, concept analysis, sensemaking models(LAK) Classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization(EDM)  ",7,0,7,2
"156","Evaluating Machine Learning Models","NOTE: AccuracyAccuracy simply measures how often the classifier makes the correctprediction. It’s the ratio between the number of correct predictionsand the total number of predictions (the number of data points inthe test set):accuracy = # correct predictions/ # total data points Confusion Matrix Accuracy looks easy enough. However, it makes no distinctionbetween classes; correct answers for class 0 and class 1 are treatedequally—sometimes this is not enough. One might want to look athow many examples failed for class 0 versus class 1, because the costof misclassification might differ for the two classes, or one mighthave a lot more test data of one class than the other. For example,when a doctor makes a medical diagnosis that a patient has cancerwhen he doesn’t (known as a false positive) has very different consequencesthan making the call that a patient doesn’t have cancerwhen he does (a false negative). Log-LossLog-loss, or logarithmic loss, gets into the finer details of a classifier.In particular, if the raw output of the classifier is a numeric probabilityinstead of a class label of 0 or 1, then log-loss can be used. Theprobability can be understood as a gauge of confidence. If the truelabel is 0 but the classifier thinks it belongs to class 1 with probability0.51, then even though the classifier would be making a mistake,it’s a near miss because the probability is very close to the decisionboundary of 0.5. AUC it shows you howmany correct positive classifications can be gained as you allow formore and more false positives. The perfect classifier that makes nomistakes would hit a true positive rate of 100% immediately, withoutincurring any false positives—this almost never happens in practice. Precision-RecallPrecision and recall are actually two metrics. But they are often usedtogether. Precision answers the question, “Out of the items that theranker/classifier predicted to be relevant, how many are truly relevant?”Whereas, recall answers the question, “Out of all the itemsthat are truly relevant, how many are found by the ranker/classifier?”Figure 2-3 contains a simple Venn diagram that illustrates precisionversus recall. RMSEThe most commonly used metric for regression tasks is RMSE(root-mean-square error), also known as RMSD (root-mean-squaredeviation). This is defined as the square root of the average squareddistance between the actual score and the predicted score:",14,6,8,5
"157","Why Is Measuring Learning So Difficult?","NOTE: Learning is: so many different things multi-dimensional contextual different things to measure between subject(e.g. programing &amp; humanities) hard to see if we just look at the result but not the process that is constantly changing may not have reliable proxy indicators to measure about cultures in different individuals that influence their behaviors not always tests score, and that does not necessarily pertains to understanding about how to help students understand their learning and where to improve on, but not always about creating diagnostic tool  ",0,1,-1,1
"158","Saturday Morning Breakfast Cereal","NOTE: It is humorous but also reflects the politics around educational reformation and irreversible impact when it is messed up.",2,1,1,2
"159","The Data Wrangling Cheatsheet","NOTE: There are a couple of major clusters of data manipulative skill in the dplyr and tidyr packages: 1. syntax:     view()    piping: %&gt;%    tbl_df()  2. reshaping data:  gather() separate() spread() unite() arrange()  * in both ascending &amp; descending order rename() * specify new column name before the equal sign  3. subset observations (rows)/ variables (columns):  filter() distinct() sample_frac() sample_n() top_n() * useful after grouping w/  group_by() select() select(data, arg2)      arg2: contains(), ends_with(), everything(), matches(), num_range, one_of(), starts_with(), : * w/ two col names specifying range, - * indicate excluded col    4. summarize data:  summarise() summarise_each() * apply function to each column count(data, column, weight) * count the num of rows with each unique value of variable (w/ or w/o weights)  5. group data:  group_by() ungroup()  6. make new variable():  mutate() mutate_each() * apply function to each column transmutate() * create one or more columns, dropping original column(s)  7. combine data sets:  left_join() right_join() inner_join() full_join() semi_join() anti_join() intersect() union() setdiff() bind_rows() bind_cols() ",1,0,1,1
"160","Data wranglers: human interpreters to help close the feedback loop","NOTE:  Interpreting learning data is complex and requires different academic staff/teachers to participate Single-loop learning: LA is used to achieve set goals Double-loop learning: LA is used when these goals can be interrogated, challenged, and developed Data wranglers play a vital role in making sense between learning data and users (school staff/teachers) to improve learning experience Despite the engagement of Data Wrangler, many issues could arise in the process of sense-making with LA such as communicating the data, different way of interpreting data, and standards of treating the data(human factors). ",0,1,-1,1
"161","Zuckerberg is ploughing billions into 'personalised learning' – why?","Note: The definition of personalized learning remains vague. Some common definitions include: 1. what all good teachers do as a matter of course – modifying learning materials and teaching styles to accommodate the different ways pupils learn. 2.Others see it as an antidote to top-down, centralised school bureaucracy, with the term “personalised” used interchangeably with individual, learner-centered or customised.   Zuckerberg's definition: personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. The danger of personalized learning: 1. Education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. 2. While learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. 3.children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher. ",5,5,0,2
"162","Feature Selection","NOTE: Reasons to reduce/select features  Knowledge discovery Interpretability Vsual effect The curse of dimensionality: the more features, the more dimensions to analyze (2 to the power of n). That's why we have to decrease the number of feature or select features  ",0,0,0,5
"163","Translating Learning into Numbers: A Generic Framework for Learning Analytics","NOTE:  The management of LA pertains to two things: soft issue such as competence and ethics, and hard issues like hardware and database integration Some critical dimensions of LA: Internal limitations(competence, acceptance), external constraints(conventions, norms), instruments, data, objectives, stakeholders. Information flow between stakeholders: government(policy) &gt; institution &gt; teachers &gt; students (top-down) All the critical dimensions of LA should be included between pedagogical behavior and consequence Bottom-up (students-oriented) approach focusing on the interests of learners should be the driving force to develop different dimensions of LA ",3,3,0,1
"164","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","NOTE: Because the random assignment of participants is not viable on MOOCs, so post-research comparison was used to make sure different groups of subjects are comparable:      ""Because stu- dents self-enrolled in the MOOC and in the face-to-face class, random assignment to treatment conditions was not possible. However, the instructor, course content and ob- jectives, and main course assessments were held constant, and data on demographic characteristics and precourse subject matter knowledge were used to ensure that the online and face-to-face groups being compared were similar in the relevant respects. ""     Another challenge about MOOCs is that it is hard to define course completion:       ""However, not unlike other researchers in this nascent field, we struggle with how to define completion rates. Moreover, since we also collected data longitudinally and effi- ciently (e.g., only requesting postcourse responses from those who completed precourse materials), our denominator for calculating response rates shifted necessarily. Table I consolidates our data on numbers of respondents and participant/response rates for our study.""   The findings of this research could be a bit counter-intuition                 ""it is worth noting how many factors did not affect course completion, defined either by the writing- based or the exam-based variables. Age, sex, English proficiency, and United States residency all had no impact on completion, nor did status as a profes- sional, graduate or undergraduate student, or most of the reasons students expressed for taking this MOOC."" Some salient predictor of learning outcomes:                ""the models show that knowledge, experience, and strong intentions influ- enced both measures of                         completion. The higher a student’s score on the knowledge pretest, the greater the number of                             MOOCs she had taken in the past, and the stronger her intention to complete the course, the more                     likely was it that she would complete both the writing assignment and exam in question."" Some other major findings:    Student knowledge increased: face-to-face students learned at least as much as online-only students   Students at all incoming knowledge levels benefited similarly from the course.    Students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge.     Result: Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest.     Among students who responded to a 5-month follow-up, most student learning gains were retained after 5 months. Programming students retained more than concepts students did; very limited data on face-to-face students suggests their retention is at least as high as that of online-only students.                                 ",10,4,6,4
"165","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Notes: The process of building a Q-Matrix: (1) clustering assessment items with latent features that would best characterize the similarity in the difficulties of assessment items. (2) proposing a new skill model by assuming that the above-mentioned cluster of assessment items provides a hint for new skills (3) searching for the best skill model by comparing multiple skill model candidates There are two latent-feature extraction strategies: (1) the Matrix Factorization (MF) strategy (2) the Bag-of-Words (BoW) strategy. The goal of feature extraction, regardless of the strategy difference, is to generate a two-dimensional matrix, the P-Matrix, showing a mapping between assessment items and “skill candidates To evaluate model fit, we can use cross-validation to compare machine-generated and expert-defined skill dimensions",7,0,7,5
"166","Chapter 1: Social Network Data","NOTE: This is the first major emphasis of network analysis: seeing how actors are located or ""embedded"" in the overall network. But a network analyst is also likely to look at the data structure in a second way -- holistically.  Rather than thinking about how an actor's ties with other actors describes the attributes of ""ego,"" network analysts instead see a structure of connections, within which the actor is embedded. Actors are described by their relations, not by their attributes. And, the relations themselves are just as fundamental as the actors that they connect. The major difference between conventional and network data is that conventional data focuses on actors and attributes; network data focus on actors and relations. The difference in emphasis is consequential for the choices that a researcher must make in deciding on research design Network analysis focuses on the relations among actors, and not individual actors and their attributes. This means that the actors are usually not sampled independently, as in many other kinds of studies (most typically, surveys). The nodes or actors included in non-network studies tend to be the result of independent probability sampling. Network studies are much more likely to include all of the actors who occur within some (usually naturally occurring) boundary. Often network studies don't use ""samples"" at all, at least in the conventional sense. Rather, they tend to include all of the actors in some population or population Social network data tend to differ from more ""conventional"" survey data in some key ways: network data are often not probability samples, and the observations of individual nodes are not independent. These differences are quite consequential for both the questions of generalization of findings, and for the mechanics of hypothesis testing. There is, however, nothing fundamentally different about the logic of the use of descriptive and inferential statistics with social network data.",2,0,2,4
"167","Learning Analytics Dashboards","NOTE: Data that can be incorporated into dashboard  1. Artefacts produced by learners, including blog posts, shared documents, software, and other art efacts that would often end up in a student project portfolio. 2. Social interaction, including speech in face-to-face group work, blog comments, Twitter or discussion forum interactions. 3. Resource use can include consultation of documents (manuals, web pages, slides), views of videos, et cetera. Techniques like software trackers and eye-tracking can provide detailed information DERXWZKDWSDUWVRIUHVRXUFHVH[DFWO\DUHEHLQJ used and how. 4. Time spent can be useful for teachers to identify students at risk and for students to compare their own efforts with those of their peers. 5. Test and self-assessment results can provide an indication of learning progress.  To get started with building data dashboard 1.Understand Your Goals 2.Acquire and (Pre-)Process Your Data(80% of the total work time) 3.Mapping Design 4.Documentation 5.Add Interaction Techniques 6.Evaluate Continuously   Data visualization and methodologies are keys enablers for • Learners to gain insight into their learning actions and the effects these have. • Teachers to stay aware of the subtle interactions in their courses. • Researchers to discover patterns in large data sets of user traces and to communicate these data to their peers. ",5,1,4,2
"168","Measurement and its Uses in Learning Analytics","NOTES:  LA is a tool that expresses a commitment to a particular educational worldview, designed to nurture particular educational worldview, designed to nurture particular kinds of learners. LA is based on EPA triad: Epistemology, Pedagogy, Assessment   ",0,0,0,2
"169","Predictive Modelling in Teaching and Learning","NOTE: 1. Is is important to distinguish predictive and explanatory modeling 2.In explanatory modelling, the goal is to use all available evidenceto provide an explanation for a given outcome. Forinstance, observations of age, gender, and socioeconomicstatus of a learner population might be usedin a regression model to explain how they contributeto a given student achievement result. The intent ofthese explanations is generally to be causal (versuscorrelative alone), though results presented using theseapproaches often eschew experimental studies andrely on theoretical interpretation to imply causation(as described well by Shmueli, 2010).   3. In predictive modelling, the purpose is to create a modelthat will predict the values (or class if the predictiondoes not deal with numeric data) of new data based onobservations. Unlike explanatory modelling, predictivemodelling is based on the assumption that a set of knowndata (referred to as training instances in data mining literature)                                                    can be used to predict the value or class ofnew data based on observed variables (referred to asfeatures in predictive modelling literature). Thus theprincipal difference between explanatory modellingand predictive modelling is with the application of themodel to future events, where explanatory modellingdoes not aim to make any claims about the future,while predictive modelling does. 4. More casually, explanatory modelling and predictivemodelling often have a number of pragmatic differenceswhen applied to educational data. Explanatorymodelling is a post-hoc and reflective activity aimedat generating an understanding of a phenomenon.Predictive modelling is an in situ activity intended tomake systems responsive to changes in the underlyingdata.",1,2,-1,5
"170","Ethics and Learning Analytics: Charting the (Un)Charted"," NOTE:  Ethical implications around the collection, analysis, and use of student data should  take cognizance of the potentially conflicting interests and claims of various stakeholders Critical question in focus regarding LA: storage and interpretation of data, privacy of data, management of data. Students should be given the access to view and update their data as a participant of LA. A sensorship must be established regarding false or outdated data so that irrelevant information could be removed or petitioned against ",2,2,0,2
"171","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","NOTE: 1.Educational data mining research has largely focusedon developing two types of models: the statistical modeland the cognitive model. Statistical models drive theouter loop of intelligent tutoring systems (VanLehn,2006) based on observable features of students’ performanceas they learn. Cognitive models are representationsof the knowledge space (facts, concepts,skills, et cetera) underlying a particular educationaldomain. 2. Difficulty factors assessment (DFA; e.g., Koedinger &amp;Nathan, 2004) moves beyond expert intuition by usinga data-driven knowledge decomposition process toidentify problematic elements of a defined task. Inother words, when one task is much harder than aclosely related task, the difference implies a knowledgedemand of the harder task that is not present in theeasier one.    ",0,0,0,5
"172","Statistical graphics: making information clear – and beautiful","NOTE: Constructing a more beautiful and informative summary of data and inferences:  Who is your target audience? s What are you trying to show? Avoid distracting elements. s Use informative colour to visually associate elements. s Keep the figure simple (and therefore interpretable).  Keep the x- and y-axes on the same scale. Eliminate repetitive information. Maintain consistency across plots.",0,1,-1,2
"173","How to display data badly","NOTE:   Examine the data carefully enough to know what they have to say. And then let them say it with a minimum of adornment. Following reasonable regularity practices in the depiction of scale and label clearly and fully.Spend some time looking at work of the masters of the craft.; this is a test note",4,0,4,3
"174","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","NOTE: One key difference between the two approaches is that Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods that have a similar look and feel across a wide range of applications. Few statisticians are trying to develop anything new; they are using the standard well-tried tools. Infovis places a high value on creativity and difference, whereas statistics is centered on objectivity and replication Another important difference is in the expected audience. Statisticians assume that their viewers are already interested and want to provide structured information, often a carefully prepared argument. For statisticians, graphics are part of an explanation. Even exploratory analysis typically has a clear structure. In contrast, Infovis deisgners want to draw attention to their graphics and thus to the subject matter. For them, graphics are more of a door opener.",2,1,1,2
"175","Junkcharts Trifecta Checkup: The Definitive Guide","NOTE: The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?  The Question occupies the top corner because any data visualization project needs a worthy cause. Question needs to be well-posed, and interesting; the former focuses the search for appropriate data while the latter ensures an engaged audience. The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly. ",3,2,1,2
"176","Measurement and its Uses in Learning Analytics","this chapter covers the types of measurements, instruments, models and the validity and reliability of different instruments in learning analytics. ",0,0,0,5
"177","Ethics and Learning Analytics: Charting the (Un)Charted","this article covers the path of development for learning analytics and explains some unexpected consequences of certain algorithms during this process. It also calls for more attention in examining the ethics of data analysis. ",0,0,0,2
"178","Predictive Modelling in Teaching and Learning","this article brings out the challenges for policy makers to support non-computer scientists in predictive modeling activities as it argues that different algorithms exist for building predictive models such as linear regression, neural networks and etc.",1,1,0,3
"179","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","there are two goals addressed in this article: first is to build a predictive model by finding a combination of features that best predict outcomes and possess accuracy in predicting data; another is to build an explanatory model that identifies interpretable causal relationships between constructs that can either be observed or inferred from the data.",1,0,1,5
"180","Statistical graphics: making information clear – and beautiful","This paper presents the visualization of data followed by a set of principles, and they are: avoid distracting items, use informative colors, and keep the figure simple. The article also addresses that the figures presented in the paper is not aesthetically as pleasing as ones created by InfoVis, yet they do provide more granularity of the information compared to InfoVis.   ",0,2,-2,2
"181","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This paper aims at broadening discussion between statisticians who value arguments over aesthetics and graphic designers who place more value on various visualizations. With the understanding of both sides, the authors hope to see more integrated information visualizations that engage the audiences with not only the design but also the data and arguments. Some points made in this paper echos the blog post on Trifecta Checkup since they both convey important characteristics of good data visualizations.",1,0,1,2
"182","Junkcharts Trifecta Checkup: The Definitive Guide","This post is really informative and concise with the type of problems that data visualizations normally fall under. The crux is around these three aspects: question, data, and visualization. A good chart should address the question and premises (why is the question interesting and relevant&gt;), represent data rigorously and adapt visualization that neither overcomplicates the data nor undermines the messages and information.",1,2,-1,2
"183","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This paper uses hierarchical cluster analysis to illustrate how it can be used to predict early dropouts. In most learning analysis research, cluster analysis is used to identify certain patterns that can predict future outcomes.",0,1,-1,3
"184","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","this paper conveys how social network analysis can provide rich information, which has been overlooked in many undergraduate classroom. It also argues for a broader use of the rich contextual information offered by social network analysis for scholars and educators to understand learning behaviors. ",2,1,1,2
"185","Why Students Should Own Their Educational Data","this interview stressed the importance of individual achievement and differences instead of using the “average” to represent the overall performance.",0,1,-1,4
"186","Knowledge tracing: Modeling the acquisition of procedural knowledge","the article examines the empirical validity of knowledge tracing, which is a model in students and tutoring setting. the reviews have led to modifications in the process and the paper calls for further modifications to refine the performance level.",1,0,1,3
"187","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","this article addresses the increasing attention on education data mining and calls for more open and resourceful connection between the field of data mining and learning analytics in order to advance research and development in these fields. ",0,0,0,2
"188","Evaluating Machine Learning Models","this article goes in depth about classification metics which is the prediction of class labels with given input data. the accuracy measures how often the classifier makes the correct prediction, which is an example of what is known as micro-average. it also explains how evaluation metrics are tied to machine learning tasks and the different types are: regression, ranking, clustering, and etc.",1,1,0,5
"189","Why Opting Out of Student Data Collection Isn’t the Solution","this article provides guideline on how to keep educational datasets helpful to students without endangering their privacy, and argues that opt-out options should be offered to parents prior to the release of these data and parents and students should have the option of not participating.",0,0,0,2
"190","Why Is Measuring Learning So Difficult?","Learning is multidimensional and sometimes it is over simplified in order to capture it by data; when you engage and participate more effectively is the goal of learning, which is hard to measure in a contextual way; learning is also personal, as it is done by oneself, and the construct of learning as a cultural construct can not be measured because one’s thoughts is not easily accessible.There's also no proxy to measure the process of going from curiosity to memory, and from imagination to paraphrase. ",1,1,0,1
"191","Saturday Morning Breakfast Cereal","The humor of this comics is established on the basis of pushing boundaries. A few ideas I got from this comics in the perspective of data analysis in the field of education are:1. education is socially, politically and economically important 2. the political implication of policies should be considered when applying results from educational research and analysis (doesn't mean any results should be fabricated) 3. educational data can be interpreted in various ways through different values and purposes, then what are the premises for conducting and using educational research and data so that it does not overused or abused?",1,1,0,2
"192","Data wranglers: human interpreters to help close the feedback loop","This article presents how institutional learning about the quantity and interpretation of the available data can be improved. It does so by analysing and presenting learning analytics data by scholars and researchers who are in a position to make decisions and actions.",1,0,1,1
"193","Zuckerberg is ploughing billions into 'personalised learning' – why?","the article addresses the approach to replace human work by technology using the algorithms that provide users with content based on an analysis of their pas behaviors and demonstrated interest. It raises the question of whether personalised leaning is essentially the way to maximize student learning and if the loss of interpersonal connection is the desired future of learning analytics.",2,1,1,2
"194","Feature Selection","The video introduces answers on the question “why do we do machine learning?”, and the answer consist of two components the first is knowledge discovery, which includes interpretability and offering insights, and the other is related to the curse of dimensionality. ",0,0,0,5
"195","Chapter 1: Social Network Data","The web post discusses important components of social network data, which includes nodes, population, samples, boundaries, relations, multiple relations and etc. It also stresses that network analysis in statistical inference is about working out the probability distribution for statistics directly, and the fundamental structure for this is to compare how actors are similar to each other across attributions. ",1,1,0,4
"196","RStudio Cheat Sheets","this form covers the basic functioning of R markdown",0,0,0,1
"197","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","This article introduces a software (ASSISTment) that was introduced in New England to predict whether a student will go to college based on data of a student’s family economic background and other data on one’s exposure and access to college related information. The software turns out to have  68.6% of accuracy for prediction and is argued to have much potential for growth compared to other software on college enrollment prediction.",0,0,0,3
"198","Translating Learning into Numbers: A Generic Framework for Learning Analytics","this paper argues that leaning analytics can be used to understand and predict personal learning needs and performance, which can be an arbitrary statement if examined in relation to the article on ""why is measuring learning so difficult"". The paper also presents ethical issues of dealing with educational data and how they can be exploited if not used properly.",2,2,0,2
"199","The Big Five and Visualisations of Team Work Activity","This paper examines some dangerous consequences of the exploitation of education data by looking into the field of learning analytics. It also addresses how ethical complications of learning analytics can be addressed by potential policy reform. ",1,2,-1,2
"200","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","this article address the challenge of prediction for course evaluation as ""about the only pre-course factor that we found to be highly predictive is an intention, and even this predictive power is probably dominated by the fact that those who do not intend to complete usually do not""",0,0,0,4
"201","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","The article compares the performance of expert and matrix factorization and discovers similar patterns in the outcome produced by both sides, which proves the validity of matrix factorization. There also exists differences as the factorization approach performs better than the expert Q-matrix. ",1,0,1,5
"202","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This paper identifies the problem with large scale online classes whose breadth of content makes it hard to articulate briefly the key skill sets of knowledge it contains. The researchers build correlations between student performance and test items to produce a statistical model that is more efficient and accurate than the work done by human experts.",2,2,0,5
"203","Using data mining to predict secondary school student performance","the article approaches student performance using Business Intelligence/ Data Mining techniques, which uses data on student grades, family background information and demographics. These data were collected by questionnaires and Math and Portuguese were the two subjects involved in the data collection process. The research shows that besides past evaluations, student performances are also impacted by other relevant features such as parental influences, substance consumption and etc.",1,0,1,3
"204","Developing a generalizable detector of when students game the system","this paper is about a system that detects whether students are ""gaming the system"" by attempting to succeed in the environment through exploitation of the system's properties or are providing the correct answer by learning the materials and using their possessed knowledge. the paper further argues that an idea detecting system should accurately identify a category of behaviors that is known to be associated with a meaningful difference in student experience or outcomes.",2,1,1,5
"205","Big Data in Education","this series of videos introduces some skill sets in data mining like clustering and q-matrices as well as how to create them and interpret them.",3,0,3,5
"206","Cross Validation","cross validation is using a model that is complex enough to fix the data without causing problems in the test set.",1,2,-1,5
"207","Hands-On Programming with R","these three chapters are really informative and contains lots of detailed information on the basics of R (eg: vector, argument, script and etc)",0,0,0,1
"208","Principal Component Analysis explained visually","PCA appears to be more useful with three dimensions as it is hard to see through a cloud of data with three dimensions. The data can also be projected into 2D through a transformation and rotating the axes to find the best angel.",2,2,0,2
"209","Measurement and its Uses in Learning Analytics","In this handbook chapter, the authors make the case of the inseparability between making educational measurements and the measurer's educational philosophy's principles.",0,0,0,5
"210","Ethics and Learning Analytics: Charting the (Un)Charted","A number of ethics-related issues regarding the use of educational data and the creation of automatic measurements are raised in this paper. The authors also provide a list of principles, with the intention of influencing practioneers in the field towards ethical standards in the profession. ",1,0,1,2
"211","Predictive Modelling in Teaching and Learning","Best practices in creating and interpreting predictive models in EDM and LA (chapter from the handbook). Other video: introduction to ""big data"" in education.",1,0,1,2
"212","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Chapter from the handbook. They make the case that EDM and LA researchers should move into more explanatory models (seek to identify interpretable causal relationships between constructs) rather than obstinating about predictive power only.",0,0,0,5
"213","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Principles and best practices for how to visualize data.",1,0,1,2
"214","Junkcharts Trifecta Checkup: The Definitive Guide","Framework to check if your data representation: &gt; What is the QUESTION?&gt; What does the DATA say?&gt; What does the VISUAL say?",0,0,0,1
"215","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data visualizations can help teachers and administrators to make educational decisions.",0,0,0,2
"216","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Didn't read yet. Must do - looks like it provides great examples abou how SNA can generate insights into what happens in classrooms.",2,0,2,4
"217","Why Students Should Own Their Educational Data","Vast amounts of student data may let us move beyond designing educational materials for the average students (which is actually no one in reality).",0,0,0,3
"218","Knowledge tracing: Modeling the acquisition of procedural knowledge","knowledge tracing models (AS BKT) to predict test performance - based on the study of on online tutor system",0,0,0,3
"219","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","The text is a call for the interaction/union of researchers in the self-proclaimed fields of educational data mining and learning analytics.",0,0,0,2
"220","Evaluating Machine Learning Models","Evaluation metrics (precision, recall, etc.)",0,0,0,5
"221","Saturday Morning Breakfast Cereal","A funny story about interpreting correlation as causation. ",0,0,0,2
"222","Data wranglers: human interpreters to help close the feedback loop","Learning analytics can support human beings in taking better decision (while letting them still be in-charge)",2,0,2,1
"223","Zuckerberg is ploughing billions into 'personalised learning' – why?","""What is personalized learning?"" Great question! ""Personalized learning"" is a seductive idea. I have been recently wondering - why won't large philantropies focus on the core Technologies of education? Like textbooks, initial teacher training programs, or simply trying to answer ""what does a good math class look like?"" They also argue that personalized learning is already what good teachers do - and I agree with that. Japanese educator Akihiko Takahashi recommends that teachers read students' notebooks EVERY DAY after class. Can anything be more personalized than this simple analog practice?  ",7,0,7,2
"224","Feature Selection","Features should be interpretable!",0,0,0,5
"225","RStudio Cheat Sheets","Cheatsheets are awesome. My favorite is the data-wrangling cheatsheet, which I used a lot. I didn't use this one, though.",1,0,1,1
"226","Translating Learning into Numbers: A Generic Framework for Learning Analytics","A long and (maybe too large) framework for understanding the processes incurred in doing educational data analytics.",0,0,0,1
"227","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Application of data analytics to the case of a mooc (on recommender systems). Prettty meta-analytic!",1,0,1,3
"228","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","They showcase their predictive model for student skill mastery on a Mooc, testing it again previously known models and showing that their new model performs better.",2,0,2,5
"229","Big Data in Education","Explains what is the Q-matrix. I watched it innatentively and didn't get it.",0,0,0,5
"230","Cross Validation","Cross validation visually illustrated (train data vs. test data)",0,0,0,5
"231","Hands-On Programming with R","Reference book for programming in R. I did'nt use it - it just can't beat google search + stackoverflow.",0,0,0,5
"232","Principal Component Analysis explained visually","Visual explanation about how PCA is a change in the direction of your base vectors",0,0,0,3
"233","Statistical graphics: making information clear – and beautiful","Important insights are often hidden in the data, and they help drive the business. But the problem is that with raw data alone, you can't always see the truth. When you see the data presented in a visual form, patterns, associations, and other moments of understanding emerge, which are often not known by simply viewing the data.",0,1,-1,1
"234","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","if school can create a data system about student,school can help students to plan their personal interests reasonably, or provide them with opportunities in this regard. ",2,0,2,2
"235","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Previous social sciences often focused on the characteristics of individuals (or actors, such as enterprises and individuals), but ignored the relationship between individuals. The research of social network is just the method and perspective of the research of relationship. The biggest feature is to consider the interdependence between individuals, which is closer to the real society. These relationships are shown in the pictures as shown in the title, which can directly see the position of each actor in the network and the overall structure of the network.",0,0,0,4
"236","Why Students Should Own Their Educational Data","The student's score data is created by himself. Not every student wants his score to be known by everyone. So students should have their own data and let them decide how to use it.",0,0,0,3
"237","Evaluating Machine Learning Models","machine leaning working process: First, parameter data with known answers is fed to the model. Then, the algorithm is run and adjusted until the output (learning result) of the algorithm is consistent with the known answer. At this time, the amount of input data continues to increase to help the system learn and process more advanced computing decisions.",2,0,2,1
"238","Why Opting Out of Student Data Collection Isn’t the Solution","In 2014, the U.S. Department of Education released a new school and district guidance program on how to give parents and students a better understanding of what student data the school collects and how it is used.   In the guidance program issued by the privacy technology service center of the U.S. Department of education, schools and regions are required to actively inform how to use student data. The privacy technology service center of the U.S. Department of education is a one-stop source for educational stakeholders to understand data privacy, confidentiality and security measures related to student data.",1,0,1,2
"239","Saturday Morning Breakfast Cereal","cute comic and easy to understand",1,0,1,2
"240","Feature Selection","Machine learning is that the machine, through the input of big data, actively seeks and verifies the laws, and finally comes to the conclusion that the machine comes from the main solution to the problem, if there is a deviation, it will correct the error on its own.",1,3,-2,2
"241","Chapter 1: Social Network Data","if school want to collect social network data from student,they should make protection of student privacy during gathering data, 1: students can provide data on their own initiative only with the student’s consent,2: these data are summary of student’s life outside the school, so school can’t mandatory ask information.  ",1,0,1,2
"242","RStudio Cheat Sheets","R has a unique ggplot and data. Table (its syntax is too simple). Of course, the most significant feature of R is that its language features support ultra-high signal-to-noise ratio (especially when the data is clean and analyzed, the other times is the opposite!) , the same function takes up more than half of the characters in r than in Python.",2,0,2,1
"243","Translating Learning into Numbers: A Generic Framework for Learning Analytics","for internal limitations, its like very personal thing, for example that today I am sick and today is deadline for the assignment, so no matter",1,2,-1,1
"244","The Big Five and Visualisations of Team Work Activity","in general, big five theory is: Openness to experience Conscientiousness Extraversion Agreeableness Neuroticism https://en.wikipedia.org/wiki/Big_Five_personality_traits",0,1,-1,5
"245","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","matrix use a lot in stats, for me, I use matrix in multivariate linear regression a lot. For example, we usually represent a multivariate linear regression as:[Y]=[beta]^T*[X]+error matrix.",0,2,-2,5
"246","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","R is a language specially developed for statistics and data analysis, with various functions and functions,. The language is easy to learn. Although it is quite different from programming languages such as C (for example, the language structure is relatively loose, it is not necessary to define the variable type clearly before using variables, etc.), it still retains the basic logic and natural language style of programming languages.",1,1,0,4
"247","Using data mining to predict secondary school student performance","The school can draw the students' scores into a line chart, which can be very intuitive to see the changes of students' scores, so that teachers can see the fluctuations of students' scores in time and communicate with students in time.",0,0,0,3
"248","Developing a generalizable detector of when students game the system","Sandro.F and her colleagues found out that playing action video games will improve children's reading speed and attention abilities. For children, visual attention is crucial for learning letter identities of language knowledge. the improvement of attention can translate into better reading abilities and visual attention, “providing a new, fast, fun remediation of dyslexia that has theoretical relevance in unveiling the causal role of attention in reading acquisition”(Sandro.F, Simone.G, Milena.R, Simona.V, Massimo.M 2013).",3,0,3,5
"249","Cross Validation","Cross validation is a common method in machine learning to build models and verify model parameters. Cross validation, as the name implies, is the repeated use of data. The sample data obtained is segmented and combined into different training sets and test sets. The training set is used to train the model and the test set is used to evaluate the quality of model prediction",0,0,0,5
"250","Hands-On Programming with R","Learning statistics is the basis of learning R. This is the most important part of the whole R learning. Most of the time, you don't know where to find, how to use the parameters of a function, and more of the time, you don't know the principle of a statistical method, the meaning of which you don't even know what method to use. So learning statistics is often the key to learning R. after that, finding functions and how to use them are all idiotic. You don't need to write algorithms from scratch.",0,2,-2,1
"251","Principal Component Analysis explained visually","there are two main porperties of pca:Nearest reconstruction: the distance between the sample point and the hyperplane is close enough Maximum separability: the projection of sample points on this hyperplane can be separated as much as possible",1,0,1,4
"252","Measurement and its Uses in Learning Analytics","The mathematical part is hard to understand --&gt; need to read again.   curiosity: the similarities &amp; differences between PCA and factor analysis",0,1,-1,2
"253","Ethics and Learning Analytics: Charting the (Un)Charted","3 Issues:  The location and interpretation of data Informed consent, privacy, and the de-identification of data The management, classification, and storage of data  6 principles:  Learning analytics as moral practice - focusing not only on what is effective, but on what is appropriate and morally necessary. Students as agents - to be engaged as collaborators and not as mere recipients of interventions and services. Student identity and performance as temporal dynamic constructs - recognizing that analytics provides a snapshot view of a learner at a particular time and context. Students success as a complex, multidimensional phenomenon. Transparency as important - regarding the purposes for which data will be used, under what conditions, access to data, and the protection of an individual’s identity. That higher education cannot afford not to use data.  Student-centered learning analytics",5,2,3,2
"254","Predictive Modelling in Teaching and Learning","Predictive Models: 1. Linear Regression 2. Logistic Regression 3. Nearest Neighbours Classifiers 4. Decision Trees 5. Naive Bayes Classifiers 6. Bayesian Networks 7. Support Vector Machines 8. Neural Networks 9. Ensemble Methods",1,2,-1,3
"255","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","characters of explanatory models: 1. clean independent variables 2. dependent variable maps to a well-defined construct 3. fewer estimated parameters  ",1,0,1,5
"256","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Discovery goals: 1. giving an overview 2. conveying the sense of the scale and complexity of a dataset 3. exploration   Communication goals: 1. communication to self and others 2. telling a story 3. attracting attention and stimulation interest",0,1,-1,2
"257","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. Q: What is the QUESTION? D: What does the DATA say? V: What does the VISUAL say?",0,2,-2,2
"258","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","the big limitation is that it could only predict the local outcome. If we want to generalize it, we need diverse sample. (another point) -&gt; if the district develops fast, the quality of sample will change a lot -&gt; the pattern will also change a lot  ",1,1,0,1
"259","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social network analysis will be a good reference for SEL system, Educators could select and engage students into different group activities, based on their social network performance. For example, student who has a few interaction/relationship with others could be engaged into small group in which teacher as the leader of activity instead of students.",1,0,1,4
"260","Why Students Should Own Their Educational Data","I do think students should have their own study dataset. Although we are at the same college ( to some degree we should say that our qualities are similar), we are good in different fields (e.g., our different majors). Therefore, even if we are in the same class, some people will learn, understand, and master knowledge faster than others. However, it does not mean they are smarter people. It is possible that people have different study styles or processes so that makes differences. I think if people have their own study data, they would know much more about themselves and increase their confidence.",5,0,5,2
"261","Knowledge tracing: Modeling the acquisition of procedural knowledge","Most of these similar apps/programs focus on and are good at STEM education. However, how about art education? social skills? communication?  ",1,0,1,2
"262","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Technical, pedagogical, and social domains must be brought into dialogue with each other to ensure that interventions and organizational systems serve the needs of all stakeholders. Def. of EDM &amp; LAK EDM: Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in. LAK: the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs. Similarities &amp; Differences --&gt; Table 1 EDM &amp; LAK learn from each other.          ",1,1,0,2
"263","Saturday Morning Breakfast Cereal","Only one signal cannot represent the whole picture. Like in this comic that people who are good at disassembling and repairing clocks cannot represent that they could be engineers one day.",2,0,2,2
"264","Data wranglers: human interpreters to help close the feedback loop","""A learning analytics system may be used simply to attempt to achieve set goals (single-loop learning); greater value and insight will come if those goals themselves can be interrogated, challenged, and developed (double-loop learning)."" (*****Is Data Wrangler a information collector, but a personalized one? )",0,0,0,1
"265","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning: working with students to customise instruction to meet the student’s individual needs and interests.   3 flaws:    1 education also about acquiring general knowledge;   2 the real world life will not always be so accommodating;   3 children’s preferences are not fixed",3,1,2,2
"266","Feature Selection","Example: spam case knowledge discovery     Interpretability &amp; insight Curse of dimensionality",0,0,0,5
"267","Chapter 1: Social Network Data","First note on Zotero.; Q: the difference between ""mathematical"" and ""statistical or quantitative analysis"" is not clear yet.  ",1,0,1,4
"268","RStudio Cheat Sheets",".Rmd --&gt; knit --&gt; html",0,0,0,1
"269","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Framework for LA:    Stakeholders: Data subjects &amp;Data clientsObjective: ReflectionData: Protected dataset, Relevant indicators, Time scaleInstruments: Pedagogic theory, Technology, PresentationExternal limitations:Conventions: Privacy &amp; Ethics (Norms) &amp; Time scaleInternal limitations Required competences: Interpretation &amp; Critical thinking   ",1,2,-1,1
"270","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","useful lessons for future courses: 1. successful and motivating activity: the generation of a class-specific dataset used for the assignment. 2. personal test data 3. open-sourse infrastructure for distributing course  ",1,0,1,5
"271","Big Data in Education","1.1 Introduction Data mining &amp; Learning analytics For data miners: You will find that there are some current trends in data mining that are not represented. Some of those have not gotten here yet Some of those have not been very useful yet You will find some classic algorithms are not well represented; 1.3 Classifiers, Part 1 Step Regression --&gt; cut off 0.5 Logistic Regression Interaction effects--&gt; decision tree; 1.4 Classifiers Part 2 Decision Rules:     Sets of if-then rules (check in order)     -&gt; Take all remaining data points; Find the most common value for those data points; Make an ""otherwise"" rule using that   K* -&gt; predicts a data point from neighboring data points when data is very divergent  ; 2.5 Cross-Validation and Over-Fitting DEF: fitting to the noise as well as the signal  ; 4.2 Bayesian Knowledge Tracing goal: Measuring how well a student knows a specific skill/knowledge component at a specific time assumptions: 1. each item must involve a single latent trait ot skill 2. each skill has four parameters 3. commute 4. 2-state learning model 5. in problem-solving, the student can learn a skill at each opportunity to apply the skill 6. a student does not forget a skill, once know it  ; 7.1 Clustering K-Means clustering algorithm (simplest) strange positions --&gt; run several times; 7.2 Validation and Selection Distortion (Mean Squared Deviation) --&gt; does not work for choosing cluster size -&gt; Class-validation can't neither    ; 7.6 Knowledge Inference: Q-Matrix Knowledge Structure KC Model/Skill-item mapping   Automatic &amp; hand-development and refinement tool: Pittsburgh Science of Learning Center DataShop  ",11,5,6,1
"272","Cross Validation","IID Train act like test set",1,0,1,5
"273","Hands-On Programming with R","Chapter 1: The Very BasicAbility for a data scientist: Memorize; Recall; Perform; Repetitive tasks basic calculation (+ - * /) Objects: element-wise execution Functions: args(); default value; Sample with Replacement; replace = TRUE Writing Your own Functions: function() {} Arguments:values for variables  Scripts   Chapter 2: Packages and Help Pages Packages: ggplot2 --&gt; qplot (quick plots) Help Pages: ?xxxx More Help --&gt; R-help mailing list; Stack Overflow   Chapter 3: R objects Atomic Vectors: doubles, integers, characters, logicals, complex, raw Doubles: regular numbers Integers: L Characters: small pieces of text; strings Logicals: TRUE FALSE Complex: complex numbers (e.g., i Raw: raw bytes of data Attributes: put information; most common --&gt; names, dims, classes write.csv()    ",0,4,-4,1
"274","Principal Component Analysis explained visually","DEF: Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a data-set. It's often used to make data easy to explore and visualize. (Select the variables with strong connections)",2,0,2,2
"275","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","   School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8.    ",1,3,-2,3
"276","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","   Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.    ",4,1,3,4
"277","Why Students Should Own Their Educational Data","Interesting topic-- if you design a textbook to meet the average students' needs, you might not succeed in meeting anyone's needs. ""Technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.”"" ""education is decidedly not a functional market right now. There’s not enough transparency.""",3,0,3,2
"278","Knowledge tracing: Modeling the acquisition of procedural knowledge","I could not access this file.",0,0,0,1
"279","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","   The EDM community brings together an inter-disciplinary community of computer scientists, learning scientists, psychometricians, and researchers from other traditions.  Educational Data Mining and Learning Analytics and Knowledge developed separately. LA: bridging the computer science and sociology/psychology of learning. Leveraging human judgement is key; automated discovery is a tool to accomplish this goal. EDM: Automated discovery is key; leveraging human judgment is a tool to accomplish this goal.   ",2,0,2,2
"280","Why Is Measuring Learning So Difficult?","because learning is multidimensional. It's hard to simplify.",1,1,0,1
"281","Saturday Morning Breakfast Cereal","This comic addresses how findings can get blown out of proportion and changes can be made that aren't even accurate. They assumed causality when there was just a correlation. And it backfired in a very negative way.",1,0,1,5
"282","The Data Wrangling Cheatsheet","Note-- group by! Summarize",0,0,0,5
"283","Data wranglers: human interpreters to help close the feedback loop","   Closing the feedback loop to improve learning is at the heart of good learning analytics practice. However, the quantity of data, and the range of different data sources, can make it difficult to take systematic action on that data. Previous work in the literature has emphasised the need for and value of human meaning-making in the process of interpretation of data to transform it in to actionable intelligence.  This paper describes a programme of human Data Wranglers deployed at the Open University, UK, charged with making sense of a range of data sources related to learning, analysing that data in the light of their understanding of practice in individual faculties/departments, and producing reports that summarise the key points and make actionable recommendations.  The evaluation of and experience in this programme of work strongly supports the value of human meaning-makers in the learning analytics process, and suggests that barriers to organisational change in this area can be mitigated by embedding learning analytics work within strategic contexts, and working at an appropriate level and granularity of analysis.    ",9,1,8,1
"284","Zuckerberg is ploughing billions into 'personalised learning' – why?","what is personalised learning anyway? Because despite some politicians’ enthusiastic endorsements of personalised education, there’s still no clear definition.   modifying learning materials and teaching styles to accommodate the different ways pupils learn. Others see it as an antidote to top-down, centralised school bureaucracy, with the term “personalised” used interchangeably with individual, learner-centered or customised. It’s far from clear how teachers are supposed to support such personalised learning with personalised resources on a per pupil basis, nor who should bear the costs of doing so.",5,0,5,2
"285","Feature Selection","this video talks about feature selection.",0,0,0,5
"286","RStudio Cheat Sheets","Lots of important notes and information here. Bookmark/print for future reference. What does Shiny do in R Markdown? There's a lot on the R markdown sheet that I don't understand, but perhaps it'll be a good reference for the future.",1,0,1,1
"287","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","   In the fall of 2013, we offered an open online Introduction to Recommender Systems through Coursera, while simultaneously offering a for-credit version of the course on-campus using the Coursera platform and a flipped classroom instruction model. As the goal of offering this course was to experiment with this type of instruction, we performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course.  Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had sig- nificant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the program- ming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.    ",11,5,6,4
"288","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester’s worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the Q- Matrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2)skill models discovered by our method are interpretable, and (3)our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability.    ",17,2,15,5
"289","Chapter 1: Social Network Data","In this chapter, we will take a look at some of the issues that arise in design, sampling, and measurement for social network analysis. Our discussion will focus on the two parts of network data: nodes (or actors) and edges (or relations). We will try to show some of the ways in which network data are similar to, and different from more familiar actor by attribute data. We will introduce some new terminology that makes it easier to describe the special features of network data. Lastly, we will briefly discuss how the differences between network and actor-attribute data are consequential for the application of statistical tools.",1,0,1,4
"290","Learning Analytics Dashboards","I could not find this file on the syllabus.",0,0,0,1
"291","Measurement and its Uses in Learning Analytics","                   Measurement of latent variables is, after all, a noisy endeavor that can neverthe- less have high-stakes consequences for individuals and groups. This chapter is intended to serve as an introduction to educational and psychological measurement for practitioners historically, from more conceptual material about constructs, instruments, and sources of measurement error toward increasing technical detail about particular measurement                     ",0,1,-1,5
"292","Predictive Modelling in Teaching and Learning","    This article describes the process, practice, and challenges of using predictive modelling  analytics (LA) predictive modelling has become a core practice of researchers, largely with  chapter, we provide a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process,     ",0,0,0,3
"293","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","    In the statistical modelling of educational data, approaches vary depending on whether  combination of features that best predict outcomes; they are typically assessed by their  causal relationships between constructs that can be either observed or inferred from the data. The vast majority of educational data mining research has focused on achieving pre-  -  such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process.  Keywords: closing the loop, cognitive models     ",1,0,1,5
"294","Statistical graphics: making information clear – and beautiful","    The obvious way to present information is in a graph. But not all graphs are created equal. A well-designed graph can make clear what an ill-thought-out one conceals. Jarad Niemi and Andrew Gelman present visualisations of a measles epidemic.     ",1,1,0,2
"295","How to display data badly","This article give examples of poorly displayed data/graphs.",0,1,-1,2
"296","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?  The Question occupies the top corner because any data visualization project needs a worthy cause. I'd like the Question to be well-posed, and interesting; the former focuses the search for appropriate data while the latter ensures an engaged audience. The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly. ",4,2,2,2
"297","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","1. Similarities  data-intensive approaches to education improve education by improving assessment improve the quality of analysis of large-scale educational data  2. Distinctions  type of discovery: LAK (leverage human judgment); EDM (automated discovery) type of adaption: LAK (inform and empower instructors and learners); EDM (automated adaption) frameworks: LAK (Holism); EDM (Reduction)   3. Call for communication and collaboration",0,0,0,2
"298","The Data Wrangling Cheatsheet","Data Wrangling Reshaping data gather (): wide to long spread (): long to wide separate()/unit() Subset Observations (Rows) Subset Variables (Columns) Summarize Data Make New Variables Group Data Combine Data set  ",0,0,0,1
"299","Data wranglers: human interpreters to help close the feedback loop","   Data wranglers: human interpreters to help close the feedback loop    Introduction ""...sense-making and social processes are important because of the complexity of the data and because “learning is a complex social activity”    “A learning analytics system may be used simply to attempt to achieve set goals (single-loop learning); greater value and insight will come if those goals themselves can be interrogated, challenged, and developed (double-loop learning).” Context and role of data wranglers 1. Survey feedback data from students, gathered at the end of their course. 2. Activity data from the VLE/LMS (Moodle). 3. Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums). 4. Aggregated completion, pass rate and demographic data.    The role of the Data Wrangler is not only to analyse the data, but to increase the familiarity of academics with the data sources, to build learning analytics capacity as part of a Community of Practice.   Evaluation           ",0,2,-2,1
"300","Measurement and its Uses in Learning Analytics","Chapter3: Measurement and its uses in learning analytics 1. What is measurement? Philosophy and Basic Ideas Construct (latent variable) Steven's (1994) definition of measurement: ""the assignment of numerals to objectives or events according to rules"" Model-based reasoning means accepting a simplified representation of a system. The challenge remains to come up with useful models or useful measurement rules. A partial list of learning analytics:     A. intelligence (e.g., the Stanford–Binet Intelligence Scale), B. scholastic aptitude (e.g., that SAT test), C. academic achievement (numerous examples include both large-scale tests and course exams), D. personality (e.g., the “big ve” factor model; Digman, 1990), E. achievement-goal orientation (e.g., Midgley et al., 2000), F. achievement emotions (Pekrun, Goetz, Frenzel, Barchfeld, &amp; Perry, 2011), G. grit (Duck- worth, Peterson, Matthews, &amp; Kelly, 2007), H. self-theories of intelligence and xed/growth mindset (Dweck, 2000; Yeager &amp; Dweck, 2012), I. intrinsic motivation (Deci &amp; Ryan, 1985; Guay, Vallerand, &amp; Blanchard, 2000), J. self-regulated learning and self-ef cacy (e.g., Pintrich &amp; De Groot, 1990), K. learning power (Bucking- ham Shum &amp; Deakin Crick, 2012; Crick, Broadfoot, &amp; Claxton, 2004), L. crowd-sourced learning ability (Milligan &amp; Grif n, 2016). Measurement Instruments tests or questionnaires-a matter of efficiency and standardization Source of Error in Measurements     People’s responses to an instrument may not faithfully re ect their abilities, attitudes, or other constructs of interest.     The inherent non-repeatability Reliability-a measure of the consistency of scores         Reliability coefficient-alpha [0,1] Test-retest reliability inter-rater reliability?     *Effort in improving the reliability of a scale can often outweigh the bene t of recruiting larger samples. Validity     Validity refers to the degree to which evidence and theory support the interpretations of test scores for proposed uses of tests ... It is incorrect to use the unqualied phrase ‘the validity of the test’” Measurement Models  2. Specific Uses of Measurement Models in Learning Analytics Factor Analysis (Mulaik, 2009) Exploratory factor analysis (EFA): determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development. Requires a number of methodological decisions Principal components analysis (PCA): a dimensionality reduction technique, which can result in erroneous conclusions about true factor structure.     Confirmatory factor analysis (CFA): a complementary set of techniques to test a theoretically proposed factor model by examining residuals between expected and observed correlations.Used to reject a model. Latent Class and Latent Mixture Models-Dedic, Rosenfeld, and Lasry (2010)         Dedic, Rosenfeld, and Lasry (2010) used latent class analysis to understand the distribution of physics misconceptions based on students’ wrong answers on a physics concept test. Item Response Theory (IRT)-?     Item response theory distinguished itself in the historical development of testing theory by modelling individual person-item interactions rather than total test scores, as in classical test theory. Growth model     Growth models apply any time a latent trait is changing systematically between measurements. Focus on cognitive ability domains. 3. Explanation and Prediction Education data mining; middle space between explanatory and predictive modelling.                              ",5,5,0,5
"301","Ethics and Learning Analytics: Charting the (Un)Charted","Chapter 4: Ethics and Learning Analytics: Charting the (Un)Charted Setting the context: Why ethics is relevant 1) potentially conflicting interests and 2) claims of a range of stakeholders (students and institutions) Establishing ethical principles: how far have we come? Categories of ethical issues-Slade and Prinsloo (2013) 1. The location and interpretation of data 2. Informed consent, privacy, and the de-identification of data 3. The management, classification, and storage of data Principles-Slade and Prinsloo (2013) 1. Learning analytics as moral practice 2. Students as agents 3. Student identity and perfomance as temporal dynamic constructs 4. Student success as a complex, multidimensional phenomenon 5. Transparency as important 6. The higher education cannot afford not to use data-? Six elements that could form a basis for a student-centered learning analytics: 1. Students should be able to make informed opt in/out decisions 2. Students should know what data is collected and how it is used 3. Students should ensure that their personal data records are complete and up to date 4. The harvesting of data must not harm student progress 5. Algorithmic output should be subject to human review 6. Learning analytics essentially provides context and time-specific, provisional, incomplete pictures of students, and algorithms should be frequently reviewed and validated Recent Development in Ethical Frameworks OU: 1. Learning analytics is an ethical practice that should align with core organizational principles. 2. The OU has a responsibility to all stakeholders to use and extract meaning from student data for benefit of students where feasible 3. Student should not be wholly defined by their visible or our interpretation of that data 4. The purpose and the boundaries regarding the use of learning analytics should be well defined and visible 5. transparent 6. students should be engaged as active agents 7. Modelling and interventions based on analysis of data should be sound and free from bias 8. Adoption of learning analytics within OU requires broad acceptance of the values and benefits and the development of appropriate skills across the organization.",9,4,5,2
"302","Why Students Should Own Their Educational Data – Wired Campus - Blogs - The Chronicle of Higher Education","Why Students Should Own Their Educational Data L. Todd Rose- ""Center for Individual Opportunity"" 1. average learber: we know now that you can’t actually tell anything in population studies about any individual in that group. 2. Aggregate data was all we had. trend: looking for personal patterns across dimensions. 3. In classroom: personality and learning varies across contexts. 4. MOOCs with AI can transform education? The user should own their data. A third party who can protect learner data.  ",1,0,1,2
"303","Saturday Morning Breakfast Cereal - Clock","""War is politics by other means. Once education is politics, it must have soldiers by other means"" question: what is the role of data scientists in education policies?",0,0,0,2
"304","Video: Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult? 1. Learning is multi-dimensional. For capturing data, we might simplify the process of learning too much. 2. Learning is too broad. Knowledge is rooted in the context where it is used. 3. In different fields, learning is measured differently. For example, in computer science, learning is easier to be measured with all kinds of soft wares and tools, while in humanity and social sciences, it's much harder. 4. Learning is too personal. Learning is difficult to define and measure.  5. What is the meaning of ""measure""? No reliable indicators. 6. Measure of competence or measure of learning? How to assess learning in different time points? 7. The role of analytics: divising a media to reveal to learners what they are learning that they may not be aware of. Reveal to the learner their potential.  ",2,2,0,1
"305","Shiny - The R Markdown Cheat sheet","R markdown Cheatsheet Workflow: 1. open a new .Rmd file 2. Write document 3. knot document to create report 4. Preview Outpur 5. Publish 6. Examine build log 7. Use output file. Interactive documents:? 1. add runtime: shiny to the YAML header 2. call shiny input functions to embed input objectives. 3. call shiny render functions to embed reactive output. 4. render with rmarkdown:: run or click on Run Document in Rstudio IDE Embed code with knitr syntax Inline code: r&lt;code&gt; code chunks global options: opts_chunk$set() Parameters 1. add parameters 2. call parameters 3. set parameters Create reusable template Table suggestions Citations and Bibliographies      ",0,0,0,1
"306","Translating Learning into Numbers: A Generic Framework for Learning Analytics","   Translating Learning into Numbers: A Generic Framework for Learning Analytics    Critical dimensions of learning analytics soft issues-questions to consider:    Who is the target group for LA? What are we trying to achieve? How do we deal with privacy and data protection? Proposed design framework for learning analytics         note: six dimensions 1. Stakeholders Information flow:   students: personalized recommendations teachers: course monitoring systems, better curriculum design institutions: monitor the performance of students, evaluate their courses and improve outcomes 2. Objectives Reflection: ""quantified self"" Prediction: predicting and modelling learner activities 3. Educational data 4. Instruments ""LA takes advantage of so-calledinformation retrieval technologies like educational data mining (EDM; cf. Romero et al., 2008), machine learning, or classical statistical analysis techniques (cf. Figure 1), but other techniques may also be considered relevant, e.g., social network analysis (cf. Buckingham &amp; Ferguson, 2011) or Natural Language Processing (NLP)."" 5. External constraints Ethical and privacy issues 6. Internal limitations Human factors: competences and acceptance The place of pedagogy in learning analytics framework         ""LA collects snapshots taken from educational datasets. These snapshots can be used to reflect or predict, in order to make adjustments and inform interventions, either by a human or by a system. Apart from offering efficiency benchmarking and business information for education providers, new support services for learning and more qualitative personal experiences can be achieved.""             ",7,3,4,1
"307","Measurement and its Uses in Learning Analytics","Learning analytics can either support current educational practices or challenge them. Six questions to consider when creating learning analytics to make sure the tool will help learners and not hinder them:  What are we measuring? How are we measuring? Who is the assessment/analytic for? Why is this knowledge important to us? Where does the assessment happen? When does the assessment and feedback occur?   ",1,1,0,2
"308","Ethics and Learning Analytics: Charting the (Un)Charted","Policies and ethics regarding with institution using student data have not kept pace as learning analytics becomes more establishes and needs to use student data. It's been agreed that high education institution have the right to collect and use student information but no one can agree on if student can and/or should consent to having their information collected.",2,0,2,2
"309","Predictive Modelling in Teaching and Learning","Predictive analytics are a group of techniques used to make inferences about uncertain future events. The goal of explanatory modelling is to use all available evidence to provide an explanation for a given outcome. The purpose of predictive modeling is to create a model that will predict the value of new data based on observations. Unlike explanatory modeling, predictive modeling is based on the assumption that a set of known data (referred to as training instances in data mining literature) can be used to predict the value or class of new data based on observed variables. Explanatory modeling does not many any claims about the future, while predictive modeling does.",0,1,-1,3
"310","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Educational data mining research has largely focused on developing two types of modes: the statistical model and the cognitive model. Statistical models drive the outer loop of intelligent tutoring system based on observable features of students' performance as they learn. Cognitive models are representations of the knowledge space underlying a particular educational domain. Cognitive models map knowledge components to problem steps or task on which student performance can be observed. This mapping provides a way for statistical models to make inferences about students' underlying knowledge based on their observable performance on different problem steps.",0,2,-2,5
"311","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Infovis and statistical graphics approaches designing graphs differently. Infovis are interested in grabbing the readers' attention while statisticians are interested in making sure the readers can get the most data out of the graph. Infovis does a great job of creating unique and interesting graphs. The only negative part is that the graphs they create may be hard to interpret or there isn't much to interpret. Statistician on the other hand, usually create more ""boring"" graphs, like bars and charts, but you are able to decipher the data from the graphs. The author believes if both groups work together, they can come up with interesting graphs that can also be useful to readers'.",3,2,1,2
"312","Junkcharts Trifecta Checkup: The Definitive Guide","Kaiser Fung provides a ""Junk Charts Trifecta Checkup"", which is a framework to think about when viewing data visualization. It involves three questions to think about viewing data visualization:  What is the question? What does the data say? What does the visual say?  This makes it easier to critique any graphs that infovis or statistician creates. The only part this framework is missing is that it doesn't think about how can we make the graph more visually appealing. The visual may represent the data in a concise, clear manner but it may be boring to the viewer so it doesn't grab their attention.",4,3,1,2
"313","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This study took a look at longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district, demonstrates using hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Hierarchical cluster analysis and pattern visualization methods provides an useful way to visualize and assess an entire disaggregated data history pattern for a student in comparison with every other student's data pattern in a sample. The clustergram allows for the visualization and interpretation of every data point.",0,0,0,3
"314","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article gives a good insight of how we can use social network to investigate classroom-scale hypotheses to ultimately inform better instruction. Reading about why R has one of the most complex statistical capabilities for SNA and why matrices is a powerful way to store and represent social network data, helped tied what we're learning in class to this article. It also gives a good overview on how to think about collecting and analysis data in SNA.",3,1,2,4
"315","Why Students Should Own Their Educational Data","Mr. Rose believes there are no ""average"" people so when anything is designed for the ""average"" person, it actually ends up not fitting anyone. Instead, people have ""jagged profile"", meaning people are strong and weak in different areas, even in learning. If teachers knows what type of learning style he/she has in the classroom, they might be able to group students in different learning style to try to reach more students in the lesson. If students own their educational data, they will have more ownership on how they learn.",1,1,0,2
"316","Knowledge tracing: Modeling the acquisition of procedural knowledge","All students can achieve expertise in a domain if two conditions are met:  the domain knowledge is appropriately analyzed into a hierarchy of component skills learning experiences are structured to ensure that students master prerequisite skills before tackling higher level skills in the hierarchy   ",4,0,4,3
"317","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Learning Analytics (LAK) and Educational Data Mining (EDM) should communicate and work with each other to help broaden their research since this collaboration can only help both fields. Both communities are working towards improving the quality of analysis of large-scale educational data. EDM focus on automated discovery while LAK has a greater focus on leveraging human judgment.",2,0,2,2
"318","Evaluating Machine Learning Models","Evaluation metrics are tied to machine learning tasks. Classification is about predicting class labels given input data. In binary classification, there are two possible out put classes. In multiclass classification, there are more than two possible classes.",0,0,0,5
"319","Why Opting Out of Student Data Collection Isn’t the Solution","Fair Information Privacy Principles (FIPPS) require data collectors to specify the purpose for which they are collecting data, and to seek informed consent for the collection and use of this data. Consent can be implied when the purpose of collection is obvious and the primary reason for collecting the data but when the use of data is unrelated, additional permissions are needed. Opt-out rights should be an opportunity for parents to decline uses of data that are secondary but not for primary uses of education policy issues.",2,1,1,2
"320","Why Is Measuring Learning So Difficult?","Difficult to measure learning because learning in one of the most multi-dimensional things out there. One of the problem with measuring learning is that sometimes we have to simplify it too much in order to capture data or to capture understanding of it so we can use it. Understanding is one of the cognition word for things we can't measure but we do know certain kinds of things can demonstrate understanding.",0,2,-2,1
"321","Saturday Morning Breakfast Cereal","This comic shows that we shouldn't jump to any conclusion from data so quickly without considering everything related to the data. Once we realized there was more to the data and what we initially analyzed and summarized to others was not the entire story, it may be too late to change the policy. This shows how important it is to make sure we have all the information and analyzed why the data is showing that way before sharing with others.",0,0,0,2
"322","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers are a group of academics who analyze data on student learning. They work with faculty members to provide reports with actionable recommendation based on the data. Eventually, faculty members should be more comfortable retrieving and analyzing data themselves. The feedback from faculty members was mostly positive, saying they value the process. Some negative feedback from the faculty was that they wanted more data, the analysis and recommendations weren't consistent, and data quality.",6,0,6,1
"323","Zuckerberg is ploughing billions into 'personalised learning' – why?","The authors says there is three major flaws to Zuckerberg's idea of personalized learning:  Feeding children only the content they're interested in, we may end up with many specialist and few generalists While learners may cope poorly with trying to learn in a way not suited to them, in the real world life will not always be so accommodating To predict content relevant for children there needs to be sensitive, human-directed input - not automation  I'm not sure where the author's idea that personalized learning will only be feeding children they're interested in since that wasn't what happened when I worked at Summit Public School, which used Personalized Learning Platform developed with Facebook's engineers as part of Chan Zuckerberg Initiative's Personalized Learning Platform. One thing PLP does well in the subject of math, is teaching procedural knowledge. You still need teachers to conceptual knowledge. PLP is a way to assist and enhance teacher's teaching but not to replace teachers.",3,2,1,2
"324","Feature Selection","Feature selection is good for interpretability and insight.  Curse of dimensionality says that the amount of data you need grows exponentially in the number of feature you have. Feature selection will help go from a whole bunch of features to a few feature. The goal is to take a bunch of feature, because you think they are important, and then apply some kind of algorithm to get to just the important feature. This way, you will understand your data better but you will have an easier learning problem.",4,1,3,1
"325","Chapter 1: Social Network Data","Social network analysts use a specialized language for describing the structure and content of the set of observations they use. They emphasis on how actors are located in the overall network and how the whole pattern of individual choices gives rise to more holistic patterns. Network data set is similar to conventional data except network data focus on actors and relations while conventional data focus on actors and attributes. Network data analysis focus on the relations among actors and not individual actors and their attributes. Network data tend to study the whole populations by means of census, rather than by sample.",0,0,0,4
"326","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Prediction is a data that will pose a problem to acquire since the university and professor may already have data on students predicting how well each student will do in a class based on past data. Institution and teachers also have data on students in granular and high level view that shows how current and past students have perform in the classroom that we do not have access to. There have been more data created with increase in technology. This has lead Greller and Drachsler to identify six dimensions of Learning Analytics to make sure we are using data in an educationally beneficial way. The six dimensions of the Learning Analytics framework is stakeholders, objectives, data, instruments, external constraints, and internal limitations. This descriptive framework can later be developed into a domain model. With this framework, designers of analytic process can implement what is technically possible and legally allowed, but to also consider holistically the outcomes for stakeholders and the consequences for the data subjects. Learning analytics need to consider all six dimensions to provide the optimal outcome for the data processed. _____________________________________________________________________________________________________________________________________________________________________________________________ Proposed Design Framework for Learning Analytics  6 dimensions: stakeholders, objectives, data, instruments, external constraints, internal constraints  Stakeholders  Includes data clients data subjects. Data clients are the beneficiaries of the LA process who are entitled and meant to act upon the outcome. Data subjects are the suppliers of data. Main stakeholder groups of LA in formal learning institutions are learners, teachers, and educational institutions.  Objectives  Main opportunities for LA as a domain is to unveil and contextualise hidden information out of educational data and prepare it for the different stakeholders. Reflections is the critical self-evaluation of a data client as indicated by their own datasets in order to obtain self-knowledge. Prediction can be used for predicting and modelling learner activities, which can lead to earlier intervention or to adaptive services and curricula.  Educational Data  One of the major challenges LA researchers faces are the availability of publicly available  datasets to evaluate their LA methods. Idealised datasets remains the biggest challenge for analytics.  Instruments  Information retrieval technologies like educational data mining and machine learning, can contribute tailored information support system to the stakeholders and report on demand. Competing methods, technologies and algorithms applied to the same set of data, will result in different outcomes and thus may lead to different consequences in terms of decision making based on these outcomes.  External Constraints  Two subdivision for external constraints: conventions (such as ethics, personal privacy, and similar socially motivated limitations) and norms (restricted by laws or specified mandated policies or standards)  Internal Limitations  Two main internal limitations are competences and acceptance. Application of learning analytics requires new higher-order competence to enable fruitful exploitation in learning and teaching. Ways to increase acceptance is vitally important also in order to produce usable outcomes. ",6,9,-3,1
"327","The Big Five and Visualisations of Team Work Activity","In order for a group of students to learn to work collaboratively, they need to put effort in not only task-work but also teamwork. The elements that make up teamwork, independent of the task a team has to perform are:  Team leadership Mutual performance Backup behavior Adaptability Team orientation ",1,0,1,2
"328","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This massive, online, open course attracted a diverse group of students that comes to the course with different goals and intentions. Predicting course completion is hard. The only precourse factor that they found to be highly predictive is intention. Predicting knowledge gains is even harder. The factors that were predictive were all related to effort, prior courses, and baseline knowledge.",1,1,0,4
"329","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","The ALS factorization method offers a promising means of deriving Q-matrices from data given an expert defined Q-matrix to start with. ALS Q-matrix derived generates slightly better predictive item outcome performance supports the hypothesis that the discrepancies between this matrix and expert matrix are potentially valuable hints towards improving the expert Q-matrix.",2,0,2,5
"330","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","When designing and implementing large-scale online courses, defining a set of skills to be learned and having individual skills associated with particular part of course contents often becomes quite challenging. ePHINPHANY is a collection of data-mining techniques to automatically refine (or rebuild) a human-crafted set of skills, initially given by course designers and developers. The most important goal of ePHINANY is to provide constructive feedback to online course designers and developers for iterative course improvement. ePHINANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction.",5,1,4,5
"331","Using data mining to predict secondary school student performance","Several studies have used Business Intelligence (BI) / Data Mining (DM) methods to improve the quality of education and enhance school resource management. The studies found that it is possible to achieve a high predictive accuracy, provided that the first and/or second school period grades are known. This confirms that student achievement is highly affected by previous performances.",0,1,-1,3
"332","Developing a generalizable detector of when students game the system","Gaming has been documented in many interactive learning contexts beyond intelligent tutors but so far all gaming detectors have been developed within the context of intelligent tutoring systems. Meta-analysis provides a relatively easy technique for comparing models across different contexts, or aggregating measures of model accuracy across contexts. The development of accurate detectors of student affect may increase the accuracy of future systems which detect gaming the system.",0,0,0,5
"333","Big Data in Education","Clustering is a type of structure discovery algorithm. In cluster, you have a large number of data points and you want to find what structure there is among the data points. Clustering tries to find data points that ""group together"". Clustering works for and is effective in large feature spaces. More clusters almost always leads to smaller distortion. Q-Matrix is a table where each row is an item and each column is a skill. Also called a KC (knowledge component) model or a skill-item map. Every item requires at least one skill. How to get a skill-item mapping:  automatic model discovery  learn the mapping between items and skills solely from data   hand-development and refinement  a domain expert creates the Q-Matrix using knowledge engineering   hybrid approaches  Strategies for Q-Matrix Refine  try to smooth learning curves look for skills with no apparent learning look for problems with unexpected error rates  Educational data mining and learning analytics are exploring the ""big data"" available on learners and learning. Their goal is to promote new scientific discoveries and to advance learning sciences, to better assess learners along multiple dimensions, and for better real-time support for learners.",10,3,7,5
"334","Cross Validation","The goal is always to generalize. The test set is a stand in for what we don't know what we're going to see in the future. Fundamental assumptions for algorithms is that data is independent and identically distributed.",0,0,0,5
"335","Hands-On Programming with R","RStudio gives you a way to talk to your computer. R gives you a language to speak in. The code you type is called a command because it will command your computer to do something for you. The line you type it into is called the command line. R will not run anything that follows a hashtag on a line. Hashtags are useful for adding comments and annotations to your code. Humans will be ale to read the comments but your computer will pass over them. The hashtag is known as the commenting symbol in R.",0,0,0,1
"336","Principal Component Analysis explained visually","Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize. PCA is more useful with three dimensions because it's hard to see through a cloud of data.",1,2,-1,2
"337","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This paper discussed the importance of communication and collaboration between Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK), as data in the education field is drawing more and more attention. One of the major reasons to this rising interest in data in education is that through extracting and analyzing these data, it allows scientists to understand better and find ways to improve learning processes in formal settings, as well as non-traditional learning environments, such as websites. Both EDM and LAK serve important roles, however, they do have their own similarities and differences. To help both communities grow, this paper outlines benefits both communities will gain through communication and collaboration. The most significant similarity will have to be their shared goal of using data and methods to understand and optimize learning. Some of the areas in the education field that scientists can be informed of and make adjustments to are assessments, the way problems are understood, and ways in which interventions are planned and selected. On the other hand, one major distinction between the two communities would be their approach to systems. EDM typically breaks down a system into parts, whereas LAK views the system as a whole.",4,2,2,2
"338","Hands-on programming with R","Ch. 1 Project 1: Weighted Dice The existence of computer has spared us from having to memorize and recall data and to perform complex calculations quickly. With computer’s aid, we could put our energy on understanding the data and making decision. This chapter introduced the first project that involves R code to build a dice. Through this exercise, we will learn an overview of the components of R — objects, data types, classes, notation, functions, environments, if trees, loops, and vectorization.   Ch. 2 The Very Basics In the dice exercise, the RStudio is introduced as the application to run R codes. In RStudio, the code we type is a command given for the computer to perform something. A line we type in is called a command line. The exercise provides a step by step guide that helps learners familiarize with the symbols and functions that operate in RStudio.   # à commenting symbol. Allows people to add comments and annotations to code. By pressing ctrl + c, you can cancel a command : à allows you to create group of numbers from 1 to 6 (ex: 1:6 à 1, 2, 3, 4, 5, 6) R Object à just a name to call up stored data. For example, you can save data into object like a and b. Wherever R encounters the object, it will replace it with the data saved inside.   R object naming rule à You can name an object in R almost anything you want, but there are a few rules. First, a name cannot start with a number. Second, a name cannot use some special symbols, like ^, !, $, @, +, -, /, or *:     Ch. 3 Two tools are introduced in this chapter: repetition and visualization. These functions are part of the R package, which consists of many useful tools.   Replicate function à does the repeating qplot function (ggplot2 package)à visualize à https://cran.r-project.org    ",2,6,-4,1
"339","Measurement and its Uses in Learning Analytics","Making inference from the metrics  Disagreements in defining data analytics    Being clear on what specifically that you want to do --&gt; in a loop as you have to keep going back and restate It    Characteristics   Should be specific/tightly defined  Should be measurable  Should be attainable  Should be time-limited (setting a time frame)  ",1,0,1,1
"340","Predictive Modelling in Teaching and Learning","Ground truth: data that is available, relevant, most trustworthy to train your model Baseline: initial measurement Gold standard: comparative measurement   Precision &amp; Recall (Sensitivity)   Precision: True Positive/ True positive + false positive Recall: True positive/true positive + False negative (how many times we miss)",3,1,2,5
"341","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Quantified self vs. quantified student    Quantified self (QS)  Physical/biological data Optimization  Multi-Modal Learning:   The use and integration of different modalities (sensors) present in learning activity. Having multiple sensors doesn’t necessarily mean it’s effective.  Having students create data and inviting them to participate and interpret the data they collected and documented.",1,0,1,2
"342","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Infographics --&gt; turning numbers into useful information   Visualization   Creative decision (how is this going to make an impact) Technical decision (certain types of data) Demonstrate data demographically (usually a select of things, never everything) to demonstrate a point --&gt; to stand out Don’t distort the data to make a point Take context into considerations  Description, exploration, tabulation, decoration  Decoration --&gt; the background Tabulation --&gt; to compare groups Exploration  Description --&gt; Show overall trends, characteristics of situations ",0,1,-1,1
"343","Junkcharts Trifecta Checkup: The Definitive Guide","“Chartjunk” à portions on chart that are unnecessary. Serves no purpose or has no messages. Non-informative What's trifecta checkup?  It's a framework for data visualization criticism. It helps you articulate your opinions and criticism better.  Trifecta Checklist:  What is the question?  What's the reason behind the project. What's the problem statement and is there really a problem?  What does the data say?  The data should be relevant to the question. To increase relevance, we can reduce noise and remove errors in the data.  What does the visual say?  The visual element should represent the data and reflect the the question directly.    8 types of critiques:  - the trifecta - Type Q (Single) - Type D (Single)  - Type V (Single)  - Type QD (double) - Type QV (double)  - Type DV (double)  - Type QDV (Triple)",1,6,-5,2
"344","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","3DM: Data driven decision making  --&gt; a powerful practice that teachers and admins utilize to gather data to inform decision making. From the data they gathered, they can gain new insights and improve on their instructions in class. The data could also help the school admins decide on which area requires more attention and allocate more resources to meet the needs. Hierarchical Cluster Analysis:   ""Multivariate statistical method that uses a series of nested correlation calculations, or distance measures, to reorder a dataset such that “clusters” of data patterns are closest to each other in a list"" HCA also provides a means to draw what is known as a cluster tree ",1,0,1,3
"345","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research"," Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. Social networks have been successfully used to test and create paradigms in diverse fields ""Network analysis entails two broad classes of hypotheses: those that seek to understand what influences the formation of relational ties in a given population (e.g., having the same major, having relational partners in common), and those that consider the influence that the structure of ties has on shaping outcomes, at either the individual level (e.g., grade point average [GPA] or socioeconomic status) or the population level (e.g., graduation rates or retention in science, technology, engineering, and mathematics [STEM] disciplines)."" SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of nodes, and what, if any, the impacts are of these relationships on nodes.   Unipartite: when the network only consists of one node. bipartite: network that links nodes to the group which they belong. The most basic measurement in network analysis is network density. Density:  The density of a network is a measurement of how many links are observed in a whole network divided by the total number of links that could exist if every actor were connected to every other actor. Density is a global metric that simply indicates how many ties are present. 1 is as high as the density can go Gross measure of how many connections there are. Allows comparison between two sets of connections.    Centrality:  Degree centrality represents the total number of connections a node has. Degree centrality is often useful for examining the equity or inequity in the number of ties between individuals and can be done by looking at the degree distribution, which shows the distribution of degrees over an entire network. Tells you who controls the network Calculate the distance between the nodes     ",1,1,0,4
"346","Why Students Should Own Their Educational Data","Most teaching and learning standards make the assumptions that learners have average skills across content areas. Keeping ""average learners"" in mind when designing instructions is not sufficient to ensure that learners will actually attain anything. Rose proposed that technology can play a role in helping educators identify learners' needs more specifically. not only does technology provide data collected on students, it also allows educators to customize teaching materials accordingly. There has been a notable shift in terms of population studies and the patterns derived from it. In the past, people firmly believed that by study a population would help them chart out patterns and understand individuals better. Now, that practice has shifted to analyzing individual patterns instead of studying an aggregated data. Back then, we could only study aggregated data because there wasn't enough data to be extracted from. People look for ""personal patterns"" across dimensions. This further led us to personality research and its impact on the way we behave. It is proved that a person's personality and his/her learning vary across contexts. The data gathered predicts the person's behaviors. Food for thought... --&gt; What is it that you can do face-to-face that you can't do online? To foster a more personalized learning experience, it is important for the learners to own their data, so they have access to data on the way they are learning. However, this can be difficult to achieve as the education field is not yet ready for this type of transparency.        ",4,1,3,2
"347","Data wranglers: human interpreters to help close the feedback loop","With the amount of data and the wide range of sources collected, it requires human interpreters to process and transform the data into actionable intelligence. Learning analytics serves as a feedback loop that informs people about learners and their contexts. With the gathered information, interventions are created in hope of improving learning. Since learning itself involved complex activities, it is important that the data go through a sense-making and social processes.    Academic faculty and researchers need to be supported to learn to interpret and design learning analytics. Establish a culture of data use as part of increasing organizational capacity. Support a community of practice     Single Loop learning à attempt to achieve set goals Double Loop learning à achieved set goals are interrogated, challenged, and developed.    Role of Data Wranglers  Managing large scale data could lead to gaps between the data about learning and the academics responsible for improving teaching. à the gap could become wider as the quality and complexity of data increases.  Data wranglers is implemented to ensure that the collected data is interpreted appropriately and turned into actionable insights. WHO ARE THE DATA WRANGLERS?   They are a group of academics who analyze data about student learning and prepare reports with actionable recommendations based on that data.  Their role is to act as human sense-makers, facilitating action on feedback from learners, making better sense of what that feedback means and how the data can be improved (double-loop learning), and helping to develop the Community of Practice around the use of learning analytics.   Tidyr &amp; dplyr (data wrangling)     Reshape: take on structure and turn it into another structure  Subset: take a subsection and separate it out  Generating variable à Create new data frame/ ge Collapse à create the means by subgroup and create a new data frame/ generation  Combine  Summarize à collapse all numbers into aggregates  ",6,2,4,1
"348","Chapter 1: Social Network Data","Dimensionality reduction    Feature selection: select a subset of dimensions. Which variable, column should I keep or discard. Feature extraction: transform lots of dimensions into fewer dimensions. Collapse columns together to reduce the overall space.   Curse of dimensionality  Adding dimension without adding rows à spread actual data too thinly.  Sparsity: the more dimensions that you add, the more comparisons will be missing. How to reduce dimensions?   Average the dimensions (mean, media, mode) --&gt; collapse them into one Could also reduce the rows by collapsing them. ",0,0,0,1
"349","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Based on the diagram from Greller &amp; Draschler, what would pose problems for you to actually acquire the data you want?   One limitation would be the lack of knowledge of the data. The meaning attributed could be different for other people.   Why randomize?  take bias out of sampling no systematic differences in data generate comparable groups allows calculations of probabilities    Translating Learning into Numbers (Greller &amp; Draschler, 2012)   Internal limitations à can people understand the numbers and make inferences from it. External constraints à not used to timed data Instruments à technology, theories. How do you operationalize the numbers and what theories are you backing it up with? Stakeholders à institutions, teachers, learners, others Data à is it protected? Or is it opened? ",0,5,-5,1
"350","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Adaptive systems    Systems that adjust to students’ behaviors Example: GRE à determine the levels you’re at and adjusts according to it Intelligent tutors à changes the questions based on Zone of proximal development concept  Similarity-based systems   Recommender systems:  collaborative filter  content filter: using the characteristics of an item to help recommend other items with similar properties    Some type of structure that showcase knowledge/contents in an orderly manner.   Leaner model -&gt; how the learner is going to acquire content and whether they are making progress.   Structure of knowledge Quantified epistemology à counting knowledge  ",3,0,3,5
"351","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Machine learning  Tracks behaviors (“learning” through prediction) trained to behave differently Input --&gt; Process --&gt; Output (pipeline) Machine connects the input and the output Take training data and train the untrained model    Development Phase  Take raw data to pre-process, processed data, feature engineering, model training    Evaluation phase  Decides what model is best    Deployment Phase   Prediction --&gt; characterization of the point cloud   Supervised learning:  labeled data (ex: pass or fail)   Unsupervised learning: when there’s np label. Machine will have to learn the characteristics to figure out      ",1,2,-1,5
"352","Big Data in Education","Clustering:  Focused on the rows à finds rows that are similar and group them together.    K-means  K à the numbers of clusters  (?) Uses the mean of some numerical variables that make clustering decisions. Only works. Good at finding clusters.     select random points from the clusters à Associate all the points that are closest with those points (standardizing) Move the selected points to the point that is closest to the mean of the group.      *Start with a range of selected points (values) *Does not work on certain shapes à it requires even spread *Doesn’t work on categorical data à make sure it only work with numerical",5,0,5,1
"353","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Teacher-assigned grades matter: - predictive of overall student outcomes + to assess a student's ability to negotiate the school process      The main goal of this study is to present hierarchical cluster analysis (HCA) and visualization techniques as a useful method for the organization and pattern analysis of large sets of school and district data to aid data driven decision making (3DM).      (a useful and interesting means to visualize and assess an entire disaggregated data history pattern for a student in comparison with every other student’s data pattern in a sample.)     -    identifying student dropout        - provides an attractive avenue for identifying time points for early instructional intervention by exploring specific student grade cluster patterns.       ",0,1,-1,3
"354","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social Network Analysis:    SNA aims to understand the determinants, structure, and consequences of relationships be- tween actors.    Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.  Uniqueness of SNA: the importance of relationships and emergent structure. Network analysis can give a baseline understanding of classroom net- work norms and illuminate major aspects of undergraduate learning.    Network Types: 1. unipartite (only one type of actor) 2. bipartite     Ties: 1. binary whether or not a relation exists 2. valued include additional quantitative information about the relation.       Social Network Data Collection    Egocentric studies focus on a sample of individuals (called “egos”) and the local social environment surrounding them without explicitly attempting to “connect the dots” in the network further. Census networks, some- times referred to as whole networks, collect data from an entire bounded population of actors,    Network measures 1. network density: a global metric that simply indicates how many ties are present.  2. homophily: a propensity for similar actors to be disproportionately connected in a relation of interest.    - happens in mutliple processes:     social selection and social influence. Social selection occurs when a relationship is more likely to occur due to two actors having the same attributes, while social influence occurs when individuals change their attributes to match those of their relational partners, due to influence from those partners.    Actor-level variable: centrality - measures of centrality 1. degree: the total number of connections a node has. examining the equity or inequity in the number of ties be- tween individuals and can be done by looking at the degree distribution, which shows the distribution of degrees over an entire network.  2. betweeness: whether actors serve as bridges in the shortest paths between two actors 3. closeness: how close one actor is to other actors on average, measured along geodesics. 4. eigenvector: Eigenvector centrality places importance on being connected to other well-connected individuals; having well-connected neighbors gives a higher eigenvector centrality than having the same number of neighbors who are less well connected.    Data Collection: Survey Timing of survey:    1. classroom descriptions consisting of a single network ---&gt;  as early as possible    2. longitudinal studies involving several collections ---&gt; at regular intervals or around important classroom events.                       ",3,1,2,4
"355","Why Students Should Own Their Educational Data","the myth of average: population--&gt;individuals (x) wrong: not stable; too contextualized   --&gt;start by analyzing individual patterns instead of aggregate data  ",1,2,-1,3
"356","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","  Comparison between EDM&amp; LAK   EDM: 1. tech field 2. machine learning 3. individual 4. automation   LAK: 1. educ field 2. text&amp; SNA 3. holistic 4. human judgement           ",0,0,0,2
"357","Why Is Measuring Learning So Difficult?","why is measuring learning so difficult? 1. simplify the learning process 2. learning is contextual 3. black box (social, psychological) 4. hard to find the reliable proxy 5. include growth? 6. what connections are learners making?",0,2,-2,1
"358","Saturday Morning Breakfast Cereal","1. be cautious of the implication of a finding 2. correlation is not equal to causality 3. or an indicator cannot be the end 4. as an educator we have to look beyond the indicators can 5. think what is the origins of international trends",0,0,0,5
"359","The Data Wrangling Cheatsheet","reshaping data: tidyr::gather( ) tidyr::separate( ) dplyr::select( )   Summarise data:  dplyr::summarise(.data, avg=mean())   Make new variables dplyr::mutate(.data)   Combine datasets dplyr::left_join dplyr::right_join dplyr::inner_join dplyr::full_join    ",0,0,0,1
"360","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers:   - sense-making and social processes are important     because ""learning is a complex social activity.""   - Data Wranglers: to translate the theory described above into practice:     to act as human sense-makers, facilitating action on feedback from learners,     making better sense of what that feedback means and how the data can be improved (double     -loop learning), and helping to develop the Community of Practice around the use of learning analytics.    ",1,1,0,1
"361","RStudio Cheat Sheets","The R Markdown Cheat Sheet  1. open a new .Rmd file 2. Write a document 3. Knit document to create report 4. Preview Output 5. Publish 6. Examine build log 7. Use output file",0,1,-1,1
"362","Translating Learning into Numbers: A Generic Framework for Learning Analytics","       Dimension        V alues          Stakeholders        Data subjects: a group of learners. Data clients: tutor, discussion moderator.          Objective        Reflection: Analyse student interactions in a forum discussion, identify network connections between students, and identify isolated students to bring them back into the discussion.          Data        Protected dataset: Student interactions and posts in the discussion forum of the LMS. Relevant indicators: Posts published, posts replied to. Time scale: what time frame is applied to the analysis?          Instruments        Pedagogic theory: socio-constructivist, hypothesis is that active participants in a discussion show better learning outcomes. Technology: Social Network Analysis (SNA), statistics. Presentation: network diagram visualisation, stats table.          External limitations        Conventions: (1) Privacy: is the analysis in accordance with privacy arrangements, are the students properly informed? (2) Ethics: What are the dangers of abuse/misguided use of the data? Norms: Are there e.g., legal data protection or IPR issues related to this kind of use of student data?  Time scale: will the students still be able to benefit from the analytics outcome? Is the analysis post-hoc or just-in-time?          Internal limitations        Required competences: (1) Interpretation: Do the data clients have the necessary competences to interpret and act upon the results? Do they understand the visualisation or presentation of the information? (2) Critical thinking: Do they understand which data is represented and which data is absent? How will they use this information?       ",5,5,0,1
"363","Learning Analytics Dashboards","Understand your goals--&gt; Acquire and  (Pre-) Process the data --&gt;Mapping Desig --&gt;Documentation --&gt;Add Interaction Techniques --&gt; Evaluate Continuously   Four main questions:         1. What kind of data can be visualized? - artefacts produced by students - social interactions - resources include consultation of documents - time spent - test and self-assessment results 2. For whom are the visualizations intended? 3. why: what is the goal of the visualization? 4. How can the data be visualized?     Which interaction techniques can be applied?     What tools, libraries, data formats, ..., can be used for the technical implementations?      What workflow and recipe can be used to develop the visualization.   - Static visualizations --&gt; provide answers to a limited number of questions that a user might have about a data set --&gt; the ability to reveal problems with the data itself (the way the data has been collected)           - Choose the visualization tools according to the contexts     . some techniques have been proven to work better than others             - pie charts not a good idea             - bar charts can be quite powerful             - coordinated graphs enable rich exploration             - 3D graphics often do not convey any additional information             - Scatterplots and parallel coordinates are good representations for depicting correlations.   - Documentation 1. rationale 2. alternative 3. evolution   - add interaction techniques -evaluate continuously",7,3,4,2
"364","Measurement and its Uses in Learning Analytics","   1. the use of a learning analytics tool is always aligned with assessment regimes. theories are even more important when working with big data.   2. a certain kind of analytical tool--&gt; specific worldview &amp; learners   3. (1) assessment can be the driving force in how we understand what ""knowledge"" is   (2) assessment about pedagogy is influnence who we assess and ho (3) assessment and pedagogy are sometimes in tension, where the desire for summative assessment override pedagogically motivated formative feedback;  (4) drawing alignment between one’s epistemological view (of the nature of knowledge) and assessment or pedagogy practices is challenging — relationships between the three may be implied, but they are not entailed     Epistemology — What/How Are We Measuring?      Pedagogy — Why is this Knowledge Important to Us?          Pedagogy — Who is the Assessment/ Analytic For?      Assessment — Where Does the Assessment Happen?      Assessment — When Does the Assessment, and Feedback, Occur?                           ",1,1,0,2
"365","Ethics and Learning Analytics: Charting the (Un)Charted","current: frameworks, code of practices and conceptual mappings of ethical implications in learning analytics.   Future directions: 1. explore potential conflits between students' concerns, their right to pot-out, and the implications for the mandate of higher education to use student data to make interventions at an individual level. 2. balance research ethics and online datasets 3. balance optimism around AI -- risk of AI (discrimination)   Essential Elements: accountability, transparency, and regulatory frameworks",1,3,-2,2
"366","Statistical graphics: making information clear – and beautiful","Two key decisions: (1) who is your target audience? (2) what are you trying to show?   Guiding principles (1) avoid distracting elements (2) use informative color to visually associate elements (3) keep the figure simple   Guiding principles of creating small multiple plots (1) keep the x- and y- axes on the same scale (2) eliminate repetitive information (3) maintain consistency across plots",0,3,-3,2
"367","How to display data badly","The aim of good data graphics is to display data accurately and clearly.   (a) showing data - rule 1 include all the data             measure: data density - rule 2 don't hide data              ( don't use a overabundance of chartjunk + choose a scale)                 measure: data-ink ratio   (b) showing data accurately - rule 3 visual metaphor - rule 4 the order of numbers+ mangitudes - rule 5 display the data in the context the essence of a graphic display is that a set of numbers have both magnitudes and an order are represented by an appropriate visual metaphor -- the magnitude and order of the metaphorical representation match the numbers. (space, time, ....) --&gt; carefully choose the interval   (c) showing data clearly - rule 6 don't change scales in Mid-Axis -rule 7 emphasize the important, not the trivial -rule 8 when doing comparison, start from the same base - rule 9 don't oder data in alphabetical way - rule 10 labelling     (1) Illegibly     (2) Incompletely     (3) Incorrectly     (4) Ambiguously - rule 11     (a) decimal places, not too many to be understandable     (b) dimensions     In conclusion, examine the data carefully enough to know what they have to say, and then let them say it with a minimum of adornment.      ",5,2,3,3
"368","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","   (1) Statistical data visualization, which is focused not on visual appeal but on facilitating an understanding of patterns in an applied problem (recall the Discovery goals listed above), both in directing readers to specific information and allowing the readers to see for themselves.  (2) Infographics, which ideally should be attractive, grab one’s attention, tell a story and encourage the viewer to think about a particular dataset, both as individual measurements and as a representation of larger patterns (as in our Communication goals).    KEY difference:  Infovis: unique, distinctive displays+ want to draw attention to the graphics and subject matter Statistician: generic methods that have a similar look and feel across a wide range of applications+ viewers already shown interest and want structured information, often a carefully prepared argument   ",3,1,2,2
"369","Junkcharts Trifecta Checkup: The Definitive Guide","The Trifecta Checkup:   What is the QUESTION? What does the DATA say? What does the VISUAL say? ",0,0,0,2
"370","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data driven decision making (3DM)  Primarily has focused on test scores, he’s looking at grade assignment too aggregated descriptive statistics give only an overview of the central tendency of a sample, obscuring the actual trends in individual student achievement that may provide the clues to inform teachers and school leaders that a student has shifted from on-track performance to significantly challenged with school.  An alternative is to inspect every data element individually for each student, but  understanding and interpreting trends becomes impossible.  a third option, single student course failures could be used, since early failure in reading or mathematics has been shown to be highly predictive of student schooling outcomes  However, this issue returns to the problem of reducing the data represented by individual student achievement trends to aggregated means and fitted regression slope equations that are generalizable to the population, but less useful for making data driven decisions for individual students and schools. Author combines hierarchical cluster analysis (HCA) and heatmaps to pattern and interpret longitudinal trends in student data, such as teacher-assigned grades ",0,3,-3,3
"371","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Network Types: Unipartite: consist of only one type of actor Bipartite: two mode Directional: one way or two way Egocentric studies focus on a sample of individuals (called “egos”) and the local social environment surrounding them without explicitly attempting to “connect the dots” in the network further. census networks, sometimes referred to as whole networks, collect data from an entire bounded population of actors, including identifiable information about the respondents’ relational partners. These alters are then identified among the set of respondents, yielding a complete picture of the network. network density. The density of a network is a measurement of how many links are ob- served in a whole network divided by the total number of links that could exist if every actor were connected to every other actor. homophily: a propensity for similar actors to be disproportionately connected in a relation of interest. Social selection occurs when a relationship is more likely to occur due to two actors having the same attributes Social influence occurs when individuals change their attributes to match those of their relational partners, due to influence from those partners. Triads and transitivity: Transitivity is a simple, local measure of a more general set of concepts related to clustering or cohesion, which may extend to much larger groups beyond size three. a preponderance of transitive triads is considered an indicator of hierarchy (with A always giving and C always receiving), while a preponderance of cyclical triads is an indicator of egalitarianism (with everyone giving and everyone receiving). degree centrality - the total number of connections a node has. In networks in which relations are directional, this includes measures of inde- gree and outdegree closeness centrality - how close one actor is to other actors on average, measured along geodesics. betweenness centrality - focuses on whether actors serve as bridges in the shortest paths between two actors. eigenvector centrality - being connected to other well-connected individuals Timing of data collection is important; can do it over a period of time IRB: Data used solely for curricular improvement and not for gen- eralizable research often do not require consent, but any use of the data for generalizable research does (Martin and In- wood, 2012) Because social networks often describe vulnerable populations, talking with IRB is important; this can be especially true for educational network research, when researchers are often also acting as instructors or supervisors to the student subjects and are thus in a position of authority. This may create the impression in students’ minds that re- search participation is linked to student assessment. In many scenarios, re- searchers must plan on anonymizing or removing identifiers on data opt-in and opt-out procedures: a standard opt-in procedure would use an individual not involved with the course to talk students through a consent script, answer questions, and retrieve signed consent forms from consenting subjects. While the opt-in procedures are more common and foreground subject protection, they tend to omit data with a bias toward underserved and less successful populations. An opt-out procedure would provide the same opportunities for student information and questions but ask subjects to opt out by signing a centrally located and easily accessible form kept confidential from researchers until after the research is completed. commonly leads to higher rates of data return.Matrices: sociomatrix or adjacency matrix - A unipartite sociomatrix will always be square, with as many rows and columns as there are respondents. For undirected networks, the sociomatrix will be symmetric along the main diagonal; for undirected, the upper and lower triangles will instead store different information. Matrices for binary networks will be filled with 1s and 0s, indicating the existence of a tie or not, respectively. edgelist, a two-column matrix with each row identifying a pair of nodes in a relationship Matrices for binary networks will be filled with 1s and 0s, indicating the existence of a tie or not, respectively. In cases of nonbinary ties (e.g., how many hours each student studied together) the numbers within the matrix may exceed one. The matrix storing nodal attribute information need not be square; it will have a row for each respondent and a column for each attribute measured. ",8,2,6,4
"372","Why Students Should Own Their Educational Data","historically, learning data has been presented and digested on a meta level, because that is the only way that it could be presented now, there are opportunities to collect and retrieve data on more individualized and contextualized bases The more granular and more specific the data can be, particularly in terms of context, the better the analysis can be, which could lead to better learning Organizations can be developed which can secure and provide to students their data, for better learning outcomes",4,0,4,2
"373","Knowledge tracing: Modeling the acquisition of procedural knowledge","Examines the use of a programming tutor and its effectiveness on student learning in a self-paced environment Only an abstract and short stub   ",0,0,0,3
"374","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","“big data” + computation = improving learning processes Two communities: Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment. EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners LAK researchers typically place a stronger emphasis on attempting to understand systems as wholes, in their full complexity. ",1,0,1,2
"375","Evaluating Machine Learning Models","Classification is about predicting class labels given input data.  In binary classification, there are two possible output classes. In multi- class classification, there are more than two possible classes.  Accuracy simply measures how often the classifier makes the correct prediction.  False negatives can be worse than false positives (look at the situation) - e.g., diagnosing no cancer when there is, v. Diagnosing cancer when there isn’t.Per-class accuracy Log-loss is a “soft” measurement of accuracy that incorporates this idea of probabilistic confidence.  AUC stands for area under the curve. Here, the curve is the receiver operating characteristic curve, or ROC curve for short. The ROC curve shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives. In other words, it shows you how many correct positive classifications can be gained as you allow for more and more false positives. The ROC curve is not just a single number; it is a whole curve.  Precision answers the question, “Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant?”  Recall answers the question, “Out of all the items that are truly relevant, how many are found by the ranker/classifier?”  precision = # happy correct answers / # total items returned by ranker  recall = # happy correct answers / # total relevant items  harmonic mean: F1 = 2(precision*recall / precision + recall)  NDCG - normalized discounted cumulative gain. There are three closely related metrics here: cumulative gain (CG), discounted cumulative gain (DCG), and finally, normalized discounted cumulative gain.  Cumulative gain sums up the relevance of the top k items.  Discounted cumulative gain discounts items that are further down the list.  Normalized discounted cumulative gain is a normalized version of discounted cumulative gain. It divides the DCG by the perfect DCG score, so that the normalized score always lies between 0.0 and 1.0. regression: RMSE (root-mean-square error), also known as RMSD (root-mean-square deviation). This is defined as the square root of the average squared distance between the actual score and the predicted score  RMSE, because it is an average, it is sensitive to large outliers. If the regressor performs really badly on a single data point, the average error could be very big.In statistical terms, we say that the mean is not robust (to large outliers).  median absolute percentage: MAPE = median (of absolute value of)yi - yi /yi Look out for data outliers which could skew the overall data",19,9,10,5
"376","Why Is Measuring Learning So Difficult?","simplification waters down meaning can't measure, too contextual in meaningful way weak tools in humanities learning is personal; construct of learning is difficult but can measure behavior no reliable simple proxy indicators that we can trust ranges from curiosity to memory can measure indicators of understanding but not understanding itself cultural, social, psychological factors to consider need to measure pre competencies learning is the growth in competence measure constructs or achievement analytics for the learner would be interesting hard to define learning",1,3,-2,1
"377","Saturday Morning Breakfast Cereal","cute cartoon need to understand data better before reaching conclusions. ",2,0,2,2
"378","The Data Wrangling Cheatsheet","essential tips on sorting data  ",0,0,0,1
"379","Data wranglers: human interpreters to help close the feedback loop","Because learning is complex, need people to be interpreting the data, engaging in sense-making activities to mediate the information in ways that enable intelligent action. need to connect data wranglers/analysts with the practitioners that could benefit from the data Open University example where it is being done Gains have been made in certain areas, although the funding structure has changed which has correlated with reduced metrics, so they can't gauge the effectiveness of the program.  They think it is working, however.",2,1,1,1
"380","Zuckerberg is ploughing billions into 'personalised learning' – why?","personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”.human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests. This is similar to how Facebook’s news feed works, and other commercial personalisation models based on text and behaviour analysis.Dangers:1. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists.2. learners need to cope to learn in a way that’s not suited to them3. children’s preferences  change as immediate responses to the environment.Could work, though, if teachers are involved.",5,0,5,2
"381","Feature Selection","Good for interpretability and insight Maybe only a few items really matter in the overall analysis Less features = less curse of dimensionality",1,0,1,5
"382","RStudio Cheat Sheets","nice intro to markdown use shiny in header to get tables",1,0,1,1
"383","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Not much to gain here, as I was only able to see the first page Indicates that it is much easier to get data these days",2,0,2,1
"384","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Online Recommender Systems program offered through Coursera They learned that the effort expended in the course was a predictor of knowledge gain. Abstract only.",2,0,2,4
"385","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Making an effective course with explicit associations between a necessary set of skills and course contents requires intensive cognitive task analysis and time- consuming evidence-based iterative engineering  Learning Factor Analysis (LFA) works only when meaningful “features” are given, which (usually) requires cognitive task analysis by subject domain experts. Q-matrix (matrix factorization methods for automatic skill set) use discovery from students’ response data. However, these methods often face the issue of interpretability—i.e., providing meaningful feedback to course designers and developers based on the machine-generated skill set is often troublesome.  eEPIPHANY - a method developed to fully and automatically discover skill sets from online course data, which are the combination of the assessment item text data (i.e., problem and feedback text sentences for assessment items) and student learning interaction data. goal of eEPIPHANY is to provide constructive feedback to online course designers and developers for iterative course improvement. ",6,2,4,5
"386","Chapter 1: Social Network Data","network approaches tend to study whole populations by means of census, rather than by sample because network methods focus on relations among actors; if one actor happens to be selected, then we must also include all other actors to whom our ego has (or could have) ties. Boundaries: two main typesnaturally occurring clusters, or networks; drawing the boundaries around a population that is known, a priori, to be a network. Or, ""demographic"" or ""ecological"" approach to defining population boundaries.""multi-modal"" -  Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Data collection:Full network: best, but may be impracticalSnowball: starting incrementally and then gathering more as people are named; this may overstate data and may leave some outliers outEgocentric (with alter connections) - collects on chunks of the network and connections; can be usefulEgocentric (ego only) - collects on individuals, and not the network; can be good, but may miss some important network connectionsMeasurement scales:BinaryMultiple, nominal - categorical, but assigning numbersGrouped, ordinal - degrees assignedFull-rank - ranking between actorsInterval - where the numbers have real meaning (I.e., the difference between 1 and 2 is the same as the difference between 9 and 10)In general, social networks are limited to a particular group at a particular time and are not generalizable, but if a scenario were replicated many times, there could be some probability of the network occurring which could be somewhat more generalizable.",2,2,0,4
"387","Learning Analytics Dashboards","visualization has the potential to be more precise and revealing than conventional statistical computations (Tufte, 2001). Because static visualizations usually lead to more questions, adding dynamic interaction techniques to the visualization can lead to meaningful visualization tools that encourage exploratory data analysis. The first step is getting to know the problem domain, the data set, the intended end-users of the tool, the typical tasks they should be able to perform, and so on. The following questions need to be answered at this stage: Why: What is the goal of the visualization? What questions about the data should it answer? For whom: For whom is the visualization intended? Are the people involved specialists in the domain, or in visualization? What: What data will the visualization display? Do these data exhibit a specific internal structure, like time, a hierarchy, or a network? How: How will the visualization support the goal? How will people be able to interact with the visualization? What is the intended output device? Visual properties ranked:For quantitative data:PositionLengthAngleSlopeAreaVolumeLightnessSaturationHueTextureConnectionContainmentShapeFor categorical dataPositionHueTextureConnectionContainmentLightnessSaturationShapeLengthAngleSlopeAreaVolumeBar charts good, pie charts badScatter plots good for correlations ",6,3,3,2
"388","Measurement and its Uses in Learning Analytics","operationalization, the repeatability or precision of measurements, sources of error, and the interpretation of the measure itself. Model-based reasoning: accepting a simplified representation of a system that captures salient aspects (e.g., patterns) and allows us to explain or predict phenomena In learning analytics, efficient collection of data is usually not the problem, but the lack of standardization can make it challenging to account for measurement error.  A measurement model is a formal mathematical relationship between a latent variable or set of variables and an observable variable or set of variables.  learning analytics and educational data mining  explores relationships between psychological scales, behavior, and performance in digital learning environments  Factor analysis (Mulaik, 2009) models the correlations among observed variables through a linear relationship to a set of latent variables known as factors.  Factor analysis is:Exploratory factor analysis (EFA) - used to determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development (note: don’t use EFA with PCA) and confirmatory factor analysis (CFA) is a complementary set of techniques to test a theoretically proposed factor model by examining residuals between expected and observed correlations. CFA can be used to reject a model.  Predictive modelling v. Measurement theory“in explanatory modelling the focus is on minimizing bias to obtain the most accurate representation of the underlying theory. In contrast, predictive modelling seeks to minimize the combination of bias and variance, occasionally sacrificing theoretical accuracy for improved empirical precision”  data modelling culture (98%) vs the algorithmic modelling culture (2%)",1,7,-6,5
"389","Predictive Modelling in Teaching and Learning","In predictive modelling, the purpose is to create a model that will predict the values (or class if the prediction does not deal with numeric data) of new data based on observations. the principal difference between explanatory modelling and predictive modelling is with the application of the model to future events, where explanatory modelling does not aim to make any claims about the future, while predictive modelling does. In explanatory modelling, all of the data collected from a sample (e.g., students enrolled in a given course) is used to describe a population more generally (e.g., all students who could or might enroll in a given course). In a predictive model, a hold out dataset is used to evaluate the suitability of a model for prediction, and to protect against the overfitting of models to data being used for training With educational data, it is common to see models built using methods such as these:     1.    Linear Regression predicts a continuous numeric output from a linear combination of attributes.     2.    Logistic Regression predicts the odds of two or more outcomes, allowing for categorical predictions.     3.    Nearest Neighbours Classifiers use only the closest labelled data points in the training dataset to determine the appropriate predicted labels for new data.     4.    Decision Trees (e.g., C4.5 algorithm) are repeated partitions of the data based on a series of single attribute “tests.” Each test is chosen algorithmically to maximize the purity of the classifications in each partition.     5.    Naïve Bayes Classifiers assume the statistical independence of each attribute given the classification, and provide probabilistic interpretations of classifications.     6.    Bayesian Networks feature manually constructed graphical models and provide probabilistic interpretations of classifications.     7.    Support Vector Machines use a high dimensional data projection in order to find a hyperplane of greatest separation between the various classes.     8.    Neural Networks are biologically inspired algorithms that propagate data input through a series of sparsely interconnected layers of computational nodes (neurons) to produce an output. Increased interest has been shown in neural network approaches under the label of deep learning.     9.     Ensemble Methods use a voting pool of either homogeneous or heterogeneous classifiers. Two prominent techniques are bootstrap aggregating, in which several predictive models are built from random sub-samples of the dataset, and boosting, in which successive predictive models are designed to account for the misclassifications of the prior models. ",4,4,0,3
"390","Ethics and Learning Analytics: Charting the (Un)Charted","with all of the data, we need some sort of an ethical framework to guide further research and activities",0,0,0,2
"391","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Explanatory models seek to identify interpretable constructs that are causally related to outcomes The focus is on why a model fits the data well rather than only that it fits well.  A knowledge component (KC) is a fact, concept, or skill required to succeed at a particular task or problem step. We refer to this specialized form of a cognitive model as a KC model or, alternatively, a Q-matrix (Barnes, 2005).  Cognitive models map knowledge components (i.e., concepts, skills, and facts; Koedinger, Corbett, &amp; Perfetti, 2012) to problem steps or tasks on which student performance can be observed.  Difficulty factors assessment (DFA; e.g., Koedinger &amp; Nathan, 2004) moves beyond expert intuition by using a data-driven knowledge decomposition process to identify problematic elements of a defined task.  LFA searches across hypothesized knowledge components drawn from different existing KC models, evaluates different models based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model. As such, LFA greatly reduces demands on human effort while simultaneously easing the burden of interpretation, even if it does not automatically accomplish it.  SimStudent, a state-of-the-art machine-learning agent,  to discover cognitive models automatically without requiring existing ones. SimStudent is an intelligent agent that inductively learns knowledge, in the form of rules, by observing a tutor solve sample problems and by solving problems on its own and receiving feedback. SimStudent can be used to test alternative models of human learning to see which best predicts human behaviour  Both LFA and SimStudent are capable of producing cognitive model discoveries that not only significantly improve predictive accuracy but are readily interpretable and, thus, explanatory  The fact that methods like LFA are “human-in-the-loop” — that is, requiring input from a domain expert — has been cited as a limitation. In the case of LFA, one or more expert-tagged cognitive models are required initially in order to produce new model discoveries.  For a model to be explanatory, one should be able to understand why the model achieves better predictive accuracy than alternatives. In addition, the understanding of this why should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both.  Explanatory modelling efforts tend to start with “clean” independent variables that have either simple functions or map to clearly defined constructs. For example, LFA derives new variables from existing, expert-labelled variables using simple split, merge, or add operators.  Another feature of explanatory models, one that relates most to actionability, is that the dependent variable maps to a well-defined construct. The work on learning rate groups is an example of this: since the groups to which students are classified are defined up front, it is clear what it means for a student to be in the “flat” learning curve group, as opposed to the “steep” one.  explanatory models tend to be characterized by fewer estimated parameters (independent variables, or features). For example, the AFM has only one parameter for each student and two parameters for each knowledge component. Adding learning rate groups extends the model by only one additional parameter, group membership. This makes the contribution of the added parameter easy to attribute and interpret. Having fewer parameters also allows each parameter’s estimates to have more explanatory power, alleviating issues of indeterminacy.",14,7,7,5
"392","Statistical graphics: making information clear – and beautiful","Avoid distracting elements.Use informative colour to visually associate elements.Keep the figure simple (and therefore interpretable).  Keep the x- and y-axes on the same scale. Eliminate repetitive information.Maintain consistency across plots.",0,1,-1,2
"393","How to display data badly","1. Show as few data elements as possible (data density)2. Minimize the Data to Ink Ratio3. Be consistent with visual metaphors4. Show data accurately; remember that order is not the only variable5. Maintain context6. Consistency of scale7. Emphasize the important8. Maintain the baseline9. Avoid alphabetical unless it helps10. Label clearly11. Simplify (particularly numbers)12. Don’t need to improve on a good thing",4,0,4,3
"394","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Don’t put too much into the graph papers in the Journal of Computational and Graphical Statistics are about 80% computation and 20% graphics  Graphics is typically thought of as a way to help with simple tasks such as data cleaning and exploration, before getting to the serious task of inference.  lack of interaction between the worlds of statistical graphics and information visualization  Infovis - Information Visualization  the statistical approach concentrates on what can be got out of the available data and the Infovis approach uses the data to draw attention to wider issues. Both approaches have their value and it would probably be best if both could be combined.  Modern exploratory data analysis involves using interactive graphics, and such tools are also frequently used for Infovis graphics in web displays, along with sound and video.  Statistical graphics references:Bertin and WilkinsonCleveland Tufte Infovis references:HeerKosaraMunznerShneiderman Kosara’s blog, eagereyes.orgShneiderman (1996): Overview first, zoom and filter, then details-on-demand  Infovis workshops, BELIV (BEyond time and errors: novel evaLuation methods for Information Visualization)  Discovery goals:         -  Giving an overview        -  Conveying the sense of the scale and complexity of a dataset.         -  flexible displays to discover unexpected aspects of the data<U+2028> Communication goals         -  readily understandable        -  Telling a story        -  Attracting attention and stimulating interest.  Best: WordleDecision TreeSteamgraphDisplay in a way that people can easily digest",4,4,0,2
"395","Junkcharts Trifecta Checkup: The Definitive Guide","    •    What is the QUESTION?    •    What does the DATA say?    •    What does the VISUAL say? Multiple examples of how the blogger sees charts as either being good in all three categories or missing the mark in one or more categories.",1,1,0,2
"396","Measurement and its Uses in Learning Analytics","The purpose of this chapter is to introduce practitioners in education and psychometrics throughout history, increasing the technical details of specific measurements from more conceptual material structures, instruments, and sources of measurement error. Measuring latent variables is a noisy job, and data modeling and data visualization means telling viewers what we have learned from the data in a simple and meaningful way",0,1,-1,5
"397","Predictive Modelling in Teaching and Learning","In the teaching of LA and EDM, predictive modeling has become a core practice. This article describes the process, practice, and challenges of using predictive modeling analysis.",0,0,0,3
"398","Junkcharts Trifecta Checkup: The Definitive Guide","As a useful piece of data, it is important for our audience to understand our models and research questions. Therefore, we need to ask three questions, such as mentioned in the reading: 1. What's the problem? 2. What does the data say? 3. What does vision say. If there are no answers to all three questions, a type of junk chart is formed.",0,2,-2,2
"399","Why Students Should Own Their Educational Data","Everyone absorbs knowledge differently, so creating different education data for different students is necessary. The education system may be better at studying average patterns, if we want the system to work for everyone, we have to do research for everyone.",2,0,2,2
"400","Why Is Measuring Learning So Difficult?","What people learn depends on people's definition of independence, not what is listed on the syllabus. From the video, learning is a multi-dimensional thing, so we must simplify data capture to figure out what people need to learn.",0,0,0,1
"401","Zuckerberg is ploughing billions into 'personalised learning' – why?","There are few main flaws in Zuckerberg's personalized learning philosophy. Although learners may cope with learning in ways that are not suitable for them, in the real world, life is not always so adaptive. Their lack of compensation may mean that they have suffered losses. Also, children's preferences are not fixed. Motivation is the key idea of personalized learning",2,4,-2,2
"402","Feature Selection","In the data world, keywords are the most useful content in everyday life. As you can see from the video, capturing keywords is useful for anything, and we can do that with word clouds or other machine learning.",0,1,-1,1
"403","Chapter 1: Social Network Data","Instead of focuses on itself, network data more likely to pay attention to data analysis methods to guide a different result. It is easier for network data analysts to see individuals nested in network relationships with others.",2,0,2,4
"404","Translating Learning into Numbers: A Generic Framework for Learning Analytics","It can be seen from this article that the combination of data and information retrieval technology is not only the foundation of the emerging data economy, but also has great application prospects in the field of education.",1,0,1,2
"405","Using data mining to predict secondary school student performance","Due to advances in information technology, interest in business intelligence has led to exponential growth in business and organizational databases. This article is a good introduction on how to use more effective student prediction tools to improve the quality of education and strengthen school resource management.",2,0,2,2
"406","Developing a generalizable detector of when students game the system","From this article, we can learn about the topic of psychometric measurement such as construction, instrumentation, and specific measurement models can provide us with a relatively reliable standard for judging mental state.",0,0,0,5
"407","Cross Validation","As you can see from this video, cross-validation ensures that each data is used as efficiently as possible without overfitting.",0,0,0,5
"408","Hands-On Programming with R","This book has an introduction to the basic code of R, which has a certain reference value for beginners.",0,0,0,1
"409","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," The article made me understand how similar methods (clustering and data visualization) can be used in HR analytics, to predict turnover and absenteeism. Learning data mining in education can help me make sense of how data analytics can also be used in HR analytics / organization analysis. The pictures in this article already contains a lot of useful information and implications for intervention.  Some basic concepts:   3DM: data driven decision making SSF: success at school factor cluster tree / dendrogram — based on the distance calculation [uncentered correlation was used as the distance measure here]   shorter horizontal lines indicates more similarity;  vertical lines connect the closest rows to form the clusters. each data row is clustered by similarity.   heatmap: hotter color indicates a higher score (red); cooler color indicates a lower score (blue); neural color indicates a central score (grey) hierarchical cluster analysis (HCA): supervised clustering — begins with a defined set of assumptions about the categorization of the data; unsupervised clustering — assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the dataset, a procedure well suited to discovering the underlying patterns within student data in education. missing data might have patterns (average linkage can help to address the missing data issue) combination of the cluster analysis, cluster tree, and heat map, creates the clustergram can compared with categorical data as well   Some interesting things worth notice:   teacher-assigned grades is a weak indicator of academic knowledge when compared to standardized test score — 75% of teacher-assigned grades appear to assess a student’s ability to negotiate the social processes of school don’t forget the goal of the study. this is very important.   ",5,4,1,3
"410","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research"," From this article I learn some basic concepts, especially measurement of SNA. By contrasting SNA and conventional data, it is very clear. It is also great to go through a thorough research, like how to do the analysis, what are some limitations and things to keep in mind. Network Concepts   SNA aims to understand the determinants, structure, and consequences of relationships between actors; focus how individuals may have similar network positions due to shared attributes actors/nodes network types:    unipartite/monopartite/one-mode; bipartite/two-mode bidirectional/undirected; directed ties can be binary or valued     network data collection: egocentric; census/whole network level concepts and measure   density: how many links are observed in a whole network  divided by the total number of links that could exist; hard to interpret without comparable data from other similar networks; global metric that simply indicates how many ties are present  homophily: a propensity for similar actors to be disproportionately connected in a relation of interest social selection: when a relationship is more likely to occur due to two actors having the same attributes social influence: when individuals change their attributes to match those of their relational partners, due to influence from those partners dyad-level analysis vs. triads triad census: count of how many different triad types exist in a network transitivity: value representing the likelihood of student A being tied to c transitive triad (A-&gt;B-&gt;C; hierarchy) vs. cyclical triad (A-&gt;C / C-&gt;A; egalitarianism)   actor-level variables   degree centrality: total number of connections a node has. in directional network, include measures of indegree and outdegree betweenness centrality: whether actors serve as bridges in the shortest paths between two actors closeness centrality: how close one actor is to other actors on average, measured along geodesics. it is a poorly suited for disconnected network. eigenvector centrality: being connected to other well-connected individuals.     survey fatigue -&gt; it is important to avoid overuse of surveys pilot studies with your survey is important  data management: nodal attributes vs. relational data (sociomatrix / adjacency matrix) SNA lends itself well to exploratory analyses, it is often judicious to have a priori hypotheses before beginning data collection. visualizing the network is often the first stem taken in performing SNA. always remember data dependence, like conduct permutation correlation test general measurements: edges; density; triad(0/1/2/3); transitivity degree distribution - view the increase in overall study partnership parallel coordinate plot - view general trends (the plot is beautiful and I want to learn!) test for association between exam scores and both degree centrality and betweenness centrality ",6,6,0,4
"411","Why Students Should Own Their Educational Data"," Even there is not much details in this article, I love the idea that students should own their education data. We still face the core question - Who should own the data? Traditional standard teaching practice assumes at least average skills across the board. However, it failed to take the individual differences into consideration. For a group of people, statistics patterns might have some implications on adjustment in policies, design of teach activities. Sometimes those general implications try to satisfy most people, but actually they fit nobody. The aggregate statistics means nothing towards an individual. However, if we start from an individual pattern perspective (like IRT, CDM), it could provide more insights towards each individual.  I agree that personality and learning varies across contexts. That’s why when we make attribution or interpretation through data, we need to be very careful about the assumptions and limitation that we might have. This article also raises a very interesting question - what is your value proposition of 4-year education, considering the trend of MOOCs. Some people might think it is the climate of the school, also the network or soft resources in school. From my perspective, these face-to-face things still can be done through the internet as long as we have proper platform and regulation, have something to support from a system perspective. At the end of the day, the question should be answered by individual differences - who am I? what kind of study suits me better? what do I want to be in the future? That’s why even from learning perspective, educational data should contain individual patterns, and it should be owned by students, to stimulate their awareness, ownership, engagement towards their life. The interviewee did understand this phenomena from a  relative objective perspective - business model, and he did not anti-company as well. Instead, he thinks that market needs an innovative solution in order to become a functional market. I am surprised to see that the interviewee also pointed out the phenomena - everyone is trying to innovate in their platform, and there is lack of interoperability standards or formate standards from a long-term sustainable development perspective. This is “a lack of appreciation that data is the thing”. ",8,5,3,2
"412","Knowledge tracing: Modeling the acquisition of procedural knowledge"," This study made me think of the PL (parameter logistic) models in IRT, and I can’t help wondering the connections and distinctions between the two, especially the slip parameter. At the beginning of this article, the concepts like mastery learning, ideal student model, model tracing, declarative knowledge vs. procedural knowledge, etc. the learning assumptions of ACT-R are complex. the students acquire both goal-independent declarative knowledge and goal-oriented procedural rules. knowledge tracing assumes a two-state learning model. each coding rule is either in the learned state or in the unlearned state. several interpretations of slips   individual differences in the slip weight reflect a pure performance effect   may be that individual differences in the slip parameter actually reflect learning-state differences   reflects differences in the strength of underlying production rules   providing more practice exercises even after the student has reached the criterion learning state can improve test performance   reflect the content of the rules the student has formulated   it is necessary to monitor the content of students’ rules more closely     goal of the research: implement a simple student modeling process that would allow the tutor to monitor the student’s knowledge state and tailor the sequence of practice exercises to the student’s needs simple two-state learning model enables us to estimate the student’s knowledge state from performance and predict performance from that knowledge state. successive evaluations led to:   abandon an initial ideal student model and to model a sufficient set of rules model differences in rule difficulty model individual differences among students in learning and performance   it may be possible to improve on the level of performance and enable more students to reach mastery by manipulating incentive in testing, by providing additional procedural practice or by monitoring and remediating students’ knowledge of key declarative concepts ",7,2,5,3
"413","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Questions:  Do you think EDM and LAK will become one in the future?    Notes:  Similarities  are defined in relatively similar ways both reflect the emergency of data-intensive approaches to education; both have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education   Key Distinctions  Discovery: LAK - leverage human judgement; EDM - automated discovery. Adaptation &amp; Personalization: LAK - informing and empowering instructors and learners; EDM - automated adaptation (by computer with no human in the loop) Reduction &amp; Holism: LAK - understand systems as wholes, in their full complexity; EDM - reduce to components and analyze individual components and relationships between them Origins: LAK - semantic web, ""intelligent curriculum"", outcome prediction, and systemic interventions; EDM - educational software and student modeling, predicting course outcomes Technique &amp; Methods: LAK - social network analysis, sentiment analysis, influence analytics, learner success prediction, concept analysis, sensemaking models; EDM - classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization   collaboration allows creativity and advancement that might not otherwise occur in a single, monolithic research culture formalize approaches for dissemination of research and enacting cross-community ties; strengthen opportunities to influence non-academic research and practice ",2,0,2,2
"414","Evaluating Machine Learning Models"," this article is very important for concluding the basic metrics classification metrics   accuracy: simply measures how often the classier makes the correct prediction (makes no distinction between classes) confusion matrix/table: rows (ground truth labels), columns (prediction)  pre-class accuracy: average of the accuracy for each class (large variance when there are very few examples of one class) log-loss: a gauge of confidence, used when the raw output of the classifier is a numeric probability  instead of a class label of 0 or 1 AUC (area under the curve - ROC): high is good   ranking metrics   precision-recall   precision: out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant? recall: out of all the items that are truly relevant, how many are found by the ranker/classifier? look at the only top k items from the ranker: “precision@k” “recall@k”   precision-recall curve &amp; F1 score   precision-recall curve: plotting precision vs. recall over a range of k values. it is closely related to the ROC curve. F1 score: harmonic mean. small if either precision or recall is small   NDCG   cumulative gain (CG): sums up the relevance of the top k items discounted cumulative gain (DCG): discounts items that are further down the list normalized discounted cumulative gain (NDCG): normalized version of DCG DCG and NDCG are important metrics in information retrieval and in any application whiter the positioning of the returned items is important     regression metrics (predict numeric scores)   RMSE (root mean square error, or RMSD, root mean square deviation): most commonly used metric Quantiles of errors: much more robust  “Almost Correct” predictions: the percent of estimates that differ from the true value by no more than X%. the choice of X depends on the nature of the problem   caution   the different between training metrics and evaluation metrics: it is always better to train the model to directly optimize for the metric it will be evaluated on. always think about what is the right evaluation metric, and see if the training procedure can optimize it directly skewed datasets - imbalanced classes, outliers, and rare data: always be on the look out for data skew (where one kind of data is much more rare than others, or when there are very large or very small outliers that could drastically change the metric)   effective solutions for large outliers would probably involve careful data cleaning, and perhaps reformulating the task so that it’s not sensitive to large outliers     ",11,7,4,5
"415","Why Is Measuring Learning So Difficult?","Conclusion: 1.The core reason why learning is difficult to measure comes from its controversial definition/construct. - WHAT  Oversimplify not good, too complex not good. Need to find a point somethere in the middle Clarify what things(like what behaviors) happen that could indicate learning, or what specifically care about  2.Another important reason is the difficulty to measure competencies - HOW  Competencies and Learning are latent variables, psychological construct. hard to measure may because of the controversial definition Ability to assess competencies -&gt; need new technology Contextual - some fields tend to have weaker tools to measure and some not  3.Measure learning is not just for diagnosis, but for revealing more possibilities to the learner - WHY   Note - Why measuring learning is difficult:  multi-dimensional: simplify it too much to capture the data / the understanding of the data learning is too board: too much, too contextual and idiosyncratic in some fields like computer science, have impressive tools to figure out; but in other fields especially humanities and professions we have much weaker tools for measuring learning learning is very personal thing: culture construct is hard to define and measure, but behaviors patterns/outputs can ask a wrong question - depends on what you mean by ""measure"": maybe no reliable simple proxy indicators of learning. learning is curiosity -&gt; memory; imagination -&gt; paraphrase. U word is understanding, cant's used because it is cognition word, things that we can't measure. certain kinds of things could indicate learning. culture and social implication, individual psychology. learning is complex and blackbox, which makes more difficult to respond to the data. 1.ability to assess any competencies is problems. 2.Like MOOC, we don't know what people's competencies are. learning is kind of multiple measures of competence strung together that can associate with a particular experience. need to have new technologies to assess learning, people's learning at different time points. say what you want, measure efficiently and precisely. constructs. when talk about measure, really talking about either psychological constructs like self-efficacy or achievement. analytic is for the learner as well, be conscious. not to answer a question right or wrong, but reflection their learning process. analytic to reveal more possibilities for their own connected learning, not just diagnosis. be a doorway to suggest what else is possible. both oversimplify and too complex to understand are problems. maybe somewhere in the middle can find a good definition.   ",11,15,-4,1
"416","Saturday Morning Breakfast Cereal"," This is a funny but thought-provoking comic. Undoubtedly, what we care (educational concept or psychological construct) plays an important role in the policy, and then education process of the students. Cause-and-effect relationship is not correlation. The direction of correction can be two sides. We should not over-interpret the statistics results. Statistics is dead until it is connected with the context, the theory etc. How we organize and interpret the data is much more important. ",2,1,1,2
"417","Data wranglers: human interpreters to help close the feedback loop"," After reading this article I started to realize and appreciate the idea that “closing the feedback loop to improve learning is at the heart of good learning analytics practice”. Human meaning-making plays an important role to support the learning analytics process. In fact, I am deeply impressed by the good case practice of human Data Wranglers at the Open University, UK, because of the systematic approach they are adopting in the organization. No matter for which organization in education area, the trend of data is a huge change that impact on nearly everyone. From an organization psychology perspective, how to manage the change from a systematic approach is very important, and it can influence the actual results. That’s why I appreciate the organization practice of Open University, like ""academic staff/faculty and researchers need to be supported to learn to interpret and design learning analytics”, “establishment of a contextual framework”, “developing a culture of data use as part of increasing organizational capacity”. I am also excited to see that data wranglers “building up relationships with key stakeholders toenable the reports to focus on areas where they can be of most value” and “seek opportunities to engage withFaculty academics”. By doing this, every stakeholder can have proper communication with each other, and can “steer the agenda towards richer conceptions of learning than a naive quantitative view”, to make sure synergy can happen between learning analytics and learning design. I appreciate this systematic approach. Just like what it mentioned at the end of the paper: “present data 'to those involved in strategic institutional planning in ways that have the power to motivate organizational adoption and cultural change’”. I feel strongly inspired by this as a social-organizational psychology student. They also utilize a human resource development approach to build learning analytics capacity as part of a Community of Practice, breaking the general assumption that the role of data wrangler is only to analyze the data. Additionally, all data is available to academics directly, which can stimulate their autonomy to a larger degree. The article makes it clear by presenting three scenarios clearly and concisely in the pictures. Meanwhile, we also have to admit that this is a high cost approach in terms of time.    Now it is an institution-wide top-down analytics strategy in place, and this is built on a bottom-up understanding of at least some of the potential of the data to improve learning.  A bottom-up, grounded approach is necessary for sense making. However, as Macfadyen &amp; Dawson powerfully argue, organisational change is hard to achieve without meaningful engagement at the strategic, top-down level as well. Students and teachers areclosest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact.   Transformatory change is likely to take substantial amounts of time. It is only through the detailed processof engagement and dialogue between analysts, stakeholders andthe data that insight and organisational change are developed.    other important notes:  A learning analytics system may be used simply to attempt toachieve set goals (single-loop learning); greater value and insight will come if those goals themselves can be interrogated, challenged, and developed (double-loop learning) goals of data wrangler   immediate goal: producing reports with actionable recommendations overall aim: drive systematic improvement through single-and double-loop learning, and through the support and development of a Community of Practice at the Open UniversityUK (OU)   data wranglers work with four main data sources: Survey feedback data; Activity data; Delivery data; Aggregated completion, pass rate and demographic data. good practice   concerns the importance of assessment students' enjoyment of different learning activities data wrangler process at its best   feedback   positive: value the process, iterative, conversational nature; stimulate productive reflection and discussion with many stakeholders. less positive: desire for more data to be included; unevenness of the process across faculties; data quality   ",27,4,23,1
"418","Zuckerberg is ploughing billions into 'personalised learning' – why?"," This paper offers the pros and cons of personalized learning, and the potential compromising solutions for its promising future. For Zuckerberg, the definition of personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”. the underlying principles are the similar with how Facebook’s news feed works: human work is replaced by technology, algorithms provide users with context based on analysis of their past behavior and demonstrated interested. The author thought there were three major flaws of that   generable knowledge and skills are also important, but they are ignored in personalized learning the real world life will not be always accommodating and students need the ability to compensate children’s preferences often change as immediate responses to the environment, and valuable social contact between students, teachers and parents are important it also poses a privacy risk if it is not managed properly   personalized learning could help a lot in the motivation, which is crucial for effective learning. we can combine user data with standard educational content. ",7,2,5,2
"419","Feature Selection","feature selection   knowledge discovery (human being)   interpretability for insights should not be ignored!       curse of dimensionality (machines and machine learning algorithms)   the amount of data you need grows exponentially in the number of features that you have. reduce the number of features hopefully, to make learning problems easier the goal is to be able to use a bunch of features, and then by applying some of the algorithms to get to just the important features -&gt; understand data better + have easier learning problems    ",3,2,1,5
"420","Chapter 1: Social Network Data","  This article also introduces basic statistical measures/concepts of social network. It emphasized the dependent characteristics of social network data as well. It is great that it compare the scales of measure of network with conventional data, which is very clear. network data is a special form of conventional data, but actors are described by their relations, not by their attributes. nodes (actors); edges (relations). network designs can be described as nested designs / hierarchical designs usually identify some population and conduct a census (include all elements of the population as unites of observation)   two types of boundaries of the populations: boundaries that already known (priori) vs. more demographic/ecological approach to define the boundaries expand the boundaries by replicating populations: expand the scope vs. inclusion of multiple levels of analysis / modalities   sampling ties   full network methods: collect information about each actor’s ties with all other actors   maximum of information; costly and difficult to execute, difficult to generalize   methods that like conventional survey research: less information about network structure, less costly, easier generalization.   snowball methods    continues until no new actors are identified, or until we decide to stop (usually for reasons of time andresources, or because the new actors being named are very marginal to the group we are tryingto study). particularly helpful for tracking down ""special” populations limitations: actors who are not connected are not located; no guaranteed way o findings all of the connected individuals in the population   ego-centric networks (with alter connections)   begin with a selection of focal nodes (egos), identify the nodes to which they are connected effective for collecting a form of relational data from verylarge populations, and can be combined with attribute-based approaches   ego-centric networks (ego only)   focus on the individual, rather than on the network as a whole understand how networks affect individuals, give a incomplete picture of the general texture of the network as a whole       if don’t know what relations to examine, can use systems theory to decide   material domain: “conserved” in the sense that they can only be located at one node of the network at a time informational domain: “non-conserved” in the sense that they can be in more than one place at the same time simple possession of a common attribute (e.g. gender) vs. the presence of a tie (e.g. the exchange of views between two persons on issues of gender)   scales of measurement   binary measures multiple-category nominal measures    nominal or quantitative, each person’s relationship to the subject is coded by its type, rather than its strength. similar to “dummy coding""   grouped ordinal measures   coded -1, 0, 1 to reflect negative liking, indifference, and positive liking “strength”: frequency of interaction “intensity”: the degree of emotional arousal associated with the relationship ties can be strong if involving many different contexts or types of ties; or reciprocated   full-rank ordinal measures   score the strength of all of the relations of an actor in a rank order from strongest to weakest such scales reflect differences in degree of intensity, but not necessarily equal differences usually it will be treated as if they were interval   interval measures (most advanced level of measurement)   mathematical approaches to network analysis tend to treat the data as deterministic. statistical analysts tend to regard the particular scores on relationship strengths as stochastic or probabilistic realizations of an underlying true tendency or probability distribution of relationship strengths differences of social network data: not probability samples; not independent. -&gt; these differences might bring questions of generalization of findings, and for mechanics of hypothesis testing.  ",10,5,5,4
"421","RStudio Cheat Sheets"," workflow: open a new .Rmd file -&gt; write document -&gt; knit document to create report -&gt; preview output -&gt; publish -&gt; examine build log -&gt; use output file embed code with knit syntax: inline code, code chunks, global options parameters:    add parameters: params call parameters: param$&lt;name&gt; set parameters: knit with parameters / render()   Pandora’s Markdown: check the cheatsheet. a useful way to edit the document Set render options with YAML: very confused… will work on it very soon. create a reusable template   create a new package with a inst/rmarkdown/teamplates directory in the directory, place a folder that contains   `template.yaml skeleton.Rmd any supporting files   install the package access template in wizard at File -&gt; New File -&gt; R Markdown   table suggestions:    knit::kable() print(xtable::xtable(),type=“html”,html.table.attributes=“border=0”)) stargazer::stargazer(data,type=“html”,title=“table with stargazer”)   citations and bibliographies:    set bibliography file use citation keys in tex render   ",2,0,2,1
"422","Translating Learning into Numbers: A Generic Framework for Learning Analytics"," Thanks to this generic framework, I have a general understanding towards learning analytics. The framework contains both technically-focused research questions and softer issues and problem areas. There are six critical dimensions of LA, including stakeholders, objectives, data, instruments, external constrains, internal limitation. It is very impressive that the generic framework also includes soft issues - challenges that depend on assumptions being made about humans or the society in general. The framework can be used as a checklist when designing a purposeful LA process; or as a sharable description framework to compare context parameters with other similar approaches in other contexts. I agree that the framework is more like “both a descriptive approach as well as a guide to the design process of LA applications”, and that “development should not happen without a guiding framework that combines use of educational data with theprotection of individuals and their learning.”. Personally for me, this is more like a standardized process and materials, and it is qualitative instead of quantitative. We are not sure how the inherent connections among the six dimensions are connected. The general preference of this article is more soft issues focused, and less technically-focused. I am most impressed by the assumption of this framework - “responsible designers of analytic processes will not only implement what is technically possible to do and legally allowed (or at least not prohibited), but to consider holistically the outcomes for stakeholders and, even more importantly, the consequences for the data subjects.” Other insights that I’ve got are   I never thought of this perspective until seeing this article - ""by comparison, still seem somewhat bizarre that in the commercial worldwith clicking the “register” button, the default access to all user data becomes owned by some company, whereas educational institutions operate on the default that everything is protected from virtually everyone.” “Using statistical analytic findings is a quantitative not a qualitative support agent to such decision making.” “aligning and regulating performance and behaviour of individual teachers or learners against a statisticalnorm without investigating the reasons for their divergence may strongly stifle innovation, individuality, creativityand experimentation"" “From a technical point of view, idealised datasets probably remain the biggest challenge for analytics” “users ‘pollute' databases by producing erroneous or incomplete datasets."" “High drop-out rates are a challenging problem in education, especially distance education."" “Competing methods, technologies and algorithms applied to the same set of data, will result in different outcomes, and thus may lead to different consequences in terms of decision making based on these outcomes."" ""The fundamental question legislators need to ask is: who does a person’s lifedata belong to?"" ""the extent of a student’s data contract with an institution and its individual staff representatives indifferent roles (teacher, administrator, secretary, researcher, IT support staff, Deans and management, etc.) needs to be urgently clarified.""   “data economy” is a current trend and it made collecting data an affordable activity, and it can reflect real and un interrupted user behavior. ",17,6,11,1
"423","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC"," I love the research goals of this paper. They are very interesting and relevant, especially considering the application of MOOC in life, and how are the effects comparing with traditional face-to-face courses’ effects. The six research goals not only provide the teaching recommendations, but also they imply the trend of the education in the future. However, this article is a little bit boring for me. It might because the simple statistics methods, heavy design and performance measure details, and more importantly, it might not be my particular interest field. I will just mark down some key results:   intention predicts completion; little else does. student knowledge increased face-to-face students learned at least as much as online-only students students at all incoming knowledge levels benefited similarly from the course students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking     ",7,4,3,4
"424","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement"," The eEPHIPHANY proposed in this article is really fantastic. It provides a new method to refine the skills for me (previously I did test refinement with the combination of LFA and human experts, that is, using expert to define and revise the Q-matrix in CDM). eEPIPHANY has high accuracy and requires low human labor, and it is very impressive. Their core goal is to provide evidence-based feedback for online course refinement (clear educational goal). Transfer to eEPIPHANY method, technically, their goal is to find a skill model (Q-matrix) that produces the best prediction of the A-matrix. The predictive power is measured by cross-validation feature extraction: clustering assessment items with latent features that would best characterize  the similarity in the difficulties of assessment items   Matrix factorization (MF) strategy: check the paper for more detailed information. it is very great. Bag-of-words (BoW) strategy: create the F-matrix directly from a collection of item stems for assessment items.   skill model construction: proposing a new skill model by assuming that the above-mentioned cluster of assessment items provides a hint for new skills   Replace strategy: the P-matrix is straightforwardly converted into the Q-matrix Append strategy adds more skill-item associations to the default skill model, while the original skill-item associations in the default skill model remain intact Split strategy: individually splitting skill-item associations into multiple new skill-item associations   model search: searching for the best skill model by comparing multiple skill model candidates model interpretation: the DoE (degree of enhancement) analysis results: MF strategy always outperformed BoW strategy. when MF strategy is used, replacing the default skill model with completely new skill model discovered by eEPIPHANY yielded the best skill model, while split strategy always resulted in producing inferior skill model (suggesting that the split strategy hardly improves on the human-crafted skill). ",25,6,19,5
"425","Big Data in Education","Chapter 1 Video 1    This course mainly introduces EDM/LAK. The whole idea is that EDM/LAK is great! Well, it talks about the methods, background, application, contents in this class with regard to EDM/LAK. Here are the most useful things: types of EDM/LA method   prediction: develop a model which can infer a single aspect of the data (predicted variable) from some combination of other aspects of the data (predictor variables)   classification regression later knowledge estimation   structure discovery: find structure and patterns in the data that emerge “naturally”; no specific target or predictor variable   clustering factor analysis domain structure discovery network analysis   relationship mining: discover relationships between variables in a data set with many variables   association rule mining correlation mining sequential pattern mining causal data mining   distillation of data for human judgment discovery with models: pre-existing model; applied to data and used as a component in another analysis   Closing thoughts    EDM/LAK methods emerging for big data in education   we will learn key methods and use them for   promoting scientific discovery driving intervention and improvements in educational software and systems   strengths and weaknesses of methods for different applications is your analysis trustworthy? is it applicable?     ; Chapter 2 Video 2 &amp; 3 &amp; 4    metrics for classifiers   accuracy / agreement (when measuring inter-rater reliability)   accuracy does poorly when there is non-even assignment to categories, which is almost always the case   kappa (learn how to compute kappa in a 2x2 example)   kappa = 0: agreement is at chance kappa = 1: agreement is perfect kappa = -1: agreement is perfectly inverse kappa &gt;1: you messed up somewhere kappa &lt;0: your model is worse than chance. seen more commonly if you are using cross-validation (it means your model is junk) 0&lt;kappa&lt;1: there is no absolute standard for a good kappa   why is there no standard? because kappa is scaled by the proportion of each category. when one class is much more prevalent, expected agreement is higher than classes are evenly balanced. because of this, comparing kappa values between two data sets, in a principled fashion, is highly difficult. it is okay to compare Kappa values within a dataset. informally, can compare two data sets if the proportions of each category are “similar""     ROC (receiver-operating characteristics curve)   predicting something which has two values prediction model outputs a probability or other real value four possibilities: TP, FP, TN, FN ROC curve   A’ (A prime, a close relative of ROC)   the probability that if the model is given an example from each category, it will accurately identify which is which is mathematically equivalent to the Wilcoxon statistics  useful result, because it means that you can compute statistical tests for   whether two A’ values are significantly different (same data set or different data sets) whether an A’ value is significant different than chance   not really a good way (yet) to compute A’ for 3 or more categories this test assumes independence.  closely mathematically approximates the area under the ROC curve, called AUC caution: the implementation of AUC are buggy in all major statistical packages that I’ve looked at. special cases get messed up.   A’ and Kappa   A’: more difficult to compute; only works for two categories (without complicated extensions); meaning is invariant across data sets (A’=0.6 is always better than A’=0.55); very easy to interpret statistically A’ values are almost always higher than Kappa values A’ takes confidence into account   precision and recall   precision = the probability that a data point classified as true is actually truer recall = the probability that a data point that is actually true is classified as true   still active debate about these metrics   A’ is more robust to skewed distributions than Kappa and also several other metrics models selected with RMSE come close to true parameter values than A'     metrics for regressor   linear correlation   same correlation, different functions look at scatter why are small correlations OK in education? lots and lots of factors contribute to just about any dependent measure   r square   the correlation, squared a measure of what percentage of variance in dependent measure is explained by a model r square is often used as the measure of model goodness rather than r (depends on teh community)   RMSE (root mean squared error ) / MAD (mean absolute deviation)   MAD   average of  absolute value (actual value minus predicted value)   RMSE   square root of average of  (actual value minus predicted value) square   MAD vs. RMSE   MAD tells you the average amount to which the predictions deviate from teh actual values: very interpretable RMSE can be interpreted the same way (mostly) but penalizes large deviation more than small deviation     Good model = low RMSE/MAD, high correlation   low RMSE/MAD is good high correlation is good high RMSE/MAD, high correlation = model goes in the right direction, but is systematically biased low RMSE/MAD, low correlation = model values are in the right range, but model doesn’t capture relative change (particularly common if there is not much variation in data)     information criteria   BiC   Bayesian Information Criterion makes the trade-off between goodness of fit and flexibility of fit (number of parameters) values over 0: worse than expected given number of variables values under 0: better than expected given number of variables can be used to understand significance of difference between models said to be statistically equivalent to k-fold cross-validation for optimal k BiC is easier to compute than cross-validation, but different formulas must be used for different modeling frameworks. no BiC formula available for many modeling frameworks   AIC   alternative to BiC stands for: an information criterion / akaike’s information criterion makes slightly different trade-off between goodness of fit and flexibility of fit (number of parameters) said to be statistically equivalent to leave-out-one-cross-validation   AIC or BIC: which one should you use?   “the idea of looking for a single best measure to choose between classifiers is wrongheaded.""     ; Chapter 2 Video 5    over-fitting   fit the noise as well as the signals reduce over-fitting   use simpler models: fewer variables (BiC, AIC, Occam’s Razor); less complex functions (MDL)   eliminate over-fitting?   every model is overfit in some fashion the questions are: how bad? what is it over-fit to?   assess generalizability   does your model transfer to new contexts? or is it overfit to a specific context? training set/test set model tested on unseen data, but uses data unevenly     cross-validation   split data points into N equal-size groups train on all groups but one, test on last group for each possible combination how many groups?   K-fold: pick a number K, split into this number of groups   quicker; preferred by some theoreticians   leave-out-one: every data point is a fold   avoid issue of how to select folds (stratification issues)     cross-validation variants   flat cross-validation   each point has equal chance of being placed into each fold   stratified cross-validation   biases fold selection so that some variable is equally represented in each fold the variable you’re trying to predict or some variable that is thought to be an important context   student-level cross-validation   folds are selected so that no student’s data is represented in two folds allows you to test model generalizability to new students as opposed to testing model generalizability to new data from the same students usually seen as the minimum cross-validation needed, in the EDM conference papers that don’t pay attention to this issue are usually rejected easy to do with Batch X-Validation in RapidMiner     other levels sometimes used for cross-validation: lesson/content, school, demographic (urban/rural/suburban/race/gender), software package important consideration   where do you want to be able to use your model? make sure to cross-validate at that level     ; Chapter 7 Video 1 &amp; 2   video 1 - clustering  the biggest takeaway from this video is to understand how k-means clustering algorithm work through different examples clustering: have a large number of data points; want to find what structure there is among the data points; don’t know anything a priori about the structure. clustering tries to find data points that “group together” clustering works for (and is effective in) large features spaces k-means clustering algorithm is the simplest one   first, decide how many clusters we wanted pick starting values for the “centroids” of the clusters   usually chosen randomly sometimes there are good reasons to start with specific initial values, like insights from old data set   classify every point as to which centroid it’s closest to   this defines the clusters typically visualized as a voronoi diagram   refit the centroids as the center of the points in each cluster repeat the process until the centroids stop moving “converge"" - no points switched   outliers. starting points might be in a strong place. (cluster might be empty as well)   one solution: run several times, including different    a lot depends on initial positioning and on the number of clusters    video 2 - Validation and Selection of K  distortion / mean squared deviation    steps   take each point P find the centroids of P’s cluster C find the distance D from C to P square D to get D’ sum all D’ to get Distortion   works for choosing between randomized restarts not works for choosing cluster size, because more clusters almost always leads to smaller distortion   distance to nearest cluster center should almost always be smaller with more clusters it only isn’t when you have bad luck in your randomization cross-validation can’t solve this problem   a different problem than prediction modeling   you are not trying to predict specific values you are determining whether any center is close to a given point   more clusters cover the space more thoroughly so distortion will often be smaller with more clusters, even if you cross-validate   solution:    penalize models with more clusters, according to how much extra fit would be expected from the additional clusters can use the Bayesian Information Criterion or Akaike Information Criterion (not just cross-validation) using an informational criterion   assess how much fit would be spuriously expected from a random N centroids (without allowing the centroids to move) assess how much fit you actually had find the difference   so how many clusters?   try several values of k find “best-fitting” set of clusters for each value of k choose k with best value of BIC (or AIC) alternate approach (not data driven): “why am I conducting cluster analysis?”   if your goal is to just discover qualitatively interesting patterns in the data, you may want to do something simpler than using an information criterion — add clusters until you don’t get interesting new clusters anymore           distance   usually Euclidean distance  distance from A to B in two dimensions Euclidean distance can be computed for an arbitrary number of dimensions   ; Chapter 7 Video 6   knowledge inference: Q-Matrix   what is the Q-Matrix   a table, where rows are items, and columns are skills also called a KC (knowledge component) Model, or a skill-item mapping   how do we get a skill-item mapping?   automatic model discovery   learn the mapping between items and skills solely from data recent interest in non-negative matrix factorization; lots of linear algebra first question - how many skills do we use? this is determined empirically.   try 1 skill try 1 more skill than previous model does the new model do better than the previous model? if so, go to step 2; if not, quit and use the previous model.   for each number of skills, the algorithm will be run a certain number of times, with a different (random) initial assignment of items to skills. this avoids local minima. next, take a set of passes through the table. systematically look at whether flipping each 1 to 0 (and each 0 to 1). produces a better model.   continue this process a predetermined number of times, or until a pass results in no changes.   how do we know whether it is a better model   Barnes et al.’s definition   better models have the property that if a student knows skill X. and item 1 and item 2 both have skill X. then a student who gets item 1 right will be more likely to get item 2 right. item 1 wrong -&gt; item 2 wrong. item 2 right -&gt; item 1 right. item 2 wrong -&gt; item 1 wrong given a skill-item mapping, you can predict, for each combination of skills whether a student should get each item correct or not a model’s degree of error is based on how many item-student pairs the prediction gets wrong it assumes no learning   subtlety   is skill conjunctive? (need all relevant skills to get an item right) is sill compensatory? (any relevant skill leads to getting an item right)   alternate test of model goodness   look at student improvement over time fit a model like PFA or BKT, see how well it fits data, given the skill-item mapping       hand-development and refinement   the original way that Q-Matrices were created a domain expert creates the Q-Matrix using knowledge engineering strategies for Q-matrix refinement   try to smooth learning curves look for skills with no apparent learning look for problems with unexpected error rates tool: pittsburgh science of learning center datashop   pslcdatashop.web.cmu.edu     learning curve   shows relationship between about of practice and performance spikes in learning curves, often imply two (or more) skills are being treated as a single skill can inspect curves for individual skills - many curves show a reasonable decline. some do not -&gt; opportunity to improve model (can be teaching really bad) also look for problems with unexpected error rates (if actual error rate is much higher than predicted error rate, need to look at it -&gt; might be the skill did not fit what you think it is)   datashop can apply model for you   applies a mathematical model called LFA (similar to PFA) to data can give AIC and BIC goodness measures for different skill-item mappings     hybrid approaches    ",74,48,26,5
"426","Cross Validation"," This video introduced the cross validation concept, including the training set and testing set, overfit, k-fold. use a model that is complex enough to fit the data without causing problems on the test set  k-fold: goodness of the fit, is to average all the errors from all models together. pick a model with lowest error. ",2,4,-2,5
"427","Data wrangling cheatsheet.pdf"," dplyr::tbl_df() dplyr::glimpse() dplyr::%&gt;% tidy data: each variable is saved in its own column. each observation is saved in its own row. reshape the data   tidyr: gather(), spread(), separate(), unite() dplyr: data_frame(), arrange(), rename()   subset observations (dplyr)   filter(), distinct(), sample_frac(), sample_n(), slice(), top_n() %in%: group membership   subset variables (dplyr)   select() some helper functions: contains(): ends_with(), everything(), matches(). num_range(), one_of(), starts_with().   summaries data (dplyr)   summarise(): summarise_each(): count() first(), last(), nth(), n(), n_distinct(), min(), max(), mean(), median(), var(), sd()   make new variables (dplyr)   mutate() mutate_each() transmute()   combine data sets (dplyr)   mutating joins: left_join(), right_join(), inner_join(), full_join() filtering joins: semi_join(), anti_join() set operations: intersect(), union(), setdiff() binding: bind_rows(), bind_cols()   group data (dplyr)   group_by() ungroup() .. %&gt;% group_by() %&gt;% summarise() .. %&gt;% group_by() %&gt;% mutate()   ",0,0,0,1
"428","Ethics and Learning Analytics: Charting the (Un)Charted.pdf","Thoughts and Feelings:  It is good to see some people take ethic in learning analytics seriously. I am deeply impressed by that learning analytics is a MORAL practice, and the problems are not only privacy as we usually thought. The “moral practice"" has shown the respectiveness towards data, and more importantly, the people/intention behind the usage of data. It has to be student-centered without doubt, and they are supposed to have choices to opt-in or opt-out. Central to this issue is the question of “who benefits?” A lot of other issues will also concern on the technical aspects (including interpretation of the data etc.) and current policy / organization culture. It will be great if more people from different areas their attention could be attracted on this essential issue, and collaborate to solve it.    Notes:   consensus of future learning: digital, distributed, data-driven. ethical concerns: data governance, data security, privacy issues   location and interpretation of data informed consent, privacy, and the de-identification of data the management, classification, and storage of data   Learning analytics in future will be essentially based on and driven by algorithms and machine learning and we therefore have to consider how algorithms “reinforce, maintain, or even reshape visions of the social world, knowledge, and encounters with information”   Accountability, transparency, andregulatory frameworks will be essential elements   ",4,5,-1,2
"429","Measurement and its Uses in Learning Analytics.pdf","Thoughts and Feelings:  I love this paper. I’ve studied several psychometric classes during my undergraduate study, and this article reminds me of lots of important concepts in a nutshell. However, i hope to see some connections between psychometric methods and learning analytics, or the implications for future learning analytics / psychometric development. I am interested in the multidimensional construct. It is true that     Notes:  question on P37 P38 P39 GROW MODEL prediction and explanation  The use of tests and questionnaires is a matter of both efficiency and standardization. In learninganalytics, efficient collection of data is usually not the problem, but the lack of standardization can make it challenging to account for measurement error. reliability: sample-dependent (in true score theory), model-dependent (more complicated models)   reliability coefficient - Cronbach’s alpha test-retest reliability inter-rater reliability - Cohen’s kappa   validity: evidence and theory support the interpretationsof test scores for proposed uses of tests   response process internal structure of the instrument convergent and discriminant evidence criterion references (including predictive criteria) generalizability types of response bias: acquiescence bias. social desirability bias, bias from extreme and moderate types of responders, intentional rapid guessing behavior   measurement models factor analysis   true score theory / classical test theory EFA, PCA, CFA, path analysis, later growth models, SEM   latent dirichlet allocation (LDA), model-based cluster analysis item response theory (IRT) growth models: Bayesian knowledge tracking (BKT), Additive factors models (AFM), Learning curve analysis cognitive diagnosis models (CDM) explanation and prediction   “in explanatory modelling the focus is on minimizing bias to obtain the most accurate representation of theunderlying theory. In contrast, predictive modellingseeks to minimize the combination of bias and vari-ance, occasionally sacri cing theoretical accuracyfor improved empirical precision”   learning analytics as a “middle space” between learning scienceand analytics; Perhaps it may also be thought of asoccupying a methodological middle space between explanatory and predictive approaches. ",4,10,-6,5
"430","k-Means Clustering","use of K-means clustering:  The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. / If n points are embedded in a p-dimensional space, then k clusters are summarized by their respective centroids (average of the cluster members' coordinates) in that space. k-means is most suited for separating convex clusters (clusters in which any line passing through a cluster intersects its boundary only twice). finding a satisfactory set of centroids given a set of data.  The simplest is to pick an initial set of centroid seeds randomly (assuming we know how many clusters we want) and to assign each point to its closest seed. If there really are blobs of points, we do much better to begin with locations that are relatively close to the center of these blobs. [stagewise method]   “we need to know k to find clusters and we need to identify clusters to determine k.” - Hartigan gives an approximate F statistic that can be used to test the ""significance"" of this reduction, but a simple method that works well for most datasets is to look for a proportional reduction in error (PRE) of about .4 or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares. Use the PRE method to determine the number of clusters present.  limitations of K-means clustering:  If your data contain doughnut-shaped or wormy-shaped clusters, don't expect k-means to find them. There will also be rare instances when clearly separated blobs are not identified. These are cases where the PRE statistic misses the cutoff (.4) by a small amount. There is always a tradeoff between false positives and false negatives, but we could improve this situation a bit by using more information than simple sums of squares. Data mining programs incorporating k-means sometimes ignore the subtleties of the algorithm. However, it might find nice clusters even when they don't exist in the data. ",8,5,3,1
"431","Predictive Modelling in Teaching and Learning"," This paper mainly focus on the basic concepts and issues of predictive modeling in teaching and learning. explanatory modeling is a post-hoc and reflective activity aimed at generating an understanding of a phenomenon. the largest methodological difference between the two modeling approaches is in how they address the issue of generalizability.  several strategies for producing hold out datasets: k-fold cross validation, leave-one-out cross validation, randomized subsampling, and application-specific strategies. several factors make predictive modeling more difficult or less appropriate   data sparsity / missing data noisy data in some domains, inferences produced by predictive models may be at odds with ethical or equitable practice   event-data: largely student activity-based, and is derived from the larding technologies that tudents interact with. this data is large and complex, requires significant effort to convert into meaningful features for machines learning. four types of data: categorical, ordinal, interval, and ratio   in practice, ordinal is often treated as categorical. interval and ratio are considered as numeric. classification algorithms are used to predict categorical values, while regression algorithms are used to predict numeric values   feature selection   collect more information rather than less examine the correlation between features: either remove highly correlated attributes (the multicollinearity problem in regression analysis), or apply a transformation to the features to eliminate the correlation (in practice, the dependencies between features are often ignored) missing values in a dataset: methods depends on whether data is missing is because it is unknown or because it is not applicable   remove the attributes (columns) or instances (rows) that have missing values (drawback like in domains where the total amount of data is quite small) infer the missing values from the other known data: replace missing values with a normal value, such as the mean of the known values. fill in missing values in records by finding other similar records in the dataset, and copying the missing values from their records     methods for building predictive models   basic assumption: the relationship that exist in the data gathered in the past will still exist in the future linear regression, logistic regression, nearest neighbors classifiers, decision trees, naive bayes classifiers, bayesian networks, support vector machine, neural networks, ensemble methods once a given technique has shown promise, time is better spent reflecting on the fundamental assumptions of classifiers, exploring ensembles of classifiers, or tuning the parameters of particular methods being employed   evaluating a model: compare two models. k-fold cross validation. challenges and opportunities   supporting non-computer scientists in predictive modeling activities creating community-led educational data science challenge initiatives engaging in second order predictive modeling. second order predictive models - include historical knowledge as to the effects of and intervention in the model itself    ",5,20,-15,3
"432","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data."," The main idea of this article is to use examples to illustrate that explanatory models can improve learning outcomes and/or learning theories. It reminds me of the CDM (cognitive diagnostic model) that I’ve learned before, and I realized that limits of using expert opinions as a way of determining the Q-matrix at that time, and what I could do differently now.   transitional ways of constructing cognitive models: structured interviews, think-aloud protocols, rational analysis, and labeling by domain experts. they require human input and are often time consuming, subjective. Expert-engineered cognitive models often ignore content distinctions that are important for novice learners.   It also provides more bottom-up methods of creating stereotyped groups of students. This method yielded student groups that are readily interpretable and potentially actionable (prior attempts include K-means and spectral clustering) For a model to be explanatory, one should be able to understand why the model achieves better predictive accuracy than alternatives. In addition, the understanding of this why should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both. AFM: Additive factors model DFA: Difficulty factors assessment KC: Knowledge component Learning factors analysis (LFA) was developed to automate the data-driven method of KC model refinement to further alleviate demands on human time. predictive models: aim to find a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data explanatory models: seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. EDM research has focused on developing two types of models   statistical models: drive the outer loop of intelligent tutoring systems based on observable features of students’ performance as they learn cognitive models: representations of the knowledge space (facts, concepts, skills) underlying a particular educational domain   common characteristics of explanatory models   tend to start with “clean” independent variables that have either simple functions or map to clearly defined constructs   incorporating some human time and thought into defining and labeling these independent variables up front can greatly improve the explanatory power of the resulting model   having parameters that map to interpretable constructs   actionability: the dependent variable maps to a well-defined&amp;;construct   having fewer parameters overall   fewer independent variables. AFM has only one parameter for each student and two parameters for each knowledge component   involving human input early in the model development process   ",6,1,5,5
"433","Measurement and its Uses in Learning Analytics","    The authors of this article argue that the use of learning analysis tools is always consistent with the assessment system. The evaluation system is based on the epistemological hypothesis and teaching practice. Thus, a specific learning analysis tool expresses a commitment to a specific educational worldview, aimed at cultivating a specific type of learner. ",0,0,0,2
"434","Ethics and Learning Analytics: Charting the (Un)Charted","    This chapter describes how our own minds have evolved, contrasting our journey learning analysis with broader developments. With technological advances, ubiquitous monitoring, and growing concerns about the role of algorithms and unintended consequences, the study of learning analytics as an ethical and moral practice has provided a rich picture of fear and reality.     Each framework, practical code, and the concept of ethical meaning in learning analysis discussed in this article adds a deeper level and richer understanding of how to move forwardIt is economically feasible to use student data agents to improve the effectiveness and appropriateness of teaching, learning, and student support strategiesMethods. But actual implementation remains largely incomplete.",3,3,0,2
"435","Predictive Modelling in Teaching and Learning","    Learning analysis is the embodiment of the transformation of society to the popularization of algorithms. In this article, the authors argue that the use of learning analysis tools is consistent with the assessment system. The evaluation system is based on the epistemological hypothesis and teaching practice. Therefore, fundamentally, the author believes that the development of a specific learning analysis tool expresses a commitment to a specific educational worldview in order to cultivate a specific type of learner. The author discusses some key problems in the development of learning analysis technology. For example, the purpose and hypothesis of learning analysis are proposed. And use ""claim analysis"" to analyze the position of the design of the technology.",1,1,0,2
"436","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","    In the statistical modeling of educational data, there are many ways to build prediction models or explain models according to the goal. The purpose of a predictive model is to find the combination that best predicts the outcome. Explanatory models attempt to find an interpretable causal relationship between constructs that are observable or inferred from data.      The article also summarizes some of the common characteristics of interpretive models, such as having parameters that map to interpretable constructs, having fewer parameters, and the manual inputs involved early in the model development process.",1,0,1,5
"437","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","    The author proposes a set of graphical display objectives, which are mainly based on and from the perspective of statistics to explore some inherent contradictions in the objectives that hinder the communication between statistics and information systems. For Infovis practitioners and statisticians, constructive advice is to try to present better in two or more charts. The authors realize that only one perspective is provided, and hope that this article is a starting point for a broad discussion of statistical methods among graphic designers, statisticians, and users. The purpose of this article is not to criticize but to explore different goals that lead researchers in different fields to value different aspects of data visualization.",2,4,-2,2
"438","Junkcharts Trifecta Checkup: The Definitive Guide","    After reading this article, I learned that the Trifecta examination framework established the classification of the dataviz review.     There are eight types of reviews: 1.The trifecta 2.The singles -Type Q -Type D -Type V 3.Doubles -Type QD -Type QV -Type DV 4.Triple (Type QDV)  ",0,0,0,2
"439","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","    At present, school staff lacks effective methods to model and visualize the collected data of student performance. The authors describe a study. In this study, an entire cohort of students was recorded using test scores assigned by longitudinal primary and secondary school teachers. It shows the novel's hierarchical cluster analysis and the pattern visualization of all the data points in the application queue. Visualization can help teachers and administrators in data-driven decision-making and interpretation. In addition, as a proof-of-concept study, overall school outcomes, such as students dropping out or taking college entrance exams, are identified from data patterns and compared over timeDropout identification method. Hierarchical cluster analysis correctly identified more than 80% of dropouts using historical patterns throughout the grade.",1,2,-1,3
"440","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","    This paper introduces the basic concept of SNA, the methods of data collection, data processing and data analysis. We analyzed the structure of the partnership network, explored the generation process, created a learning network of student observations, and tested the connection between network location and exam success. The article also discusses practical problems. Take, for example, the unique human commentary on Internet research. The author's goal is to make people feel that SNA can be used for rich and informative analysis in the classroom environment.",2,1,1,4
"441","Why Students Should Own Their Educational Data","I have to draw inferences about a population from a sample because I cannot get the population data at most of times. This main idea structures the some knowledge of basis of statistics: inference, hypothesis test.  Because when the MOOC owns the student's data, students are given to study the knowledge that set by MOOC, teachers need to own their student's data, and nurture every single one's future. ",0,0,0,4
"442","Knowledge tracing: Modeling the acquisition of procedural knowledge","    The author of this paper describes the modeling of students' knowledge state changes in the process of skill acquisition. In the study, students learned to write short programs under the guidance of the ACT programming tutor (APT). APT is built around the cognitive model of programming knowledge, which is an ideal student model. This model allows mentors to help students with their studies. In the process of learning, the tutor can also estimate the probability of each rule that the student learns in the model, which is called knowledge tracking. Based on these estimates, the instructor gives the students a personalized sequence of exercises until they ""master"" each rule.",3,0,3,3
"443","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","    This article focuses on increasing formal communication and collaboration between EDM and LAK. To develop research, methods, and tools for sharing data mining and analysis in the LAK and EDM domains. ""The EDM and LAK communities are defined in a relatively similar way"".     Both EDM and LAK reflect data-intensive approaches to education. In many departments, data mining and analysis have become an increasingly prominent activity for organizational insight. Extracting value from data for decision-making is a fundamental shift in the way an education system works. For example, LAK and EDM share the goal of improving educational assessment through improvements. Models and strategies. Both EDM and LAK communities have improved the quality of large-scale education data analysis and supported basic research and educational practices.",3,0,3,2
"444","Evaluating Machine Learning Models","    In this article, author Zheng introduces the workflow of machine learning and discusses the selection of evaluation indicators and models. The rest of the article covers hyper parameter tuning and A/B testing, which benefits more experienced machine learning practitioners. After reading this article, I learned about the basics of model evaluation, the metrics used to monitor learning models, and the stages involved in developing machine learning models for software applications",1,0,1,5
"445","Why Opting Out of Student Data Collection Isn’t the Solution","    The article mainly discusses how privacy principles can help us consider student data. The problem has two parts. First is how does data collection help students · Schools need to know basic information about students and parents during their operations. These include the need to keep track of students' grades, know who is eligible for subsidies, and who has special learning needs · Evaluating performance through data analysis is a necessary step to improve education. Second is when to opt-out · Share student data when parents' expectations of education and activities are irrelevant. · FERPA requires schools to provide opt-out opportunities for parents. Third is why opting out isn't the solution    ",0,2,-2,2
"446","Why Is Measuring Learning So Difficult?","    Learning knowledge, learning skills, learning from other's experiences are three things that I think of learning. After we learn these things, we need to execute them for measureing. How well we execute them is also hard to measure to see how well we learned. Testing if we have learned is hard to complete.",2,2,0,1
"447","Saturday Morning Breakfast Cereal","    The clocks means changeless test requirements. If the education goal is just pass the test requirement, the science, economy will also be encumbered. Creativity and various interests are the main sources of new discoveries in the progress of our culture and society.",1,0,1,1
"448","Data wranglers: human interpreters to help close the feedback loop","    The authors of this article argue that closing the feedback loop to improve learning is central to good learning analysis practice. However, the amount of data and the different data sources may make it more difficult to take systematic action on this data.     This article describes an activity scheme in which a group of ""data adjusters"" is used for meaning analysis activities and learning to analyze data. The objective is to produce recommendations and reports for action. The overall goal is to promote the systematic improvement of the Open University community of practice through single-cycle and double-cycle learning.",2,2,0,1
"449","Zuckerberg is ploughing billions into 'personalised learning' – why?","    Can we put the requirements into the personalized learning that including essential general knowledge into each person's personalized learning, changing learning ways in each period to train each person's ability to cope different learning ways, and reminding some new and different topics during studying? If we can, this personalized learning could decrease its dangers mentioned in the article. This should be a study tool to help students studying easier and more efficiently.",2,1,1,2
"450","Feature Selection","    Because when we have n features, we need 2 to the power of N observations to well predict the features. In some cases, only a few variables among a lot of ones have association with the response variable, so feature selection is really important to make the problem easier to solve.",2,1,1,5
"451","Chapter 1: Social Network Data","    The authors begin the article with a question: what's different about social network data?First, social network analysts use a special language to describe the structure and content of their observation sets.Second, data sets developed by social network analysts are often very different from the traditional rectangular data arrays familiar to survey researchers and statistical analysts. These differences lead to different ways of looking at data and thinking about how to apply statistics.",1,0,1,4
"452","RStudio Cheat Sheets","    R Studio cheat sheets helped me a lot. It tells me how to create a new .Rmd file, how to write document, how to knit document to create report, preview output and how to publish. It contains all the introductions to the rstudio. This is a good cheat sheet for a beginner in rstudio.",1,2,-1,1
"453","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","    This article discusses measurement and its application in learning analysis. It also introduces educational and psychometric practitioners in learning to analyze and mine educational data.",0,0,0,2
"454","Translating Learning into Numbers: A Generic Framework for Learning Analytics","    In this paper, the authors explore the key dimensions of learning analysis, problem areas, and potential dangers to the beneficial use of educational data. The authors present and discuss a design framework as a guide for establishing learning analysis services to support educational practice and learner mentoring, quality assurance, curriculum development, and teacher effectiveness and efficiency. In addition, this article will introduce the soft barriers and limitations of learning analysis. We identified the skills and capabilities necessary to meaningfully use learning analysis data to overcome gaps in explanatory literacy among education stakeholders. The final article also discusses the privacy and ethical issues and suggests how to address them through policy guidance and examples of best practices.",5,3,2,2
"455","The Big Five and Visualisations of Team Work Activity","    The authors have created a novel set of visualizations of group activities that reflect the interaction of individual activities. The author then evaluates these visualizations in a software development project course. Using the framework of ""big five"" teamwork theory, the author makes a theoretical analysis of visual design, and carries out a qualitative research on visual design and students' reflection reports. Finally, a conclusion is reached. These visual approaches provide a powerful and valuable mirroring effect that can help teams learn more efficiently.",1,0,1,2
"456","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","    This article introduces the recommendation system through Coursera, and USES Coursera platform and flipped classroom teaching model to provide the credit version of online courses. The purpose of this course is to experiment with new ways of teaching. So the authors conducted a wide range of assessments, including demographic surveys, self-assessment skills, and learning intentions. The authors also designed a knowledge assessment tool specific to the subject of the course, using it before and after the course to measure learning, and using it five months later to measure retention. In addition, the authors track students throughout the course, separating students who register for credit from those who only register for free open courses.",2,0,2,4
"457","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","    By reading this article, I quite agree with the author. Finding the right skills behind a problem is a difficult task. The authors explore how to use data-driven matrix decomposition to help experts accomplish this task. Two maps of projects and skills, one is expert, the other is matrix factorization. Experts compared their differences and performance in a linear model of skill assessment and project outcome prediction. Visual analysis shows that expert maps and factor maps are relatively similar patterns, albeit with differences. The comparison of prediction results shows that the performance of the factorization method is slightly better than that of the original expert q matrix, which provides supporting evidence for the effectiveness of the factorization mapping.",6,2,4,5
"458","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","    This article compares the models developed by the authors' team with existing methods (LFA) and human engineering skills models that can find precise sets of skills and knowledge for specific courses. The results show that the author's model is explicable, better than the artificially-designed skill model, and much faster than the existing methods. The authors first describe their assumptions and how they process the data. Then the model is built and applied to an example. Finally, evaluating and analyzing the results.",5,0,5,5
"459","Using data mining to predict secondary school student performance","    The high student failure rates in Portugal is mainly because of lack of success in Mathematics and the Portuguese language. Using business and data mining to analyze the data, including four data mining models. The results found that students' achievement has association with number of absences, parents' job and education, etc.",1,1,0,3
"460","Developing a generalizable detector of when students game the system","    The article describes how some students try to use this knowledge to answer questions correctly by developing features of the system in an interactive learning environment, thus achieving success in the environment. In this paper, the author also proposes a system that can accurately detect whether students are in the game system. The probes also distinguish between two different types of games, which are associated with different learning outcomes. The authors explore the ubiquity of this detector and find that it has been successfully transferred to the curriculum of new students and new instructors.",3,0,3,5
"461","Big Data in Education","    Big data in education course focuses on the methods of broadest usefulness, which is a good news for those students who have weak foundation of data mining including me. I am wondering what the difference in r^2 means.",2,1,1,2
"462","Cross Validation","    Cross validation is really a good way to test the model. Extract a part of data to test the model generated based on the rest of data. Do the same process for each part of data to get the lowest error. This method is really helpful in experiments",1,1,0,5
"463","Hands-On Programming with R","    R provides a number of functions that can be used to perform complex tasks, such as random sampling. Three basic parts in every function in R: a name, a body of code, and a set of arguments. I think function() function is very useful for me. I learned that the two most important components of the R language are objects that store data, and the functions that process the data.     This chapter describes library function, help pages and how to install packages. R's packages and help pages can make me a more efficient programmerFunctions and data sets in R have their own help pages. The help page contains many cables and examples to help you learn how to use functions.       ",0,2,-2,1
"464","Principal Component Analysis explained visually","    Principal component analysis is a technology that define the same number of new coordinate axis based on the variations to better visualize the data.",1,0,1,2
"465","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","The data on this seems to be very detailed, and would make for a good study.",1,0,1,1
"466","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","I think many teachers will benefit from this.",1,0,1,2
"467","Why Students Should Own Their Educational Data","I think there are alot of innovative questions here.",0,0,0,2
"468","Evaluating Machine Learning Models","I found it difficult to understand some of the mathematic areas related to machine learning.",0,1,-1,5
"469","Why Is Measuring Learning So Difficult?","This was an interesting question,",0,0,0,2
"470","The Data Wrangling Cheatsheet","I will refer to this cheatsheet in the future.",0,0,0,1
"471","RStudio Cheat Sheets","I found this very useful during the homework assignments.",0,0,0,4
"472","Translating Learning into Numbers: A Generic Framework for Learning Analytics","I think what is written here can be used in alot of contexts.",0,0,0,2
"473","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Eventually in the future, perhaps 90% of all analytic firms will be running some form of analytic software.",0,0,0,2
"474","Chapter 1: Social Network Data","This book was very informative on the methods of social networking.",0,0,0,4
"475","Learning Analytics Dashboards","Learning analytics is very important to many industries and will be very useful in the near future.",0,0,0,2
"476","Measurement and its Uses in Learning Analytics","With the advent of smartphones, it is easier than ever to use measurements in high grade analytic software.",1,0,1,3
"477","Predictive Modelling in Teaching and Learning","Predictive modeling is something that I wish to learn much more about.",0,0,0,1
"478","Ethics and Learning Analytics: Charting the (Un)Charted","I feel that the ethics presented in this book are questionable at best.",1,0,1,2
"479","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","I think predictive analytics will be very important to many industries going forward.",0,0,0,2
"480","Statistical graphics: making information clear – and beautiful","This was a very useful note during the assignments.",0,0,0,4
"481","Measurement and its Uses in Learning Analytics","pages 34-48 Psychological measurement is a process for making warranted claims about states of mind. This paper's definition of psychological measurement seems off. I suggest the following definition: psychology measurement is process for measuring aspects of human behavior and mental processes. ""Since constructs are invented things, there is no empirical limit to their number."" -What does it mean for social constructs to have an empirical limit? What is the operational definition of an empirical limit? It seems to imply that it is the complement event of that something finite.   Measurement Instruments Psychological measurement terms: tests, questionnaires, surveys, inventories. Measurement scale used interchangeably with instrument.   Specific Uses of Measurement Models in Learning Analytics Educational measurement used in classification, diagnosis, ranking, placement, certification of individuals, and corresponding inferences about groups   Item Response Theory (IRT) Modelling individual person-item interactions vs. total test scores.",1,3,-2,5
"482","Ethics and Learning Analytics: Charting the (Un)Charted","""Clicks to constructs""   Claims analysis: analysis of the implicit or explicit stances taken in the design and deploying of technologies; productive human-centered method to address key questions in learning analytics. EPA Triad - epistemology, assessment, pedagogy Epistemology - what do we want to measure. how to quantify activity and outputs within specific tasks.",0,0,0,2
"483","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Links to a duplicate reading for some reason.",0,0,0,1
"484","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Interesting read on data visualizations. First thoughts that come to mind when reading this: wondering which program to dive deeper into. Academic research labs favor programs such as SPSS and R, but industry researchers require certifications in programs such as Tableau.   In undergrad research training, was strongly encouraged to produce ""bare bones"" data visualizations focused on conveying information as opposed to creating beautiful visualization that may distract from the objectivity of the data--also highly discouraged from using any colors.   Another train of thought: ""...the aspects of a display that register as ""beautiful"" or ""cool"" can make a reader more comfortable with the statistical information and substantive context of a graph.l   Goals of graph: (1) discovery, (2) communication. Balancing conflict goals of designs and statisticians.   Statistical data visualization vs. Infographics. Statistical data visualization defined as a focus on facilitating an understanding of patterns in an applied problem in directing readers to specific information and illustrating the data. Infographics defined as an attractive method to tell a story and encourage viewer to reflect on a particular dataset as a representation of individual measurements and larger patterns.",6,4,2,2
"485","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data driven decision making (3DM) is a means to collect data at the student and school level to inform decision-making, tailor instruction, and allocate resources to students and classrooms. Schools are inundated with data, such as test scores, teacher assigned grades, periodic formative and summative assessments, attendance, and discipline records. Much of the focus has been on standardized test scores. However, low criterion validity has been shown for test scores in relation to overall student school (e.g., graduation, dropping out) or life outcomes. Teacher-assigned grades are predictive of overall student outcomes; however, it is a weak indicator of academic knowledge compared to standardized test scores. 25% of variance in teacher-assigned grades attributed to assessing academic knowledge. 75% of grades assess a student's ability to negotiate the social processes of school.   Proposed methods to analyze student data:     (1) Cross-sectional means and standard deviations,     (2) individually inspect elements of student's data,     (3) single student course failures.",0,2,-2,3
"486","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Network analysis entails two broad classes of hypotheses: (1) Understanding what influences the formation of relational ties in a given population (e.g., same major, same friends) (1) Influence the structure of ties has on shaping outcomes on the individual level (e.g., GPA, SES) or the population level (e.g., graduation rates, retention in STEM sciences) Goal of paper is to enable researchers to perform analyses that use relational data Network Types 1. Number of actors they contain  Unipartite- networks that consist of only one type of actor (e.g., students) Bipartite - networks that link actors with the groups to which they belong. Example: scholars to author papers, instead of linking author to author or student to student, etc.  2. Nature of Ties  Undirected- if ties between actors are inherently bidirectional. Directed- Relation interest of a network has an associated direction. Example: student a thinks student b is smart, vice versa not necessarily true.  3. Binary or Valued  Binary - whether a relation exists or not Valued ties- additional quantitative information about the relation  Network Data Collection requires setting a time frame for relationships of interest, bc real-world networks rarely static (i.e. bonds change through different bonds being formed or breaking).",1,3,-2,4
"487","Why Students Should Own Their Educational Data","Interesting read. There seems to be a train of thought that one must",0,0,0,2
"488","Knowledge tracing: Modeling the acquisition of procedural knowledge","Cannot access. Requested access from library.",0,0,0,2
"489","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Learning Analytics and Knowledge (LAK) conference was established in 2010.     LAK focuses on leveraging human judgment vs. automated processes. Understanding systems in their entirety with complexity.     Social network analysis, sentiment analysis, influence analytics, discourse analysis, learner success prediction, concept analysis, sensemaking models.     Addressing needs of multiple stakeholders through data-based information.   Educational Data Mining (EDM) formed in 2011.     EDM places an emphasis on automated discovery. Understanding systems through individual components and the relationships between them.     Classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization.     Greater focus on model generalizability (e.g., multi-level cross-validation, replication across data sets)   Different research standards and values in both frameworks. Provides opportunities for perspective. Respective frameworks allows for creativity and advancement that a singular monolithic research culture might not foster.            ",2,0,2,2
"490","Evaluating Machine Learning Models","Evaluating machine learning models Core task in building a machine learning model is evaluating its performance. Machine Learning Workflow: stages include (1) prototyping/model selection (2) deploy into production, (3) further testing on live data  Online evaluation measures live metrics of the deployed model on live data; accuracy and precision-recall. Offline evaluation measures offline metrics of the prototyped model on historical data and sometimes on live data. Different metrics are used for respective evaluations.  Evaluation Metrics: different machine learning tasks have different performance metrics.  Classification performance - average accuracy, log-loss, area under the curve (AUC) Numeric score prediction - root-mean-square error (RMSE); for example, stock prediction Ranking items by relevance [to search engine query] - ranking losses (e.g., precision-recall), normalized discounted cumulative gain (NDCG)  Offline Evaluation Mechanisms  Picking right model to fit the data; model must be evaluated on a dataset that is statistically independent from the one it was trained on, bc performance on training set is overly optimistic estimate Statistician's solution to problem of not having new data: generate new data by holding out part of the training set and using it only for evaluation (e.g., k-fold cross-validation, bootstrapping or jackknife resampling)  All diff ways of chopping up data to resample and simulate new data   ",3,3,0,5
"491","Why Opting Out of Student Data Collection Isn’t the Solution","If opting out isn't the solution, then is opting in the the solution? People really should have a choice in the matter and may have reasons for wanting to opt out that are not cited by the author.",0,0,0,2
"492","Why Is Measuring Learning So Difficult?","Idiosyncratic and multi-faceted components of life that are difficult to abstract. Oversimplified abstractions of learning that are easier to define and measure with current research. Perhaps everyone should walk around with mini fMRIs.",1,1,0,2
"493","Saturday Morning Breakfast Cereal","Why did Charles put a cartoon in here??",0,0,0,2
"494","Data wranglers: human interpreters to help close the feedback loop","What is a feedback loop? Paper has a lot of jargon. Learning analytics a relatively new field; is this an effort to build the learning analytics literature? Single-loop learning: using a learning analytics systems to attempt to achieve set goals Double-loop learning: Value and insight from Interrogating, challenging, and developing set goals Dearth of actionable items, such as learning analytic programs, driven by data.",0,2,-2,1
"495","Zuckerberg is ploughing billions into 'personalised learning' – why?","Author of the article is clearly not impressed by Mark Zuckerberg's efforts at systematically improving educational outcomes. Seems personal.",2,0,2,2
"496","Feature Selection","Reducing number of features makes models more easily interpretable–especially important for the success of a predictive algorithm. Classification and Regression Tree (CART) algorithms: feature reduction can be conducted as part of a pre-processing or modelling step of using algorithms which perform an internal feature selection. For example, out of 1,000 features, only 10 of them may matter for solving a problem of prediction. For the purpose of solving a problem, some features, that were previously thought to have mattered, might not actually matter for the purpose of prediction. Curse of dimensionality: as more features are add, may need exponentially more data",1,3,-2,5
"497","Chapter 1: Social Network Data","Figure 1.2 Example of square array of network data Equal numbers of ones and zeros in the matrix suggests there is moderate ""density"" of liking overall. Actors = ""nodes"" Relations = ""edges"" Major difference between conventional data vs. network data: Conventional data focuses on nodes and attributes, while network data focuses on nodes and relations.",1,0,1,4
"498","RStudio Cheat Sheets","Did this reading.",0,0,0,2
"499","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Critical Dimensions of Learning Analytics Framework, pg. 44 Learning My goal for this semester: prepare a working draft of research manuscript to submit for publication. External constraints: ordinal ranking system from A-F   Instruments, how to operationalize data collection   Data: do you have access to the data   Objectives:   Stakeholders: authors on the paper",1,1,0,1
"500","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Q-Matrix: a table where each row is an item and each columns is a skill. Skill-item mapping can be done with automatic model discovery, hand-development and refinement, and hybrid approaches. Automated model discovery is defined as learning the mapping between items and skills solely from data. (Refer to Barnes, Ditzer, &amp; Vouk. 2005. Experimental analysis of the q-matrix method in knowledge discovery)     The number of skills which should be used are determined empirically. Firstly, try one skill. Then, try two, three, etc. If the new model does better than the previous model, then we try another skill. If it does not do better than the previous model, we stop and return to using the previous model. Strategies to guide refinement: (1) smooth learning curves, (2) search for skills with no apparent learning, and (3) search for problems with unexpected error rates. (Helpful resource: Pittsburgh Science of Learning Center DataShop) Learning Curve in Brief: the learning curve illustrates relationship between amount of practice and performance.     Spikes in learning curves often imply two (or more) skills are being treated as a single skill.  For example, if geometry area is analyzed as a single skill, the learning curve is marked with significant spikes (i.e. the learning smooth is not smooth); however, if it is split into 12 skills, the result is a smooth learning curve.     Can inspect curves for individual skills. Many curves demonstrate a decline (i.e. there are less errors over time), However, some do not, which presents an opportunity to improve the model or quality of instruction, or both. Ideally, the curve should have a negative slope. Problems with High Error Rates: items with an error rate that is much higher than expected from the model are problematic. It is possible that the problem does not measure the skill that it is intended to.",19,9,10,5
"501","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Challenge: MOOCs contain a wide breadth of course materials, and thus, it is difficult to define a set of skills for learning and having respective skills associated with a specific part of course contents. ePPIPHANY is based on systems engineering and used to comprehensively and automatically undercover skill sets from online course data.  Assessment item text data (e.g., problem and feedback text sentences for assessment items Student learning interaction data ",4,2,2,5
"502","Using data mining to predict secondary school student performance","Issue: lack of success in mathematics and language of Portuguese among students of the Portuguese population, 40% drop out rate, ranked as Europe's lowest in educational performance. Past performance on evaluations are predictive of future success but likely other factors that effect performance (e.g., level of parent education and profession, alcohol consumption, truancy). Computational environment: study used RMiner in the R environment. Classification (e.g., mining, saveMining) and regression tasks (e.g., Cortez In press)",3,3,0,3
"503","Developing a generalizable detector of when students game the system","Gaming the system is defined as attempting to succeed in an educational environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. Cognitive Tutors Learning environments designed to promote learning by ""doing."" CT environment breaks down mathematics problems into steps of the process used to solve problem; cog model assesses whether the student's answers map to correct understanding or to a known misconception. If knowledge is indicated of a known misconception, student is given a message to indicate how their current knowledge differs from correct understanding. Two groups: (1) students who gamed and had low post-test scores, (2) students who gamed and had high post-test scores. General problems with modeling user behavior and strategies should focus on behaviors associated with differences in user experiences and outcomes. Latent Response Models Fast Correlation-Based Filtering In general, detectors of user behavior and strategies would be more useful if can be used to identify why users engage in studied behaviors and strategies.",5,7,-2,5
"504","Cross Validation","Cross-validation concept: Test set visualized geometrically in 2D graph. Goal is to find a way to predicting values and then testing them; run a regression to fit a line to data points. Using higher order polynomial to improve fit to the data points in the training set (line may look very squiggly). If line is fit exactly to the test set, the fit will not generalized to the real world. It will make that squiggly line again, and the model will make predictions in odd places (with no data points in some squiggles). Goal is to generalize the model b/c we do not know what the data values will be in the future. Model should be a ""stand-in"" for unknown data in the future. Using test data to be representative of future data. IID: Count on the data being independent and identically distributed. All the data that we've collected comes from the same source (i.e. the world we live in). Fundamental assumption of algorithms that have been used. Ideally, we want to use a model that is complex enough to fit the data without causing problems on the test set. How can we pick a model that is complex enough to model the data while making sure it hasn't started to diverge in terms of how it will be applied to the test set? Split training data into ""folds."" For example, there are four folders: train on folds 1,2,3; then test on the 4th fold. Train on folds 2, 3, 4; then check on 1st fold. Train on folds 4, 1, 2; then check on the 3rd fold. Different combinations. Then, average all the errors of the tests to check how well the model does. The one with the lowest error will be the one that is used.",4,9,-5,5
"505","Measurement and its Uses in Learning Analytics","This article was really difficult when I first read it. Some of the distinctions around model, measurement are more concrete now. Would like to go back and read it again when I have more time.",1,1,0,2
"506","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Spent a long time saying they weren't criticizing, but of course they went pretty hard against some of these charts. Boy's name ending sounds visualization was fascinating. Wonder if others have taken up their 6 principles or if this is a one-off thing.  ",2,2,0,2
"507","Junkcharts Trifecta Checkup: The Definitive Guide","Interesting article and interesting that he represents his trifecta as a triad type graph, which I just was reading about in the",0,0,0,2
"508","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Need to look into active learning more. Recent research in physics education has found that a stu- dent’s position within communication and interaction net- works is correlated with his or her performance (Bruun and Brewe, 2013). An informal learning environment was found to be facilitative in mixing physics students of diverse back- grounds (Fenichel and Schweingruber, 2010 performing a brief analysis of a classroom network along three avenues: descriptive analysis of the network, exploration of network evolution, and analysis of network position as a predictor of individual outcomes. Highlighted: In situations in which a presence or absence of so- cial support is suspected to be important to outcomes of in- terest, such as formal learning within a classroom, the SNA paradigm is appealing. Betweenness centrality focuses on whether actors serve as bridges in the shortest paths between two actors. Actors with high betweenness centrality have a high probability of existing as a link on the shortest path",3,1,2,4
"509","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","I looked at the article but also ended up watching a video of this presentation--Siemens at the 2012 conference. It was a good introduction. Siemens seems like an interesting speaker. I'd be curious to track down other talks he's given. https://www.youtube.com/watch?v=Xpcg3n_YUY4   Interesting to get at the key differences in the two fields but also see the commonalities. At least in the talk, Siemens and a few audience members seemed to really promote interchange and collegiality.",2,0,2,2
"510","Zuckerberg is ploughing billions into 'personalised learning' – why?","Interesting quote: personalised learning is conceived of as the means to adapt and customise a pupil’s learning according to their needs as well as teachers’ experience and school requirements, it holds promise. As Mike Sharples and other Open University colleagues write in their Innovating Pedagogy 2015 report, personalised learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment could be a very powerful combination.   Want to look into the distinction between customized and personalized more",2,0,2,2
"511","Principal Component Analysis explained visually","I was impressed with this visualization, but I actually found another one online that I helped me understand PCA a little better: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579",2,0,2,2
"512","Measurement and its Uses in Learning Analytics","In the big data era, people don't need to make a guess on how things work, the data will show everything to people. Learning analytics and educational data mining are the two product of the big data era. Educators and researchers are now using these two new method to examine the educator and students' performance. Learning analytics, as a new form of assessment instrument, have potential to support current educational practices, or to challenge them and reshape education. The most important thing for researcher to be clear is how to use these two method correctly. Tools can be used in many ways, and should not be isolated from their context of use.",4,0,4,2
"513","Ethics and Learning Analytics: Charting the (Un)Charted","Learning analytic, as a new emerging technology, is facing lots of problems, but people also have so much expectation on it. There is some consensus that the future of learningwill be digital, distributed, and data-driven such that education ""enables quality of life and meaningful employment through (a)exceptional quality research;(b)sophisticated data collection and; (c) advanced machine learning and human learning analysis/support"".  Ethical implications around the collection, analysis, and use of student data brings benefit along as risks and conflicts.  At first, people in Learning Analytic are only consider problems related to data governance, data security, and privacy issues, but as the Learning Analytic group growing, the problem now grows beyond the boundary. ""how student data is used and under what conditions"" is the priority ethical problem needed to be solved.",1,7,-6,2
"514","Predictive Modelling in Teaching and Learning","explanatory modeling is to use all available evidence to provide an explanation for a given outcome. understanding a happened phenomenon predictive modeling is to create a model that can be used to   predict values of new data based on observations. While both methods intend to inform the design of intervention systems, the former does so by building software based on theory developed during the review of explanatory models by experts, the later us using collected data from historical log files The feature, cross validation, is also a key factor of predictive model that makes it more generalized. accuracy of model increases when size of of available data increases.",0,0,0,5
"515","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","better cognitive model lead to better prediction of what student knows. expert-engineered cognitive models often ignore content distinctions that are important for novice learners. The method  for cognitive model refinement iterates following steps: 1)inspect learning curve visualizations and fitted  AFM coefficient estimates for given KC model, 2) identify problematic KCs  and hypothesize changes to the KC model, 3) refit the AFM with revised KC model and check if revised KC model fits better. One of the benefit of SimStudent is that it can simulate features of novices’ learning trajectory of which domain experts may not even be aware.  Methods like LFA still require human input as a cited lmitation.",6,0,6,5
"516","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The sorts of graphs we do best are being squeezed fromboth ends, from one direction by the good-enough bar plots that just about anyone can make in Excel, and from the other by the beautiful professionally-designed images that are the Armani suits to our clunky plaid shirts with pocket protectors. the first consumer of any graph is the person who makes it, and it can often be useful to use “presentation” skills to communicate to ourselves as well as to others. “Graphs are exceptionally powerful tools for data analysis.” “There is no statistical tool that is as powerful as a well-chosen graph.” “Diagrams prove nothing, but bring outstanding features readily to the eye.” Graph should be a strong tool to convey your idea to readers. Use it to communicate with readers but not to prove something.chart",5,1,4,2
"517","Junkcharts Trifecta Checkup: The Definitive Guide"," What is the QUESTION? What does the DATA say? What does the VISUAL say?  In this article, the author addressed 8 types of problem that a visual may have. Using Trifecta Checkup framework we can build an intuitive visualization.",0,1,-1,2
"518","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","teacher-assigned grades have a long history of predictingoverall student outcomes teacher-assigned grades could bea useful type of data for 3DM, especially when it comesto early determinations of possible overall studentoutcomes, such as dropping out of school. This is one of the main purposes ofdata driven decision-making; using data already collectedin schools to help drive decisions on improving specificschool, teacher and student outcomes. the central aim of this study is to adapthierarchical cluster analysis and heatmaps for use withteacher assigned grades for data driven decision-making.",0,0,0,3
"519","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Learning process does not happen uniquely in the classroom. Right now, students can have infinite ways to get in touch with new knowledge on social media and network. Classic method that studys only students' in class performance isn't enough to thoroughly understand students. Then, our new method, social network analysis had been introduced to researchers to add impact of social network on undergraduate students for better understanding on students performance. ",4,0,4,4
"520","Why Students Should Own Their Educational Data","The education system may be better by studying on average model but will never be perfect. The model studying on average point is studying on nothing. If we want the system fits for everyone, we have to have a study on everyone.",2,0,2,2
"521","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","In the ""big data"" era, Educational Data Mining, EDM, and Learning Analytics and Knowledge, LAK, are becoming more and more important. The concepts of these two similar but also differs at technological, ideological, and methodological orientations research communities have already developed their own role within schools, university, and corporate learning and curriculum organizations. With the improvement in software and analytical methods, researchers and educators will gain innumerous benefits from deep analyzing big data generated from students’ interactions with educational software and online learning.",3,0,3,2
"522","Evaluating Machine Learning Models","Sometimes, simply detecting a prediction is incorrect is not enough, we have to detect wether it is false positive or true negative, for deeper understanding of the predictive model.When the probability of classification can be measured, we can use log-loss to calculate the probability of making an error. Even though sometimes the model may generate false prediction, but if the probability of generating an error remains a low level, then the model can be regarded as fine.",3,4,-1,5
"523","Saturday Morning Breakfast Cereal","The caricature is full of ironical images. The clock locks every possibilities of kids as well as possibilities of our future.",1,0,1,2
"524","Data wranglers: human interpreters to help close the feedback loop","As the group of online academic grows, useful educational data are being generated generously. It is thus important for someone with multidisciplinary to carefully clean up the data and analyze it for better educational use. With these trained people, we can build up a system allow more users to use the data directly. The aim of this paper is to construct a community of Learning Analytics with plenty of data to practice with. After all, hopefully the learning experience will be improved. ",4,0,4,1
"525","Zuckerberg is ploughing billions into 'personalised learning' – why?","For Zuckerburg, personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”.  human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests Three dangers 1.By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. 2.Their lack of ability to compensate may mean they suffer as a result 3. we can hardly predict children's performance.   Motivation is the key idea of personalized learning that used on children.",1,4,-3,2
"526","Feature Selection","amount of data needed grows exponentially as increase of number features (2 to the power of number of features). Using PCA method can solve this problem by filtering out irrelevant features and only keep those that mean a lot to the model.",0,1,-1,5
"527","Chapter 1: Social Network Data","The major difference between conventional and network data is that conventional data focuses on actors and attributes; network data focus on actors and relations. The difference in emphasis is consequential for the choices that a researcher must make in deciding on research design, in conducting sampling, developing measurement, and handling the resulting data. It is not that the research tools used by network analysts are different from those of other social scientists (they mostly are not). But the special purposes and emphases of network research do call for some different considerations.   Since actors are correlated to each others, network analyst always study the whole population but not a sample from it. Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches. The distinction between the two approaches is not clear-cut. Mathematical approaches to network analysis tend to treat the data as ""deterministic."" That is, they tend to regard the measured relationships and relationship strengths as accurately reflecting the ""real"" or ""final"" or ""equilibrium"" status of the network. Mathematical types also tend to assume that the observations are not a ""sample"" of some larger population of possible observations; rather, the observations are usually regarded as the population of interest. Statistical analysts tend to regard the particular scores on relationship strengths as stochastic or probabilistic realizations of an underlying true tendency or probability distribution of relationship strengths. Statistical analysts also tend to think of a particular set of network data as a ""sample"" of a larger class or population of such networks or network elements -- and have a concern for the results of the current study would be reproduced in the ""next"" study of similar samples.",3,1,2,4
"528","RStudio Cheat Sheets","The cheat sheet is really useful for me to make the R mark down file clear, beautiful and readable, especially when I need to present the R mark down file to others.",2,1,1,1
"529","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The general need for learning analytics is to understand and predict students performance. It is needed by schools and large educational institutions. But there is limitation that preventing people entering the industry. People in Learning analytics industry should have sufficient programming skills and deep understanding about the process of learning and how to analyze the process of learning. This requires long-time and systematic learning.",1,1,0,2
"530","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","; sfjjlldsfmndskf",0,0,0,5
"531","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","cognitive task analysis driven by human experts has an issue in its accuracy and scalability; applying it for a large-scale online course is often impractical. This article proposed a method can be used to automatically analyze data generated by online courses. By first transforming students' performance on assessment into difficulty matrix that represents difficulty of assessment to each student, researcher can build up a skill model for each students. The final goal is to build up a model that can predict the skill model.",2,1,1,5
"532","Big Data in Education","accuracy to judge a model kappa, better than accuracy,  kappa = 0, agreement is at chance kappa = 1 ,agreement is perfect; clusters are really useful for large sample First determine how many clusters to have then pick centroids value of cluster classify every point to the closest centroids re-fit centroids so that center of the points in each cluster repeat the process until the centroid stop moving anymore; No specific target or predictor variable driving intervention and improvements in educational software and systems; predict future or make inference about present step regression, binary classification, bigger than cut off point is 1, less than is 0 logistics regression also use binary classification, 1/(1+exp(-m))   decision tree  ; To determine how many skills need, first try 1 skill, then try 2 skills. If model gets better with 2 skills, then we take 2 skills, and then try 3, 4, 5... For items contain same skills, if student can do 1 correct, then it is very likely to do other correct conjunctive or compensatory? skills correlated? learning curve, error rate decreases if student practice more, make sense.",9,3,6,5
"533","Hands-On Programming with R","With functions, we can build our own function that can help us to deal with data. With packages, we can use build-in functions within the package to do some magic things that would be hard to achieve manually. The help page, although with some limits, is the very first thing we should check when we get stack on any function. In the help page, it offers detailed explanation about all arguments within the function. R objects include basic structure of how R studio understand our input then give output back respectively.",1,3,-2,1
"534","Principal Component Analysis explained visually","Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize. PCA is useful for eliminating dimensions. For a data set contain so many dimensions at the time we do not care them all, we can use PCA method to eliminate plenty of them that does not play important role and thus create a clearer picture for us to  look at and explore.",2,0,2,2
"535","Measurement and its Uses in Learning Analytics","Validity refers to the degree to which evidence and theory support the interpretations of test scores for proposed uses of tests  Reliability is attributed to an instrument and is a measure of the consistency of scores   ",1,0,1,5
"536","Ethics and Learning Analytics: Charting the (Un)Charted","The development of analytic approaches in learning involves making decisions about what knowledge will, and will not, be focused on; to measure what we value rather than value merely that which is easily measured",0,0,0,1
"537","Predictive Modelling in Teaching and Learning","When choosing what data to collect, the practitioner should err on the side of collecting more information rather than less, as it may be difficult or impossible to add additional data later, but removing information is typically much easier. Ideally, there would be some single feature that perfectly correlates with the cho-sen outcome prediction. ",3,2,1,3
"538","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Naïve Bayes Classifiers assume the statistical independence of each attribute given the classi-fication, and provide probabilistic interpretations of classifications. Bayesian Networks feature manually constructed graphical models and provide probabilistic inter-pretations of classifications. Support Vector Machines use a high dimensional data projection in order to find a hyperplane of greatest separation between the various classes.",2,0,2,3
"539","Junkcharts Trifecta Checkup: The Definitive Guide","The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly. ",1,2,-1,2
"540","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","A heatmap takes tables of clustered numbers, which the human mind can not easily interpret for pattern recognition, and converts the table into blocks of color, aiding the human eye in visualizing patterns within clustered data and combining these blocks with a dendrogram creating a clustergram ",0,0,0,3
"541","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Density is a global metric that simply indicates how many ties are present. Nodes within a network also have their own set of measurements. These include the exogenously defined attributes with which we are generally familiar (e.g., age, race, major), but they also include measures of position of nodes in the network.",0,0,0,4
"542","Why Students Should Own Their Educational Data","Aggregate data can protect students' privacy, but it can also affect the accuracy of analysis sometimes if the data scientists don't take into account all of the factors.",1,0,1,3
"543","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.",1,1,0,2
"544","Evaluating Machine Learning Models","A confusion matrix (or confusion table) shows a more detailed breakdown of correct and incorrect classifications for each class. The rows of the matrix correspond to ground truth labels, and the columns represent the prediction. The AUC is one way to summarize the ROC curve into a single number, so that it can be compared easily and automatically. A good ROC curve has a lot of space under it (because the true positive rate shoots up to 100% very quickly). A bad ROC curve covers very little area. So high AUC is good, and low AUC is not so good.",4,3,1,5
"545","Why Opting Out of Student Data Collection Isn’t the Solution","Legitimate education policy concerns need to be addressed by fixing these problems for all students, not just the minority who protest by opting out. Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system",1,3,-2,2
"546","Why Is Measuring Learning So Difficult?","Great insights.It's hard to measure learning but it's achievable if we collect the right data. Cognition is immeasurable but the behavior people show can be measured and stored in data. ",2,1,1,1
"547","Saturday Morning Breakfast Cereal","The comic just shows what a disaster it could end up if the data scientist interpret the data in the wrong way even if the data is solid.",1,1,0,2
"548","Zuckerberg is ploughing billions into 'personalised learning' – why?","Human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests. As the article points out, there are several major flaws of Zuckberg's idea. The automated learning can't change according with students' minds.",2,2,0,2
"549","Feature Selection","n features means 2^n data, so feature selection is important",0,0,0,5
"550","Chapter 1: Social Network Data","Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches.   ",0,0,0,4
"551","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The concepts in this article highly correlate with those we learned in HUDK 4050. From my personal experience, net work analysis and classification methods are often used in educational data.",1,0,1,4
"552","The Big Five and Visualisations of Team Work Activity","Teamwork can be defined as “...a set of interrelated thoughts, actions, and feelings of each team member that are needed to function as a team and that combine to facilitate coordi-nated, adaptive performance and task objectives resulting in value-added outcomes.",0,1,-1,2
"553","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","I have purchased courses from Coursera and Udemy and I think overall Coursera has a better course recommendation system. In comparison with Udemy, Coursera will recommend courses based on the course u have checked.",3,0,3,4
"554","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","OELEs offer opportunities for students to exercise higher-order skills that include: (i) cognitive processes for accessing and interpreting information, constructing problem solutions, and assessing constructed solutions; (ii) metacognitive and self-regulation processes for coordinating the use of cognitive processes and reflecting on the out-come of solution assessments; and (iii) emotional and motivational regulatory processes, such as curiosity and persistence.",1,1,0,2
"555","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","eEPIPHANY can either find a Q-matrix by itself or refine a given Q-matrix by the following steps: (1) clustering assessment items with latent features that would best characterize the similarity in the difficulties of assessment items (section 3.1), (2) proposing a new skill model by assuming that the above-mentioned cluster of assessment items provides a hint for new skills (section 3.2), and (3) searching for the best skill model by comparing multiple skill model candidates (section 3.3). ",6,0,6,5
"556","Using data mining to predict secondary school student performance","TheRMinerlibrary2presents a set of coherent func-tions (e.g.mining,saveMining) for classification andregression tasks (Cortez In press). In particular, the li-brary uses therpart(DT),randomForest(RF),nnet(NN) andkernlab(SVM) packages.  There is a potential for an automatic on-linelearning environment, by using a student prediction en-gine as part of a school management support system.This will allow the collection of additional features (e.g.grades from previous school years) and also to obtaina valuable feedback from the school professionals",1,0,1,3
"557","Developing a generalizable detector of when students game the system","Latent Response Models have the advantage of easily and naturallyintegrating multiple data sources, at different grain sizes, into a single model.  ",0,0,0,5
"558","Cross Validation","goal of prediction is always generalized and representative. make folds and use every fold as a train test and test set. get the model with least average error.",0,1,-1,5
"559","Hands-On Programming with R","Week one Reading: my job: make decisions and assign meanings vector, a one-dimensional set of numbers ls(): sees what object names I have If you give R two vectors of unequal lengths, R will repeat the shorter vector until it is as long as the longer vector, round a number with the round function sample takes two arguments: a vector named x and a number named size replace = TRUE means can roll again the number my_function &lt;- function() {}qplot will make a histogram whenever you give it only one vector to plot. replicate provides an easy way to repeat an R command many times.      ",0,2,-2,1
"560","Principal Component Analysis explained visually","If we're going to only see the data along one dimension, though, it might be better to make that dimension the principal component with most variation.",1,0,1,2
"561","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This article using clustering method and heatmap along with some categorical variable to analyze student data to analyze the character of good/bad students. The result shows that good students are less likely to drop out during the study and more likely to take ACT exam. The red color in heatmap indicates good students and blue indicate poor students. The graph is really nice and direct with all kind of information. I really like it!",6,1,5,3
"562","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article carried out a research among some students in the same class. First, it introduces some basic concepts of social network. Then it constructs a graph showing the interaction and communication between students. It can be very direct and helpful.",1,0,1,4
"563","Why Students Should Own Their Educational Data","Because different individuals have different talents interests and potential. We should have data for each person so that we can give students the ""best"" education for them. However, I have a different point of view. Although it is good for customized education, it is also necessary to consider social efficiency and cost. It is a good and final destination that we should design education for everyone. It is also important that we should first provide every children with basic education.",4,0,4,2
"564","Knowledge tracing: Modeling the acquisition of procedural knowledge","The article shows the mechanisms of a cognitive model used in an intelligence tutoring system. It describes an effort to model students' changing knowledge state during skill acquisition. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. The model is quite successful in predicting test performance. The advantage of this model lies in its ability to incorporate previous empirical information. It can capture whether students have done the exercises wrongly or rightly in the prior problems, its ability to use individualized parameters for each student, and its ability to adopt slipping and guessing parameters.",3,3,0,3
"565","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This article is an inspiring research in the field of learning analytics.  Since most of the previous study of learning analytics are qualitative research, it is important that we should use methods of data mining to do some quantitative research. Nowadays, there are many ways to get large amount of data. Educational data mining and learning analytics are different but correlated with each other. Therefore, it is important and necessary that we should have more knowledge of data mining.  ",0,0,0,2
"566","Evaluating Machine Learning Models","I really like this article because it introduces many useful techniques of measurement algorithms in data mining. It includes classification, ranking, and regression which are all very useful and each type has different focuses, advantages and disadvantages. The article also provides us with some problems with the data that may render the metrics problematic. It also denotes some important issues in using these methods to pursue our goals of research.",1,4,-3,5
"567","Why Is Measuring Learning So Difficult?","1.Learning is one of the most multi-dimensional issue in the world. 2.The knowledge and range of learning is too broad to be able to fit anyone or any project. 3.The educational data mining is not mature. We don't have a specific coding or package for EDM. 4.The construct of learning with different culture ground is difficult to define. 5.It's hard to find simple proxy indicators for our topic. Latent variables and all kinds of factors in different fields including education, psychological and cultural needs to be considered.",1,2,-1,1
"568","Saturday Morning Breakfast Cereal","Our research has to be meaningful and reasonable. We can never overestimate or overtrust the result from our mining. It is also necessary to know the basic theory and common knowledge for education, so that we can interpret the result correctly.",2,0,2,5
"569","The Data Wrangling Cheatsheet","OMG!!!!! This is sooooooooo useful!!!!!! Checking reading every time. Very basic but overall techniques for R coding.",1,0,1,4
"570","Data wranglers: human interpreters to help close the feedback loop","This paper introduce a project called Data wranglers. It helps to gather information from students and gives some feedback and evaluations. I think it is a nice example of using data mining into education. It also saves time for researcher and make data easy to find by building personal educational data.",1,0,1,2
"571","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article discusses both the danger and potential of personalized learning. For the dangers: First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Finally, children’s preferences are not fixed. Besides, there is no evidence or proof of the personalized learning could be significantly helpful than the general education. Although it seems to be conservative, I think it’s worth to be discussed seriously.",3,3,0,2
"572","Feature Selection","Feature selection is a very useful and important work for our research. Usually, if there are many features in our study, only a few of them really matter. For the first aspect, we need to choose small number of features to make our result or model interpretable and reasonable to all theories or researches we have. The second reason is to reduce the effect of Curse of dimensionality.",1,0,1,5
"573","RStudio Cheat Sheets","Again! Very useful and helpful!!!!! Love this!",2,0,2,2
"574","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This paper introduce some of the key dimensions for educational data mining and framework when we are designing experiments for education research. This paper also introduced some limitation of EDM, which is also helpful.",1,1,0,2
"575","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This report is to evaluate the lessons by using An Introduction to Recommender Systems. The goal of this project is to create a high-quality graduate course and MOOC on recommender systems and to explore MOOC broadly through both department interest and university interest. Then followed by some research methods, data and results of the test.",2,0,2,4
"576","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article introduces a way to find the Q matrix of item-skill correspondence. The new method is more complicated than the currently popular LFA method. It incorporates several machine learning algorithms such as matrix factorization, bag-of-words modeling and clustering. The results of study show that the new method outperforms human-engineered skill models, skill models discovered by the new method are interpretable, and the new method is remarkably faster than existing methods.",5,1,4,5
"577","Chapter 1: Social Network Data","The first chapter of the book mainly introduce us the concepts of social network data and the difference between it and classic data. It also introduce us some methods in analyzing these data and what people are doing in this field currently.",1,0,1,4
"578","Learning Analytics Dashboards","Creating a dashboard is one of the most efficient way for education Generally it has three advantages. First, students can get a direct insight to the learning process. Second, teachers can interact with students easily during their study process. Third, researchers can get important data directly from the dashboards. It is important that one must understand his/her goals and subjects before making a dashboard.",1,0,1,2
"579","Measurement and its Uses in Learning Analytics","This chapter provides the baseline for educational data mining and learning analytics. It indicates that we should not pay too much attention on the coding skills but we should follow the principal of learning theory and make full use of data mining skills. It also introduces some possible structures, main factors and theories we might use during the EDM process.",1,0,1,2
"580","Predictive Modelling in Teaching and Learning","Chapter 5 gives us a general introduction to predictive modeling in educational studies. It refers to data collection, feature engineering, common algorithms, diagnostic measures of model evaluation and challenges and opportunities for researchers in this area. It also helps us to understand the difference of data and how to deal with missing data.",0,1,-1,5
"581","Ethics and Learning Analytics: Charting the (Un)Charted","Since the educational data mining is still not mature, it is important that we should follow some ethic principals for collecting the data. In order to make our research appropriate, the introduction to ethic rules is necessary.",2,0,2,2
"582","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Chapter 6 of the book recommends us different approaches to model educational data which are predictive models and explanatory models. It indicates that although we always seek for accuracy of the prediction, the explanatory models may work better in explaining behaviors or results of educational data. The chapter also summarize some of the common characteristics of explanatory models.",3,0,3,5
"583","Statistical graphics: making information clear – and beautiful","It is important to make a neat and beautiful graph to show your result. Basically there are three steps to build a nice graph. First, know who is your audience and who you want to show the graph. It is always important to know their level of knowledge and their expectations before you make your graph. Second, you should avoid irrelevant information and keep the graph as simple as possible. Third, you should keep all graphs consistent and use the same scale in order to show comparison.",2,0,2,2
"584","How to display data badly","This article gives us 12 ways to display data along with some examples. I think it is very useful and understandable.",1,0,1,2
"585","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The article shows the differences between Information visualized graphics and statistical graphics. Infovis graph are prone to show as many information as possible, the techniques are fancy. However, it does not always show what people want. Statistical graphs are more likely to show the result researchers got during the study. The plots are usually simple and plain, but it shows very important information and comparative results of their research. Therefore, both field should learn from each other and get a better outcome.",3,1,2,2
"586","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how people like to organize the thinking behind their critique pieces. It is a clear framework to show whether the chart is properly and nicely built with three aspects, Question, Data and Visual.",4,2,2,2
"587","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Hierarchical cluster analysis and pattern visualization",0,0,0,3
"588","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","The difference between LAK and EDM.",0,0,0,2
"589","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Matrix factorization vs Q-matrix",0,0,0,5
"590","Developing a generalizable detector of when students game the system","Game the System - Cognitive Tutor Features: Details about the action; knowledge assessment; time; previous interaction - accurately detects which students game the system- makes predictions about when students game the system, which are difficult todirectly validate, but which have been used to drive learning interventions whichimprove student learning- expands our knowledge about the behavioral construct of “gaming the system”- can generalize between contexts",0,1,-1,5
"591","Cross Validation","Fundamental assumption Use a model that is complex enough to fit the data without causing problems on the test set. Split the training set to get a check set, run multiple times and get average error together.",1,4,-3,5
"592","Measurement and its Uses in Learning Analytics"," Bergner, Yoav. “Measurement and Its Uses in Learning Analytics.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 34–48. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This paper illustrated the promise of the combination of measurement theory and learning analytics. This point of view is thought-provoking for me as a student majored in Measurement and Evaluation. It is important to understand that the huge trend of visual learning and educational big data are leading the measurement into a multimodal analysis level. With these approaches available, more and more understanding on potential learning will be generated.    Now researchers have reported findings of whether and how MOOC log file data can assist in understanding how MOOC participants use (often) messy, chaotic forums to support complex, unpredictable, contingent learning processes. On a time efficiency perspective, Learning and Development in education are frequently asked to report on the effectiveness of their training programs. However, reporting simple completion statistics for training just isn’t cutting it anymore. Measuring and reporting the return on investment for education is essential. Being able to measure learning properly in this digital age could lead to more effective learning and teaching.   Educational data can even be pushed back to the learner to support and encourage them. For example, successful learning incorporates the 3 Fs: Focus (the learning process), Feedback (use of learning data), Fix it (learner’s continuous improvement). Learning data can deliver feedback to the learner which is customized to reflect both the learner’s past behavior and can recommend future actions to improve success.    ",11,4,7,2
"593","Ethics and Learning Analytics: Charting the (Un)Charted"," Prinsloo, Paul, and Sharon Slade. “Ethics and Learning Analytics: Charting the (Un)Charted.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 49–57. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This paper talks about different ethical issues faced in the field of learning analytics. It is true that once the Pandora’s Box of data availability has been opened, then individuals lose control of the data about them that have been harvested. They are unable to specify who has access to the data, and for what purpose, and may not be confident that the changes to the education system which result from learning analytics will be desirable....The transport of data from one context to another can result in an unfair and unjustified discrimination against an individual.   One of the ideas mentioned in the paper is thought-provoking. “Data may only be collected when the purpose /use of the collected data is made explicitly clear.” To expand on this point, researchers must have a defined understanding of what data will be collected, how it will be used, and for what purpose. By establishing the scope and purpose of your learning analytics, they can set ethical boundaries that can explain and defend when learners have questions about how their information is used.   Also, as the social media now is prevalent and more educational data can be obtained from different channels, it is important to pay sufficient attention to the privacy issue. Not everyone who has access needs complete access - only give staff and administrators the kind of permissions that they need to have. Whenever possible, the researcher should make learner data anonymous. Also, it is important to be sure that student information is protected when contracting with third parties for data storage and analysis  ",3,2,1,2
"594","Predictive Modelling in Teaching and Learning"," Brooks, Christopher, and Craig Thompson. “Predictive Modelling in Teaching and Learning.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 61–68. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This article introduces the terms and workflows related to predictive modelling, with a particular emphasis on how these techniques are being applied in teaching and learning. The author first made a comparison between explanatory models and predictive models, where differences in principal, pragmatics and methodologies are examined. Then, predictive modelling workflow is introduced, where major steps are “Problem Identification”, “Data Collection”, “Classification and Regression”, and “Feature Selection”. The author also introduced a number of methods for building models from historical data, and considerations when implementing different algorithms. There is also a need to assess the quality of the model with a test dataset, and the feature of the test dataset is call for attention. The author also provides real practice in teaching and learning where predictive analysis is used. In the last section, the author raised a number of challenges and opportunities when building predictive models.   Referring to the article on explanatory model, which emphasizes more on the interpretation of the data, the predictive model is a step forward, in which a more specific problem is to be addressed. In the “Problem Identification” part, the author mentioned quantifiable characteristics of the subject being modelled, a clear outcome of interest, the ability to intervene in situ and a large dataset are needed for a suitable problem to implement predictive model. Thus, it is reasonable that the example the author uses for providing real world practice are about institutional education data analysis, as well as online MOOC. However, this kinds of dataset is not always available in an open source. Thus, a question for me to explore further is the accessibility of the dataset in different cultural education system. Also, as mentioned in the last part of the article, supporting non-computer scientists in predictive modelling also has a great potential in promoting educational data access.  ",5,2,3,5
"595","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data"," Liu, Ren, and Kenneth Koedinger. “Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 69–76. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This article reviewed examples of explanatory model in Cognitive Model discoveries, as well as other work in the field of educational data mining. The author argued that explanatory models can be beneficial and lead to improvements to learning outcomes and learning theory. By examining Data-Driven Cognitive Model Improvement, Learning Factors Analysis, and Automated Cognitive Model Discovery Using SimStudent, the author demonstrates how data-driven techniques can alleviate expert bias while reducing human labor, and more importantly, reveal more interpretable features. In other works rather than cognitive modeling, the author reviewed the study on student grouping conducted by Liu and Koedinger, in which the method used yielded student groups that are readily interpretable and potentially actionable. The author then summarized three features that tend to characterize explanatory models. First, explanatory modelling efforts tend to start with “clean” independent variable that have either simple functions or map clearly defined constructs. Second, the dependent variables of the model are constructed in a well-defined structure. Finally, fewer estimated parameters serves in explanatory models, including characterizing independent variables, or features.   Linking to the topics in class, clustering and principle components theories are doing works to eliminate overwhelming variables and grouping them into fewer well-defined features. I am wondering if this is what the author referred to as “start with “clean” independent variable”. Also, it is important to know that when generating a model, the pre-treatment of data is very important, because the structure of the data can influence the explicitness of the model. A question for me to explore is how to construct well-defined structure for both independent variables and dependent variables.  ",11,2,9,5
"596","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)"," Gelman, A, and A Unwin. “Infovis and Statistical Graphics: Different Goals, Different Looks (with Discussion),” 2012.  This paper talks about differences in perspectives, goals and principles for data visualization between info visualization and statistics graphs. The dialogue is important for them to communicate and compare different sources, different goals and different demands from the audience.   However, although people in both fields pursue unique and distinctive displays to solve unfamiliar problems, most of them rely on proving generic methods. In the book, Readings in Information Visualization: Using Vision to Think, by Stuart Card, Jock Mackinlay, and Ben Shneiderman says: “Information visualization is the use of computer supported, graphical representations of abstract data to augment cognition.” When information visualizations display quantitative data, which is usually the case, they are in fact “statistical graphics.” The authors also state: “One key difference between the two approaches is that Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods that have a similar look and feel across a wide range of applications.”    It is true that, “In the world of Infovis, design goals can be pursued at the expense of statistical goals.” However, it is not desired that they should be pursued in this way anymore than in the world of statistics.    From the paper and related topic, it is more interesting to find the negotiations. Statistical graphics (or visual data mining, visual analytics, or any other name you like) typically do not provide a final answer. But, statistical graphics often help to detect the unexpected, formulate new hypotheses, or develop new models. Later on, additional experiments or ongoing data collection as well as more formal methods (and p–values if you really want) may be used to verify some of the original graphical findings.’  ",4,3,1,2
"597","Junkcharts Trifecta Checkup: The Definitive Guide"," Fung, K. “Junkcharts Trifecta Checkup: The Definitive Guide.” Blog. Junkcharts (blog), 2014. http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html.  This paper expanded Tufte’s principle regarding to data visualization and talks about data vis in a research perspective. It is of great importance that we pay attention to the questions, data and visualization at the same time. The author uses a triangle network to explain different types of weakness in junk charts.    However, on the other side, the internet granted us with enormous access to the data and source itself, then it comes to the question, is junk chart really a junk?  Guidelines for designing information charts often state that the presentation should reduce ‘chart junk’ - visual embellishments that are not essential to understanding the data. In contrast, some popular chart designers wrap the presented data in detailed and elaborate imagery, raising the questions of whether this imagery is really as detrimental to understanding as has been proposed, and whether the visual embellishment may have other benefits.   To investigate these issues, researchers have conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. They found that people's accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better.    After all, it is a debate and all about the balance. The fundamental issue is whether embellishments support the data or to some degree distract from it or distort it. Embellishments that represent data, even metaphorically, can themselves qualify as “data ink.” Embellishments that are not data in themselves can sometimes support the display of data in a useful manner.   ",7,8,-1,2
"598","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," Bowers, Alex J. “Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis.” Practical Assessment, Research &amp; Evaluation 15, no. 7 (May 2010).  This article examines a longitudinal study on teacher grading histories using clustering and showed how patterned, visualized and interpreted data can aid teachers in decision making and instructing. The study conducted in two districts and all the data of teachers’ grading was in the paper files. To describe that data, the researchers chose to use descriptive statistical analysis that brings empirically defined organization to a set of previously unorganized data. The author chose clustergram as a way of providing data pattern visualization. It is composite with cluster analysis cluster tree and heatmap. The study used hierarchical cluster analysis and visualization with data to identify dropout. It has also provided an attractive avenue for identifying time points for early instructional intervention by exploring specific student grade cluster patterns.   The major take away in this article is the usage of clustering in predicting possible behavior that can be drawn from teachers grades history. It is intriguing for its combination of data and first hand resources from teachers. Also, as a longitudinal study, it selects a subject that is K-12. However, in different cultures, students may not be in the same school for all 12 years of elementary study. Thus, the longitudinal data collection can be a issue to be address. Some researchers has raised the idea of block chain in education for this kinds of data collection. This may be somehow helpful for future analysis on longitudinal data. Also, which cluster methods is most beneficial for the certain research question on drop out can be of interest. Then more generally, it is useful to ask whenever do the data analysis to see what method will be a good fit for the target problem.  ",1,2,-1,3
"599","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research"," Grunspan, Daniel Z., Benjamin L. Wiggins, and Steven M. Goodreau. “Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research.” CBE-Life Sciences Education 13, no. 2 (June 20, 2014): 167–78. https://doi.org/10.1187/cbe.13-08-0162.  This article serves as both introduction guideline to social network analysis (SNA) along with an empirical study of a research addressed in an undergraduate biology class. The authors of this paper aim to convince readers that using SNA in classroom environments allows rich and informative analysis to take place and to provide some initial tools for doing so.   There are a lot of terminology explained in this article in regards to basic concepts, methods for data collection, data processing, and data analysis. For Network Concepts, the nature that differentiate SNA is the importance of relationship and emergent structures formed by relationships. There are different ways to categorize networks, such as by the number of types od actors contained (unipartite vs bipartite), the nature of the ties contained (undirected vs. directed, binary vs. valued). For network data collection, a time frame for the relationship of interest is also important. The ways of how to sample from a population can also be divided into egocentric and census. The unique measurement for network data is network density, which indicates how many ties are present. For network methods, the collection step is based on a good survey. Also, time for the survey is also important, as the class on going, the relationship will be different. The paper also talks about the ethical issues in dealing with social network data.    The big lesson to take away from this paper is the thoroughness of authors’ introduction on the SNA. It is inspiring to know that there is a growing volume of research on social influences at the postsecondary level exists, examine outcomes such as overall GPA and academic performance. As social media now performs an increasingly heavy role in people’s, especially young generations’ life, it is even possible to investigate study behavior that relate to social network which is beyong traditional classroom setting. Then it comes a old issue, how can personal data be safely used even the intention for using is for academic reason? Scandal on how Facebook leaks personal data has aroused heated discussion, and influenced Mark Zuckerberg’s plan on developing in educational area. In this article, the author addressed the experiment in the institutional level. It seems that the solution for restricting data usage is an available way, but when it comes to a more general or broader setting, the problem should be newly addressed.   Also, it is interesting to find that the subject chosed in this experiment is biology, which involves collaboration in lab activities. It is intriguing to ask when it comes to other subjects, what SNA can tell to the educators and how can this better support the classroom going. In all, as the author said, SNA is a powerful tool, and there is a lot to look into and beyond it.  ",8,5,3,4
"600","Knowledge tracing: Modeling the acquisition of procedural knowledge"," Corbett, Albert T., and John R. Anderson. “Knowledge Tracing: Modeling the Acquisition of Procedural Knowledge.” User Modeling and User-Adapted Interaction 4, no. 4 (December 1, 1994): 253–78. https://doi.org/10.1007/BF01099821.  Students’ skill measurement is of importance in testing and evaluation of education. This paper describes an effort to model students' changing knowledge state during skill acquisition. The model, though generated in 1995, had been successful in predicting test performance at that time. One of the important caution here to be called is the changing dimensions of skills along with time.   Also, in the study the author talks about individual differences in performing tasks. The author incorporated differences among students into the model in the form of individual difference weights. It is worthwhile to search for better and more informative weights for current model for students. What’s more, in today’s individualized learning era, what can be done to serve individual using modeling data is of interest.   Surprisingly, models currently in use do not allow for individual learning rates nor individualized estimates of student initial knowledge. Corbett and Anderson were interested in trying to add individualization to their model which they accomplished but with mixed results. Since their original work, the field has not made significant progress towards individualization of knowledge tracing models in fitting data. Other researchers introduced way of formulating the individualization problem. With this new individualization technique, we may be able to show a reliable improvement in prediction of real world data by individualizing the initial knowledge parameter.    In all, enhancing existing intelligent tutoring systems to more accurately estimate when a student has reached mastery of a skill is in the trend. Adaptation of instruction based on individualized knowledge and learning speed may be applied in the future to assist broader learners with exploitation on user models.  ",9,2,7,3
"601","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration"," Siemens, George, and Ryan S. J. d. Baker. “Learning Analytics and Educational Data Mining: Towards Communication and Collaboration.” In Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge, 252–254. LAK ’12. New York, NY, USA: ACM, 2012. https://doi.org/10.1145/2330601.2330661.  Without a personalized touch, educators would otherwise stick to the traditional model of teaching and tailor instruction not to the individual, but to a mass classroom filled with supposedly homogenous mental make-ups.   Thankfully, educators and policy makers have caught on and realized the importance of personalized attention. Everyone’s brain processes information differently and with the help of learning analytics, the model of education is gradually moving away from the unrealistic institution and towards every individual student.   Learning analytics is the measurement and dissection of data about learners used to optimize their learning experience. As a student uses an educational software system or walks through an online problem set, data mining technology tracks their every move, translates these movements into raw data, and stores it away for further analysis. Some artificial intelligence-based software systems even explain, analyze, and interpret data themselves. Otherwise, the data is analyzed for patterns and used to create a teaching strategy personalized to the individual student’s strengths, weaknesses, and learning preferences.   It sounds like the teaching methods of tomorrow, and in many ways, it is. The benefits of using learning analytics are astounding. In a classroom setting, it’s hard to recognize and subsequently attend to a student’s individual weakness. With learning analytics, these deficiencies are identified immediately. Once an area of weakness is identified, edtech software is programmed to begin rewiring instruction to address that need.   Learning analytics can predict whether or not a student will pass an online course and, more generally, how they’ll perform in the remainder of the course. If they pass, analytics can predict in which areas they’ll still need additional support. The ability to predict performance means that every minute is designed to help students reach their educational end goals promptly.    In the same vein, with learning analytics, every minute a student spends with an edtech program is valuable. Learning analytics isn’t a trial run – it’s the solution for every student regardless of their specific needs or prior knowledge.    With the help of learning analytics, it is possible that action educators take can move towards helping students achieve their learning goals and objectives. With the help of learning analytics, the community will learn to celebrate and progress higher through the educational whirlwind that fuels our tomorrow.                ",7,5,2,2
"602","Evaluating Machine Learning Models"," Zheng, Alice. Evaluating Machine Learning Models. Sebastopol, CA: O’Reily Media, 2015. http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page.  Understanding how well a machine learning model is going to perform on unseen data is the ultimate purpose behind working with these evaluation metrics. Metrics like accuracy, precision, recall are good ways to evaluate classification models for balanced datasets, but if the data is imbalanced and there’s class disparity, then other methods like ROC/AUC perform better in evaluating the model performance.   This document talks about evaluation matrices with a focus on classification, regression and ranking which are examples of supervised learning. This can be useful for educators to know students’ performance, relevant groups and possible cause and reasons for certain performance. The author calls attention to the difference between training metrics and evaluation metrics. It is important to keep in mind what is the right evaluation metric, and find the proper training procedure. Also, it is of great importance to pay attention to the data set itself, be careful about skewed dataset, imbalance classes outliers and rare data.   For classification, which we also applied in our group project, evaluation metric plays a critical role in achieving the optimal classifier during the classification training. Thus, a selection of suitable evaluation metric is an important key for discriminating and obtaining the optimal classifier. Generally, many generative classifiers employ accuracy as a measure to discriminate the optimal solution during the classification training. However, the accuracy has several weaknesses which are less distinctiveness, less discriminability, less informativeness and bias to majority class data. Thus, it is important taken into consideration in constructing a new discriminator metric.        ",9,5,4,5
"603","Why Is Measuring Learning So Difficult?"," Educause. Why Is Measuring Learning So Difficult?, 2015. https://www.youtube.com/watch?v=_iv8A1pHNYA.  Why learning analytics is hard?  complexity  social cultural individual psychological   reliability  factors selection   multidimensional  output inside process   goals  suggests to the learning learning is a magic it is like a black box it is a problem to oversimplify it   ",2,4,-2,1
"604","Saturday Morning Breakfast Cereal"," Weinersmith, Zach. “Saturday Morning Breakfast Cereal,” January 5, 2016. http://www.smbc-comics.com/index.php?id=3978.  It is us Human who make a decision Who decide what we learn? Or what? This ironic comic reveals a lot about education content decision making. It is for sure that all the education want to generate better results for the future of individual and the human community as a whole. But when it comes to the extent that are about the tests, all the things run out of their track. This may be one of the big reason why more and more analytics on causal relationship between learning and outcomes emerges. But then comes other problems. How to ensure the interpretation of the data and its further analysis can be unbiasedly conveyed? As the loop shown in the class, just take the data mining part as an example, that there are dimensions from professions, politics, education systems, etc. that are taking into account, not to mention all the other parts that combined into the whole loop. A single part that mistakenly convey the message will mislead the direction. Thus, the learning analytics is a collaboration.   I really appreciate this comic which helps me articulate why I chose to change my major from Journalism into Measurement, Evaluation and Statistics. One of the most precious word I learned in the journalism class was “Truth”. But what is the Truth? In my senior year of the undergraduate, I took a class in Big Data of Journalism. That is the first real deep touch of big data I have. However, when writing the report for interview and research projects, I found myself not confident about what I am telling and showing. Did I really had the data well demonstrated? And can I really trust the interpretation from the report I had at hand? Thus, I want to build myself the ability that can really touch the raw data and see the connection, association and potential causal relation myself. Then, at any link of the loop, I can check and make a choice of trusting or not myself. After all, it is us the Human that make a decision on the what to do according to what we found.",5,3,2,1
"605","Data wranglers: human interpreters to help close the feedback loop","This paper has presented an account of Data Wranglers. Educational institutions and learning process entail rich data, and they concern weighty problems of great importance to society and the social good, so education is an especially well-suited domain for data science.   It is noteworthy that the author presents four main data sources for the wranglers to work with:   Survey feedback data from students, gathered at the end of their course.  Activity data from the VLE/LMS (Moodle).  Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums).  Aggregated completion, pass rate and demographic data.    Educational data sources are replete with information on communication (text), relations(links), and accruing behavioral profiles (careers). And these four domains are serving the benefits to a broader aspect of the educational setting, since all of this information can be mined and analyzed in an effort to understand and solve persistent educational problems. Educational data science would train educators - broadly conceived - to study these forms of educational data and to make sense of educational systems, their problems and potential solutions, and to develop a deeper understanding and empirically established forms of solutions. Educational data science would empower educators to perform data visualization, data reduction and description, and prediction tasks. Through the project we are going through in class, it is important to have a good data wrangling as preparation for the further steps. Without solid data wrangling skills, the rest of the data science process simply can’t progress in any meaningful way. Data wrangling takes a lot of time and requires a lot of effort, but it’s all worth it in the end. An important goal in acquiring excellent data wrangling skills is all about keeping efforts efficient and consistent.  ",12,4,8,1
"606","Zuckerberg is ploughing billions into 'personalised learning' – why?","Kucirkova, Natalia, and Elizabeth FitzGerald. “Zuckerberg Is Ploughing Billions into ‘personalised Learning’ – Why?” The Conversation, December 9, 2015. http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940.   This feature written by lecturers in the Open University provides an interpretation for “personalized learning” in a user-tech perspective. It also examined pros and cons of personalized learning, and gives compromise approach at the end. Since the article appears on The Conversation, the audience are more likely to be general reader rather than experts in the field, and thus it is grateful to the author that they discussed both pros and cons of the topic–personalized learning.   The author starts with introducing Facebook founder Mark Zuckerberg and his wife Chan Zuckerberg’s initiative on personalized learning, which is focused on analyze students’ past behavior and demonstrated interests in order to tailor their study instructed by technology. The four main dangers of personalized learning are biased knowledge type fed to students, inconsistence of personalized learning environment and real world situation, students’ unstable preferences, and security of students’ data. At the same time, the author pointed out that a sense of ownership and relevance for learners, as well as effective analysis from personalized data are helpful aspects from personalized learning. Combining user data with standard educational content, such as adaptive course-ware platform are introduced as a compromise approach.   Investigating personalized learning from a tech market perspective is fresh, but further analysis of where the money of the initiative goes and how it works also deserves audiences’ attention. The author mentioned in the very end of the article that “conversation and collaboration” are essential in the process of promoting personalized learning, in which tech companies play a unreplaceable role. To address the potential danger mentioned above, tech company needs to invest in labor and capital to develop advanced system that provides more comprehensive learning content, relate more to real life setting, and better adaptive learners’ need. What’s more, it is important to develop a system that use learners’ data in a ethical and integrity way. Reports from 2018 shows that there was still a great concern over effectiveness and data privacy of personalized learning. What’s more, the role the school and teachers play is drawing attention under personalized learning? What and how can personalized learning better cooperate with learning in the classroom setting, and how can technology better serve teachers and thus guide students in a more effective way is where the initiative should also concern about.",10,6,4,2
"607","Feature Selection","Feature selection  Knowledge discovery  Interpretability Insight   Curse of dimensionality ",0,0,0,5
"608","Translating Learning into Numbers: A Generic Framework for Learning Analytics"," Greller, Wolfgang, and Hendrik Drachsler. “Translating Learning into Numbers: A Generic Framework for Learning Analytics.” Journal of Educational Technology &amp; Society 15, no. 3 (2012): 42–57.  Times of interaction between teacher and students  For Stakeholders:  Learners: Times of interaction will be base on students' academic and personal needs. They might not willing to spend too much time if they have a solid background. Teachers: teachers' time available is different. Institution: the private time of students and teachers cannot be access by institutions.   Internal Limitations:  Competences: not easy to collect accurate data. Online interaction?  Offline interaction? Acceptance: Probably only focus on quantity but also need quality   External Constrains:  Conventions: more time, more commitment? Really? Quality of the interaction. Norms: How much time is the standard time for ""good interaction""   Instruments:  Tech: book appointment applications will only carry out booking time, but not the actual interaction time. Algorithm: how to combine it into students' performance. Theory: Interpersonal communication? The scale of data?   Data:  Open: Apps like canvas where student post discussion and faculty interact will help, but other different types of interaction will be difficult to count. Protected: interaction in social media.   Objectives:  Prediction: set a rule for student? Reflection: students' evaluation?   ",4,2,2,1
"609","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=k9Z4ibzH-1s&amp;feature=youtu.be.  Clustering    Definition: A broad set of techniques for finding subgroups of observations within a data set. Goal: observations in the same group to be similar and observations in different groups to be dissimilar.  Method: An unsupervised method: find relationships between the n observations without being trained by a response variable.  Function: To identify which observations are alike, and potentially categorize them therein.  K-means clustering is the simplest and the most commonly used clustering method for splitting a data set into a set of k groups. ",1,1,0,5
"610","Cross Validation"," Georgia Tech. Cross Validation. Youtube, 2016. https://www.youtube.com/watch?v=sFO2ff-gTh0. Cross validation generalization use a model that is complex enough to fit the data without casing problems on the test set training the set   ",1,2,-1,5
"611","Hands-On Programming with R"," Grolemund, Garrett. Hands-On Programming with R, 2019. https://rstudio-education.github.io/hopr/.  Why R for data analysis? R is not the only language that can be used for data analysis.  It is an interactive language, has data structures, available for different types of graphics, is able to dealing with missing values, has functions as first class objects, is available to different packages and has a huge community. Data analysis is inherently an interactive process — what people see at one stage determines what they want to do next.  Interactivity is important.  Language is important.  The two together — an interactive language — is even more than their sum.     Graphics should be central to data analysis.  Humans are predominantly visual, we don’t intuitively grasp numbers like we do pictures.  It is easy to produce graphs for exploring data.  The default graphs can be tweaked to get publication-quality graphs. Real data have missing values.  Missing values are an integral part of the R language.  Many functions have arguments that control how missing values are to be handled. Functions, like mean and median, are objects that you can use like data.  We can easily change analysis to use the median (or some strange estimate you make up on the spot) rather than the mean. R has a package system that makes it easy for people to add their own functionality so it is indistinguishable from the central part of R.     There are a lot more to explore.  ",5,5,0,1
"612","rmarkdown-cheatsheet-2.0"," “Rmarkdown-Cheatsheet-2.0,” n.d., 2.  R Markdown is one approach to ensuring reproducibility by providing a single cohesive authoring framework. It allows you to combine code, output, and analysis into a single document, are easily reproducible, and can be output to many different file formats. R Markdown is just one tool for enabling reproducibility. R Markdown files are designed to be used in three ways:  For communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis. For collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them ( i.e. the code). As an environment in which to dodata science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.   ",1,0,1,1
"613","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Konstan, Joseph A., J. D. Walker, D. Christopher Brooks, Keith Brown, and Michael D. Ekstrand. “Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC.” ACM Transactions on Computer-Human Interaction 22, no. 2 (April 15, 2015): 1–23. https://doi.org/10.1145/2728171.   Scholars from University of Minnesota conducted a study on a Hybrid MOOC in the fall of 2013. Though the paper was published in 2015, when the MOOC just mushroomed, it is still worth learning regarding to its mixed methods of empirical study and diversity of perspectives examined on the research. By using both quantitative method on surveying students and testing students’ knowledge gain and retention, as well as qualitative method on observation and interviews, the study finds that students preferred MOOC, and they gained better learning result from MOOC study.   Three main measurements, pre- and postclass survey, knowledge test, and knowledge retention survey were implemented. The researchers found that intention tells about completion, and little else does; student knowledge increased in MOOC, and students at all incoming knowledge level similarly benefited from the course, and students in different tracks had similar gain  on concepts knowledge, but programming students gain more in further knowledge; normalized knowledge gains are very difficult to predict, and predicting student end-of-term performance is difficult; most student learning gains were retained after 5 months.   The preciseness, thoroughness and insightfulness are three main lessons I gained from the study. First, the researchers demonstrated integrity in presenting results. Given that 4,844 of students online and 39 in face-to-face class participated in the study, it is dangerous to generalized the result for a larger dataset. The authors clearly pointed this out when presenting the research results. Also, as a single-group, cross-sectional study, the researchers paid attention to the limited number of face-to-face group of students and barriers it brought to the statistical analysis. Second, one highlight point for the study is that much of the analysis of the study look at the differences between those enrolled in the concepts and programming tracks. Students in concept track didn’t need to accomplish programming assignment while those in the programming track needed. This made the distinction of theoretical focused course and practical focused course more obvious, and at the same time provides common ground in both type of course. It is also kind of the researchers to pointed out lesson gained from the study, such as generating class specific dataset by using successful and motivating activity, which is now incorporating in our HUDK 4050 class. Also, the tension between course semantics and platform tools were still existing now in 2019, and thus is a potential worthwhile field to develop in technology and research aspects.   One thing to question on the study is about the programming track student knowledge gain. The researchers talked about further knowledge gain by programming track students, but there lacks an elaboration on what the further knowledge is. Perhaps it needed further discussion to distinguish and identify practical knowledge and conceptual knowledge. Another point to be mentioned is that the study also analyzed student evaluation and survey results. These results related to a broader level of department and program, which can have further impact on students selection of MOOC course. This part of analysis may be interesting to conduct if possible.   Overall, it is a paper that worth read over again and draw more from it.",21,7,14,4
"614","Machine beats experts: Automatic discovery of skill models for data-driven online course refinement","Matsuda, N., Furukawa, T., Bier, N., &amp; Faloutsos, C. (n.d.). Machine beats experts: Automatic discovery of skill models for data-driven online course refinement. 8. The study developed a new method ""eEPIPHANY"", to discover skill models from the data of large scale online courses. To build the model, the team first input an A-matrix, which shows a chronological record of students' responds to assessment items. Then they developed the Matrix Factorization Strategy and the Bag-of-Words strategy to show a mapping between assessment items and ""skill candidates"" in order to generate a P-matrix. To construct the model, the team uses three strategies to refine the ""default"" skill model: Replace, Append an Split. To search for best model, the team searched for the number of components used for the Matrix Factorization (Nc), the number of clusters in k-means (Nk), the number of topics used for LDA to compute the bag-of-words clustering (Nt), and the threshold used for the split strategy (beta). To identify the part of the skill model that has been improved, the team analyzed the degree of enhancement of the proposed change in skill models. The team also evaluate the efficiency and effectiveness of the eEPIPHANY method by applying it to three OLI courses in Carnegie Mellon University. The study found that using student repondes data for generating P-matrix always yields better results. The replacement strategy always discovers the best skill model. The study shows that the degree of  enhancement analysis allows course designers to make meaningful interpretations of the proposed refinement skill model. They also argue that eEPIPHANY is less labor intensive than LFA. The core concepts in this paper are in three aspects: the choice of strategy to identify potential associations between assessments and skills. The construction of the model and searching for the best skill model. Linking to what we did in the class activity of generating Q matrix, it is inspiring in the way of validity. It is also inspiring in the way of building a comprehensive model from the starting point of analyzing. However, there are two points that arouses my question for future study. First, though the paper states that eEPIPHANY is less labor intensive with relatively high accuracy, I doubt whether the evaluation for accuracy is done also in a evidence-based way. At the same time, the empirical study was set in Carnegie Mellon University, which the online course has a through feedback system. Then it is important to consider when applying to other school context, what and how should the course developer construct for feedback. Also, the course it studied are all engineering course, which the answer is more objective than those of liberal arts. Thus, for a liberal arts analysis, what and how should the model be constructed? Or should it be constructed? Overall, the paper is worthwhile for its research concerns of refining model for the existing one for current online course. Future studies may apply it into broader scope in terms of course type and geographic setting.  ",15,5,10,5
"615","Introduction to Social Network Methods_  Chapter 1_ Social Network Data.pdf"," “Introduction to Social Network Methods_  Chapter 1_ Social Network Data.Pdf,” n.d.   Social network data   Different about the network data   seeing how actors are located or ""embedded"" in the overall network. seeing how the whole pattern of individual choices give rise to more holistic patterns.   Nodes   network data are defined by actors and by relations (or ""nodes"" and ""edges"") focuses on relations among factors, and not individual actors and their attributes. include all of the actors who occur within some boundary   Populations, samples, and boundaries   because network methods focus on relations among actors, actors cannot be sampled independently to be included as observations the boundaries of the populations studied by network analyst are made by the analyst themselves or take ecological approach   Modality and levels of analysis   multiple levels of analysis and multi-modal data rarely take advantage   Relations   census conducted select sets   Sampling ties   full network methods: collect information about each actors' ties with all other actors snowball methods: a focal actor or set of actors Ego-centric networks with alter connections Ego-centric networks ego only   Multiple relations   scales of measurement   binary measures of relations multiple-category nominal measures of relations grouped ordinal measures of relations full-raked ordinal measures of relations interval measures of relations         Regarding to the methods talking in this chapter, it is noteworthy that choosing the right network for individual or groups are of importance. Whenever one engages in network analysis, it is important not to lose sight of the fact that the relations being studied are only a subset of those within which the associated individuals are embedded. Essentially all persons live within networks of physical interaction, material transactions (e.g. exchange), interpersonal communication, etc. Along with these, we have more culturally specific networks of friendship and affiliation, social support, ascribed kinship, and the like; persons living within complex societies will additionally have non-trivial networks of institutional affiliation, collaborative task performance, advice and information sharing, training and mentorship, and technologically mediated contact (among many others). Further, this short enumeration says nothing of the many networks which may be defined among concepts, texts, organizations, or other non-human entities. Given this diversity, it is highly misleading (at best) to speak of ‘the’ social network in which a person or other entity resides.    ",5,3,2,4
"616","Network Analysis and Visualization with R and igraph.pdf"," “Network Analysis and Visualization with R and Igraph.Pdf,” n.d.  This document is an explicit guidebook for network analysis in R. It talks about wide topics from R basics, networks in R graph, read network data, turning networks into igraph objects, plotting networks with igraph, network and node descriptive, distance and path, subgroups and communities, and Assortative and homophily. The methods are always evolving, but it is also important to find the most proper one for different research questions and principles.   In the field of education, new technology enables interactive and adaptive scenario-based tasks (SBTs) to be adopted in educational measurement. At the same time, it is a challenging problem to build appropriate psychometric models to analyze data collected from these tasks, due to the complexity of the data. Researchers have begun to explore the potential of using concepts and methods from social network analysis to represent and analyze process data. Visualization of the transition networks can represent process data and provide insights for item design. Topics on how network measures are related to existing scoring rubrics and how detailed network measures can be used to make intergroup comparisons are also explored.    Also, the educational knowledge domain may be understood as a system composed of multiple, co-evolving networks that reflect the form and content of a cultural field. The educational knowledge domain as having a community structure (form) based in relations of production (authoring) and consumption (referencing), and a cognitive structure (content) based in relations of ideas and concepts.  ",1,3,-2,4
"617","Principal Component Analysis explained visually.pdf"," “Principal Component Analysis Explained Visually.Pdf,” n.d.  This paper talks about different types of visualization of principal component analysis. Principal component analysis is a technique used to emphasize variation and bring out strong patterns in a data set. Thus, for different dimensions of the data set, it has different visualization effect of PCA.    In the field of education, research on how PCA can help with understanding students’ performance and choice has been conducted. When investigating students’ motivations to enroll in university, a wide range of elements related to the overall student experience should be taken into account. Study conducted by Italian researchers moves from this point to analyze students’ choice factors from a survey completed by 27,504 students across 23 Italian institutions by means of a logistic principal component analysis.    Results confirm the presence of multiple factors jointly influencing students’ choice, with geographical proximity, job opportunities in the region, university reputation and ease of access opposing one another. Visualization here is more of a multidimensional graph, which can provide audience with more informative message.    Since all the components describe different aspects, it is more informative to different type of audience. As for the study mentioned above, aggregating results at the institutional level, students’ distribution proves to be highly heterogeneous across universities, which are selected for different contextual factors even within the same region. This increases universities’ awareness and enables them to better focus on the main served population or to target a different one. Finally, policy considerations are reported.    To sum up, principal component analysis (PCA) is a way to bring out strong patterns from large and complex datasets. The essence of the data is captured in a few principal components, which themselves convey the most variation in the dataset. PCA reduces the number of dimensions without selecting or discarding them. Instead, it constructs principal components that focus on variation and account for the varied influences of dimensions. Such influences can be traced back from the PCA plot to find out what produces the differences among clusters.",3,2,1,2
"618","data-wrangling-cheatsheet (1).pdf","This Cheat Sheet provides detailed methods to dealing with dirty data in R. Data wrangling, like most data analytics processes, is an iterative one – the practitioner will need to carry out these steps repeatedly in order to produce the results he desires. It is informative to find five broad ways to do comprehensive data wrangling:  Discovering  In this step, the data is to be understood more deeply. Before implementing methods to clean it, you will definitely need to have a better idea about what the data is about. Wrangling needs to be done in specific manners, based on some criteria which could demarcate and divide the data accordingly – these are identified in this step.  Structuring  Raw data is given to you in a haphazard manner, in most cases – there will not be any structure to it. This needs to be rectified, and the data needs to be restructured in a manner that better suits the analytical method used. Based on the criteria identified in the first step, the data will need to be separated for ease of use. One column may become two, or rows may be split – whatever needs to be done for better analysis.  Cleaning  All datasets are sure to have some outliers, which can skew the results of the analysis. These will have to be cleaned, for the best results. In this step, the data is cleaned thoroughly for high-quality analysis. Null values will have to be changed, and the formatting will be standardized in order to make the data of higher quality.  Enriching  After cleaning, it will have to be enriched – this is done in the fourth step. This means that you will have to take stock of what is in the data and strategies whether you will have to augment it using some additional data in order to make it better. You should also brainstorm about whether you can derive any new data from the existing clean data set that you have.  Validating  Validation rules refer to some repetitive programming steps which are used to verify the consistency, quality and the security of the data you have. For example, you will have to ascertain whether the fields in the data set are accurate via a check across the data, or see whether the attributes are normally distributed. Though we didn’t come across with the step 4 and step 5, but with real project, it is worth going through these steps to have the validating part to make sure the data are in ready.",14,3,11,1
"619","R Markdown","R Markdown R Markdown allows you to create documents that serve as a neat record of your analysis. In the world of reproducible research, we want other researchers to easily understand what we did in our analysis, otherwise nobody can be certain that you analysed your data properly. You might choose to create an RMarkdown document as an appendix to a paper or project assignment that you are doing, upload it to an online repository such as Github, or simply to keep as a personal record so you can quickly look back at your code and see what you did. RMarkdown presents your code alongside its output (graphs, tables, etc.) with conventional text to explain it, a bit like a notebook.   RMarkdown uses Markdown syntax. Markdown is a very simple ‘markup’ language which provides methods for creating documents with headers, images, links etc. from plain text files, while keeping the original plain text file easy to read. You can convert Markdown documents to many other file types like .html or .pdf to display the headers, images etc..",4,0,4,1
"620","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=k9Z4ibzH-1s&amp;feature=youtu.be.   Add clusters until you don’t get interesting new clusters anymore Choose K with BIC, AIC Using information criterion  Assess how much fit would be spuriously expected from a random N centroids Assess how much fit you actually had   Solution  Penalize models with more clusters, according to how much extra fit would be expected from the additional cluster   ",0,1,-1,1
"621","Big Data in Education","Q-Matrix  What is a Q-matrix  A table Where rows are items And column are skills Also called KC [knowledge component] Model  Or a skill-item mapping     How many skills to use?  Run a certain number of times, with a different random initial assignment of items to skills Is skill conjunctive?   Hand development and refinement  Try to smooth learning curves Look for skills with no apparent learning Look for problems with unexpected error rates   ",6,2,4,5
"622","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=k9Z4ibzH-1s&amp;feature=youtu.be.  Educational data mining/Learning Analytics  Big data for learner and learning  To promote New scientific discoveries to advance learning Better assessment of learners along multiple dimensions Better real time support for learners   Educational data is big, but it’s not google-big  Avoid over fitting Big compared to traditional Domains   Prediction  classification regression latent knowledge estimation   Structure discovery  clustering factor analysis domain structure discovery network analysis   Relationship mining  association rule mining correlation mining sequential pattern mining causal data mining   Distill of data for human judgment Discovery with models ",3,1,2,5
"623","Big Data in Education","Classification  Predict the label  Categorical   A set of categorical  Correct wrong Help request / worked example request / attempt to solve Etc.   Algorithm  Step regression Logistic regression Decision tree J48/C4.5   Good when same structure can be arrived in multiple ways ",3,3,0,3
"624","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=8X0UlMShss4&amp;feature=youtu.be.  Decision Rules  Algorithms Generating rules from decision tree Conservative  Find simple models Don’t over-fit   Educational data has lots of systematic noise Support vector machines Generic algorithms Neuro network ",1,0,1,3
"625","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=fGMFYTHhcHg&amp;feature=youtu.be.  Diagnostic Metrics Accuracy/agreement Kappa Scaled on the proportion comparison",0,0,0,5
"626","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=9PDwRdyb6Sw&amp;feature=youtu.be.  Diagnostic Metrics ROC Probability Four possibilities ROC curve A’ and Kappa Precision and recall",0,0,0,5
"627","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=7r3hfJW1gz0&amp;feature=youtu.be.  Diagnostic Metrics Regression Linear regression Mean absolute deviation RMean square error BIC/AIC  ",0,3,-3,5
"628","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=1P34cxpEdKA&amp;feature=youtu.be.  Cross-validation and over fitting Overfitting Assessing generalizability Training test Cross-validation Student level Other level  ",0,0,0,5
"629","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=_7CtthPZJ70&amp;feature=youtu.be.  Bayesian Knowledge Tracing The classic approach for measuring tightly defined skill in online learning Assess KC Based on a sequence of items that are dichotomously scored Each items corresponds to a single skill Slip and make a mistake Knowing a skill leads to a correct performance Correct performance implies knowing the relevant skill Inference Constrains",8,0,8,5
"630","iGraph"," “IGraph,” n.d.  R iGraph Manual Pages",0,0,0,1
"631","Measurement and its Uses in Learning Analytics"," Bergner, Yoav. “Measurement and Its Uses in Learning Analytics.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 34–48. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This paper illustrated the promise of the combination of measurement theory and learning analytics. This point of view is thought-provoking for me as a student majored in Measurement and Evaluation. It is important to understand that the huge trend of visual learning and educational big data are leading the measurement into a multimodal analysis level. With these approaches available, more and more understanding on potential learning will be generated.    Now researchers have reported findings of whether and how MOOC log file data can assist in understanding how MOOC participants use (often) messy, chaotic forums to support complex, unpredictable, contingent learning processes. On a time efficiency perspective, Learning and Development in education are frequently asked to report on the effectiveness of their training programs. However, reporting simple completion statistics for training just isn’t cutting it anymore. Measuring and reporting the return on investment for education is essential. Being able to measure learning properly in this digital age could lead to more effective learning and teaching.   Educational data can even be pushed back to the learner to support and encourage them. For example, successful learning incorporates the 3 Fs: Focus (the learning process), Feedback (use of learning data), Fix it (learner’s continuous improvement). Learning data can deliver feedback to the learner which is customized to reflect both the learner’s past behavior and can recommend future actions to improve success.    ",11,4,7,2
"632","Ethics and Learning Analytics: Charting the (Un)Charted"," Prinsloo, Paul, and Sharon Slade. “Ethics and Learning Analytics: Charting the (Un)Charted.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 49–57. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This paper talks about different ethical issues faced in the field of learning analytics. It is true that once the Pandora’s Box of data availability has been opened, then individuals lose control of the data about them that have been harvested. They are unable to specify who has access to the data, and for what purpose, and may not be confident that the changes to the education system which result from learning analytics will be desirable....The transport of data from one context to another can result in an unfair and unjustified discrimination against an individual.   One of the ideas mentioned in the paper is thought-provoking. “Data may only be collected when the purpose /use of the collected data is made explicitly clear.” To expand on this point, researchers must have a defined understanding of what data will be collected, how it will be used, and for what purpose. By establishing the scope and purpose of your learning analytics, they can set ethical boundaries that can explain and defend when learners have questions about how their information is used.   Also, as the social media now is prevalent and more educational data can be obtained from different channels, it is important to pay sufficient attention to the privacy issue. Not everyone who has access needs complete access - only give staff and administrators the kind of permissions that they need to have. Whenever possible, the researcher should make learner data anonymous. Also, it is important to be sure that student information is protected when contracting with third parties for data storage and analysis  ",3,2,1,2
"633","Predictive Modelling in Teaching and Learning"," Brooks, Christopher, and Craig Thompson. “Predictive Modelling in Teaching and Learning.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 61–68. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This article introduces the terms and workflows related to predictive modelling, with a particular emphasis on how these techniques are being applied in teaching and learning. The author first made a comparison between explanatory models and predictive models, where differences in principal, pragmatics and methodologies are examined. Then, predictive modelling workflow is introduced, where major steps are “Problem Identification”, “Data Collection”, “Classification and Regression”, and “Feature Selection”. The author also introduced a number of methods for building models from historical data, and considerations when implementing different algorithms. There is also a need to assess the quality of the model with a test dataset, and the feature of the test dataset is call for attention. The author also provides real practice in teaching and learning where predictive analysis is used. In the last section, the author raised a number of challenges and opportunities when building predictive models.   Referring to the article on explanatory model, which emphasizes more on the interpretation of the data, the predictive model is a step forward, in which a more specific problem is to be addressed. In the “Problem Identification” part, the author mentioned quantifiable characteristics of the subject being modelled, a clear outcome of interest, the ability to intervene in situ and a large dataset are needed for a suitable problem to implement predictive model. Thus, it is reasonable that the example the author uses for providing real world practice are about institutional education data analysis, as well as online MOOC. However, this kinds of dataset is not always available in an open source. Thus, a question for me to explore further is the accessibility of the dataset in different cultural education system. Also, as mentioned in the last part of the article, supporting non-computer scientists in predictive modelling also has a great potential in promoting educational data access.  ",5,2,3,5
"634","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data"," Liu, Ren, and Kenneth Koedinger. “Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data.” In The Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Friend Wise, and Dragan Gaševic, 1st ed., 69–76. Alberta, Canada: Society for Learning Analytics Research (SoLAR), 2017. http://solaresearch.org/hla-17/hla17-chapter1.  This article reviewed examples of explanatory model in Cognitive Model discoveries, as well as other work in the field of educational data mining. The author argued that explanatory models can be beneficial and lead to improvements to learning outcomes and learning theory. By examining Data-Driven Cognitive Model Improvement, Learning Factors Analysis, and Automated Cognitive Model Discovery Using SimStudent, the author demonstrates how data-driven techniques can alleviate expert bias while reducing human labor, and more importantly, reveal more interpretable features. In other works rather than cognitive modeling, the author reviewed the study on student grouping conducted by Liu and Koedinger, in which the method used yielded student groups that are readily interpretable and potentially actionable. The author then summarized three features that tend to characterize explanatory models. First, explanatory modelling efforts tend to start with “clean” independent variable that have either simple functions or map clearly defined constructs. Second, the dependent variables of the model are constructed in a well-defined structure. Finally, fewer estimated parameters serves in explanatory models, including characterizing independent variables, or features.   Linking to the topics in class, clustering and principle components theories are doing works to eliminate overwhelming variables and grouping them into fewer well-defined features. I am wondering if this is what the author referred to as “start with “clean” independent variable”. Also, it is important to know that when generating a model, the pre-treatment of data is very important, because the structure of the data can influence the explicitness of the model. A question for me to explore is how to construct well-defined structure for both independent variables and dependent variables.  ",11,2,9,5
"635","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)"," Gelman, A, and A Unwin. “Infovis and Statistical Graphics: Different Goals, Different Looks (with Discussion),” 2012.  This paper talks about differences in perspectives, goals and principles for data visualization between info visualization and statistics graphs. The dialogue is important for them to communicate and compare different sources, different goals and different demands from the audience.   However, although people in both fields pursue unique and distinctive displays to solve unfamiliar problems, most of them rely on proving generic methods. In the book, Readings in Information Visualization: Using Vision to Think, by Stuart Card, Jock Mackinlay, and Ben Shneiderman says: “Information visualization is the use of computer supported, graphical representations of abstract data to augment cognition.” When information visualizations display quantitative data, which is usually the case, they are in fact “statistical graphics.” The authors also state: “One key difference between the two approaches is that Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods that have a similar look and feel across a wide range of applications.”    It is true that, “In the world of Infovis, design goals can be pursued at the expense of statistical goals.” However, it is not desired that they should be pursued in this way anymore than in the world of statistics.    From the paper and related topic, it is more interesting to find the negotiations. Statistical graphics (or visual data mining, visual analytics, or any other name you like) typically do not provide a final answer. But, statistical graphics often help to detect the unexpected, formulate new hypotheses, or develop new models. Later on, additional experiments or ongoing data collection as well as more formal methods (and p–values if you really want) may be used to verify some of the original graphical findings.’  ",4,3,1,2
"636","Junkcharts Trifecta Checkup: The Definitive Guide"," Fung, K. “Junkcharts Trifecta Checkup: The Definitive Guide.” Blog. Junkcharts (blog), 2014. http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html.  This paper expanded Tufte’s principle regarding to data visualization and talks about data vis in a research perspective. It is of great importance that we pay attention to the questions, data and visualization at the same time. The author uses a triangle network to explain different types of weakness in junk charts.    However, on the other side, the internet granted us with enormous access to the data and source itself, then it comes to the question, is junk chart really a junk?  Guidelines for designing information charts often state that the presentation should reduce ‘chart junk’ - visual embellishments that are not essential to understanding the data. In contrast, some popular chart designers wrap the presented data in detailed and elaborate imagery, raising the questions of whether this imagery is really as detrimental to understanding as has been proposed, and whether the visual embellishment may have other benefits.   To investigate these issues, researchers have conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. They found that people's accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better.    After all, it is a debate and all about the balance. The fundamental issue is whether embellishments support the data or to some degree distract from it or distort it. Embellishments that represent data, even metaphorically, can themselves qualify as “data ink.” Embellishments that are not data in themselves can sometimes support the display of data in a useful manner.   ",7,8,-1,2
"637","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," Bowers, Alex J. “Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis.” Practical Assessment, Research &amp; Evaluation 15, no. 7 (May 2010).  This article examines a longitudinal study on teacher grading histories using clustering and showed how patterned, visualized and interpreted data can aid teachers in decision making and instructing. The study conducted in two districts and all the data of teachers’ grading was in the paper files. To describe that data, the researchers chose to use descriptive statistical analysis that brings empirically defined organization to a set of previously unorganized data. The author chose clustergram as a way of providing data pattern visualization. It is composite with cluster analysis cluster tree and heatmap. The study used hierarchical cluster analysis and visualization with data to identify dropout. It has also provided an attractive avenue for identifying time points for early instructional intervention by exploring specific student grade cluster patterns.   The major take away in this article is the usage of clustering in predicting possible behavior that can be drawn from teachers grades history. It is intriguing for its combination of data and first hand resources from teachers. Also, as a longitudinal study, it selects a subject that is K-12. However, in different cultures, students may not be in the same school for all 12 years of elementary study. Thus, the longitudinal data collection can be a issue to be address. Some researchers has raised the idea of block chain in education for this kinds of data collection. This may be somehow helpful for future analysis on longitudinal data. Also, which cluster methods is most beneficial for the certain research question on drop out can be of interest. Then more generally, it is useful to ask whenever do the data analysis to see what method will be a good fit for the target problem.  ",1,2,-1,3
"638","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research"," Grunspan, Daniel Z., Benjamin L. Wiggins, and Steven M. Goodreau. “Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research.” CBE-Life Sciences Education 13, no. 2 (June 20, 2014): 167–78. https://doi.org/10.1187/cbe.13-08-0162.  This article serves as both introduction guideline to social network analysis (SNA) along with an empirical study of a research addressed in an undergraduate biology class. The authors of this paper aim to convince readers that using SNA in classroom environments allows rich and informative analysis to take place and to provide some initial tools for doing so.   There are a lot of terminology explained in this article in regards to basic concepts, methods for data collection, data processing, and data analysis. For Network Concepts, the nature that differentiate SNA is the importance of relationship and emergent structures formed by relationships. There are different ways to categorize networks, such as by the number of types od actors contained (unipartite vs bipartite), the nature of the ties contained (undirected vs. directed, binary vs. valued). For network data collection, a time frame for the relationship of interest is also important. The ways of how to sample from a population can also be divided into egocentric and census. The unique measurement for network data is network density, which indicates how many ties are present. For network methods, the collection step is based on a good survey. Also, time for the survey is also important, as the class on going, the relationship will be different. The paper also talks about the ethical issues in dealing with social network data.    The big lesson to take away from this paper is the thoroughness of authors’ introduction on the SNA. It is inspiring to know that there is a growing volume of research on social influences at the postsecondary level exists, examine outcomes such as overall GPA and academic performance. As social media now performs an increasingly heavy role in people’s, especially young generations’ life, it is even possible to investigate study behavior that relate to social network which is beyong traditional classroom setting. Then it comes a old issue, how can personal data be safely used even the intention for using is for academic reason? Scandal on how Facebook leaks personal data has aroused heated discussion, and influenced Mark Zuckerberg’s plan on developing in educational area. In this article, the author addressed the experiment in the institutional level. It seems that the solution for restricting data usage is an available way, but when it comes to a more general or broader setting, the problem should be newly addressed.   Also, it is interesting to find that the subject chosed in this experiment is biology, which involves collaboration in lab activities. It is intriguing to ask when it comes to other subjects, what SNA can tell to the educators and how can this better support the classroom going. In all, as the author said, SNA is a powerful tool, and there is a lot to look into and beyond it.  ",8,5,3,4
"639","Knowledge tracing: Modeling the acquisition of procedural knowledge"," Corbett, Albert T., and John R. Anderson. “Knowledge Tracing: Modeling the Acquisition of Procedural Knowledge.” User Modeling and User-Adapted Interaction 4, no. 4 (December 1, 1994): 253–78. https://doi.org/10.1007/BF01099821.  Students’ skill measurement is of importance in testing and evaluation of education. This paper describes an effort to model students' changing knowledge state during skill acquisition. The model, though generated in 1995, had been successful in predicting test performance at that time. One of the important caution here to be called is the changing dimensions of skills along with time.   Also, in the study the author talks about individual differences in performing tasks. The author incorporated differences among students into the model in the form of individual difference weights. It is worthwhile to search for better and more informative weights for current model for students. What’s more, in today’s individualized learning era, what can be done to serve individual using modeling data is of interest.   Surprisingly, models currently in use do not allow for individual learning rates nor individualized estimates of student initial knowledge. Corbett and Anderson were interested in trying to add individualization to their model which they accomplished but with mixed results. Since their original work, the field has not made significant progress towards individualization of knowledge tracing models in fitting data. Other researchers introduced way of formulating the individualization problem. With this new individualization technique, we may be able to show a reliable improvement in prediction of real world data by individualizing the initial knowledge parameter.    In all, enhancing existing intelligent tutoring systems to more accurately estimate when a student has reached mastery of a skill is in the trend. Adaptation of instruction based on individualized knowledge and learning speed may be applied in the future to assist broader learners with exploitation on user models.  ",9,2,7,3
"640","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration"," Siemens, George, and Ryan S. J. d. Baker. “Learning Analytics and Educational Data Mining: Towards Communication and Collaboration.” In Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge, 252–254. LAK ’12. New York, NY, USA: ACM, 2012. https://doi.org/10.1145/2330601.2330661.  Without a personalized touch, educators would otherwise stick to the traditional model of teaching and tailor instruction not to the individual, but to a mass classroom filled with supposedly homogenous mental make-ups.   Thankfully, educators and policy makers have caught on and realized the importance of personalized attention. Everyone’s brain processes information differently and with the help of learning analytics, the model of education is gradually moving away from the unrealistic institution and towards every individual student.   Learning analytics is the measurement and dissection of data about learners used to optimize their learning experience. As a student uses an educational software system or walks through an online problem set, data mining technology tracks their every move, translates these movements into raw data, and stores it away for further analysis. Some artificial intelligence-based software systems even explain, analyze, and interpret data themselves. Otherwise, the data is analyzed for patterns and used to create a teaching strategy personalized to the individual student’s strengths, weaknesses, and learning preferences.   It sounds like the teaching methods of tomorrow, and in many ways, it is. The benefits of using learning analytics are astounding. In a classroom setting, it’s hard to recognize and subsequently attend to a student’s individual weakness. With learning analytics, these deficiencies are identified immediately. Once an area of weakness is identified, edtech software is programmed to begin rewiring instruction to address that need.   Learning analytics can predict whether or not a student will pass an online course and, more generally, how they’ll perform in the remainder of the course. If they pass, analytics can predict in which areas they’ll still need additional support. The ability to predict performance means that every minute is designed to help students reach their educational end goals promptly.    In the same vein, with learning analytics, every minute a student spends with an edtech program is valuable. Learning analytics isn’t a trial run – it’s the solution for every student regardless of their specific needs or prior knowledge.    With the help of learning analytics, it is possible that action educators take can move towards helping students achieve their learning goals and objectives. With the help of learning analytics, the community will learn to celebrate and progress higher through the educational whirlwind that fuels our tomorrow.                ",7,5,2,2
"641","Evaluating Machine Learning Models"," Zheng, Alice. Evaluating Machine Learning Models. Sebastopol, CA: O’Reily Media, 2015. http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page.  Understanding how well a machine learning model is going to perform on unseen data is the ultimate purpose behind working with these evaluation metrics. Metrics like accuracy, precision, recall are good ways to evaluate classification models for balanced datasets, but if the data is imbalanced and there’s class disparity, then other methods like ROC/AUC perform better in evaluating the model performance.   This document talks about evaluation matrices with a focus on classification, regression and ranking which are examples of supervised learning. This can be useful for educators to know students’ performance, relevant groups and possible cause and reasons for certain performance. The author calls attention to the difference between training metrics and evaluation metrics. It is important to keep in mind what is the right evaluation metric, and find the proper training procedure. Also, it is of great importance to pay attention to the data set itself, be careful about skewed dataset, imbalance classes outliers and rare data.   For classification, which we also applied in our group project, evaluation metric plays a critical role in achieving the optimal classifier during the classification training. Thus, a selection of suitable evaluation metric is an important key for discriminating and obtaining the optimal classifier. Generally, many generative classifiers employ accuracy as a measure to discriminate the optimal solution during the classification training. However, the accuracy has several weaknesses which are less distinctiveness, less discriminability, less informativeness and bias to majority class data. Thus, it is important taken into consideration in constructing a new discriminator metric.        ",9,5,4,5
"642","Why Is Measuring Learning So Difficult?"," Educause. Why Is Measuring Learning So Difficult?, 2015. https://www.youtube.com/watch?v=_iv8A1pHNYA.  Why learning analytics is hard?  complexity  social cultural individual psychological   reliability  factors selection   multidimensional  output inside process   goals  suggests to the learning learning is a magic it is like a black box it is a problem to oversimplify it   ",2,4,-2,1
"643","Saturday Morning Breakfast Cereal"," Weinersmith, Zach. “Saturday Morning Breakfast Cereal,” January 5, 2016. http://www.smbc-comics.com/index.php?id=3978.  It is us Human who make a decision Who decide what we learn? Or what? This ironic comic reveals a lot about education content decision making. It is for sure that all the education want to generate better results for the future of individual and the human community as a whole. But when it comes to the extent that are about the tests, all the things run out of their track. This may be one of the big reason why more and more analytics on causal relationship between learning and outcomes emerges. But then comes other problems. How to ensure the interpretation of the data and its further analysis can be unbiasedly conveyed? As the loop shown in the class, just take the data mining part as an example, that there are dimensions from professions, politics, education systems, etc. that are taking into account, not to mention all the other parts that combined into the whole loop. A single part that mistakenly convey the message will mislead the direction. Thus, the learning analytics is a collaboration.   I really appreciate this comic which helps me articulate why I chose to change my major from Journalism into Measurement, Evaluation and Statistics. One of the most precious word I learned in the journalism class was “Truth”. But what is the Truth? In my senior year of the undergraduate, I took a class in Big Data of Journalism. That is the first real deep touch of big data I have. However, when writing the report for interview and research projects, I found myself not confident about what I am telling and showing. Did I really had the data well demonstrated? And can I really trust the interpretation from the report I had at hand? Thus, I want to build myself the ability that can really touch the raw data and see the connection, association and potential causal relation myself. Then, at any link of the loop, I can check and make a choice of trusting or not myself. After all, it is us the Human that make a decision on the what to do according to what we found.",5,3,2,1
"644","Data wranglers: human interpreters to help close the feedback loop","This paper has presented an account of Data Wranglers. Educational institutions and learning process entail rich data, and they concern weighty problems of great importance to society and the social good, so education is an especially well-suited domain for data science.   It is noteworthy that the author presents four main data sources for the wranglers to work with:   Survey feedback data from students, gathered at the end of their course.  Activity data from the VLE/LMS (Moodle).  Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums).  Aggregated completion, pass rate and demographic data.    Educational data sources are replete with information on communication (text), relations(links), and accruing behavioral profiles (careers). And these four domains are serving the benefits to a broader aspect of the educational setting, since all of this information can be mined and analyzed in an effort to understand and solve persistent educational problems. Educational data science would train educators - broadly conceived - to study these forms of educational data and to make sense of educational systems, their problems and potential solutions, and to develop a deeper understanding and empirically established forms of solutions. Educational data science would empower educators to perform data visualization, data reduction and description, and prediction tasks. Through the project we are going through in class, it is important to have a good data wrangling as preparation for the further steps. Without solid data wrangling skills, the rest of the data science process simply can’t progress in any meaningful way. Data wrangling takes a lot of time and requires a lot of effort, but it’s all worth it in the end. An important goal in acquiring excellent data wrangling skills is all about keeping efforts efficient and consistent.  ",12,4,8,1
"645","Zuckerberg is ploughing billions into 'personalised learning' – why?","Kucirkova, Natalia, and Elizabeth FitzGerald. “Zuckerberg Is Ploughing Billions into ‘personalised Learning’ – Why?” The Conversation, December 9, 2015. http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940.   This feature written by lecturers in the Open University provides an interpretation for “personalized learning” in a user-tech perspective. It also examined pros and cons of personalized learning, and gives compromise approach at the end. Since the article appears on The Conversation, the audience are more likely to be general reader rather than experts in the field, and thus it is grateful to the author that they discussed both pros and cons of the topic–personalized learning.   The author starts with introducing Facebook founder Mark Zuckerberg and his wife Chan Zuckerberg’s initiative on personalized learning, which is focused on analyze students’ past behavior and demonstrated interests in order to tailor their study instructed by technology. The four main dangers of personalized learning are biased knowledge type fed to students, inconsistence of personalized learning environment and real world situation, students’ unstable preferences, and security of students’ data. At the same time, the author pointed out that a sense of ownership and relevance for learners, as well as effective analysis from personalized data are helpful aspects from personalized learning. Combining user data with standard educational content, such as adaptive course-ware platform are introduced as a compromise approach.   Investigating personalized learning from a tech market perspective is fresh, but further analysis of where the money of the initiative goes and how it works also deserves audiences’ attention. The author mentioned in the very end of the article that “conversation and collaboration” are essential in the process of promoting personalized learning, in which tech companies play a unreplaceable role. To address the potential danger mentioned above, tech company needs to invest in labor and capital to develop advanced system that provides more comprehensive learning content, relate more to real life setting, and better adaptive learners’ need. What’s more, it is important to develop a system that use learners’ data in a ethical and integrity way. Reports from 2018 shows that there was still a great concern over effectiveness and data privacy of personalized learning. What’s more, the role the school and teachers play is drawing attention under personalized learning? What and how can personalized learning better cooperate with learning in the classroom setting, and how can technology better serve teachers and thus guide students in a more effective way is where the initiative should also concern about.",10,6,4,2
"646","Feature Selection","Feature selection  Knowledge discovery  Interpretability Insight   Curse of dimensionality ",0,0,0,5
"647","Translating Learning into Numbers: A Generic Framework for Learning Analytics"," Greller, Wolfgang, and Hendrik Drachsler. “Translating Learning into Numbers: A Generic Framework for Learning Analytics.” Journal of Educational Technology &amp; Society 15, no. 3 (2012): 42–57.  Times of interaction between teacher and students  For Stakeholders:  Learners: Times of interaction will be base on students' academic and personal needs. They might not willing to spend too much time if they have a solid background. Teachers: teachers' time available is different. Institution: the private time of students and teachers cannot be access by institutions.   Internal Limitations:  Competences: not easy to collect accurate data. Online interaction?  Offline interaction? Acceptance: Probably only focus on quantity but also need quality   External Constrains:  Conventions: more time, more commitment? Really? Quality of the interaction. Norms: How much time is the standard time for ""good interaction""   Instruments:  Tech: book appointment applications will only carry out booking time, but not the actual interaction time. Algorithm: how to combine it into students' performance. Theory: Interpersonal communication? The scale of data?   Data:  Open: Apps like canvas where student post discussion and faculty interact will help, but other different types of interaction will be difficult to count. Protected: interaction in social media.   Objectives:  Prediction: set a rule for student? Reflection: students' evaluation?   ",4,2,2,1
"648","Big Data in Education"," Baker, R. Big Data in Education. 1st ed. New York, NY, 2014. https://www.youtube.com/watch?v=k9Z4ibzH-1s&amp;feature=youtu.be.  Clustering    Definition: A broad set of techniques for finding subgroups of observations within a data set. Goal: observations in the same group to be similar and observations in different groups to be dissimilar.  Method: An unsupervised method: find relationships between the n observations without being trained by a response variable.  Function: To identify which observations are alike, and potentially categorize them therein.  K-means clustering is the simplest and the most commonly used clustering method for splitting a data set into a set of k groups. ",1,1,0,5
"649","Cross Validation"," Georgia Tech. Cross Validation. Youtube, 2016. https://www.youtube.com/watch?v=sFO2ff-gTh0. Cross validation generalization use a model that is complex enough to fit the data without casing problems on the test set training the set   ",1,2,-1,5
"650","Hands-On Programming with R"," Grolemund, Garrett. Hands-On Programming with R, 2019. https://rstudio-education.github.io/hopr/.  Why R for data analysis? R is not the only language that can be used for data analysis.  It is an interactive language, has data structures, available for different types of graphics, is able to dealing with missing values, has functions as first class objects, is available to different packages and has a huge community. Data analysis is inherently an interactive process — what people see at one stage determines what they want to do next.  Interactivity is important.  Language is important.  The two together — an interactive language — is even more than their sum.     Graphics should be central to data analysis.  Humans are predominantly visual, we don’t intuitively grasp numbers like we do pictures.  It is easy to produce graphs for exploring data.  The default graphs can be tweaked to get publication-quality graphs. Real data have missing values.  Missing values are an integral part of the R language.  Many functions have arguments that control how missing values are to be handled. Functions, like mean and median, are objects that you can use like data.  We can easily change analysis to use the median (or some strange estimate you make up on the spot) rather than the mean. R has a package system that makes it easy for people to add their own functionality so it is indistinguishable from the central part of R.     There are a lot more to explore.  ",5,5,0,1
"651","Introduction to Social Network Methods_  Chapter 1_ Social Network Data.pdf"," “Introduction to Social Network Methods_  Chapter 1_ Social Network Data.Pdf,” n.d.   Social network data   Different about the network data   seeing how actors are located or ""embedded"" in the overall network. seeing how the whole pattern of individual choices give rise to more holistic patterns.   Nodes   network data are defined by actors and by relations (or ""nodes"" and ""edges"") focuses on relations among factors, and not individual actors and their attributes. include all of the actors who occur within some boundary   Populations, samples, and boundaries   because network methods focus on relations among actors, actors cannot be sampled independently to be included as observations the boundaries of the populations studied by network analyst are made by the analyst themselves or take ecological approach   Modality and levels of analysis   multiple levels of analysis and multi-modal data rarely take advantage   Relations   census conducted select sets   Sampling ties   full network methods: collect information about each actors' ties with all other actors snowball methods: a focal actor or set of actors Ego-centric networks with alter connections Ego-centric networks ego only   Multiple relations   scales of measurement   binary measures of relations multiple-category nominal measures of relations grouped ordinal measures of relations full-raked ordinal measures of relations interval measures of relations         Regarding to the methods talking in this chapter, it is noteworthy that choosing the right network for individual or groups are of importance. Whenever one engages in network analysis, it is important not to lose sight of the fact that the relations being studied are only a subset of those within which the associated individuals are embedded. Essentially all persons live within networks of physical interaction, material transactions (e.g. exchange), interpersonal communication, etc. Along with these, we have more culturally specific networks of friendship and affiliation, social support, ascribed kinship, and the like; persons living within complex societies will additionally have non-trivial networks of institutional affiliation, collaborative task performance, advice and information sharing, training and mentorship, and technologically mediated contact (among many others). Further, this short enumeration says nothing of the many networks which may be defined among concepts, texts, organizations, or other non-human entities. Given this diversity, it is highly misleading (at best) to speak of ‘the’ social network in which a person or other entity resides.    ",5,3,2,4
"652","Network Analysis and Visualization with R and igraph.pdf"," “Network Analysis and Visualization with R and Igraph.Pdf,” n.d.  This document is an explicit guidebook for network analysis in R. It talks about wide topics from R basics, networks in R graph, read network data, turning networks into igraph objects, plotting networks with igraph, network and node descriptive, distance and path, subgroups and communities, and Assortative and homophily. The methods are always evolving, but it is also important to find the most proper one for different research questions and principles.   In the field of education, new technology enables interactive and adaptive scenario-based tasks (SBTs) to be adopted in educational measurement. At the same time, it is a challenging problem to build appropriate psychometric models to analyze data collected from these tasks, due to the complexity of the data. Researchers have begun to explore the potential of using concepts and methods from social network analysis to represent and analyze process data. Visualization of the transition networks can represent process data and provide insights for item design. Topics on how network measures are related to existing scoring rubrics and how detailed network measures can be used to make intergroup comparisons are also explored.    Also, the educational knowledge domain may be understood as a system composed of multiple, co-evolving networks that reflect the form and content of a cultural field. The educational knowledge domain as having a community structure (form) based in relations of production (authoring) and consumption (referencing), and a cognitive structure (content) based in relations of ideas and concepts.  ",1,3,-2,4
"653","Predictive Modelling in Teaching and Learning","Process, practice and challenges in using predictive modelling in teaching and learning In both LA and EDM, predictive modeling has become a core practice. Predictive modeling =/= exploratory modeling - explanation vs prediction - key difference is in geenralizability Use cases for predictive analytics in practice - Performance measures, especially identifying students at risk in their academic programming. - e.g. determine whether students will graduate from sec school on time, formative achievement based on previous interactions with intelligent tutoring system, MOOC disengagement mid-course as an outcome. - Detect learners who are engaging in off-task behavior Challenges and opportunities - supporting non-CS in predictive modeling activites - creating community-led data science challenge initiatives - second order predictive modeling. Second order = include historical knowledge as to the effects of and intervention (e.g. email prompt or budge) in the model itself. Modeling of intervention effectiveness is important when multiple interventions are avaiable and personalized learning paths are desired.  ",2,1,1,3
"654","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Explantory models of educational data (beyond data prediction) Causal relationships between constructs that can either be observed or inferred from data Majority of EDM has been on predictive accuracy. Field could benefit from developing explanatory models. Efforts that have produced explanatory models Cognitive models - map knowledge components to problem steps/tasks where student performance can be observed. - provides a way for statistical models to make inferences about students' underlying knowledge based on their observable performance on different problem steps - Data-driven cognitive model improvement: Difficulty factors assessment (DFA) - uses data-driven knowledge decompotision to identify problematic elements of a task. Use DFA to identify and validate cognitive model improvements. Involves inspecting learning curves for KC model/Q-matrix, identify problematic KCs and hypothesize changes, re-fit the AFM with the revised KC model and assess whether the new model fits the data better. -Learning factors analysis (LFA) - atuoamte data-driven methods of KC model refinfement to alleviate demands on human time. Searches along knowledge components, evaluates models, outputs best-fitting KC model. - Automated cognitive model discovery (SimStudent)    ",4,2,2,5
"655","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Statistical graphics vs infographics Goals for graphical displays from statistical point of view (and contradictions with infographics) Different goals lead researchers to value different aspects of data visualization. Within statistics, statistical graphics have been losing importance, whereas outside, data graphics are becoming hugely popular. Statisticians: effective and precise ways to representing data, statistics or model analyses. infovis: grabbing readers' attention and telling them a story.      ",2,2,0,2
"656","Junkcharts Trifecta Checkup: The Definitive Guide","Framework for critiquing data visualisations - what is the question - what does the data say - what does the visual say Results from the questions above should be the same. The framework has 8 types of critiques, that are permutations of which component is weak/wrong.",0,0,0,2
"657","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Hierarchical cluster analysis and pattern visualization on data point on students  Correctly identified &gt; 80% of students who dropped out using entire student grade history patterns from either K-12 or K-8. Research question: to what extent do student grades cluster through HCA into patterns that identify which students are most at risk of dropping out of school. Clustering - supervised (defined set of assumptions about categorization) vs unsupervised (assumes nothing about the categorization) HCA - organizing data based on how similar the values for the list of variables are for each case. In this case, each student's grades in all subjects from grade K through 12. Clustering algorithm applied in iteractive fashion at each level of clustering, until it defines the entire dataset at the highest hierarchical level. Visualization: clustergram - cluster analysis, cluster tree and heatmap.  ",1,1,0,3
"658","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social network analysis to understand classrooms (primer to encourage more research, rather than a research paper itself)   Understanding how learning relationships fown in undergraduate classrooms and the impact on learning outcomes. Test for association between network position and success on exams. SNA - 2 hypotheses: 1) what influences formation of relational ties in a given population, 2) influence that the structure has on shaping outcomes at the individual level or socioeconomic/ population level. Network formation within classrooms to understand how the realized networks affect learning outcomes -&gt; understand social impacts of different pedagogical strategies. - E.g. Active learning is effective but why? Maybe active learning &gt; facilitation of student networks to be stronger or less centralized or structure in a new way &gt; maximize learning. Contents of article: 1. Basic concepts and terms in SNA 2. Way to organize data for analysis 3. Analysis of classroom network - descriptive, exploration of network evolution, analysis of network position as predictor of outcomes.   Case study: subset of a 10-week intro biology course, 187 students Findings: Exploratory - hypothesis: Students who are in the same lab likely to study together. Students with fewer study partners are less likely to perform well in the class. Use sociographs to visualize network - gives visual evidence but not statistical significance. Network changes overtime - measures e.g .density, triad censuses and transitivity to compare first and second exams. Overall, increase in study partnerships at the class level. As predictors of performance - test association between degree centrality and betweenness centrality and exam scores. Because of dependent nature of cetnrality measures, testing for association between network position and exam performance is not straightforward. - Permutation correlation test - distribution of corrs from data by random sampling values from one variable and matching them to another. - results: no signiciant correlation for either centrality measure for the first exam but signifciant correlation between both on the second exam. =&gt; given chance to revise network positions after some experience in the course, there is a social influence on exam performance. Note: study could not control for student effort, so unable to discern if study effort confounds findings and therefore causality is vague.",6,2,4,4
"659","Why Students Should Own Their Educational Data","Designing for the averages student if designing for nobody - L. Todd Rose, educational neurosicnece at Harvard GSE. Center for Individual Opportunities - research into ""science of the individual"". Learning style theory: Analogy to cancer, where doctors try to treat an ""average cancer"" and when it does not work says the patient has an ""aggressive form"". Today it is personalized. For learning, there are also personal patterns across dimensions, And this is beyond learning styles. Personality and learning varies across contexts. MOOCs: It has pushed colleges to thnik about what the value proposition is about face to face vs online. His vision: third party responsible for protecting learner datam and student to have a decade of data about the way that they're learning.      ",4,2,2,2
"660","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Testing",0,0,0,5
"661","Evaluating Machine Learning Models","Evaluation metrics for supervised learning models Classification metrics - accuracy = # correct predictions/ # total data points - confusion matrix: useful when you want to look at how many examples failed for class 0 vs class 1. - log-loss: can be used if classifier is a numeric probability instead of class label 0 or 1 - AUC = area under curve for ROC curve. Perfect classifier model gives AUC of 1. Ranking metrics - precision-recall = two concepts where precision = # happy corret answers/ # total items returned by ranker, and recall = # happy corret answers/ # total relevant items -precision recall curve and F1 score - NDCG Regression metrics - RMSE - Quantiles of errors",2,3,-1,5
"662","Data wranglers: human interpreters to help close the feedback loop","Role of human data wranglers at the Open University, UK (a LA program) Learning Analytics Cycle (Clow): Closing the feedback loop means actionable intelligence from data is produced, and interventions are made. Institution-wide capability-building learning analytics programs: Data wranglers deployed to engage in sensemaking activity with learning analytics data. Main data sources: survey feedback, activity from VLE/LMS, delivery data, completion and pass rates. Strong potential synergy with Learning Design, where it provides context for interpreting learning analytics, and learning analytics provide insight to underpin process of Learning Design. Examples of analyses: - activity on VLE/LMS - support development of proactive student support system, capture similar charts for new cohort of students - importance of assessments - students only do activity when specified in an assessment (as compared to just in the course) - students' reported enjoyment of different learning activities - when teaching online, use less text and more activities.            ",4,0,4,1
"663","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg argues for personalized learning Chan Zuckerberg Intiative's Personalized Learning Platform - algorithms provide users with content based on analysis of past behavior and demonsterated itnerset. Dangers of personalized learning: 1. Only feeding what learner is interested in compromizes goal of general knowledge. 2. When it is so personalized, lack of ability to compensate may mean they suffer in the real world. 3. Preferences are not fixed. Where personalized learning could help - sense of ownership and relevance - personalized assessments - E.g. AltSchool, community of microschools whose personalized learning experience involves collecting data about pupils' attainemnt, grades and memory test results and energy levels.",2,3,-1,2
"664","Chapter 1: Social Network Data","Social network methods Social network data Data structure: square array of measurements, where both rows and columns are cases/ observations. The cell describes the relationship between the actors.  Allows us to see which actors are similar to which, therefore helps us to see which actors have similar position in the network. (1) Where they are located or ""embedded"" in the overall network. Looking at data structure more holistically - e.g. ""density"" i.e. more 1s than 0s, cells above and below diagonal to see if there is reciprocity in choices. (2) how the whole pattern of individual choices gives rise to more holistic patterns. Conventional data focuses on actors and attributes. Network data focuses on actors and relations. Next sections - issues that arise in designm sampling and measurement Nodes Network studies are more likely to include all of actors who occur within some (usually nturally occuring) bounary. Often network studies don't use ""samples"", but include all actors in the population. In this sense, the population may have been selected by probability methods. Hence, it is important for analyst to be clear about boundaries of each population to be studied and how each unit is selected.  Types of boundaries - 1) imposed or created by actors themselves (i.e. who they are linked with, such as a club, neighborhood, classroom) = draw boundaries around a population that is known a priori to be a network, 2) demographic/ ecological appraoch e.g. people in a bounded spatial area or meet some income criterion, imposed by investigator.  Expansion of boundaries is done by replicating populations. Multi-modal - individual is embedded in networks that are embedded in networks that are embedded in networks. Edges All ties studied or different appraoches used that sample ties. When we collect network data, we are usually selecting from among a set of kinds of relations that we might have measured. - Full network methods - Snowball methods - Ego-centric networks (with alter connections) - Ego-centric networks (ego only) Multiple relations - in the most common type, only one kind of relation is described. Decisions on which relations to examine - conceptual appraoches may help e.g. systems theory. Note scales of measurement - nominal (binary and multi-categorical), ordinal, interval levels. Different approaches in SNA. Note: SNA is more a branch of mathematical sociology than of statistical analysis. Applications of statistic to social network data is ""cutting edge"" research - not covered in this article.",2,0,2,4
"665","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Case study: Introduction to Recommender Systems course on Coursera Coursera vs. on-campus for credit course using Coursera platform and flipped classroom instruction model. For ""knowledge gain"", main predictor was effort expended. For ""completion"", few factors had strong predictive power, main predictor was intent to complete. face-to-face tudents performed as well as the online-only students or better. Experiment design: - self-selection to enroll in MOOC and face-to-face means random assignment not possible. However, the rest held constant, and demographic data were used to ensure groups compared were similar in the relevant aspects. Measures: - Pre and post class surveys designed to measure students' backgroun, intentions with respect to the MOOC they are taking, and reactions to the MOOC expereince. - Knowledge test administered thrice, including one 5 months after the end of the course - to measure retention of subject matter knowledge. Results: - An exploratory PCA was conducted, and four factors were extracted. Eigenvalues &gt; 1 for all 15 individual items. 4 factors were underlying constructs: instructor, pragmatic, professional, interest. These constructs used to segment student population. - Completion - Logistic regression performed. Results = intention predicts completion; little else does. - Knowledge - Results = student knowledge increased. - face-to-face vs online-only: Using pre-test as a baseline, both groups were statistically equivalent in baseline knowledge. Compared the two groups in terms of normalized gains in knowledge achieved over semester. Nominal difference and low N compromises on statistical significance and external validity. - OLS that attempts to predict normalized knowledge gains, to understand factors that contribute to learning: baseline (-ve), concepts track, number of assignemtn completed (strongest), english proficiency (marginal). Unique part about this research: 1) offered in both MOOC online-only and face-to-face classroom allowed comparison, 2) mixed programming and non-programming students in a two-track course model, 3) extensive evaluation of student learning outcomes.        ",9,2,7,4
"666","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Developed an online innovative method to discover skill models from the data of online courses. Online courses have a pre-defined skill map (Q-matrix) - skills are associated with formative assesment items embedded throughout the online course. Developed an efficient, practical, and scalable method called eEPIPHANY to automatically discover skill sets from online course data, through correlations between student performance and assessment item text data. - input: matrix representing a chronological record of students’ responses to assessment items, called an A-matrix. - output: skill mode (Q-matrix) that produces the best prediction of the A-matrix. Find Q-matrix by itself or refine a given Q-matrix by 1) clustering assessment items with latent features that characterize similarity in the difficulty of assessment items, 2) proposing new skill model by assuming that cluster provides a hint for new skills, 3) search for best skill model. Feature extraction - Matrix factorization strategy - Bag-of-words strategy Findings: - Using student respondse data always yields a better skill model than using BoW strategy (and BoW &gt; those hand-crafted by human experts). - Matrix factorization strategy efficiently discovers a latent skill model from teh student learning ata. - ePIPHANY can find a better skill model automatically without human interaction.",15,0,15,5
"667","Developing a generalizable detector of when students game the system","Model students' changing knowledge state during skill acuqisition. Write short programs with the ACT programming tutor. As the student works, the ""tutor"" maintains an estiamte of the probability taht the student has learned each of the rules in the ideal model - knowledge tracing. Model is quite successful in predicting test performance.",4,0,4,3
"668","Principal Component Analysis explained visually","PCA used to eliminate dimensions.   Transforms variables to new variables called prcinciapl components (PC), and then drop those that contribute least to the variation in dependent variables.",0,0,0,5
"669","Measurement and its Uses in Learning Analytics"," the use of a learning analytics tool is always aligned with assessment regimes  which are in turn grounded in epistemological assumptions and pedagogical practices   deploying a given learning analytics tool expresses a commitment to a particular educational worldview  designed to nurture particular kinds of learners   Anderson (2008): new era; death of theory, models, and scientific method. No longer do we need to create theories about how the world works, because the data will tell us directly as we discern, in almost real time, the impacts of probes and changes we make Wise and Shaffer (2015): theory more important, not less, when so much data makes everything statistically significant. Epistemology-Assessment-Pedagogy triad Learning Analytics has potential to:  marginalize learners &amp; educators thru transofrmation of ed into technocratic system limit what we talk about as ""learning"" to what we can create analytics for exclude alternative ways of engaging in activites hard to track computationally to the detriment of learners   Six questions to ask  What are we measuring? How are we measuring? Why is this knowledge important to us? Who is the assessment for? Where does assessment happen? When does assessment/feedback occur?   ",4,4,0,2
"670","Ethics and Learning Analytics: Charting the (Un)Charted"," Ethics of Learning Analytics important to consider as field matures the future of learning will be digital, distributed, and data-driven such that education ""enables quality of life and meaningful employment through  exceptional quality research sophisticated data collection advanced machine learning and human learning analysis/support   Ethical implications around the collection, analysis, and use of student data should take cognizance of the potentially conflicting interests and claims of a range of stakeholders Eight principles:  LA is an ethical practice &amp; should align with core principles like open entry to undergraduate level study responsiblity to all stakeholders students should not be wholly defined by visible data (stereotyping) boundaries of LA need to be well defined transparent about data collection interventions free from bias broad acceptance of values and benefits   ",4,2,2,2
"671","Predictive Modelling in Teaching and Learning"," In both EDM and LA, predictive modelling has become a core practice of researchers  largely with the focus on predicting student success as operationalized by academic achievement   Predictive analytics are a group of techniques used to make inferences about uncertain future events In education, might be interested in predicting:  measurement of learning teaching impact of a given style retention   predictive vs explanatory modelling Explanatory:  goal is to use all avail evidence to provide explanation for outcome (t-tests, avgs) eg observations of age, gender, and socioeconomic status of learner population might be used in regression model to explain how they contribute to a given student achievement result intent is to be causal (vs correlative)   Predictive:  goal is to create a model that will predict the values (or class if not numeric) of new data based on observations based on assumption that a set of known data (training data) can be used to predict the value or class of new data based on observed variables   classification: predict categorical values regression: predict numeric values applying an algorithm that assumes independence can result in predictions with an over-emphasis on repeated or correlated features (eg attendance and # questions asked in class are not independent) Linear regression - predicts a continuous numeric output from a linear combination of attributes Logistic regression - predicts the odds of two or more outcomes, allowing for categorical predictions Nearest Neighbors classifiers - use only the closest labelled data points in the training dataset to determine appropriate predicted labels for new data Decision Trees - repeated partitions of the data based on a series of single attribute ""tests."" Each test chosen algorithmically to maximize purity of classifications Naive Bayes Classifiers - assume the statistical independece of each attribute given the classification, and provide probabilistic interpretations of classifications Bayesian Networks - manually constructed graphical models Support Vector Machines - use a high dimensional data projection in order to find a hyperplane of greatest separation btwn various classes Neural Networks - propagate data input through a series of interconnected layers Ensemble Methods: voting pool ",3,6,-3,3
"672","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data"," Majority of EDM research has focused on achieving predictive accuracy  argue for more focus on explanatory models   less commonly, models may be validated by their ability to predict post-test outcomes explanatory models can be connected to theory  focus on why the model fit the data rather than only that it does fit   EDM research focused on two types of models  statistical drive the outer loop of intelligent tutoring systems cognitive are representations of the knowledge space; Q-matrix   Learning Factor Analysis (LFA) - automates the data-driven method of KC model refinement to alleviate demands on human time  SimStudent discovers cognitive models w/o requiring existing ones SimStudent generated model better fit actual student performance data than human generated model SimStudent found that Ax = B was easier to understand than -x=A and split these problems into two subsets whereas humans taught them together   ",2,2,0,5
"673","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)"," In statistics, graphics are typically thought of as a way to help with simple tasks such as data cleaning and exploration, before getting to the serious task of inference outside of statistics, data graphics have become hugely popular, with innovative visualizations appearing regularly on the web and in the New York Times On the statistical side, data analysts and statisticians are interested in finding effective and precise ways of representing data, whether raw data, statistics or model analyses  graphics should enable readers to make up their own minds on any conclusions drawn, and possibly see more   the Infovis approach uses the data to draw attention to wider issues With presentation graphics you prepare some small number of graphs, which may be viewed by thousands with exploratory graphics you prepare thousands of graphs, which are viewed by one person, yourself ",2,0,2,2
"674","Junkcharts Trifecta Checkup: The Definitive Guide"," The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?   Ideally, the results of all three investigations are one and the same. ",1,0,1,2
"675","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8 This study examined longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188)  demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators   An emerging line of research has begun to ask why teacher-assigned grades are predictive of overall student outcomes, but are a weak indicator of academic knowledge when compared to standardized test scores  Termed “hodge-podge” or “kitchen sink” grading, surveys of teachers have repeatedly found that teachers award students grades for a variety of factors, including academic knowledge, attendance, participation, and behavior    much of the past research has focused on using logistic regression to predict the likelihood of dropping out of school given if a student has failed a core course  this issue returns to the problem of reducing the rich set of data represented by individual student achievement trends to aggregated means and fitted regression slope equations that are generalizable to the population, but less useful for making data driven decisions for individual students and schools.   Known as hierarchical cluster analysis (HCA), this multivariate statistical method uses a series of nested correlation calculations, or distance measures, to reorder a dataset  a means to analyze all of the data without aggregating the data, displaying each individual’s information patterned and displayed in a way that allows for interpretation of large longitudinal datasets   The combination of the cluster analysis, cluster tree, and heatmap, creates the clustergram This study has come to a rather obvious finding; students with generally low grades throughout their career in school drop out. ",3,5,-2,3
"676","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research"," Social interactions between students are a major and underexplored part of undergraduate education. Social network analysis (SNA) provides the necessary tool kit for investigatingquestions involving relational data Network analysis entails two broad classes of hypotheses:   those that seek to understand what influences the formation of relational ties have in a given population (e.g., having the same major, having relational partners in common those that consider the influencet hat the structure of ties has on shaping outcomes, at either the individual level (e.g., grade point average [GPA] or socio economic status) or the population level (e.g., graduation rates or retention in science, technology, engineering, and mathematics [STEM] disciplines)   Recent research in physics education has found that a student’s position within communication and interaction networks is correlated with his or her performance example from a subset of a 10-wk introductory biology course with 187 students who saw the course to completion. Networks that consist of only one type of actor (e.g., students) are referred to as unipartite a bipartite network could link scholars to papers they authored or students to classes they took, differing from a unipartite network, which would link author to author or student to student There does not seem to be any strong visual evidence for an association between classroom performance and number of study partners. Network changes over time ",1,0,1,4
"677","Why Students Should Own Their Educational Data"," Designing a textbook or lecture with the average student in mind means it is designed for nobody for a student with affinity for science but low reading score, science class is first and foremost a reading test due to reliance on textbooks; doubtful that student will ever show true capabilities technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual. For 150 years, we’ve thought we could understand individuals by studying groups of people and patterns in the population  we look for statistical patterns in the people. but it turns out that much to our chagrin, we know now that you can’t actually tell anything in population studies about any individual in that group You had to draw inferences about a population from a sample because you couldn’t get the population data.   It’s not that everyone’s a snowflake — I mean, that’s probably true at some level, but it’s not particularly helpful  We’re looking for personal patterns across what we call dimensions.   So let’s say there are five things that really matter for how well you’ll do in algebra, like working memory is a predictor. But it’s how you vary across those, the jagged profile, that is really important to know Your personality or your traits, they’re not actually stable  We could say, “You’re a Type A person,” or “You’re aggressive,” or whatever. But it turns out it’s just not true It turns out what’s really stable is, say, your personality in the lunchroom at work. Your aggression level, how easygoing you are in the lunchroom doesn’t tell us a lot about how you’ll be in a classroom, believe it or not Say you tend to be highly aggressive in classrooms where it’s new information and you have a male teacher. It’s that level of information. If we know that. That kind of data has been shown to be predictive of your behavior up to 10 years out   What we need to know about you is your contextualized profile of your performance and what kind of support you’ll need to be able to model your learner profile across contexts. If I had to push for one thing that I think is super important, that is that the user should own their data My vision that we’re going to push for in my organization is you’ve got to have a third party who is responsible for protecting learner data ",9,2,7,2
"678","Knowledge tracing: Modeling the acquisition of procedural knowledge"," all students can achieve expertise in a domain if two conditions are met:  (1) the domain knowledge is appropriately analyzed into a hierarchy of component skills (2) learning experiences are structured to ensure that students master prerequisite skills before tackling higher level skills in the hierarchy.   Each tutor is constructed around a cognitive model of the underlying skill that allows the tutor to solve the exercises along with the student and provide feedback on student actions. These tutors have proven to be effective learning environments; students can work through a fixed set of exercises in substantially less time than students working on their own and score as well or better on posttests ACT-R theory assumes declarative knowledge different than procedural  Example of declarative: The Lisp function car takes one list as an argument and retums the first ele- ment. ACT-R assumes that skill knowledge is encoded initially in declarative form through experiences such as reading   ",11,0,11,3
"679","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration"," Educational Data Mining (EDM) vs. Learning Analytics and Knowledge (LAK).  EDM = 2005 origin lLAK = 2010 origin   EDM: “Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.” LAK: "" “... the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.” LAK and EDM share the goals of improving education by improving assessment, how problems in education are understood, and how interventions are planned and selected EDM has a considerably greater focus on automated discovery  EDM research which leverages human judgment in many cases does so to provide labels for classification, EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. reduces phenomena to components and analyzing individual components and relationships between them.   LAK has a considerably greater focus on leveraging human judgment.  LAK research which uses automated discovery often does so in the service of informing humans who make final decisions LAK models are more often designed to inform and empower instructors and learners place a stronger emphasis on attempting to understand systems as wholes, in their full complexity     ",2,3,-1,2
"680","Evaluating Machine Learning Models"," Different machine learning tasks have different performance metrics. Examples of performance metrics for various tasks include: If I build a classifier to detect spam emails versus normal emails, then I can use classification performance metrics such as  average accuracy log-loss area under the curve (AUC).   If I’m trying to predict a numeric score, such as Apple’s daily stock price, then I might consider the root-mean-square error (RMSE). If I am ranking items by relevance to a query submitted to a search engine, then there are ranking losses such as precision-recall (also popular as a classification metric) or normalized discounted cumulative gain (NDCG).  ",2,2,0,5
"681","Saturday Morning Breakfast Cereal"," 90% of elite engineers played with clocks as children New education programs must now have clock assembly programs and tests Cancelled art class for clock repair Other countries assemble clocks better Scientists determine that:  great engineers liked clocks as kids not: children who like clocks become great engineers   But now training is in motion and unstoppable   ",5,0,5,2
"682","Data wranglers: human interpreters to help close the feedback loop"," Closing feedback loop = best practice for LA human data wranglers make sense of data at Open University related to learning  data analyzed in light of their understanding of individual departments reports summarize action &amp; key points   supports the value of human meaning-makers in the LA process suggests barriers to organizational change can be mitigated by embedding LA work within strategic contexts and working at appropriate levels of analysis feedback loop of LA  actionable intelligence produced from data about learners and their context interventions made to improve learning   Sophisticated educational data mining tools are often hard for non-specialiststo use and interpret need for multidisciplinary teams, with a key role played by humans in interpreting the data sense-making and social processes are importantbecauseof the complexity of the dataand because “learning is a complex social activity”. so far as possible the Data Wranglers are selected to have an academic background close to the Faculty they are working with work with four main data sources:  survey feedback at end of course Moodle data data about mode of delivery pass rate &amp; demographic data   data from these sources aggregated using SAS data warehouse  exported to Tableu workbook for each faculty   ",6,3,3,1
"683","Zuckerberg is ploughing billions into 'personalised learning' – why?"," Many in education would argue that personalised learning is what all good teachers do as a matter of course – modifying learning materials and teaching styles to accommodate the different ways pupils learn Others see it as an antidote to top-down, centralised school bureaucracy, with the term “personalised” used interchangeably with individual, learner-centered or customised.From Facebook outside link: Technology in personalized learning enables teachers and students to create personal learning plans, track progress and find materials to help them learn best. When technology is tailored to students' needs, it frees up time for teachers to do what they do best -- mentor students. Summit Public Schools has been a pioneer in personalized learning. Zuckerberg’s idea of personalised learning has three major flaws.  First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. Finally, children’s preferences are not fixed; To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher   AltSchool is a community of micro-schools whose personalised learning experience involves collecting data about pupils’ attainment, grades and also memory test results and energy levels. This data is crunched together with the pupil’s interests and preferences to tailor the content. Other organisations combine user data with standard educational content, for example adaptive course-ware platforms such as those from Smart Sparrow or Pearson. Personalised learning by McGraw Hill allows educators to choose between the adaptive or customized study plans.  The former adapts all topics to a learners’ pace, while the latter provides a course modified according to the teacher’s knowledge of what fits the students best.   personalised learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment could be a very powerful combination. ",12,4,8,2
"684","Feature Selection"," If I track 1000 features, maybe only 10 of them matter Feature selection good for  interpretability insight   Curse of dimensionality = amount of data you need grows exponentially with number of features you have ",1,0,1,1
"685","Chapter 1: Social Network Data"," The fundamental data structure is one that leads us to compare how actors are similar or dissimilar to each other across attributes (by comparing rows) Or, perhaps more commonly, we examine how variables are similar or dissimilar to each other in their distributions across actors (by comparing or correlating columns) ""Network"" data:   The rows of the array are the cases, or subjects, or observations. The columns of the array are -- and note the key difference from conventional data -- the same set of cases, subjects, or observations     The major difference between conventional and network data is that conventional data focuses on actors and attributes; network data focus on actors and relations Network data are defined by actors and by relations (or ""nodes"" and ""edges""). Most commonly, network analysts will identify some population and conduct a census (i.e. include all elements of the population as units of observation)   A network analyst might examine all of the nouns and objects occurring in a text, all of the persons at a birthday party   To the extent the observations used in a network analysis are drawn by probability sampling methods from some identifyable population of actors and/or ties, the same kind of question about the generalizability of sample results applies   no interest in generalizing to a larger population of such networks (either because there isn't any such population, or we don't care about generalizing to it in any probabilistic way   The other major use of inferential statistics in the social sciences is for testing hypotheses ",1,1,0,4
"686","RStudio Cheat Sheets"," .Rmd file = R Markdown knit to create report publish using shiny app     ",0,0,0,1
"687","Translating Learning into Numbers: A Generic Framework for Learning Analytics"," Plethora of data from:  web2.0 = Twitter, Flickr, YouTube, etc Sensor data = GPS location etc   ""data economy"" empowers companies to offer products at little or no cost to users (bit.ly URL, Yahoo Pipes, Gapminder.com) data mining not a separate act to normal user behavior more comparable to observational data gathering than intrusive collection via direct methods Issues related to data ownership and openness, ethical use and dangers of abuse, demand for new key competences proposed framework for LA has 6 dimensions  stakeholders objectives data instruments external constraints internal limitations   Not yet clear to what extent LA will lead to more personalized learning experiences rather than merely clustering people into behavioristic ""learner models"" Need more evidence for best padagocig LA theory  has been effectively used for behaviorist-instructivist style approaches need more evidence for constructivist approaches where learning is seen as an active cognitive process in which learner construct their own concepts of the world around them In LA, the latter is inferred by relating grades with activities during learning process Active students get better results   ",5,4,1,1
"688","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC"," offered an open online Introduction to Recommender Systems through Coursera,while simultaneously offering a for-credit version of the course on-campus using the Coursera platform Student completion of the course was hard to predict, with few factors contributing predictive power  the main predictor of completion was intent to complete   Students had significant knowledge gains across all levels of prior knowledge and across all demographiccategories. The main predictor of knowledge gain was effort expended in the course. Studentswho chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments  though the program-ming students gained additional programming knowledge.   face-to-face students performed as well as the online-only students or better While much early MOOC evaluation focused on very low rates of full course completion, as we improve our understanding of the reasons for which students take MOOCs, it becomes imperative to attend to the notion that “success” might be relative to the individual   ",7,1,6,4
"689","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Sample Note Yay!!",1,0,1,4
"690","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement"," How can we automatically determine which skills must be mastered for the successful completion of an online course? This method (eEPIPHANY) carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts  assumes that online courses have a predefined skill map for which skills are associated with formative assessment items embedded throughout the online course   The most important goal of eEPIPHANY is to provide constructive feedback to online course designers and developers for iterative course improvement. Q-matrix = skill map The primary input to eEPIPHANY is a matrix representing a chronological record of students’ responses to assessment items, called an A-matrix The goal of eEPIPHANY is to find a skill model (Q-matrix) that produces the best prediction of the A-matrix Matrix Factorization (MF) strategy.  Bag-of-Words (BoW) strategy.  the ""replace"" strategy always discovers the best skill model in our study  Matrix Factorization strategy efficiently discovers a latent skill model from the student learning data. On the other hand, the split strategy always resulted in producing an inferior skill model in our study; suggesting that the split strategy hardly improves on the human-crafted skill.   ",17,5,12,5
"691","Big Data in Education"," Watching these videos prior to reading Matsuden (2015) would have helped me better understand the paper Q-matrix = table where:  rows are items columns are skills   Automatic item discovery:  learn the mapping btwn items and skills soley from data linear algebra if n skills worked, try n+1 until not working   Human item discovery  if you treat geometry as a single skill, not a smooth learning curve if you break into 12 skills, better results   ",9,1,8,5
"692","Cross Validation"," Cross validation = apply machine learning model to training set and then validate accuracy with a test set Linear regression might be under-fitting the data  use higher order polynomial   Training set and test set are both representative of the real world   ",0,1,-1,5
"693","Hands-On Programming with R"," Ch. 1 Objects and functions can be written in scripts R Studio is interface for R language Ch. 2 install.packackes() to install ggplot2 a package for visualizations ? to bring up help page ?? to search for help keywords Ch. 3 atomic vector = one type of data  doubles, integers, characters, logicals, complex, and raw.   dim() to check dimensions of data matrix = 2d array array() creates n-dimensional array factors store categorical info coercion - transforms to simplest type ",1,4,-3,1
"694","Principal Component Analysis explained visually"," PCA is useful for eliminating dimensions. With three dimensions, PCA is more useful, because it's hard to see through a cloud of data The PCA transformation ensures that the horizontal axis PC1 has the most variation, the vertical axis PC2 the second-most, and a third axis PC3 the least.  Obviously, PC3 is the one we drop.   ",1,2,-1,2
"695","Measurement and its Uses in Learning Analytics","Learning Analytics is Measurement, but not all measurement is Learning Analytics. Learning analytics, as I understand, utilizes advances in computational and professional tools to advance the goals of stakeholders, most frequently teachers. The thing is, teachers don't catch everything, and the implementation of LA promises to address that... assuming they have the technical know how to use LA to capture that knowledge. This article seems to get at the tension of assessment and accurate data capture.",0,1,-1,2
"696","Ethics and Learning Analytics: Charting the (Un)Charted","I'm not meaningfully convinced that an ethical framework will necessarily improve practices within learning analytics; such frameworks frequently work to ensure that the status quo is not disrupted for power holders. The impression I got of the Learning Analytics suggestions seemed to be ones that would absolve the data scientist/researcher/engineer of guilt rather than any real framework. Instead, I would rather view data science practices, and those specific to learning analytices, as arising from their inherently political nature. Our goals are political, and thus our methods should reflect that intentionality.",2,2,0,1
"697","Predictive Modelling in Teaching and Learning","Predictive modeling is perhaps the holy grail of learning analytics, but it subsumes so many systemic factors, with truly siloed data. I think that predictive modeling here is missing a sort of ""secret sauce"" for understanding the pressures that students and educators might be under when they're asked to share their data for analytics purposes. It can seem a bit robotic.",0,1,-1,2
"698","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","It can be really difficult to parse out meaning using K-Means, PCA, or other modeling tools that characterize user behaviors",0,1,-1,5
"699","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","It's nice to read something that at least offers a cogent alternative to Tufte. It has been frustrating to conform to a system of remarkably limited values as it pertains to data representation.  ",1,1,0,1
"700","Junkcharts Trifecta Checkup: The Definitive Guide","Oh god, something easier to understand than tufte. This is great. 3 questions, and no Data:ink ratio.",2,0,2,2
"701","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This provided a really pragmatic example wherein cluster modeling supported instruction for a following school year. However, I always want to be conscientious of data selection and design when building a model that accords a label to a particular student.",1,0,1,3
"702","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","I really like SNA as a starting point for evaluating a population based on commonly held characteristics. I would like to learn more about the quantitative reasoning that underlies an SNA and apply it to digital learning models.",2,0,2,4
"703","Why Students Should Own Their Educational Data","MOOC's present us with a new avenue of data collection, but I appreciate his concession that user's have little access to, or knowledge of, the data that is collected on them whenever we utilize one of their services. It seems to me that provider's of online services, be they moocs or apps, lure users with the promises of convenience and ease of use. I'm personally surprised by his suggestion of third party protections of user data.",1,1,0,2
"704","Knowledge tracing: Modeling the acquisition of procedural knowledge","I couldn't access the article, but the abstract made it sound like probability tracing is likely a much better tree model than the CART algorithm we used last week. This is aligned with what we learned about ROC curves and understanding the point at which we start to lose predictive strength as a result of a high/low margin for prediction.",3,1,2,3
"705","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","I actually read this article in the buildup to making my decision to seek out a degree in learning analytics. While getting a concentrated dosage of what constitutes LaK has been deeply interesting, I am more deeply interested in having both a theoretical and technical know how necessary to be successful in the field. I would like to see how EDM is applied in the field, and if there are things I need to be doing in order to catch up to computer scientists that may not necessarily have the content background to root the work in the political mission of education.",4,0,4,2
"706","Evaluating Machine Learning Models","I didn't do the reading: to do so required that I give up my e-mail and picture for a free account. If nothing else, this program has made me more paranoid about providing that information.",1,1,0,2
"707","Why Opting Out of Student Data Collection Isn’t the Solution","I appreciate the idea that data is just a fundamental part of modern education, and that opt-out rights should really be focused on the frivolous data collection that frequently characterizes the industry.",2,0,2,2
"708","Saturday Morning Breakfast Cereal","Yup. We follow trends dog-sightedly, destroy extsiting systems in the process, and are shocked when our disruptions generate negligible gains. Education isn't like tech, and the ""disrupt"" ""breaking things"" mantra that so many developers shout is not meaningful in any sense.",2,5,-3,2
"709","Data wranglers: human interpreters to help close the feedback loop","Key goal is the generation of ""actionable intelligence"" First step is the generation of ""sense"" that allows non-specialists to access conclusions from learner data Academic staff may have an adversarial attitude towards academic metric use. Sustaining a community of practice is pivotal. Data wrangling is fundamental in this sense- thy both gather and make sense of the data before turning that analysis into actionable recommendations. Data wranglers must also work to create conditions where academics and instructors have the data literacy to service learning goals.    ",3,0,3,1
"710","Zuckerberg is ploughing billions into 'personalised learning' – why?","Okayyy, I get the author's point, but a lot of those conversations won't take place without funding, and research into these technologies is crazy stupid expensive in terms of research length, financial expenses, and diversification.",0,1,-1,2
"711","Feature Selection","Feature selection is crazy important in this field. It is great for helping me keep the whole ""lets use as many variables"" approach to a bare minimum. It's a bit too easy to turn to that, without running into the whole curse of dimensionality.",1,0,1,2
"712","Chapter 1: Social Network Data","Every text I've read on LA and Data Science seems pretty grounded in explaining the dangers of LA, as well as its limitations. But this one at least formalizes the timeline of an LA product and ensure that designers at least can shape their development timeline in accordance with principles that arise from government policy and student/educator rights. It should be required reading.",1,2,-1,2
"713","RStudio Cheat Sheets","This page is my bible when looking up cheats for activities and assignments. It rocks.",0,1,-1,2
"714","Translating Learning into Numbers: A Generic Framework for Learning Analytics","It feels like I'm reading the same article twice. These are the same 6 principles I read in another article, and I feel somewhat weirded out by it.",1,1,0,2
"715","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","I couldn't access the full article, but the sense I got from the abstract made it seem that the online only students did not outperform their traditionally taught peers. That said, they were more statisfied with the flexibility afforded to them by having both online and face-to-face instruction.",2,0,2,4
"716","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Looks like the main focus of this paper was the use of clustering models to generate ""skill trees"" for online courses based on words used and types of responses. They used a Q-Matrix generated from a response matrix to build their skill trees and applied a Bayesian trace indicator to test for its accuracy. Seemed pretty cool... if I knew half of what those things were.",4,0,4,5
"717","Big Data in Education","Clustering is a great tool for feature selection and structure discovery. I've used K-Modes frequently since we learned of them, and I was hoping to use them in a project at Sesame to characterize the quality of our games on the basis of game completion. I also like the idea of penalizing more clusters, just as you would penalize multiple statistical tests that find significance by doing post-hoc testing.",2,0,2,1
"718","Cross Validation","What a appreciate here is that we are forced to reckon with the fact that both the test set and the training set represent the future. I think test set design in particular is frustrating, and it can feel irritating to have to redo training if someone finds your model to be unreliable. But in this work, cross validation is how you defend the quality of your research, and it certainly beats post hoc testing.",1,2,-1,5
"719","Hands-On Programming with R","This is a note on a text I have already read.",0,0,0,5
"720","Principal Component Analysis explained visually","So a principle component is some combination of dimensions that captures the makeup of behavior within a model. So, theoretically, you could use PCA to identify groups of variables that account for variation meaningfully.",0,0,0,3
"721","Why Students Should Own Their Educational Data","""We’re looking for personal patterns across what we call dimensions."" ""you’ve got to have a third party who is responsible for protecting learner data"" ""education is decidedly not a functional market right now. There’s not enough transparency.""",3,0,3,2
"722","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","“Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.” Learning Analytics as: “… the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.” ""Both communities have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education."" ""EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment."" ""EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners.""",2,1,1,2
"723","Why Is Measuring Learning So Difficult?","""Learning is multidimensional, we have to simplify learning too much to capture data to understand something."" ""Learning Analytic: Should reveal to the learner what kind of connections he/she is making that they are not aware of.""",0,0,0,1
"724","Saturday Morning Breakfast Cereal","Clock Yeah!",0,0,0,2
"725","The Data Wrangling Cheatsheet","Favorite: dplyr::mutate(iris, sepal = Sepal.Length + Sepal. Width) Compute and append one or more new columns.",1,0,1,1
"726","Data wranglers: human interpreters to help close the feedback loop","""students and teachers are closest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact.""",2,0,2,1
"727","RStudio Cheat Sheets","""The R Markdown cheat sheet is a quick reference guide for writing reports with R Markdown.w""",0,1,-1,1
"728","Translating Learning into Numbers: A Generic Framework for Learning Analytics","""It is expected that personalised learning has the potential to reduce delivery costs while at the same time creating more effective learning experiences, accelerating competence development, and increasing collaboration between learners."" ""The fundamental question legislators need to ask is: who does a person’s life data belong to?"" ""provides a tool for HEIs, companies, or governments to increase manipulative control over students, employees, and citizens, thereby abusing LA as a means to reinforce segregation, peer pressure, and conformism rather than to help construct a needs-driven learning society."" ""LA processes that data can be interpreted in many ways and lead to very different consequent actions. To give a drastic example, imagine being confronted with the insight that children from an immigrant background show reading difficulties, backed by supportive data analysis. This may lead to a wide ranging variety of responses, from developing extracurricular support mechanisms, to segregated classes, up to bluntly racist abuse of various kinds."" ""In a recent survey we conducted among LA experts, only 21% of the 111 respondents felt that learners would possess the required competences to interpret LA results themselves and determine appropriate actions/interventions from it"" ""To judge a learner’s performance merely on, e.g., LMS quantitative data is like looking at a single puzzle piece.""",5,5,0,1
"729","Measurement and its Uses in Learning Analytics","""It can be said that psychological measurement comprises the following: defining a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome.""",0,2,-2,5
"730","Ethics and Learning Analytics: Charting the (Un)Charted","“The University will not engage in Learning Analyticspractices that use data sources: (a) not directlyrelated to learning and teaching; and/or (b) whereusers may not reasonably expect such data collectionby the University to occur” ""Sclater, Peasgood, and Mullan (2016), for example, review practices within higher education in the United States, Australia, and the United Kingdom. They summarize their findings by indicating that learning analytics makes significant contributions for 1) quality assurance and quality improvement; 2) boosting retention rates; 3) assessing and acting upon differential outcomes among the student population; and 4) the development and introduction of adaptive learning. The report acknowledges the many opportunities, but also highlights threats such as “ethical and data privacy issues, ‘over-analysis’ and the lack of generalizability of the results, possibilities for misclassification of patterns, and contradictory findings”.""",2,3,-1,2
"731","Measurement and its Uses in Learning Analytics","Psychological measurement instruments are typically called tests or questionnaires (also surveys and inventories). Validity refers to the degree to which evidence and theory support the interpretations of test scores for proposed uses of tests",1,0,1,5
"732","Ethics and Learning Analytics: Charting the (Un)Charted","The future of learning will be digital, distributed, and data-driven such that education ""enables quality of life and meaningful employment through exceptional quality research; sophisticated data collection and; advances machine learning  and human learning analysis/ support"". 1) Learning analytics as moral practice. 2)Students as agents. 3)Student identity and performance as temporal dynamic constructs. 4)Student success as a complex phenomenon.5)Transparency as important . 6)That higher education cannot afford not to use data.",3,1,2,2
"733","Predictive Modelling in Teaching and Learning","Explanatory modelling is a post-hoc and reflective activity aimed at generating an understanding of a phenomenon. Predictive modeling is an in situ activity intended to make systems responsive to changes in the underlying data. Noisy data occurs when a measurement fails to capture the intended data accurately",0,1,-1,3
"734","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Cognitive models map knowledge components (i.e., concepts, skills, and facts; to problem steps or tasks on which student performance can be observed.",0,1,-1,5
"735","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Tukey (1993): 1. Graphics are for the qualitative/descriptive—conceivably the semiquantitative—never for the carefully quantitative (tables do that better). 2. Graphics are for comparison—comparison of one kind or another—not for access to individual amounts. 3. Graphics are for impact—interocular impact if possible, swinging-finger impact if that is the best one can do, or impact for the unexpected as a minimum—but almost never for something that has to be worked at hard to be perceived. 4. Finally, graphics should report the results of careful data analysis—rather than be an attempt to replace it.",3,1,2,2
"736","Junkcharts Trifecta Checkup: The Definitive Guide"," Junk Charts Trifecta Checkup:  What is the QUESTION? What does the DATA say? What does the VISUAL say? ",0,1,-1,2
"737","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Much of the research on 3DM(Data driven decision making) has identified the practice of creating dialogue around student standardized test scores, which has been shown to increase professional communities of practice in schools, help teachers adjust to changing school needs, and allow school and district leaders to direct the limited resources of a school district to the instructional issues most relevant for their teachers",0,1,-1,3
"738","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","SNA aims to understand the determinants, structure, and consequences of relationships between actors. Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. ",0,0,0,4
"739","Knowledge tracing: Modeling the acquisition of procedural knowledge","Promise of mastery learning: (1) the domain knowledge is appropriately analyzed into a hierarchy of component skills and (2) learning experiences are structured to ensure that students master prerequisite skills before tackling higher level skills in the hierarchy. ",4,0,4,3
"740","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","LAK: Leveraging human judgement is key; automated discovery is a tool to accomplish this goal. ex. inform and empower instructors and learners  EDM: Automated discovery is key; leveraging human judgment is a tool to accomplish this goa. ex. intelligent tutoring system     ",2,0,2,2
"741","Data wranglers: human interpreters to help close the feedback loop","Main data source:  Survey feedback data from students, gathered at the end of their course. Activity data from the VLE/LMS (Moodle). Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums). Aggregated completion, pass rate and demographic data. ",0,0,0,1
"742","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg: personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”.",0,0,0,2
"743","Chapter 1: Social Network Data","Social network analysts rarely draw samples in their work. Most commonly, network analysts will identify some population and conduct a census (i.e. include all elements of the population as units of observation). ",1,0,1,4
"744","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The six dimensions of the proposed LA framework are: stakeholders, objectives, data, instruments, external constraints, and internal limitations.",0,1,-1,1
"745","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","LensKit is an open-source recommender toolkit developed specifically to support experimentation.",2,0,2,1
"746","Measurement and its Uses in Learning Analytics","two opinions for theoryAnderson: no longer do we need to create theories about how the world works.Wise and Shaffer: theory is more important in interpreting results.(data archeology/data geology) educators and learners: data gathering, analysis, interpretation, and intervention is no longer the preserve of the research, but shifts to embedded sociotechnical educational infrastructure. ethical dilemmas:""wicked problems"" and complex adaptive systems. drive the new horsepower: to accelerate innovation and improve evidence-based decision-making. learning analytics are incarnation of an algorithmically pervaded society. assessment and pedagogy are built on the foundation of epistemology relationship: learning analytics support educational practices or challenge education education. Epistemology-what are we measuring: encourages us to consider our learning design, the skills and facts we want our students to learn. Epistemology-how are we measuring: assess to the knowledge. pedagogy-why is this knowledge important to us:debates around the kind of important knowledge and the role of knowledge-based curricula. pedagogy-who is assessment/analytic for: 1. individual students in developing their learning 2. educators in developing their own practice 3. administrators in understanding their organizational needs.this question causes two concerns:1. create new divides between student cohorts 2. ethical concern regarding the use of student data. assessment-where does the assessment happen: in a physical location. assessment-when does the assessment, and feedback, occur: consideration of whether or not a particular technology provides after-the-fact or real-time feedback.  ",3,4,-1,2
"747","Ethics and Learning Analytics: Charting the (Un)Charted","Slade and Prinsloo estabilished one of the earliest framworks developed with a focus on ethics in learning analytics. why ethics is relevant: potential economic benefits resulting from increasing data harvesting. Ethical implications should take cognizance of the potentially conflicting interests and claims of a range of stakeholders. ethical issues: 1. the location and interpretation of data. 2. informed consent, privacy, and the de-identification of data. 3. the management, classification, and storage of data. Slade and Prinsloo proposed a framework based on six principles: 1. learning analytics are moreal practice 2. students as agents 3. student performance as temporal constructs 4. student success as a complex phenomenon. 5. transparency 6. the higher education cannot afford not to use data. ---supported by practical consideration recent developments in ethical frameworks: attempts in different geopolitical and institutional contexts. Welsh and Mckinney: relative immaturity of the discipline. Deachsler and Greller: broad overview of ethics, privacy, and frameworks, and challenges. Sclater: taxonomy of ethical, legal, and logistical. Engelfriet etal: protection of personal information.  Future considerations: 1. conflicts between students' concerns, right to opt-out and institution use student information. 2. ethical research 3. concern balancing optimism around AI, machine learning and big data.  ",7,6,1,2
"748","Predictive Modelling in Teaching and Learning","predictive analytics are a group of techniques used to make inferences about uncertain future events. Compare:explanatory modelling: to use all available evidence to provide an explanation for a given outcome. Does not aim to make any claims about the future.A post-hoc and reflective activity aimed at generating an understanding of a phenomenon. All of the data collected from a sample is used to describe a population more genereally.predictive modelling: to create a model that will predict the values of new data based on observations. Does aim to make claims about the futures. situ activity intended to make systems responsive to changes in the underlying data. Protect against the overfitting of models to data being used for training. 4 types of data considered in statistical modelling: categorical, ordinal(categorical), interval(numeric), and ratio(numeric). missing values: 1. replace missing value with ""normal"" value 2. fill in missing values in records by finding other similar records in the dataset. Methods for building predictive models: 1. linear regression 2. logistic regression 3. nearest neighbours classifiers 4. decision tree 5. naive bayes classifiers 6. bayesian networks 7. support vector machines 8. neural networks 9. ensemble methods.",2,6,-4,3
"749","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","two types of models: 1. statistical model 2. cognitive model statistical model:drive the outer loop of intelligent tutoring system based on observable features of students' performance as they learn.cognitive model:representations of the knowledge space underlying a particular educational domain. it's a important basis for the instructional design and accurate assessment. method for cognitive model refinement iterates: 1. inspect curve visualization 2. identify KCs(knowledge component) 3. re-fit the AFM learning factors analysis automate the data-driven method of KC model refinement to further alleviate demands on human time. Different structure from the original dataset, it would not have been viable to apply directly the LFA-discovered KC mdoel on this new dataset. state-of-the-art machine-learning agent, SimStudent, to discover cognitive models. Benefit is can simulate features of novices' learning reajectories. SimStudent can be used to test alternative models of human learning to see which best predicts human behaviour. other model, ""human-in-the-loop"" component like Ordinal SPARFA-Tag yielded more interpretable cognitive models than many alternative methods.",3,0,3,5
"750","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","purpose of the present article is to start a conversation between practitioners in statistical graphics and information visualization. graphical communication of data and models are important part of statistical practice and theory. two group:1. statistical side, find effective ways of representing data, graphics enable readers to make up their own mind on any conclusion. 2. Infovis side, provide contextual information and try to tell a story goals for graphics:Discovery goals: 1. giving a qualitative sense of dataset 2. conveying the sense of the scale and complexity of a dataset 3. flexible displays to discover unexpected aspects of the data.Communication goals: 1. communication to self and others 2. telling a story 3. attracting attention and stimulating interest 5 best data visualization projects of the year: 1. wordle 2. decision tree 3. radiohead music video 4. box office streamgraphs 5. britain from above problem of infographics: 1. plane crashes 2. Florence Nightingale's coxcomb: should prefer simple time-series plots 3. health spending and life expectancy: scatterplot more transparently and informatively 4. How to win in Afghanistan: no sense of priorities difference between statistical and infovis: 1. statistical prefer to use standard well-tried tools; infovis places high value on creativity 2. statisticians assume their viewers are already interested; infovis want to draw attention to their graphics, and as a door opener for the graphics  ",4,4,0,2
"751","Junkcharts Trifecta Checkup: The Definitive Guide","Junk charts Trifecta Checkup: framework for data visualization criticism. Question: project needs a worthy cause.Data: relevant to the question being addressedVisual: represent the Data in a clear manner, addressing the question directly 8 types of critiques:1. the trifecta: everything is in sync, no weaknesses for chart2. Type Q: poorly defined objective, or an unengaging premise make the effort fail.3. Type D: the data fail to illuminate the question4. Type V: the visual design confused the message5. Type QD: poor data quality, and an unclear objective6. Type QV: question not clearly defined and graphic design fail to bring out key features of the data.7. Type DV: poor execution of the graphical elements and data fail to convince8. Type QDV: graphical disasters do not get anything right when using the Trifecta Checkup Framework, question, data, visual are equally important.",4,11,-7,2
"752","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data driven decision making(3DM) teacher-a ssigned grades as useful data in schools: include academic knowledge, attendance, participation and behavior. 25% in grade is attributable to academic knowledge, 75% to assess a student's ability to negotiate the social processes of school. innovation in the data mining literature: 1. hierarchical cluster analysis(HCA), 2. heatmaps interpret longitudinal trends in student data. Method: 1. sample and district context  2. data collection 3. hierarchical cluster analysis: brings empirically defined organization to a set of previously unorganized data. two types of clustering: supervides and unsupervised. 4. missing data: reason: not all students take all of the same subjects; students dropped out of school before the end of grade 12, or transferred into or out of either district. 5. clustergrams: help visualize the organization and include a final set of data for each case's data row. 6. clustergram X-Axis subject order. Findings: 1. an example of hierarchical clustering: HCA using longitudinal grade histories. main goal of study is to present HCA and visualization techniques as a useful method for the organization and analysis to aid 3DM. 2. comparison to Past Dropout Identification Literature: goal is to identify students who will ultimately dropout of school",0,3,-3,3
"753","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","education researchers:study network formation within classroomsthree way to do analysis: 1. descriptive analysis of the network, 2. exploration of network evolution 3. analysis of network position as a predictor of individual outcomes. Social Network Basics: SNA help us understand how relationships form, what kinds of relational structures between pairs of actors, and the impacts are of these relationships on actors. Network Types: 1. number of types of actors they contain: one type of actor, student(unipartite); liking actors with the groups to which they belong(bipartite) 2. nature of the ties they contain: ties are inherently bidirectional(undirected); directed network. binary or valued. Network Data Collection: time frame of collection; how to sample from a population; census networks Network level concepts and Measures: network density(how many ties are present); who is connected with whom, homophily. data management: matrices are a powerful way to store and represent social network data.",1,0,1,4
"754","Why Students Should Own Their Educational Data","Everyone has different grade level. Even though they are in the same grade, they have different strengths and weakness. Now textbook or lecture is designed for average student, but actually there are no students are in average, most are higher or lower. This explained why there are lots of poor students, the reason for their bad grade is not because they are poor, there are no perfect customized textbook or lecture for them. Like some students are good at math, but poor at reading. Why they get the bad score in math, since reading requirement in the exam is higher than their level. Why students should own their educational data? Because individuals are in different level, not are in average. But all of textbooks are in average level. ",3,6,-3,4
"755","Knowledge tracing: Modeling the acquisition of procedural knowledge","ACT programming tutor: practice envrionment in which student write short programs in Lisp, Prolog or Pascal. These three used by different school. Three angle-bracket symbols in template:&lt;name&gt;/&lt;parameter&gt;/&lt;exprl&gt; Lisp: constructed around hundred rules for writing programs called the ideal student model. student's action is compared to applicable rules in the ideal model and immediate feedback is conventionally provided. The Cognitive Model: ACT-R theory: assumes a fundamental distinction between declarative knowledge(factual or experiential) and procedural knowledge(goal-oriented and mediated problem-solving behavior). Evaluating ACT-R procedural knowledge assumptions: three types to support:1. production rule model provides a regular analysis of learning trends. 2. production rule analyses have proven successful in predicting transfer among programming languages and across text editors. 3. a variety of results support the assumption that procedural knowledge is goal-specific.  knowledge tracing: monitor the student's changing knowledge state during practice and ensure with a high probability that each rule is in the learned state.  empirical evaluation of knowledge tracing: 1. general experimental procedure 2. internal validity: predicting tutor performance 3. external validity: predicting test performance 4. individual differences in learning and performance",6,0,6,3
"756","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Two distinct research communities: Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK). The first international conference: EDM - 2008; LAK -2010. Similarities between EDM and LAK: 1. he similar definition. 2. both reflect the emergence of data-intensive approaches to education. 3. both have the goal of improve the quality of analysis of data, to support research. Distinctions between EDM and LAK: 1. discovery 2. reduction&amp;holism 3. origins 4. adapation&amp;personalization 5. techniques&amp;methods",1,0,1,2
"757","Evaluating Machine Learning Models","classification is about predicting class labels given input data. accuracy = # correct predictions / # total data pointsa variation of accuracy is the average per-class accuracy- the average of the accuracy for each class.  AUC stands for area under the curve. AUC is one way to summarized the ROC curve into a single number. ROC curve shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives. Precision-recall: two metrics, but used together.They answer the different questions. precision: #happy correct answers/#total items returned by ranker. recall: #happy correct answers/#total relevant items.F1 = 2(precision*recall/(precision+recall)) NDCG: normalized discounted cumulative gain. cumulative gain(CG); discounted cumulative gain(DCG).regression metrics: learn to predict numeric scores. most commonly used metric is RMSE(root-mean-square-error).Since RMSE is an average, its sentitive to large ourliers. Quantiles are much more robust. MAPE(median absolute percentage). The difference between training metrics and evaluation metrics: training model always better to directly optimize for the metric it will be evaluated on. skewed datasets- imbalanced classes, outliers, and rare data: always be on the look out for data skew. Good classifier should have accuracy much high than 99%. Metric that gives equal weight to each instance of a class has a hard time handling imbalanced classes. The resulting model may not know how to predict the rare classes if class imbalance is not properly dealt with. Another problem is outliers. large outliers can be mitigated during evaluation but not for the training phase. The solution for it is doing careful data cleaning and reformulating the task.",10,3,7,5
"758","Saturday Morning Breakfast Cereal","90% of elite engineers were interested to reassemble clocks as children, but it does not mean all children who start reassemble clocks will be elite engineers. In the education, interests are the most important. If children like doing something, they will accept those knowledge faster. Otherwise, even though school has the course to force children to learn, they still refused to learn and have a hard time to get the achievement in the field. Thus, interests will promote children to be elite in the specific field. “we clocked so much clock that we're off the clock"". Children like clock, when forcing them to do, they will refuse to work and even stop doing relative thing at the end.",5,1,4,2
"759","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers: group of academics who analyse data about student learning and prepare reports with actionable recommendations based on that data. The role is not only to anaylse the data, but  to increase the familiarity of academics with the data sources, to building learning analytics capacity. Role: 1. act as human sense-makers 2. facilitating action on feedback from learners 3. making better sense of what that feedback means and how the data can be improved 4. helping to develop the Community of Practice around the use of learning analytics. Results: Tools using like SAS data warehouse to aggregated data sources and Tableau to export. Data wranglers use workbooks as their primary data to generate some charts and visualisations. Also use the data directly to produce their own charts in Excel. Macfadyen &amp; Dawson's analysis of LMS - technical discussions    Data Wrangler - analytic processes  ",4,0,4,1
"760","Zuckerberg is ploughing billions into 'personalised learning' – why?","There is no clear definition for personalised learning now but I agree with the definition from Zuckerberg,""working with students to customise instruction to meet the student's individual needs and interests"". In my opinions, since every student has different level, they need special material for them, like some students are good at math rather than verbal, they might need high level of math material and middle level of verbal. Dangers of personalised learning: 1. we will get many specialists and few generalists. 2. learners will lost their ability of compensations. 3. students, teachers and parents will lose social contact between each other. 4. data is easy to lose and misused.  nobody can guarantee personalised learning will be success. And even though you are rich enough, doing personalised learning is still hard, since it not only related with the technology problem, but also related the conversation and collaboration, how to balance the technology and teachers.",7,6,1,2
"761","Feature Selection","Feature Selection1. knowledge discovery interpretabicity &amp; insight (humanbeing)    useful when thinking about a set of data in a problem, to be able to interpret the features. 2. curse of dimensionality(machine learning): the amount of data that you need grows exponentially in the number of features that you have. selection: from whole bunch of features to a few features. use algorithm to get just important features. help to understand data better and have easier learning problem.",2,2,0,1
"762","Chapter 1: Social Network Data","difference between conventional and network data: conventional data focuses on actors and attributes; network data focus on actors and relations network analysis: 1. seeing how actors are located in the overall network2. seeing how the whole pattern of individual choices gives rise to more holistic patterns boundaries of the populations: 1. boundaries are created by the actors themselves. 2. more demographic or ecological approach strategies for deciding how to collecting  measurements on the realations among them: 1. full network methods: yields the maximum of informaiton 2. snowball methods: giving some thought to how to select the initial nodes. weakness: 1. actors who are not connected are not located 2. no guaranteed way of finding all of the connected individuals. ego-centric networks with alter connections: the network as a wholeego-centric networks ego only: focus on the individual multiple relations: 1.scales of measurement 2. binary measures of relations 3. multiple-category nominal measures of relations 4. grouped ordinal measures of relations 5. full-rank ordinal measures of relations 6. interval measures of relations mathematical approach: treat the data as ""deterministic""statistical analysts: regard the scores on relationship as probabilistic realizations",1,1,0,4
"763","RStudio Cheat Sheets","Data Wrangling1.%&gt;% passed object on left hand side as first argument of function on righthand side.2. gather(cases, ""year"", ""n"", 2:4): gather columns into rows.3. spread(pollution, size, amount): spread rows into columns.4. separate(storms, date, c(""y"", ""m"", ""d"")): separate one column into several5. unite(data, col, ..., sep): unite several columns into one.6. data_frame(a = 1:3, b = 4:6)7. arrange(mtcars, mpg): order rows by values of a column(low to high)8. arrange(mtcars, desc(mpg)): order rows by values of a column (high to low)9. rename(tb, y = year): rename the columns of a data frame.10. filter(iris, Sepal.Length &gt;7): extract rows that meet logical criteria11. distinct(iris): remove duplicate rows.12. slice(iris, 10:15): select rows by position13. select(iris, Sepal.Width, Petal.Length, Species): select columns by name or helper function(contains(), ends_with(), everything(),matches(), starts_with()).14. summarise(iris, avg = mean(Sepal. Length)): summarise data into single row of values15. summarise_each(iris, funs(mean)): apply summary function to each column.16. group_by(iris, Species): group data into rows with the same value of Species.17. mutate(iris, sepal = Sepal.Length + Sepal. Width): compute and append one or more new columns18. left_join(a,b,by = ""x1"")//right_join, inner_join, full_join, semi_join, anti_join.19. intersect(y,z): rows that appear in both y and z20. union(y,z): rows that appear in either or both y and z21. setdiff(y,z): rows that appear in y but not z22. bind_rows(y,z)///bind_cols(y,z)    ",0,2,-2,1
"764","Translating Learning into Numbers: A Generic Framework for Learning Analytics","critical dimensions:1. hard issues: challenges of the fact-based world of data and algorithms. example: compatibility of educational datasets, the comparability and adequacy of algorithmic and technological approaches.2. soft issues: challenges that depend on assumptions being made about humans or the society in general. example: questions of data ownership and oppenness, ethical use and dangers of abuse, ad the demand for new key competences to interpret and act. design framework: framework intends to be a guide as much as a descriptor of the problem zones. dimension of LA framework: (1)stakeholders: data clients: terachers; data subjects (learners)(2)objectives: reflection:self-evaluation; prediction: predicting and modelling learner activities.(3)data:protected dataset; relevant indicators; time scale(4instruments: pedagogic theory; technology; presentation(5)external constraints: conventions: privacy, ethics; time scale; norms(6)internal limitations: competences and acceptance six dimensions are mandatory to be present in LA design. The interests of the learners is important for the development of LA. Development should not happen without a guiding framework(use of educational data and protection of individuals) question in LA: the relation with theories of learning, teaching, cognition and knowledge.",2,8,-6,1
"765","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","trial MOOCS: 1. we did not choose new material and we adjust design to reflect MOOC delivery to both world and students.2. developing the software platform which students could carry out many of the activities 3. accessible to nonprogrammers as well as programmers. Research Methods: 1. design: single-group cross-sectional research design. 2. participants 3. measures: use pre- and postclass surveys designed to measure students' background. 4. preliminary analyses: by examming a set of questions that asked students to rate. Difficult to study the differences in learning between face to face and MOOC due to the lack of a measure of baseline understanding or knowledge. Results: students knowledge increased; limited data suggests that face-to-face students learned at least as much as online-only students; students at all incoming knowledge levels benefited similarly from the course; students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge. Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest; predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking.",6,6,0,4
"766","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","eEPIPHANY: a collection of data-mining techniques to automatically refine a human-crafted set of skills, it is efficient, practical and scalable method. Its goal is provide constructive feedback to online course designers and developers for iterative course improvement. Contributions: 1. new problem formulation 2. new algorithm 3. evaluation Skill-item association: mapping between a single skill and multiple assessment items in the skill map. steps for eEPIPHANY: 1. clustering assessment item 2. proposing a new skill model 3. searching for the best skill model two latent-feature extraction strategies: 1. the Matrix Factorization(MF): transformed A-matrix into the D-matrix 2. the Bag-of-Words(BoW): creates the F-matrix directly from a collection of item stems Feature extraction is to generate a two-dimensional matrix, showing a mapping betwen assessment items and skill candidates. three strategies to refine the ""default"" skill model: 1. replace strategy 2. append strategy 3. split strategy  ",9,2,7,5
"767","Big Data in Education","Video 1 chapter 7 Clustering: a type of structure discovery algorithm1. you have a large number of data points2. you want to find what structure there is among the data points3. you do not know anything a priori about the structure4. clustering tries to find data points that""group together"" k-means steps:how many clustering we want:orange, green, red, purple, black(different color point)centroids: usually chosen randomlyclassify every point re-fit the centroids as the center of the points in the each clusterconvergencesome outliers are exist Video 2 chapter 7 clustering: validation and selection of k distortion: mean squared deviation, can not choose size of k1. take each point p2. find the centroidof P's cluster C3. find the distance D from C to P4. square D to get D'5. sum all D' to get distortionDistance: euclidean  distance can be computed an arbitrary number of dimension information criterion:1. assess how much fit would be expected from a random N centroids2. assess how much fit you actually had3. find the difference how many clusters:1. try several values of k2. find “best-fitting” set of clusters for each value of k3. choose k with best value of BIC/AIC Video 6 chapter 7 Q-matrix: a table where rows are items and columns are skills. It is also called knowledge component (KC) model or skill-item mapping.Every item must include at least one skill. How do we get a skill-item mappting:1. automatic model discovery: learn the mapping between items and skills solely from data.Barnes et al.'s: better model property: 1. given a skill-item mapping, you can predict for each combination of skills whether a student should get each item correct or not. 2. fit a model like PFA or BKT, and see how well it fits data, given the skill-item mapping. 2. hand-development and refinement: original way that Q-matrices were created actually. strategies for Q-matrix refinement: 1). try to smooth learning curves(shows relationship between amount of practice and performance) 2). look for skills with no apparent learning 3). look for problems with unexpected error rates:DataShop3. hybrid approaches Video 1 Chapter 1 joint goal of exploring and promotetypes of EDM/LA method: 1. prediction: develop a model infer a single aspect data 2. structure discovery: find structure and patterns in the data, no specific target 3. relationship mining: find relationship between variables in a data set with many variables 4. distillation of data for human judgement 5. discovery with models why data mining did not start more earlier: no enough data and hard to scale Video 3 Chapter 1 classification: the thing you want to predict is categorical, to determine which features in which combination can predict the label. labels come from: in-software performance/school records/test data/survey data/field observation or video coding/text replays.step regression: fit linear regression function, all value below 0.5 are treated as 0 and all value &gt;=0.5 are treated as 1. logistic regression: fits logistic function to data to find out the frequency, closer to 1. decision trees Video 4 Chapter 1 decision rule: sets of if-then rules which you check in orderK*: predicts a data point from neighboring data points, good when data is very divergent. advantage is works when nothing else works. Drawback is need to have the whole data set. Bagged Stumps: related to decision trees, relatively conservative.support vector machine/genetic algorithms/neural networks(complicated model) good for some problem but not for most type of educational data. Video 2 Chapter 2 Diagnostic matrics: different methods, different matrics. accuracy: easiest measures of model goodness, # of agreements/total number of codes/assessments. Kappa: (agreement-expected agreement)/(1-expected agreement)Kappa = 0, agreement is at chanceKappa = 1, agreement is perfectKappa = -1, agreement is perfectly inverseKappa &gt;1, you messed up somewhereKappa &lt;0, model is worse than chance, very rare unless using cross-validation.0&lt;Kappa &lt;1, typically 0.3-0.5 is good.Kappa is scaled by the proportion of each category, so there is no standard. Video 3 Chapter 2 ROC: receiver-operating characteristic curve, predicting something which has two values. outputs a probability or real value. Four possibilities: true positive/false positive/true negative/ false negativeX axis = percent false positivesY axis = percent true positivesA‘ closely approximates the area under the ROC curve, called AUC. A' only work for two categories. it's always higher than Kappa values. precision = TP/(TP+FP); the probability that a data point classified as true is actually true.recall = tp/(tp+fn); the probability that a data point that is actually true is classifies as true.  Video 4 Chapter 2 metrics for regressors: linear correlation: Pearson's correlation. 1 is perfect, 0 none; -1 is perfectly negatively correlated. in between depends on the field. in physics correlation of 0.8 is weak. in education correlation of 0.3 is good. R^2 a measure of what percentage of variance in dependent measures. MAD/RMSE: mean absolute deviation/root mean squared error. MAS tells the average amount to which the predictions deviate from the actual values. RMSE penalizes large deviation more than small deviation. Lower MAD/RMSE and high correlation is good model. High MAD/RMSE and low correlation(model values are in the right range, but model does not capture relative change) is bad model. information criteria: 1. BIC value over 0 worse than expected given number of vairables. under 0, better than expected given number of variables. it's statistically equivalent to k-fold cross-validation for optimal k. 2. AIC an information critiera, make slightly different trade-off between goodness of fit and flexibility of fit. Equivalent to leave-out-one-cross-validation. Video 5 Chapter 2 cross-validation and over-fittingover-fitting: fitting to the noise as well as the signal. reducing over-fitting: fewer variable and less complex functions. No way to eliminating over-fitting.  groups: k-fold, pick a number K, split into this number of groups, quicker. Leave-out-one, every data point is a fold, more stable. Flat cross-validation: each point has equal chance of being placed into each fold. stratified cross-validation:biases fold selection so that some variable is equally represented in each fold. Student-level cross-validation: no student's data is represent in two folds.seen as minimum cross-validation. Video 1 Chapter 4 Bayersian knowledge tracing(BKT): classic approach for measuring tightly defined skill in online learning. goal is to measuring how well a student knows a specific skill/knowledge component at a specific time. Use: assess a student knowledge of skill. where each item corresponds to a single skill. Assumption: each item must involve a single latent skill, each skill has four parameter, able to compute latent knowledge P(Ln)/the probability P(CORR) that the learner will get the item correct. Two-state learning model. Classical BKT: two learning parameters:P(L0),P(T); two performance parameters: P(G), P(S).predicting current student correctness formularParameter constraints:to avoid model degeneracyconceptual idea behind knowledge tracing: by looking at whether a student's performance is correct, we can infer whether they know the skill. three public tools: 1. BNT-SM: Bayes Net Toolkit-Student Modeling 2. Fitting BKT at scale 3. BKT-BF:BKT-Brute Force(Grid Search)  ",43,21,22,1
"768","Cross Validation","cross validation higher order polynomial if the line does not good fit the all point.  test set is how the system id ultimately going to be used. The data being independent and identically distributed, the data all come from the same source.  we want to do use a model that is complex enough to fit the data without causing problem on the test set. pretend train data to test set.  For training data, split the data called folds then average all error together.",2,5,-3,5
"769","Hands-On Programming with R","Chapter 1 operation: + - * / stored data: die &lt;- 1:4 ## die 1 2 3 4 %*% inner multiplication  %o% outer multiplication Functions: 1. round(x, digits = #) 2. factorial() 3. mean() 4. sample(x, size, replace = TRUE / FALSE) #sample takes two arguments: a vector named x and a number named size. sample will return size elements from the vector. Replace = TRUE causes sample to sample with replacement. 5. sum() 6. roll() function constructor: function() {} Chapter 2 packages: install.packages(""ggplot2"") ## qplot makes ""quick plots"" library: library(""ggplot2"") replicate(10, roll())  ## 3 7 5 3 6 2 3 8 11 7  ### first replicate the number of times you wish to repeat and R command, and then give it the command you wish to repeat. Chapter 3 die &lt;- c(1,2,3,4,5,6) ## die 1 2 3 4 5 6 is. vector(die) ## TRUE  ### is. vector tests whether an object is an atomic vector. 1. length() 2. sqrt() 3. class() ##character/numeric 4. Sys.time() typeof() ##know what type of object you are working with, some R functions refer to doubles as ""numerics"". int &lt;- c(-1L, 2L. 4L) ## int -1 2 4 typeof(int)  ## ""integer"" logicals: 3&gt;4 ## FALSE dimensions attribute: dim(die) &lt;- c(2,3) ## die##          [,1]    [,2]    [,3] ## [1,]       1       3       5                          ###matrices## [2,]       2       4       6                          ### matrix(die, nrow =2) coercion: logical &lt; number &lt; characterTRUE = 1, FALSE = 0as. character(1) ##""1""as. logical(1) ## TRUEas. numeric(FALSE) ##0          ",2,9,-7,1
"770","Principal Component Analysis explained visually","PCA: principal component analysis is a technique used to emphasize variation and bring out strong pattern in a dataset. Find the 2 principal components. 2D example: PCA finds a new coordinate system in which every point has a new (x,y) value. 3D example: drop one dimension, project the data into 2D and it is more clear. Eating in the UK( a 17D example): try to eliminate dimension and project the data into 2D.  ",2,0,2,2
"771","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","In this article, hierarchical cluster analysis heatmap was utilized to cluster k-12 students by clustering the variables of cumulative grades from different levels. The authors tried to correlated clusters with categorical variables such as dropout, ACT taking status, gender, and district.",0,1,-1,3
"772","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article introduces the social network analysis about its concepts, data collection, processing and methods. By providing the case, authors illustrated the process of social network analysis. By comparing two sociographs, it shows the obvious differences in terms of density and transitivity.",0,0,0,4
"773","Why Students Should Own Their Educational Data","In this article, the author state his view toward learning style that student should own their educational data. He believes that it will promote the quality of learning for students. Although the personalized data will improve the learning quality, the result depends on the size of class and number of teachers.",0,0,0,2
"774","Knowledge tracing: Modeling the acquisition of procedural knowledge","In this article, a Bayesian Cognitive Model in APT tutoring system is introduced, that allows tutor to interact with student during the learning process, and to judge the learning quality and progress of the students. As presented in this article, the system has high internal and external validity.",1,0,1,3
"775","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This article summarized the differences and similarities between educational data mining and learning analytics. The authors' point is that researchers should learn from each other and improve their research in all areas.",0,0,0,2
"776","Evaluating Machine Learning Models","The article introduces the diagnostic measures of three types algorithms in data mining, including classification, ranking and regression. The authors point out that each type has advantages and disadvantages, and they suggests to select the type by the appropriate purpose.",0,2,-2,5
"777","Why Is Measuring Learning So Difficult?","In this video, they point out that although measuring learning is difficult, it is still possible to measure learning well, such as social structure. Finding a trustworthy measuring indicator is very important for measuring process. By longitudinal models, students' learning progression of educational outcomes is possible to be measured.",2,1,1,4
"778","Saturday Morning Breakfast Cereal","The comic implies the phenomenon that the current education is focusing more on the outcome other than the process and education itself. It is still doubtful whether education outcome, such as grade, is more important that the progress of learning ability.  ",1,1,0,2
"779","The Data Wrangling Cheatsheet","It is a very helpful cheatsheet for dealing with data processing, by providing lots of code directions.",0,0,0,1
"780","Data wranglers: human interpreters to help close the feedback loop","This article emphasized the point that data wranglers are very helpful to interpret educational data. I believe that data wranglers are very important on interpreting the educational data when educators make the educational policies.",0,0,0,2
"781","Zuckerberg is ploughing billions into 'personalised learning' – why?","In this article, the authors introduces Zuckerbergs's plan on personalized learning, discussing the current situation and the dangers of personalised learning. They doubt the potential of personalised learning's development due to current conditions. First, it is hard to make sure whether personalised learning is truly personalized. Second, the high cost of personalized process is not really helpful for developing the quality of education for all individuals.   ",1,3,-2,2
"782","Feature Selection","This video introduces the reasons of feature selection, including interpretation and insight, and curse of dimensionality.",0,0,0,5
"783","RStudio Cheat Sheets","It is a very helpful cheatsheet for R users. It provides lots of commands and formats about Rmarkdown, assisting users to produce better text format.",1,0,1,1
"784","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This articles provides the generic framework to learn analytics. This framework contains with 6 dimensions, etc, data, stakeholders.... The authors pointed out that the framework is not intended to be perfect and applicatble to every scenario in education, but that education practitioners may revise this framkework and make it useful to heir specific purposes.",1,0,1,2
"785","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","In this article, the authors introduces the study on a MOOC course on recommendation system, and they explore the reasons why students register by PCA analysis that the result of eigenvalues is over 1. Moreover, the authors attempt may regression analysis in order to find the variable which predicts the outcome significantly, such as grades and retention. They compared face to face students and online students with the former studies, and they state that the small former group size may lead to an unconvincing result.",2,1,1,4
"786","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","In this article, the authors introduce a way to automatically find out the Q matrix of item-skill correspondence, by AFM or BKT method. The authors point out that the new methods are more complex that the popular method- LFA method.",1,1,0,5
"787","Chapter 1: Social Network Data","This article introduces the concepts of social network analysis, by emphasizing the difference between conventional inferential statistics and descriptive statistics of SNA.  ",0,0,0,4
"788","Learning Analytics Dashboards","This article introduces the process of data visualization in education from the start stage to the end. By showing the case, it clearly emphasizes the identical key for each stage.",1,0,1,2
"789","Measurement and its Uses in Learning Analytics","In this article, the authors provide the introduction about psychometrics, such as CTT, IRT, CFA and other models in measurement. The concepts of psychoetrics have been justified for learning analytics. Since measurement is a prerequisite for researchers in empirical study, it is important to have the basic idea about how to operationalize the concepts at first.",0,0,0,5
"790","Predictive Modelling in Teaching and Learning","The article introduces the predictive modeling in education, including data collection, feature engineering, common algorithms, diagnostic measures of model evaluation. Moreover, the tips to deal with missing data are very helpful.  ",1,1,0,5
"791","Ethics and Learning Analytics: Charting the (Un)Charted","This article introduces the ethic principles for newly emerged field of learning analytic, from the introduction of history to the instruction and conferences.  ",0,0,0,2
"792","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","In this article, the authors developed explanatory models efforts of educational data mining that prevalent with predictive modeling attempts, and their focus is on the cognitive model discovery. They mention three models including DFA, LFA and SimStuden, and they find that the automated cognitive models have better fits. Moreover, they state their understanding on what variables should be included and why these are helpful.",2,0,2,5
"793","Statistical graphics: making information clear – and beautiful","In this article, a bad graph has been improved and represented by R as a sample, in order to illustrating the purpose of graph, revision guidelines and multiple graphs guidelines.",0,1,-1,2
"794","How to display data badly","This article introduces many bad quality graphs in order to help readers to avoid the mistakes when they draw their graphs. The authors present few principles including data density index, perceptual distortion and data-ink ration.",0,2,-2,2
"795","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This article introduces the data visualization, by specifying the data graph such as scatterplots and bar. The authors point out that making comparison by presenting information from graph to discover the pattern from data.",0,0,0,2
"796","Junkcharts Trifecta Checkup: The Definitive Guide","In this article, the author introduces few kinds of poor quality graphics by differing combinations of questions, data and visualization. The examples are clear and illustrative. The graphics shows the problems that it is hard to figure out what the questions are, why the data is improper and the visualization is weak.",1,4,-3,2
"797","Measurement and its Uses in Learning Analytics","Leaning analytics tools express the commitment to specific educational views for specific learners.",1,0,1,2
"798","Ethics and Learning Analytics: Charting the (Un)Charted","It focuses on the ethics in learning analytics. Ethics has been a crucial factor in learning analytics. We should respect and cited properly for previous people's work.",3,0,3,2
"799","Predictive Modelling in Teaching and Learning","Predictive analytics is a group of techniques used to make inferences about uncertain future events. Predictive modeling is to create a model that will predict the value of new data on new observations. Predictive analytics is a group of techiques used to make inferences about uncertain future events. Predictive modeling is to create a model that will predict the value of new data on new observations. The data demonstrated in the paper is about the achievement level of students.",0,2,-2,3
"800","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","There are two types of model, one is the statistical model, the other one is cognitive model. Statistical models drive the outer loop of intelligent tutoring systems based on observable features of students' performance as they learn. Cognitive models are representations of the knowledge space (facts, concepts, skills, et cetera) underlying a particular educational domain. In cognitive models, it is hard to apply the same model to another new dataset.",0,1,-1,5
"801","Statistical graphics: making information clear – and beautiful","Not list on syllabus",0,0,0,1
"802","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","It tells the difference between infovis and statistical graphics. It discusses different types of visualization. And the best graph is the one with the most attracting and engaging since it was what people are looking for.",1,0,1,2
"803","Junkcharts Trifecta Checkup: The Definitive Guide","A guide helps us to check whether our graphs are a chartjunk. It includes many examples with details, so it is very easy for readers to follow and examine their own graphs.",0,0,0,2
"804","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","It collects historical data from students to analyze, and use visualization to see the result.",0,0,0,3
"805","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","A network is a better way to see the relationship between students and their class since it has visualization. A network works well in a community as it contains many relationships. ",3,0,3,4
"806","Why Students Should Own Their Educational Data","Everyone absorbs knowledge differently, so it's good to create different educational data for different students.",1,0,1,2
"807","Knowledge tracing: Modeling the acquisition of procedural knowledge","Monitoring students' knowledge condition while they are studying for the result of practice exercise. The director changes the teaching method according to each student's progress until everyone understands every idea. Knowledge tracing is effective and need to improvement.",2,0,2,3
"808","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","In the past, research about learning analytics used quantitative methods, but we should incorporate more data mining methods to supplement our needs.",0,0,0,3
"809","Evaluating Machine Learning Models","It provides details about machine learning models that we can apply to our data and our assignment, such as accuracy is the correct predictions over the total number of data points.",1,0,1,5
"810","Why Opting Out of Student Data Collection Isn’t the Solution","Not list on syllabus",0,0,0,1
"811","Why Is Measuring Learning So Difficult?","Learning is differnt for differnt people, so we have many dimensions to measure and we need to simply the data. What people learned is depend on  what people define independent mean.; Not list on syllabus",0,0,0,1
"812","Saturday Morning Breakfast Cereal","Children will learn from interest, forced learning is not working.",0,0,0,2
"813","Data wranglers: human interpreters to help close the feedback loop","Different data have different dimensions of data, so data wrangling can organize data effectively. The paper provides some examples for data wrangling.",1,0,1,1
"814","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized data is a good try since different people have different understandings and knowledge levels. However, there are dangers of personalized learning. We will get many experts and a few generalists. Learners will lose their ability of compensation. Students, teachers, and parents will lose social contact with each other.  Data is easy to misuse.",1,4,-3,2
"815","Feature Selection","Feature selection:1. Knowledge discovery- interpretability <U+2260> insight2. Curse of dimensionality.",0,0,0,5
"816","Chapter 1: Social Network Data","Difference between social network data and conventional data. Conventional contains a rectangular measurement, whereas networks contain a square way of measurement.",0,0,0,4
"817","RStudio Cheat Sheets","It is very useful for me to be familiar with the Rmarkdown cheatsheet and I can use it when I forget something about Rmarkdown. It contains many details.",0,0,0,1
"818","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Not list on syllabus",0,0,0,1
"819","Translating Learning into Numbers: A Generic Framework for Learning Analytics","It describes the requirement behind learning analytics and the consequences for learning analytics. Visualized data with numbers allow teachers to demonstrate their results more easily.",0,0,0,2
"820","The Big Five and Visualisations of Team Work Activity","Not list on syllabus",0,0,0,1
"821","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Trails from MOOC with theory overview.",0,0,0,4
"822","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","test test",0,0,0,5
"823","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","It describes a model the author's team found for the skills and knowledge from an online course data.",1,0,1,5
"824","Using data mining to predict secondary school student performance","Not list on syllabus",0,0,0,1
"825","Developing a generalizable detector of when students game the system","Not list on syllabus",0,0,0,1
"826","Big Data in Education","It talks about clustering. First, decide the numbers of groups we wanted. Then, pick the center for each group and fix it to the nearest point within the group. Redo it until there is no more change.",0,0,0,1
"827","Cross Validation","Find how to predict values and testing them. Cross validation is which we set a line, if it doesn't fit, then we draw a higher order polynomial. And we use a model that is complex enough to fit the data without causing problems on the test set.",1,2,-1,5
"828","Hands-On Programming with R","R is a dynamic programming language, so we don't need to compile the code after we write it. You save R code to the R script. R has many useful packages that can save our time to implement.",0,0,0,1
"829","Principal Component Analysis explained visually","It provides 2D, 3D and ND examples for principal component analysis.",0,0,0,2
"830","Infovis and Statistical Grpahics: Different Goals, Different Looks","The field of statistical graphics has been neglected. it's time to pay attention! Journals in graphical stats are currently about 80% stats, 20% graphics. But data graphics are very popular these days - we get to do a better job of being more mindful of the graphics we create. Graphics helps with tasks like data cleaning and exploration (so far) - then we get to inference. Lack interaction between the worlds of statistical graphics and information visualization is an issue. The statistical approach concentrates on what can be got out of the available data and the Infovis approach uses the data to draw attention to wider issues. Both are valuable and perhaps a combination of the two would serve best. Goals of visual display of quantative information: 1. Graphics are for the qualitative/descriptive 2. Graphics are for comparison—comparison of one kind or another 3. Graphics are for impact—interocular impact if possible, swinging-finger impact if that is the best one can do, or impact for the unexpected as a minimum 4. Graphics should report the results of careful data analysis—rather than be an attempt to replace it. (Exploration—to guide data analysis—can make essential interim use of graphics, but unless we are describing the exploration process rather than its results, the final graphic should build on the data analysis rather than the reverse.)",6,4,2,2
"831","How to Display Data Badly","Good data:  shows data accurately shows data clearly  Rules on showing data badly: (All of these below are ways to screw up your graph :)) Rule#...  Show as few data as possible (minimize the data density) Hide your data you do show (minimize the data-ink ratio) Ignore the visual metaphor altogether Only order matters Graph data out of context Change scales in mid-axis Emphasize the trivial (ignore the important) Jiggle the baseline Austria first Label (a) illegibly, (b) incompletely, (c) incorrectly, and (d) ambiguously More is Murker: (a) More Decimal Places and b) More Dimensions If it has been done well in the past, think of another way to do it. ",4,3,1,3
"832","Statistical graphics: making information clear - and beautiful","A well designed graph - how do we do this? When constructing beautiful graphs, there are a few things to keep in mind. Every decision needs to be made consciously and with intent. Two key decisions are:  Who is your target audience? What are you trying to show?  Guiding principals:  Avoid distracting elements. Use informative color to visually associate elements. Keep the <U+FB01>gure simple (and therefore interpretable).  In order to use small multiple plots, use the following guiding principals:  Keep the x- and y-axes on the same scale.  Eliminate repetitive information. Maintain consistency across plots. ",1,1,0,2
"833","HLA: Chapter 12 Learning Analytics Dashboards","What should a dashboard do? Address the following: 1. What kind of data can visualized? 2. For whom are the visualizations intended? Audience?? 3. Why: What's the goal of the visual? 4. How can the data be visualized? Which interaction techniques can be applied? What tools, libraries, data formats etc. can be used for technical implementation? What workflow can be developed?   Data mining = computer number crunching - Tesla Visualization = human perceptual abilities - Honda Information visualization Specific emphasis on building models and visualizing these models - relies on humans to find trends, gaps, outliers, clusters etc. The human visual system is very powerful. ""At higher levels of processing, perception and cognition are closely interrelated, which is the reason why hte words ""understanding"" and ""seeing"" are synonymous"" therefore - visualization has the potential to be more precise and revealing than conventional statistical computations.What   Dashboards "" typically capture and visualize traces of learning activities, in order to promote awarenss, reflection and sense-making, and to enable learners to difine goals and track progress towards these goals."" What we can track changes as possibilities and capabilities expand. What can be incorporated into a dashboard: 1. artefacts produced by learners 2. social interaction 3. resource use (consultation, slides etc) 4. time spent 5. test and self-assessment results   How to get started Understand your Goals. 1. why? what is the goal of the visualization? What questions about the data should it answer? 2. For whom? For whom is the visualization intended? Are the people involved specialists in the domain? 3. What? What data will it display? 4. How? how will it support the goal? What is the intended output? Aquiring Data: 1. Raw data: know where the data comes from and when it's updated. 2. Analyzing raw data: may need to clean up the data if some is missing or erroneous. Outliers? clusters? 3. Prepare and filter data: use the initial questions and choose the relevant data from the pool.   Mapping Design: choose a design that best answers the questions you want the users to be able to answer. one way to start: Look at the measurement or scale of each data characteristic. Differentiate objects. sketch it out before making the high quality prototype Note: pie charts - usually bad. bar charts - usually quite powerful. coordinated graphs enable rich exploration.   Documentation: Be explicit about: 1. rationale - why were certain decisions made? What was the intent? 2. alternatives - which alternatives were considered? 3. Evolution: how the design evolved in different iterations. add interactive techniques Common tasks include: 1. comparing values and patterns 2. sorting 3. filtering 4. highligint data to make specific values stand out 5. clustering/grouping. 6. annotating findings 7. bookmarking/reporting specfic view on the data Evaluation continusously  ",8,3,5,1
"834","Junk Charts Trifecta Checkup: The Definitive Guide - Junk Charts","When viewing or planning a graphic, ask: 1. What is the question? 2. What does the data say? 3. What does the visual say? Ideally, the answer to all is the same. Data should be relevant to the question being asked. Visual should be clear and concise and answer the question directly. Type Q: Chart is fine, but fails because of poorly defined objective (Question). Type D: well posed questions an good graph. Issue is with the data. Type V: Data good, question good. Graph bad - too confusing. DOULBES: Type QD: graphical representation is good, but poor data quality and unclear. Type QV: data collection and processing is good, but question has not been clearly defined. Type DV: Data fails to be convincing of the question being posed. Execution of graphical elements is also poor. TRIPLES: Type QDV: All three things are poor. Poor question, poor data and poor visual.  ",10,13,-3,2
"835","HLA: Chapter 4: Ethics and Learning Analytics: Charting the (Un)Charted","Ethics and LA - now that more and more data is available and access to this data is more available, it is extremely important that we understand the roles, responsibilities and affect that this can have on students and their lives. Having access to so much information is potentially dangerous if it falls in the wrong hands or even in the hands of someone that does not fully understand the implications and responsibility of such knowledge. Through all of the current technological advances an increasing concerns about tech surveillance, the use of personal data, analysis and the role that algorithms play, a growing need for guidelines and ethics around gathering, reporting and using this surveillance responsibly has risen. The future of learning will be digital. It's already headed in this direction. This means data-driven results, data-driven decision making hopefully ultimately supporting someone in having a better quality of life. It's important to ask key questions: 1. WHO is the data for? 2. WHAT is the purpose of the data?3. HOW does one share the data? There are ethical concerns around how student data is collected, analyzed an used. It could be used to push a certain viewpoint in education. It should be used in an unbiased way. Slade and Prisloo (2013) - 3 broad overlapping, ethical categories: 1. The location and interpretation of the data. 2. Informed consent (an recurring theme in other such lists) and de-identification of data. 3. The management, classification and storage of the data. Slade and Prislooo - framework based on 6 principles: 1. LA as a moral practice - what is morally appropriate? 2. students as agents - collaborators in their own learning 3. student identity and performance as temporal dynamic constructs (LA is just a snapshot at a particular time and place). 4. student success is complex an mutli-dimensional 5. transparency** 6. Higher education cannot afford NOT to use data. QUESTION: How do we define success??   Educational triage - directing support to those that need it the most. Educational intervention. What can we do? Now with this data, we CAN do something in a meaningful direction.  But there are ethical concerns around doing educational surveillance without the student actually knowing we are doing this. Is this ok? Transparency is of utmost importance. Algorithmic output should be subject to human review and corrected, if needed. Algorithms should be frequently reviewed and validated. Student voices about data that is collected on them (unaware) is shaping policy dealing with the ethics of LA. How can we address student vulnerability? By empowering students to actively participate in learning analytics, moving from quantified data to qualifying self-evaluatoin. LA contributes: 1. QA and quality improvement 2. boosting retention rates 3. assessing acting upon differential outcomes 4. development and introduction of adaptive learning Students should not be wholly defined by their visible data or our interpretation of that data.  We should use that data only as intended or we run the risk of potential abuse/misuse and discrimination. Students rights: 1. easy access to info. 2. right to correct wrong info. 3. right to remove irrelevant info.",12,10,2,2
"836","HLA: Chapter 1: Thoery and Learning Analytics","Learning Analytics. What's so new about this? A huge shift in thinking. It's not just about analyzing data, it's about purposeful analysis to support in education reform. Now there is big data - and the tool to use to analyze this data is very important to craft purposfully, keeping the end goal in mind. Educators and learners are the key stakeholders who stand to benefit (along with students of course) and can now have access to data that previously was not accessible to them. For those in the analytic loop, people will change and react to the observation and explicit feedback.   Data-intensive revolution is about to happen (happening??) in education. There is evidence based decision making happening, but do those making the decisions really understand the data or do they just trust the person analyzing the data and giving them suggestions?   Algogriithmically-based. Now there seems to be a responsibility to deliver computational intelligence to the masses. A LA tool, when created, seems to stem from a particluar educational worldview and is designed to nurture a particular kind of learner. Triad: epistemology, assessment and pedagogy LA is a new form of assessment analytics and has the potential to support current educational practices or to reshape them as needed. Data-driven education reform is extremely valuable. LA has the potential to: 1. marginalize educators and learners through transforming education into a technocratic system. 2. limit what we talk about as learning to only what we can create analytics for. This is a huge shift in how we converse about education. 3. exclude alternative ways of engaging in activities, to the detriment of learners. Note: algorithms may mask or ignore some key elements of the learning process, this is why you would need a human to interpret the data and make meaning out of it.  ",7,2,5,2
"837","Big Data in Education","VIDEO 1: Clustering - tries to find data points that ""group"" together.  Large # of data points want to find what structure there is among the data points dont know anything prior about the structure  k-means clustering algorithm  fits the data points into different clusters.  How?  decide how many clusters pick ""cetnroids"" - usually chosen randomly to start, then we find better centroids classify each point as to which centroid it's closest to re-fit the cetnroids as the center of each cluster ""convergence"" - repeat the process until the centroids stop moving Note that there may be outliers A lot depends on initial positioning and # of clusters  VIDEO 2: K-means - how to choose K and which set of clusters to use? Distortion - (mean square deviation)  Take each point P Find the centroid of P's cluster C Find the distance D from C to P Square D to get D' Sum all D' to get distortion Find Euclidean distance (distance formula) Works for choosing radnomized restarts, but not for choosing cluster size because more clusters leads to smaller distortion. Distance to the nearest cluster center should be smaller w/more clusters  Corss-validation can't solve this problem. More clusters will cover the space more thoroughly. So distortion will often be smaller with more clusters. How to choose k? Trial and error.",3,7,-4,1
"838","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","When designing an online course - determining the right skills can be difficult. MOOCs often contain broad content usually w/ a semester's worth of material. So with all of that content online, how do we find the right set of learning objectives? They have discovered a method to determine this, but it assumes a pre-defined skills map for formative and embedded assessment. ""Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that  our method outperforms human-engineered skill models, skill models discovered by our method are interpretable, and our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability.  ""We found that eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction.  Our empirical study showed that eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. We also demonstrated that eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique.  Creating effective online courses often requires intensive, iterative system engineering. Studying techniques for automatic skill model refinement and its application for evidence-based course refinement therefore is a critical research agenda for the successful future of online education.  """,21,3,18,5
"839","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","""First, the course was simultaneously offered as a typical online-only MOOC and as a flipped-classroom face-to-face course Second, the course mixed programming and non-programming students together into a two-track course model. Third, we have performed extensive evaluation of student learning outcomes, mea-suring baseline knowledge, knowledge at the end of the course, and knowledge 5 months thereafter."" They looked at a hybrid of MOOC and face to face students. ""The factors that were predictive all relate to effort, prior courses, and baseline knowledge (in what appears to be only a negative effect resulting from ceiling effects)."" The author is looking for what affects grades significantly in these two groups. Is one more effective than the other?",0,0,0,4
"840","Chapter 1: Social Network Data","Data in its purest form consists of a square array of measurements. The rows of the array are the cases, or subjects, or observations. The columns of the array are -- and note the key difference from conventional data -- the same set of cases, subjects, or observations. In each cell of the array describes a relationship between the ""actors"". If one actor happens to be selected, then we must also include all other actors to whom we have or could have ties. The major difference between conventional and network data is that conventional data focuses on actors and attributes; network data focus on actors and relations. Network data are defined by actors and by relations (or ""nodes"" and ""edges"").  ",0,0,0,4
"841","Feature Selection","Feature selection Curse of dimentionality - amount of data you need grows exponentially with the nunber of features. So try not to have too many features.  ",0,0,0,1
"842","Zuckerberg is ploughing billions into 'personalised learning' – why?","who’s going to decide what data is collected and how it is stored and used?",0,0,0,4
"843","Data wranglers: human interpreters to help close the feedback loop","Analyzed the data, now what? Now close the feedback loop; however, the amount of data and the range of the different sources may make it difficult to take action. Interpreting this data in a meaningful way is the key to successful data wrangling. Humans are meaning-making machines. Interpreting and making meaning of the data is of the utmost importance. The heart of LA is closing the feedback loop. Use data to help drive instruction and support intervention. How? By designing and using effective EDM tools --&gt; then humans must interpret this data --&gt; then relay and mediate this iformation to lead to intelligent action --&gt; then figure out how we can improve this data! Sophisticated educational data mining tools are often hard for non-specialists to interpret. OU - university in the UK were there are 25000 online students. As data goes up, the gap in knowledge also goes up. Data wranglers: 1. analyze data 2. prepare reports 3. actionable recommendations What's the difference between a data wrangler and a data analyzer? The goal is to improve the experience, but so far, it's been less than optimal.",5,2,3,1
"844","Saturday Morning Breakfast Cereal","This cartoon shows the potential risk of what irresponsible and incorrect usage of data analytics can do. First they overract and then if the information falls in the wrong hands, it can have a huge impact on education and reform. The education reform can go in a totally wrong direction. In this case, it created resentment among teachers and they begin teaching to these incorrect standards. This shows how irresponsible and unethical practices can create elitism and division. Eventually, teachers begin pushing back and incorrect assumptions are made.",2,8,-6,2
"845","Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult? -multi-dimensional - sometimes we have to simplify too much in order to capture usable data. -the construct of learning as a cultural construct is really difficult to define and measure. -define measure? There are no reliable, simple, proxy indicators. - curiosity to memory -certain kinds of things will measure ""understanding."" When students teach what they've learned, it indicates transfer across domains. -to think about: cultural, social implications, individual social things that you can't capture in learning analytics (?) -we don't know what people's competencies were when they enter into a field. -you can measure ""competence"", but how to measure the growth? -assess at multiple time points. -measure constructs: achievement or psychological constructs (like self-efficacy) -analytics - divising a medium to reveal to the learner, what kinds of connections he/she may be making that they may not e aware of. How? Get students to narrate their learning on the web. -Analytics shouldn't be a diagnosis of what's happening now, but analytics at their best should be doorway that suggests what else is possible. -What is learning?? How to define it? What are analytics? What types of analytics exist?",3,2,1,1
"846","Evaluating Machine Learning Models","Machine learning is overwhelming! (YES :)) Evaluating Machine Learning Models - O'Reilly Media       'article aside footer header main nav section time'.replace(/\w+/g,function(n){document.createElement(n)})            #menu-toggle:checked ~ .mobile-nav {     display:block;   }   .mobile-nav {     display: none;   }                                O’Reilly report, machine-learning expert Alice Zheng takes you through the model evaluation basics. Evaluating Machine Learning Models - O'Reilly Media       'article aside footer header main nav section time'.replace(/\w+/g,function(n){document.createElement(n)})            #menu-toggle:checked ~ .mobile-nav {     display:block;   }   .mobile-nav {     display: none;   }                                 Learn the stages involved when developing a machine-learning model for use in a software application Understand the metrics used for supervised learning models, including classification, regression, and ranking Walk through evaluation mechanisms, such as hold?out validation, cross-validation, and bootstrapping Explore hyperparameter tuning in detail, and discover why it’s so difficult Learn the pitfalls of A/B testing, and examine a promising alternative: multi-armed bandits Get suggestions for further reading, as well as useful software packages               ",1,3,-2,5
"847","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","There are two research communities:  EDM - Educational Data Mining LAK - Learning Analytics and Knowledge  These were developed (separately) to address the growing interest in data and analytics in education.   Currently, very large data sets are available from students online learning and assessment. What to do with all this data? How to use it to support education reform? From this was born EDM and LAK. Timeline: 2005 - first workshop in educational data mining held in Pittsburgh. 2008 - 1st international conference on EDM. 2009 - 1st edition of the Journal of EDM (Kalina Yacef, editor) 2010 - 1st handbook of EDM 2010 - LAK conference series initiated.          The conference emphasized its role: Bridging the computer science and sociology/psychology of learning.      Three domains:  technical pedagogical social      All of these three need to be addressed in tandem in order best serve all stakeholders (students, teachers, parents, administrators, school districts, states). 2011 - IEDMS formed   SIMILARITIES (EDM &amp; LAK): EDM: developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students and the setting which they learn in. PURPOSE: better understand students an the setting in which they learn. LAK: the measurement, collection, analysis and reporting of data about learners and their contexts. PURPOSE:  understanding and optimizing learning and the evironment in which it occurs. Shared Goal: improving education by improving:                         assessment                         how problems in education are understood                         how interventions are planned and selected   KEY DISTINCTIONS (EDM &amp; LAK) The type of discovery that is prioritized. EDM:  focus on automated discovery used in CAT or CA lessons (AI) reductionistic paradigm  LAK:  focus on leveraging human judgement used to inform and empower teachers and students holistic paradigm   Both EDM and LAK communities understand the importance and potentially revolutionary impact of data driven education analysis.  ",6,1,5,2
"848","Why Students Should Own Their Educational Data","Typically in the past, learning data was collected by studying large groups of people or organizations and then we would use that data to make inferences and predictions at the individual level. That didn't work so well. Data collection now however, can be done on a more individualized and contextualized level. The more granular and more specific the data can be, particularly in terms of context, the better the analysis can be, which could lead to better learning This article though, is about allowing students to own this individualized data. There are pros and cons to this. It will keep the data private - no marketing from a million companies - but then will it be used in the most effective way to support student growth?  ",7,0,7,2
"849","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Understanding the classroom through SNA: SNA can help answer questions about pedagogy, equity, learning and educational policy &amp; organization. Network analysis: 2 broad classes of of hyoothesis: 1. those that seek to understand what influences the formation of relational ties in a given population (ex: having thee same major) 2. those that consider what influences that the structure of ties has on shaping outcomes. possible implications of SNA: the importance that randomly determined relationships can have on a student's experiences ex: a randomly selected roommate or lab partner.   Basic concepts and terms in SNA:  SNA aims to understand the determinants, structure, and consequences of relationships between actors.    helps to understand how relationships form   what kind of relational structures emerge   what, if any, the impacts are of these relationships on actors   Network types:     By # of actors:   unipartite/monopartite - contain only one actor (ex: students) bipartitie (two mode) are also possible (links actor to groups)   By nature of the ties they contain:  undirected network - ex: a network of students studying w/one another directed network - ex: Student A thinks student B is smart, but student B does not think student A is smart, then directed network.   Ties can be binary or valued:  binary - whether or not the relation exists. valued - additional quantitative information about the relation.     Network Data Collection:      time frame for data collection:   Measuring and analyzing dynamic networks may be challenging because the set of actors in a classroom is mostly static, but the relationships may change over the course of a semester (or whatever time period). High-quality census networks are rare, due to the exhaustive nature of the data collection, as well as the need to bind the data in a reasonable way.   Network level concepts and measures.      Network analysis entails numerous concepts and measurements. Example: network density         Social selection vs. social influence      social selection - occurs when a relationship is more likely to occur due to two actors having the same attributes. social influence - occurs when individuals change their attributes to match those of their relational partners, due to influence from those partners.   Homophily - a propensity for similar actors to be disproportionately connected in a relation of interest.      we can see homiphily by gender, ethnicity, GPA, office-hours attendance, or any other characteristic that can be similiar between two students.      reason to study homophily?      social support in classrooms are more likely to be seen between stuents with similar backgrounds and having sufficient social support that is important for STEM retention.       dyad-level analysis - analyzing the ties between two individuals independently. transitivity - (same as math) Cetrality      can be measured by:  degree closeness betweeness eigenvector cetranlity      Network Methods: Data Collection:  can collect data using sureveys - designing these effectively is challenging.      survey fatigue      ",7,3,4,4
"850","Knowledge tracing: Modeling the acquisition of procedural knowledge","The goal of the research was to implement a simple student modeling process that would allow the tutor to monitor the student's knowledge state and tailor the sequence of practice exercises to the student's needs."" ""Successful evaluations led us to:  abandon an initial ideal student model and to model a sufficient set of rules, to model difference in rule difficulty  to model individual differences among students in learning and performance. The resulting model predicts student performance quite well and enables most students to reach a high level of task performance.  The article talks about the use of a programming smart tutor and its effectiveness on student learning in a self-paced environment, (Like Khan Academy?)  ",6,0,6,3
"851","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","3DM = Data driven decision making. It's all the rage these days. 3DM is what's up. Teachers/administrators and districts use stqandardized test scores for this. This not only supports the students learning trajectory, but also helps drive instruction in the classroom. This has high value for teachers. Customize learning. However, sschools are flooded with data from test scores, to periodic, formative, summative, benchmark etc. etc. assessments. What is often overlooked in 3DM is teacher given scores. The study conducted here combines these two types of 3DM. The article goes on to talk about how this is done, the method, results and visualization. The main goal of this study is to present hierarchical cluster analysis (HCA) and visualization techniques as a useful method for the organization and pattern analysis of large sets of school and district data to aid data driven decision  making  (3DM).  ",1,2,-1,3
"852","CLA: Chapter 5: Predictive Modeling in Teaching and Learning","Predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic acheivement. Predictive analytics aqre a group of techniques used to make inferences about uncertain future events. Predictive Modelling Workflow:  Problem identification - The intent of the predictive modelling activity is to set up a scenario that would accurately describe the outcomes of a given student assuming no new intervention. For instance, one might use a predictive model to determine when a given individual is likely to complete their academic degree. Data collection - In predictive modelling, historical data is used to generate models of relationships between features. One of the 1st acitivies for a researcher is to identify the outcome variable. Classification and Regression - In statistical modelling, there are generally four types of data considered: categorical, ordinal, interval, and ratio. Feature Selection - In order to build and apply a predictive model, features that correlate with the value to predict must be created. When choosing what data to collect, the practitioner should err on the side of collecting more information rather than less, it may be difficult or impossible to add additional data later, but removing information is typically much easier.  Methods for Building Predictive Models  Linear Regression Logistic Regression Nearest Neighbours Classifiers Decision Trees Naive Bayes Classifiers Bayesian Networks Support Vector Machines Neural Network Ensemble Methods ",4,7,-3,3
"853","Chapter 5","Predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic acheivement. Predictive analytics aqre a group of techniques used to make inferences about uncertain future events. Predictive Modelling Workflow:  Problem identification - The intent of the predictive modelling activity is to set up a scenario that would accurately describe the outcomes of a given student assuming no new intervention. For instance, one might use a predictive model to determine when a given individual is likely to complete their academic degree. Data collection - In predictive modelling, historical data is used to generate models of relationships between features. One of the 1st acitivies for a researcher is to identify the outcome variable. Classification and Regression - In statistical modelling, there are generally four types of data considered: categorical, ordinal, interval, and ratio. Feature Selection - In order to build and apply a predictive model, features that correlate with the value to predict must be created. When choosing what data to collect, the practitioner should err on the side of collecting more information rather than less, it may be difficult or impossible to add additional data later, but removing information is typically much easier.  Methods for Building Predictive Models  Linear Regression Logistic Regression Nearest Neighbours Classifiers Decision Trees Naive Bayes Classifiers Bayesian Networks Support Vector Machines Neural Network Ensemble Methods ",4,7,-3,3
"854","Predictive modelling in teaching and learning","Brooks &amp; Thompson, 2017 Notes  A chapter introducing predictive analytics. Predictive analytics are techniques to ""make inferences about uncertain future events"" p.61 Explanatory modelling the aim is to explain an event/ trend in the past using all available data already collected. It is ""post-hoc and reflective"" p.62  Usually, the ""intent of these explanation is generally to be causal"" p.61 Data ususally collected from a sample and aim is to generalize. Not necessarily implemented to result in changes in interventions etc   Predictive modelling is to create a model to predict the values/ class of new data based on observations. p.61  Assumes known data can be used to train a machine to predict new data. It is ""in situ"" and designed to lead to changes. More action-focused and designed for real-time use p.62 Datasets are often split into two, with one used for training and a second ""hold out"" set used to evaluate effectiveness of a model.   ""the principal difference...is with the application of the model to future events, where explanatory modelling does not aim to make any claims about the future, while predictive modelling does."" p.62 Predictive modelling best used:  Quantifiable characteristics of the phenomenon/ problem in focus. Understanding of goals and what the output looks like. Large dataset. ""recurring need"" where you can accurately use past data to predict future data. I.e. data will also exist in the future.   Steps to do predictive modelling:  Identify outcome variable. Identify the suspected correlates of this variable. Often you'll have to do feature selection on the dataset, since it can be large and complex.  Look at correlation between variables and remove highly correlated variables (avoid multicollinearity). p.63   Deal with missing data- different options with different implications/ affects. p.64 Choose algorithm. Lots of options- good overview p.64.  Linear regression. Logistic regression. Nearest neighbors classifiers. Decision tree. Naive Bayes classifiers. Bayesian networks. Support vector machines. Neural networks. Ensemble method.   Test the 'goodness fit'/ prediction accuracy of a model.  Recommend k-fold cross validation rather than having a 'hold out' set of data.     Classification algorithms are used to predict categorical values (categorical, ordinal data). Regression algorithms are used to predict numerical values (interval, ratio etc). ",7,9,-2,3
"855","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Liu &amp; Koedinger, 2017 Notes  Argue for explanatory models over predictive models in EDM for better ""interpretability and actionability of educational data mining efforts"".  Need to understand WHY the model has more accurate predictions. And WHY and HOW this affects instructional design. p.73   ""Explanatory models seek to identify interpretable constructions that are causally related to outcomes...they provide an explanation of the data that can be connected to existing theory. The focus is on why a model fits the data well rather than only that it fits well."" p.69 Authors focus on cognitive models which ""map knowledge components (i.e., concepts, skills, and facts;...) to problem steps or tasks on which student performance can be observed.""  This means you can infer about student knowledge based on performance on specific tasks. p.70 KC model or Q-matrix capture these knowledge components.   Talk about Difficulty factors assessment:  i.e. a harder task involves a knowledge component which is not required in an easier task. Authors find DFA is great for refining explanatory KC models to help improve instruction. p.71   Learning factors analysis:  ""searches across hypothesized knowledge components drawn from different existing KC models, evaluates different modesl based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model"". Reduced human effort and increases interpretability   Key characteristics of explanatory models pp.73-74:  ""clean"" independent variables- i.e. neatly delineated constructs or simple functions. Usually ""feature representations motivated by interpretable, theoretical frameworks"" are the best for turning raw data into data to be analyzed via machine-learning. To support actionability, the dependent variable should map onto a ""well-defined construct"". Tend to have less parameters and independent variables/ features (to support interpretability and ensure the explanatory power is greater). Interpretability is required, basically: ""'this 'human-in-the-loop' feature leads the results of such modelling efforts to be explanatory."" p.72  Using human effort first helps and then the data-driven element reduces any biases. ""Methods such as LFA leverage both the unique strengths of human involvement and of automation towards creating models that are more predictive and explanatory."" p.73     ",11,2,9,5
"856","Bayes or bootstrap? A simulation study comparing the performance of Bayesian Markov chain Monte Carlo sampling and bootstrapping in assessing phylogenetic confidence","Zheng, 2015 Notes  Evaluation metrics are used in machine learning. This chapter looks at supervised learning models evaluation metrics.  Classification  Classification metrics: predicting class labels based on data provided. Can be binary or mult-class classifications. Classification performance can be measured using: accuracy, confusion matrix, log-loss, AUC, and precision-recall. Accuracy: measures ""how often the classifier makes the correct prediction"".  Correct predictions divided by total number of predictions. Makes no distinction between classes i.e. how accurate was prediction in class 1 versus class 0.   Confusion matrix: allows you to look at prediction accuracy by class. Rows of the matrix correspond to actual data truths, and columns represent the prediction. Per-class accuracy: average accuracy within each class (macro-average). If classes are imbalanced, accuracy distorts the picture and per-class accuracy takes this into account.  But if this imbalance is very large, the variance is large and the estimate won't be as reliable. Also, the average ""obscures the confidence measurement of individual classes"".   Log-loss: is a measure of accuracy which also draws on probabalistic confidence. Use when the output is a numeric probability instead of binary class labels p.9  Log-loss helps identify the additional noise that occurs when using predictors rather than actual data. The algorithm minimizes cross entropy to ""maximize the accuracy of the classifier"" p.10   AUC- area under the curve: curve is the ROC curve which shows you ""how many correct positive classifications can be gained as you allow for more and more false positives."" p.10  AUC helps to summarize the ROC curve into a number, to support comparison. A high AUC is good, and low AUC is less good.   Precision-recall: a ranking metric that can be used for classification tasks.  Precision: of all the items predicted to be relevant, how many are actually relevant? Recall: of all the items that are actually relevant, how many are found by the rank/ classifier? Think of each as a circle in the venn diagram and the overlap as the 'best answers'. Can average the precision and recall scores to get something similar to accuracy per class.    Ranking  Can encompass some binary classification before ordering by assigning a number score to all items rather than a category label. ",11,1,10,5
"857","Knowledge tracing: Modeling the acquisition of procedural knowledge","Corbett &amp; Anderson, 1995 Notes  Authors are looking at an ACT Programing Tutor and implement a model that allows the tutor to track the students' knowledge state and then tailor following content for the student to practice and work towards knowledge mastery.  This is referred to as a knowledge tracing process.   The authors built a model to assess the students' knowledge state based on previous performance and predict performance from that. Their model predicts performance relatively well and the support given to students to work towards mastery helps them to reach a high level of performance. The authors think by changing incentives in the APT, students might even perform better. ",6,0,6,3
"858","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data itself is crucial, so is Data visualization. Sometimes, we don’t think the importance of data in education. Students are the future of the world, and education is the only tool leading them to become an elite. I think it is also useful to include average when comparing with other schools, and also the its own average when comparing with previous records.",2,0,2,2
"859","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","good article",1,0,1,2
"860","Why Students Should Own Their Educational Data","Cause they can analyze how they learning a new course.",0,0,0,5
"861","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","As I mentioned before, we never think the importance of data in educational fields. I think it is great that two organizations are aiming the best for quality and equality in education. And I think it is the best to bring awareness to let the world know that education matters through data, and also to encourage more scholars to devote themselves in creating a better environment in education.",4,0,4,2
"862","Evaluating Machine Learning Models","How I think about a data scientist is somewhat differ than the author. I believe data scientists are experts in coding and machine learning, but what’s more important in a data scientist is that the ability to corporate the data itself, with visualizing, and tightly combined with industry. The overall goal for data scientists is to deliver a relevant message with data for the certain industry with languages that could be understand by people with no prior coding knowledge.",0,0,0,2
"863","Why Is Measuring Learning So Difficult?","Interesting video",0,0,0,4
"864","Saturday Morning Breakfast Cereal","From the comics, it is sad that we are trying to turn the children into something that they are not. People who work in educational fields should really take children’s interest into account.",1,1,0,2
"865","The Data Wrangling Cheatsheet","What I like the most of R is that it has lots of useful packages and cheat sheets we can find online. The dplyr package is especially useful when we try to select the data partly. Because in real life, not every data we gathered are relevant to conduct our research.",1,1,0,1
"866","Zuckerberg is ploughing billions into 'personalised learning' – why?","I agree with personal learning is an important way to success.",1,0,1,2
"867","Feature Selection","From the video, it is clear that catching the key words will be useful for any business, and we can achieve that by word cloud or other machine learning. Not only in data world, we also key words and main idea are the most useful content in daily life.",1,1,0,2
"868","RStudio Cheat Sheets","I always think of R as the most important and useful coding language. Not only because of the abundance packages in r to provide us with beautiful graphs, but also, we are able to code python in r. And also, we can find so many useful information online for FREE.",1,0,1,1
"869","Translating Learning into Numbers: A Generic Framework for Learning Analytics","agree",0,0,0,2
"870","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","I think it is great that people are making effort to achieve a successful online platform. I believe the platform will benefit lots of students world-wide. The only thing is that we should keep track of the data, and potential keep track the students after they done online platform.",3,0,3,2
"871","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","I admire the outcome of the study, but we still need to think about other ways to make online course more effective. My suggestion is that to find out when people exist the online platform, and potential reasons behind it. Just as business owners care about bounce rate and etc.",1,0,1,5
"872","Chapter 1: Social Network Data","Nowadays, we are immersed in the world of internet with numerous social media platform. I don’t think the different social platforms hinders data analysis, but the core thing we need to do is to match the same user on different platforms to create a complete user profile.",0,1,-1,2
"873","Learning Analytics Dashboards","Reading the article really makes me happy that the progress we achieved in the past ten years in educational learning. And I am proud of myself in the field that is able to make the world in a better place especially for education. Looking forward to the conference!",3,0,3,2
"874","Measurement and its Uses in Learning Analytics","From the reading, I totally agree with the author’s point on “claims analysis”. Because at the end of the day, data modeling and data visualizing are meant to tell the audience what we learned from the data in a meaningful way – that is to tell the audience what they really want to get from the data.",0,0,0,2
"875","Predictive Modelling in Teaching and Learning","From the reading, I totally agree with the author’s point on “claims analysis”. Because at the end of the day, data modeling and data visualizing are meant to tell the audience what we learned from the data in a meaningful way – that is to tell the audience what they really want to get from the data.",0,0,0,2
"876","Ethics and Learning Analytics: Charting the (Un)Charted","From the reading, I agree that we don’t have much privacy in browsing internet world. But from a data analyst perspective, we need users data to create useful content. I always think this as we always have to give up something in order to gain the access to the other. As long as there is regulation to ensure the legit use for those data, I think it is normal to share our privacy.",1,0,1,2
"877","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","I agree that the first step in any model rebuilding process is to make sure what is the outcome that we want to study. But why limit ourselves? In educational research, every detail matter, and I believe it is the best that we explore the data under different concepts and using different methods to fully understand the data for students.",1,1,0,2
"878","Junkcharts Trifecta Checkup: The Definitive Guide","I totally agree with the author’s point. Regardless what we create, the important thing is to make our audience understand our model and research question. To think from an audience perspective, it is easier to achieve the goal this way.",1,0,1,2
"879","Measurement and its Uses in Learning Analytics","Before measurement, start thinking about:epistemology — what and how are we measuring? Pedagogy — why is this knowledgeimportant to us and who is the analytics for? Assessment — where does theassessment happen? When does theassessment, and feedback, occur?",0,0,0,2
"880","Ethics and Learning Analytics: Charting the (Un)Charted","Ethical concerns raised after the emergence of learning analytics.",0,1,-1,2
"881","Predictive Modelling in Teaching and Learning","The purpose of predictive modelling is to create a model that will predict the values or class of new data based on observed variables so that the systems can be responsive to new changes. The general steps of predictive modelling is as follows: problem identification (research questions will set up prediction goals as well as requirement of data type and further analyses), data collection, classification and regression, feature selection (choose features that correlate with the value to predict), and model evaluation.",1,2,-1,3
"882","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","    Explanatory or predictive purpose determine the type of approaches to statistical modelling of educational data. For an explanatory models, it's important to understand why the model achieves better predictive accuracy than alternatives and why should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both.    ",3,0,3,5
"883","Statistical graphics: making information clear – and beautiful","Beautiful and informative information visualization are made with deliberate design by considering key questions such as: Who is your target audience? What are you trying to show? Moreover, there are a set of general guidance: Keep the x- and y-axes on the same scale; eliminate repetitive information; maintain consistency across plots. ",1,0,1,2
"884","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","A set of goals for data visualization: Discovery goals, including giving an overview, conveying the sense of the scale and complexity of a dataset, and exploring different aspects of data; Communication goals, including communication to self and others, storytelling, and attracting attention and stimulating interest.",0,1,-1,2
"885","Junkcharts Trifecta Checkup: The Definitive Guide","A checklist for data visualization: What is the question? What does the data say? What does the visual say?",0,0,0,2
"886","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","The study aims to introduce hierarchical cluster analysis and pattern visualization methods to identify student dropout from student K-12 longitudinal grades. The clustergram allows for the visualization and interpretation of every data point, which shows each student's data pattern.",0,1,-1,3
"887","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","The paper used Social Network Analysis (SNA) to understand the formation of learning relationships and how they affect learning outcomes. Three kinds of analyses were performed: : descriptive analysis of the network, exploration of network evolution, and analysis of network position as a predictor of individual outcomes. The case study is a 10-week  introductory biology course of 187 students with significant amount of guided student–student interaction. The data collected included who students studied with for the first three exams, all of their class grades, the lecture and lab sections to which they belonged, and general demographic information. Sociographs allow us to look at structural changes in network over time in terms of number of connections, high transitivity and trends toward triads. Moreover, we can examine the effect  of social interactions (measured by degree centrality and betweenness centrality) on learning outcomes (measured by exam scores) by integrating student performance data with network data. There are more complex models of network formation we can adopt.",0,1,-1,4
"888","Why Students Should Own Their Educational Data","Mr. L. Todd Rose at Harvard University believes that technology can inform educators of detailed data about individual learner and customize teaching material accordingly so as to realize every one's potential. He thinks that analyzing individual patterns instead of aggregate data can generate more insights. Patterns of learning derived from overall population can not be applied to each individual. Nowadays with more data on learners, researchers can model an individual and look for personal patterns across dimensions. Since researchers have found that learning varies across contexts, it's essential to build contextualized profile of learner's performance. Therefore, Mr. Rose proposes that the students should own their data. Right now the education industry is not transparent enough and the companies owns the user data as part of their business model. Mr. Rose and his nonprofit organization Center for Individual Opportunity aim to protect learner data. Author: Minruo WANG Email: mw3399@tc.columbia.edu",3,0,3,2
"889","Knowledge tracing: Modeling the acquisition of procedural knowledge","The study sets up an ideal student model and trace knowledge gained by students by comparing their performances to the model. In this way, tutoring can bee standardized and given automatically based on student's performance. Currently the model is quite successful in predicting test performance.",3,0,3,3
"890","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","With the emergence of unique types of big data from educational settings, it's promising to develop and adopt data-intensive approaches to education. Gaining insights into educational activities through analytics help to better understand the learners and the settings around them, as well as optimizing learning process and the corresponding environments. Two research communities, Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK), have developed in response to reach the goals above. Specifically speaking, both EDM and LAK strive to improve education by improving assessment, how problems in education are understood, and how interventions are planned and selected. Evidence from educational institutions have also validated the importance of applying insights from data to planning, interventions, and decision-making. Despite the overlapping areas, the distinctions between the two communities remain evident. EDM arises from educational software and student modeling. And LAK stems from semantic web. Due to different origins, EDM prioritizes automated discovery and adopts a reductionist view of reducing phenomena and analyzing individual components, while LAK emphasizes more on leveraging human judgment and embrace holistic analysis of the whole system. Although both of them are composed of inter-disciplinary backgrounds, EDM often use techniques from computer science and LAK combines sociological, psychological, pedagogical methods. Still, different values and methodologies in each community can spur creativity and growth. It also calls for more communication and collaborations for the greater benefits of educational research and practices. The authors suggest the two communities to institutionalize the dissemination of research to the industry and establish cross-community ties. Author: Minruo WANG Email: mw3399@tc.columbia.edu",4,1,3,2
"891","Evaluating Machine Learning Models","The steps of machine learning: problem identification, partition the data into training, test and validation, model training, model buildup using combination of hyperparameters, model selection based on evaluation metrics.",0,1,-1,5
"892","Why Opting Out of Student Data Collection Isn’t the Solution","Students have the right to choose their data not to be collected or used. The ""opt-out"" right is protected by privacy law such as Fair Information Privacy Principles (FIPPS). It requires data collectors to specify the purpose of collecting data and seek informed consent for collecting and using the data. The primary purpose for schools to collect and use student data is to improve education and address areas of concern, therefore satisfy the needs of all students. If the students opt-out, the absence of their needs and performances will cause risks for schools to provide good education. For purposes secondary to the functioning of our educational system, parents have the right to opt-out data usage. Policymakers should address the concerns of different parties by considering privacy rights of parents and students, as well as data-informed decisions of the school administrators. Author: Minruo WANG Email: mw3399@tc.columbia.edu",8,3,5,2
"893","Why Is Measuring Learning So Difficult?","Since learning consists of cultural and psychological constructs embedded in social context, it's hard to measure such multidimensional thing in a meaningful way. Some of the difficulties lie in finding reliable, simple proxy indicators of learning that people trust and assessing people's competency at different time points. It's easy to oversimplify the learning process so as to capture information from statistics. In addition, analytics should enforce learners to reflect and narrate on their own connected learning experience. Author: Minruo WANG Email: mw3399@tc.columbia.edu",2,2,0,1
"894","Saturday Morning Breakfast Cereal","Learning should be motivated by curiosity. Once learning approaches are standardized, it will hinder the realization of personal potentials for those who don't fit with the method. Author: Minruo WANG Email: mw3399@tc.columbia.edu",0,1,-1,2
"895","Data wranglers: human interpreters to help close the feedback loop","Establishing a Community of Practice in learning analytics.",0,0,0,2
"896","Zuckerberg is ploughing billions into 'personalised learning' – why?","Chan Zuckerberg Initiative funds US$45 billion in personalized learning. Zuckerberg's definition of personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”. However, it ignores the aspect of acquiring general knowledge and the context of learner's preferences - the social interaction between students and teachers as well as the environment. In addition, it may not be good for learners to adjust to inappropriate ways of learning in the future. Moreover, privacy concerns arise in the collection and usage of student data. There are different models of personalized learning. For example, AltSchool collects learning data and tailor content accordingly. Adaptive learning platform such as Pearson and Smart Sparrow combine user data with standard educational content and adapts all topics to a learners’ pace. McGraw Hill also adopts customized study plans where courses are modified according to the teacher’s knowledge and experience of what fits the students best. Despite the risks of personalized learning, it holds promise if considering both needs of children and teachers in education, which takes time, conversation and collaboration beyond technology. Author: Minruo WANG Email: mw3399@tc.columbia.edu  ",5,2,3,2
"897","Feature Selection","Two major reasons of feature selections are knowledge discovery - only some features are important for solving the prediction problems we care, and curse of dimensionality.",0,1,-1,5
"898","Chapter 1: Social Network Data","The conventional data structure with observations as rows and attributes as columns allow researchers to compare how actors are similar or dissimilar to each other across attributes, or examine how variables are similar or dissimilar to each other in their distributions across actors. Social network data also has observations as rows, but what distinguishes ""network"" data from conventional data is that its columns describe a relationship between the actors (e.g. friendship, same courses taken). The fundamental difference behind is seeing a structure of connections within the actors. In other words, actors are described by their relations instead of attributes. The different emphasis of network  research influences the research design, sampling, measurement, and interpretation. As a result, there are two major emphasis of conducting network analysis on such data structure. Firstly, locate the position of actors in the overall network. Secondly, conclude holistic patterns from the whole pattern of individual choices. Author: Minruo WANG Email: mw3399@tc.columbia.edu  ",0,0,0,4
"899","RStudio Cheat Sheets","Note that SQL can also be integrated into R Markdown file.",0,0,0,1
"900","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","The study contributes to the literature on examining the effect of Intelligent Tutoring System and predictive modeling in education. The paper used logistic regression and data from 3,747 students in New England using educational software over the course of a year of middle school and found that a combination of features of student engagement and student success in ASSISTments can distinguish a student who will enroll in college 68.6% of the time.",1,1,0,3
"901","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Learning Analytics arises from the context of Technology-Enhanced Learning(TEL). LA can offer new methods and tools to diagnose learner's needs and provide personalized instructions to better address their needs. The paper proposed a design framework of learning analytics. Six dimensions of the proposed LA framework are: stakeholders, objectives, data, instruments, external constraints, and internal limitations. LA designer can address pedagogical concerns through setting goals and objectives. Pedagogic behaviors or intervention is the input of LA design and pedagogic consequences is the output.",1,2,-1,1
"902","The Big Five and Visualisations of Team Work Activity","Social interactions will occur under certain environment. Therefore it's important to scrutinize its social and psychological dimension. The paper applies “Big Five” model to study the components of teamwork and how it will affect work effectiveness. The path from teamwork to effectiveness will be mediated through shared mental models, mutual trust, and closed-loop communication. The paper draws visualizations of the components of teamwork, however, they do not show how a group or a team member should perform. In the meantime, a qualitative analysis revealed a number of relations between patterns observable in the visualizations and team performance.",3,0,3,2
"903","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","The paper adds to the literature on the empirical evidence of the effect of Teaching Recommender System. As a result, the students gains significant amount of knowledge due to efforts devoted. In addition, only those who have intention to complete the knowledge tests and complete the course.",2,0,2,4
"904","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Mapping items to latent skills is one of the hardest part of measurement. The study showed that the factorization approach performs slightly better than the original expert Q-matrix.",2,0,2,5
"905","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","The study contributes to the literature on using statistical tools to find the key determinants of completion of an online course. The study showed thateEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. ",3,0,3,5
"906","Using data mining to predict secondary school student performance","The paper used Business Intelligence/Data Mining techniques to answer two questions in education: Is it possible to predict student performance? What are the factors that affect student achievement? The study predicted secondary student grades of two core classes (Mathematics and Portuguese) by using past school grades (first and second periods), demographic, social and other school related data. The prediction models have three Data Mining goals: i) binary classification (pass/fail); ii) classification with five levels (from I very good or excellent to V - insufficient); and iii) regression, with a numeric output that ranges between zero (0%) and twenty (100%). Models were evaluated using higher Percentage of Correct Classifications (PCC) in classification and lower Root Mean Squared (RMSE) in regression. Four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) were used. Also, distinct input selections (e.g. with or without past grades) were explored. The results showed that it is possible to achieve a high predictive accuracy with the first and/or second school period grades, indicating that student achievement is highly affected by previous performances. However, in some cases, there are other relevant features, such as: school related (e.g. number of absences, reason to choose school, extra educational school support), demographic (e.g. student’s age, parent’s job and education) and social (e.g. going out with friends, alcohol consumption) variables.",6,3,3,3
"907","Developing a generalizable detector of when students game the system","The study of developing detectors of gaming behavior contributes to the literature on the development of detectors of other types of behavior.",0,0,0,5
"908","Big Data in Education","http://www.columbia.edu/~rsb2162/bigdataeducation.html A guide to understand the emergence of learning analytics with basis in big data in education.  ",0,0,0,2
"909","Cross Validation","The purpose of cross-validation is preventing over-fitting when the sample size is too small and find appropriate model parameters. The method is to randomly partition the sample data into training set and cross validation set. Train the model based on training set and evaluate model performance on cross validation set.",0,0,0,5
"910","Hands-On Programming with R","Use the book to fill in the gaps of programming with R.",0,0,0,1
"911","Principal Component Analysis explained visually","Usually the 2D data will not be fitted on a linear line. A point can be expressed by linear combination of two orthogonal basis e1, e2. Since the distance from the point to origin point is constant, i.e. d2 = x2 + y2, if x is higher, then y is lower. In other words, if there are more variation in x-axis, then pc1 is the x-axis.",0,0,0,3
"912","Zuckerberg is ploughing billions into 'personalised learning' – why?","-personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. - human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests-using algorithms to feed information to kids can go wrong and produce uneven development, neglecting ""general"" areas-this article looks at personalized learning as running opposite to using teachers, but I really view the two as complementary approaches-data privacy is a issued with personalized learning",1,3,-2,2
"913","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","-Prof Bowers presents a novel way of visualizing and patterning data to help schools make certain decisions about their students -this is done with hirearchical cluster analysis this method correctly identified over 80% of students who dropped out -He uses teacher grades, data that is already widely available, to build a model to improve student outcomes -HCA doesnt summarize or aggreagte the data in any way, but models longtudinally off of the raw data -it draws from multivariate statistics, where it relies on interclass correlations to first reorder the data by likeness and then contstruct a dendrogram, a cluster tree",3,0,3,3
"914","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Network basics-SNA aims to understand the determinants, structure, and consequences of relationships between actors-Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.Network Types. -One way to categorize networks is by the number of types of actors they contain. Networks that consist of only one type of actor (e.g., students) are referred to as unipartite (or sometimes monopartite or one-mode). -While notdiscussed in detail here, bipartite (or sometimes two-mode) networks are also possible, linking actors with the groups to which they belong.-a unidirectional network is one where the ties between nodes are inherently unidirectional-a directed network has bidirectional relationships-ties can also be binary (exist or not) or encode other quantiative information, valueddata-usually collected in specific interval of time, as networks are ever changing-""cross-sectional"" realization-how to sample from a population. Egocentric studies focus on a sample of individuals (called “egos”) and the local social environment surrounding them without explicitly attempting to “connect the dots” in the network further -At the other end of the spectrum, census networks, sometimes referred to as whole networks, collect data from an entire bounded population of actors -high quality census networks are rarenetwork levels concepts-density: measurement of how many links are observed in the whole network divided by the total number that could exist if all were connected-usually small and vary by type and size of network-homophilt - are similar actors more likely to be connected to each other?-this is like social selection-tansitivityactor-level variables-Degree centrality represents the total number of connections a node has. -Betweenness centrality focuses on whether actors serve as bridges in the shortest paths between two actors",2,0,2,4
"915","Why Students Should Own Their Educational Data","-Professor Rose belives in using the science of the individual to study learning and development-he gave a great example of the colin cancer-you draw inferences from a sample, but we are dealing with the population. Model at the individual level.-the idea of jaggedness implies we all vary in all of our trains, no one is average",1,2,-1,2
"916","Knowledge tracing: Modeling the acquisition of procedural knowledge"," - This paper describes an effort to model students' changing knowledge state during skill acquisition- In this paper we attempt to bring a cognitive model of skill acquisition to bear on the goals of mastery learning.- This theory assumes a fundamental distinction between declarative knowledge and procedural knowledge. Declarative knowledge is factual or experiential- As described earlier, the learning assumptions of ACT-R are complex. - The student acquires both goal-independent declarative knowledge and goal-oriented procedural rules. With practice, both declarative and procedural knowledge are strengthened in memory and student performance grows more reliable and rapid (Anderson 1993). ",3,1,2,3
"917","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Both EDM and LA are responses to big data and advance of computingEDM-first workshop in 2005-first jounral in 2009-International Education Data Mining Society (IEDMS) formed in 2011-EDM community brings together an inter-disciplinary communityof computer scientists, learning scientists, psychometricians, andresearchers from other traditions- The International Educational Data Mining Society definesEDM as follows: “Educational Data Mining is an emergingdiscipline, concerned with developing methods for exploring theunique types of data that come from educational settings, andusing those methods to better understand students, and the settingswhich they learn in.”Learning analytics-first conference in 2010-""The conference explicitly emphasized its role asbridging the computer science and sociology/psychology oflearning in declaring that the “technical, pedagogical, and socialdomains must be brought into dialogue with each other to ensurethat interventions and organizational systems serve the needs ofall stakeholders""-The Society for Learning Analytics Research defines LearningAnalytics as: “… the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes ofunderstanding and optimizing learning and the environments inwhich it occurs.”  Similarities- LAK and EDM share the goals of improving education by improvingassessment, how problems in education are understood, and howinterventions are planned and selected. Differences-EDM is all abotu automation, LA sees this a tool-EDM is more about the individual, LA about the whole system-EDM origins in software and prediction, LA about this and systemaic interventions-EDM focus on automation and personalized adaptation, LA about empowerment-EDM:-LA: Social networkanalysis, sentimentanalysis, influenceanalytics, discourseanalysis, learnersuccess prediction,concept analysis,sensemaking models",1,2,-1,2
"918","Evaluating Machine Learning Models","-Evaluation metrics are used to evaluate machine learning tasks, differnt metrics exist for different tasks-classifaction, regression, ranking, clustering, topic modeling all have different metrics-classification, regression and ranking are examples of supervised learning-has great information on accuracy,-confusion matrix formulates the true positive, true negatice, false pos, false neg matrix-accuracy masks the per class predictions by averaging them together-there is also per-class accuracy-log-loss considers how close an inccorect prediction was to the threshold of being correct-can only be used on methods that return probabilities, not 1 or 0-AUC- Area under the curve, the curve is the receiver operating characteristic curvey, or ROC-AUC basically summarized the ROC curve into a single number-ranking metrics can use precision-recall-Precision answers the question, “Out of the items that the ranker/classifier predicted to be relevant, how many are truly rele- vant?” -Whereas, recall answers the question, “Out of all the items that are truly relevant, how many are found by the ranker/classi- fier?”-regression deals with numeric prediction-room mean square error, which is basically the residual mean square, is the most common way of assessing model adequacy-the median absolute percentage is suggested as an alternative as it is more robust when there are outliers present",3,3,0,5
"919","Data wranglers: human interpreters to help close the feedback loop","Data wranglers: human interpreters to help close the feedback loop-Previous work in the literature has emphasised the need for and value of human meaning-making in the process of interpretation of data to transform it in toactionable intelligence.-Learning analytics is widely seen as entailing a feedback loop, where ‘actionable intelligence’ [7] is produced from data about leaners and their contexts, and interventions are made with the aim of improving learning - multidisciplinary teams, with a key role played by humans in interpreting the data, engaging in sense-making activities to mediate the information in ways that enable intelligent action-“will be institution-wide efforts” [4], with careful consideration given to how they will interact with educational systems, leaders and other stakeholder-culture of data use, community of practice-learning analytics system may be used simply to attempt to achieve set goals (single-loop learning); greater value and insightill come if those goals themselves can be interrogated, challenged, and developed (double-loop learning)-this report covers data wranglers deployed to created some repoirts with actionable recommendationsThe Data Wranglers work with four main data sources:-Survey feedback data from students, gathered at the endof their course.-Activity data from the VLE/LMS (Moodle).-Delivery data about the mode of delivery and structureof courses (e.g. what use each course makes of onlineforums).-Aggregated completion, pass rate and demographicdata.-In practical terms, data from these sources is aggregated using a SAS data warehouse, and exported to a Tableau workbook for each Faculty. -To help make sense of the data, the Data Wranglers develop an understanding of the particular situation of the Faculty they are working with, building up relationships with key stakeholders to enable the reports to focus on areas where they can be of most value -The reports form the basis of an ongoing conversation with the Faculty about feedback on the learning experie-The role of the Data Wrangler is not only to analyse the data, but to increase the familiarity of academics with the data sources, to build learning analytics capacity as part of a Community of Practice",3,0,3,1
"920","Translating Learning into Numbers: A Generic Framework for Learning Analytics","NotesAbstract- In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. -We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency.- In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency.Introduction-recent explosion of data-data mining is similar to observational data, it is obtained in a highly non-insaive mannerCritical dimensions of LA-there are a number of ""softer"" issues in LA: ownership and openness, ethical use and dangers of abuse, and the demand for new key competences to interpret and act on LA results-they propose 6 critical dimensions of LA needed to make is successul-their model includes more soft issues, like the assumptions about people we make, ethics, etc.1: internal limitations2: external constraints3:instruments4: data5: objectives6: stakeholdersstakeholders-data clients (teachers) and data subjects (learners), also institutionsobjectives-reflection:  critical self-evaluation of a data client as indicated by their own datasets in order to obtain self-knowledge-prediction: predicting and modelling learner activities, can lead to intervention or adaptive services or curricula Instruments-in the broadest sense “translate” raw data into informationexternal constraints- ethical, legal, and social constraints, but also to feature organisational, managerial, and process constraints. internal limitations-competences and acceptance",12,14,-2,1
"921","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","They look at the effects of learning in a MOOC-The main predictor of knowledge gain was effort expended in the course-Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete-they used a non-equivalent control group design, and since ppl selected into the experiment randomization was not possible-",1,1,0,4
"922","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","-Matsuda et al write about the possibility for automatically determining which skills must be mastered for successful completion of online courses-its interesting, their machien learning approach beats models built by people-their solution is cheaper and faster as well, meaning it is probably scalablebuilding a skills model-requires multiple low stakes formative assessments to assess target skills-each formative assessment must have multiple items, associated with one or more skills-need a skill map, or Q matrix, to show how a student relates to certain skill areas-",10,0,10,5
"923","Chapter 1: Social Network Data","-social network analysts use a data format that is very different from the typical rectangular format-""Network"" data (in their purest form) consist of a square array of measurements. The rows of the array are the cases, or subjects, or observations.-the columns and rows are the same unit, like the individual or whatever is the focus in the social network-in this format, the cell describes the relationship between the actors in some regard-this form of the data allows one to see how certain actors are embedded in a wider network-But a network analyst is also likely to look at the data structure in a second way -- holistically. The analyst might note that there are about equal numbers of ones and zeros in the matrix. This suggests that there is a moderate ""density"" of liking overall. -The analyst might also compare the cells above and below the diagonal to see if there is reciprocity in choices (e.g. Bob chose Ted, did Ted choose Bob?)-holistic patterns are seen in network analysis-One can think of the rows as simply a listing of cases, and the columns as attributes of each actor (i.e. the relations with other actors can be thought of as ""attributes"" of each actor). -Indeed, many of the techniques used by network analysts (like calculating correlations and distances) are applied exactly the same way to network data as they would be to conventional data.-the network analysts see the connections holistically, the focus is on relationships-The difference in emphasis is consequential for the choices that a researcher must make in deciding on research design, in conducting sampling, developing measurement, and handling the resulting dataNodes-Actors: nodes-relations: edges-there is no focus on the individuals and their attributes, only their relationships-as a result network data is not sampled independently-the notes are the result of probability sampling-have whole population usuallt, not samples-""nested"" designs: Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks.-micro-relationships-sampling networks from wider populationsRelations (edges)-the other hald of social network data-many ways to measure edgesfull network: full network data give a complete picture of relations in the population-can be very expensive to get this type of data-snowball method: Each of these actors is asked to name some or all of their ties to other actors. Then, all the actors named (who were not part of the original list) are tracked down and asked for some or all of their ties. The process continues until no new actors are identified, or until we decide to stop (usually for reasons of time and resources, or because the new actors being named are very marginal to the group we are trying to study).-ego-centric: use focal points-in social network only a single piece of information is shared by each person/unit-scalues of measurement are similar to other data and can affect what techniques you can use-",5,0,5,4
"924","Learning Analytics Dashboards","Intro-Data mining plays to the strength of computers to do number crunching, while visualzation techniques play to the remarkable perceptual abilities that humans possess. The difference Data mining uses automatic-pattern matching for remote control while thedashboard provides visual communication to assist a human driver who remains in control of the vehicle.-human perceptual abiliteis are high, so we are better at finding clues form visualzations-visualzations lead to new questions, so the experince should be dynamic to allow an exploration of these oter-This second data source is evolving especially rapidly, with mobile devices that now include sensors to report physiological, emotional, and other kinds of learner characteristics that have so far mostly eluded automated capturing-Besides tracking, self-reporting can also be a valuable source of data-dashboards can include work artifacts, resource use, social interactions, time pent on tasks, test and self-assessmentsMaking a dashboard-intelligent systems help people make the right decision and try to empower them-who is the audience?-what is the goal? who is using it? why visualzation? what questions should the dashboard answer? how will visualzation support the goal? what will the visualzation show?-the main obstable is getting ""pre"" data to build it.-need raw data, analyzing raw data, preparing and filtering the datawainer",5,0,5,2
"925","Measurement and its Uses in Learning Analytics","NotesThis is a great source and talks comprehensively but breifly about measurement. A lot of good leads-educational measuremnet ""the bible""What is measurement-important facets of psychological measurement are raised in the process, namely its instrumentation or operationalization, the repeatability or precision of measurements, sources of error, and the interpretation of the measure itself-Psychological measurement is a process for making warranted claims about states of mind-As such, it typically comprises the following: defining a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcomeConstructs-We say that variables like physical length of an object are directly observed, or manifest, whereas a person’s mental states or psychological traits are only indirectly observed, or latent-The term construct is used interchangeably with latent variable, while trait is used to imply a construct that is stable over time -Math ability is then equivalent to a score on a math test, and extraversion is a score on a Likert-item questionnaire. This positivist attitude is reflected in Stevens’ definition of measurement as, “the assignment of numerals to objects or events according to rules” (-operationalism is rejected, for a construct would face a redefinition for every differnt instrument designed to measure it- Model-based reasoning means accepting a simplified representation of a system — for example, a construct-mediated relationship between persons and responses — that captures salient aspects (e.g., patterns) and allows us to explain or predict phenomena- some constructs are multidimensionalMeasurement instruments-typically called tests or questionnaires (surveys, inventories)-Scale implies that the test or questionnaire has been scored. -The use of tests and questionnaires is a matter of both efficiency and standardization, compared with the alternative of observing people in real life and waiting for them to spontaneously express thoughts or exhibit the behaviours of interest Sources of error in measurement-Statistical models allow us to think of items, indicators, or tests as random samples of a latent variable-The latent variable can be a random variable, or it can be fixed, as in true score theory-random vs systematic error (the later produces bias)Reliability-attributed to an instrument and is a measure of consistency of scores, it is the proportion of total variance accounted for by the latent variable-.7 is lower bound of acceptabiltyValidity- depends on use of test, not an attribute of test itselfMeasurement models- A measurement model is a formal mathematical relationship between a latent variable or set of variables and an observable variable or set of variables - A fully statistical measurement model may specify a distribution for the latent variable(s), a distribution for the observed variable(s), and a functional relationship between them.- The latent variables are often understood as causally explaining the observations, which are subject to errorsFactor analysis-Factor analysis (Mulaik, 2009) models the correlations among observed variables through a linear relationship to a set of latent variables known as factors-Factor analysis is commonly divided into two enterprises. Exploratory factor analysis (EFA) is used to determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development. - Confirmatory factor analysis (CFA) is a complementary set of techniques to test a theoretically proposed factor model by examining residuals between expected and observed correlations.Latent class and latent mixture models-topic modeling of categorical dataItem response theory (IRT)-Item response theory distinguished itself in the historical development of testing theory by modelling individual person-item interactions rather than total test scores, as in classical test theory-uses ICC curveGrowth models-Growth models apply any time a latent trait is changing systematically between measurements. -They can be applied to changing attitudes or IQ-in terms of cognitive ability, you can map their growth and plan their mastery sequence by patterning the approdiate learning modules after one anotherCognitive Diagnostic models-Q-matrix method and a model for diagnosing specific sub-skills-The Q-matrix is a discrete mapping of items to requisite sub-skills and is traditionally specified in the assessment mode-Goodness-of-fit tests evaluate the consistency between the observed data and the generating model to retain or reject the modelExplanation and prediction-",5,9,-4,5
"926","Predictive Modelling in Teaching and Learning","-this paper explores the topic of prediction in education, the whole process-First, it is important to distinguish predictive modelling, the goal is to use all available evidencesteps-identify DV and suspected correlates, only use data that you will have when using the model in real situations-classification algorithms exist for predicting categorical variables, regression handles numerical valuesmethods of prediction1. Linear Regression predicts a continuous numeric output from a linear combination of attributes.2. Logistic Regression predicts the odds of two or more outcomes, allowing for categorical predictions.3. Nearest Neighbours Classifiers use only the closest labelled data points in the training datasetto determine the appropriate predicted labels for new data.4. Decision Trees (e.g., C4.5 algorithm) are repeated partitions of the data based on a series of single in each partition.5. Naive Bayes Classifiers assume the statistical independence of each attribute given the classifications6. Bayesian Networks feature manually constructed graphical models and provide probabilistic interpretations of classifications7. Support Vector Machines use a high dimensional data projection to find the hyperplane of greatest separation between the various classes.8. Neural Networks are biologically inspired algorithms that propagate data input through a series of sparsely interconnected layers of computational nodes (neurons) to produce an output. Increased interest has been shown in neural network approaches under the label of deep learning.9. Ensemble Methods use a voting pool of either prominent techniques are bootstrap aggregating, in which several predictive models are built from random sub-samples of the dataset, and boosting, in which successive predictive models are the prior models.Evaluating model fit-prediction accuracy, precision, recall-crossvalidation, k-fold CV-",3,6,-3,3
"927","Ethics and Learning Analytics: Charting the (Un)Charted","notes-Although now becoming more established, ethics and the need to question how student data is used and under what conditions was very much a marginal issue in the early years of the field- A range of ethical issues was grouped within three broad, overlapping categories, namely: • The location and interpretation of data • Informed consent, privacy, and the de-identification of data • The management, classification, and storage of data Slade and Prinsloo (2013) proposed a framework based on the following six principles: 1. Learning analytics as moral practice — focusing not only on what is effective, but on what is appropriate and morally necessary 2. Students as agents — to be engaged as collaborators and not as mere recipients of interventions and services 3. Student identity and performance as temporal dynamic constructs — recognizing that analytics provides a snapshot view of a learner at a particular time and context 4. Student success as a complex, multidimensional phenomenon 5. Transparency as important — regarding the purposes for which data will be used, under what conditions, access to data, and the protection of an individual’s identity 6. That higher education cannot afford not to use data -debate around ""survellance""Learning analytics is an ethical practice that should align with core organizational principles, such as open entry to undergraduate level study. 2. The OU has a responsibility to all stakeholders to use and extract meaning from student data for the benefit of students where feasible. 3. Students should not be wholly defined by their visible data or our interpretation of that data. [This principle furthermore warns against stereotyping students and acknowledges those individuals who do not fit into typical patterns. The principle also makes it clear that members of staff may not have access to the full data set, which can seriously impact the reliability of the analysis.] 4. The purpose and the boundaries regarding the use of learning analytics should be well defined and visible. 5. The University is transparent regarding data collection, and will provide students with the opportunity to update their own data at regular intervals. 6. Students should be engaged as active agents in the implementation of learning analytics (e.g., informed consent, personalized learning paths, interventions). 7. Modelling and interventions based on analysis of data should be sound and free from bias. 8. Adoption of learning analytics within the OU requires broad acceptance of the values and benefits (organizational culture) and the development of appropriate skills across the organization. Learning analytics is an ethical practice that should align with core organizational principles, such as open entry to undergraduate level study. 2. The OU has a responsibility to all stakeholders to use and extract meaning from student data for the benefit of students where feasible. 3. Students should not be wholly defined by their visible data or our interpretation of that data. [This principle furthermore warns against stereotyping students and acknowledges those individuals who do not fit into typical patterns. The principle also makes it clear that members of staff may not have access to the full data set, which can seriously impact the reliability of the analysis.] 4. The purpose and the boundaries regarding the use of learning analytics should be well defined and visible. 5. The University is transparent regarding data collection, and will provide students with the opportunity to update their own data at regular intervals. 6. Students should be engaged as active agents in the implementation of learning analytics (e.g., informed consent, personalized learning paths, interventions). 7. Modelling and interventions based on analysis of data should be sound and free from bias. 8. Adoption of learning analytics within the OU requires broad acceptance of the values and benefits (organizational culture) and the development of appropriate skills across the organization. ",23,3,20,2
"928","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","-prediction models are based on predicting outcomes, assessed by accuracy of predictions-explanatory models seek to identify causal relationships between constructs-most LA is in the predictive realm, but these scholars believe there is alot to be gained from explantory model building-Cognitive models map knowledge components (i.e., concepts, skills, and facts; Koedinger, Corbett)-Learning factors anlaysis was developed to automate the data-driven method of KC model refinement",1,0,1,5
"929","Statistical graphics: making information clear – and beautiful","Statistical graphics-labeling axes appropriately is important, include units-main thing to think about is:  who is your target audience?  what are you trying to show?",1,0,1,2
"930","How to display data badly","Wainer-Tufte (1983) came up with a way to qunatify who much information is displayed in a grph, you want as much info as possible, font waste people's time with a basically empty graph-Keep visual ""metaphor"" appropriate to proption of sizes-be careful with the scales on the axes-dont neccessarily order in alphabetical order, set things up for conceptual understanding",0,0,0,2
"931","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","-interesting take on two competing visualzation camps, one by staticians and one by Infovis people -the two have different goals and aims, which is partly where the difference lies. -On the statistical side, data analysts and statisticians are interested in finding effective and precise ways of representing data, whether raw data, statistics or model analyses -On the Infovis side, computer scientists and designers are interested in grabbing the readers’ attention and telling them a story.  -We might argue that the statistical approach concentrates on what can be got out of the available data and the Infovis approach uses the data to draw attention to wider issues.  -dont cram everything into a single graph where multiple would be better -One issue that arises is the familiar distinction between exploratory and presentation graphics.  -Exploratory graphics is all about speed and flexibility and alternative views. Presentation graphics is all about care and specifics and a single view -many from statistics have emphasized that graphics are for comparisons, should not be a single thing that is shared on them -making our graphs prettier can make them more attention grabbing, and possible improve what a normal reader can get out of them. -graphs and analysis are complementary -graphs apparently make people less willing to engage in a book like freakanomics -discovery and communication are general goals of graphs -data visualzation in statistics is about comprehension and understanding",2,2,0,2
"932","Junkcharts Trifecta Checkup: The Definitive Guide"," -this provides a proposal for a standard way to criticize graphs-The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?   -if the answer to these three questions is not the same, then it is a lousy graphics -it all starts with the question, and then flows to the data and visualzation -The Trifecta Checkup framework establishes a taxonomy of dataviz critique",0,1,-1,2
"933","Chapter 1: Theory and Learning Analytics in the handbook of LA","-moving from clicks to contructs requires-Fundamentally then, we argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learner-We suggest that using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.-Anderson (2008) predicted the end of thoery in research thanks to the amazing quantity of data -but he is refuted: ""What counts as a meaningful finding when the number of data points is so large that something will always be significant? […] In sum, when working with big data, theory is actually more important, not less, in interpreting results and identifying meaningful, actionable results""-outside of this debate is real effects on educators and learners: Data gathering, analysis, interpretation, and even intervention (in the case of adaptive software) is no longer the preserve of the researcher, but shifts to embedded sociotechnical educational infrastructure. So, for educators and learners, the interest turns on the ability to gain insight in a timely manner that could improve outcomes. -they present a triad of epistemology, pedagogy, and assessment in the deveopment of a learning analytic systemEpistemology - what are we measuring?-what does knowledge look like in our system? What are we measuring?-concerns the nature of constructsPedagogy - why is this knowledge important to us?-measure that we value instead of what is readily available to us-Who is the assessment for? 1) individual students in developing their learning; 2) educators in developing their own practice and in targeting their support at individual student needs; and 3) administrators in understanding how cohorts are developing and their organizational needsAssessment: where does it happen?-does the assessment method bias the results? Is it meaningful?-Is our test or measurement instrument reliable and valid?-when does it occur? what about feedback?-summative vs formative assessment",9,2,7,2
"934","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","""Data driven decision making (3DM), has recently emerged in the literature as a powerful means through which teachers and school leaders are able to gather together around student and school-level data to inform decision making and tailor instruction and resource allocation to students and classroom"" ""This is one of the main purposes of data driven decision-making; using data already collected in schools to help drive decisions on improving specific school, teacher and student outcomes."" ""Termed a Success at School Factor (SSF), teachers appear to award grades as an assessment of student performance in the institution of schooling, awarding higher grades for participation, behavior, and attendance which in the end appears to be a fairly accurate assessment of overall student outcomes, such as graduating on time "" ""the hierarchical cluster analysis and visualization method, detailed here as a clustergram, provides additional information about students that past regression analyses do not. While both types of methods provide information for identification of overall student outcomes prior to those outcomes, the clustergram displays the entire set of data analyzed for every case in the dataset, patterned in a way that aids overall interpretation.""    ",4,1,3,3
"935","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","""Network analysis can inform our understanding of student network formation in classrooms and the types of impacts these networks have on students"" ""Network analysis entails two broad classes of hypotheses: those that seek to understand what influences the formation of relational ties in a given population (e.g., having the same major, having relational partners in common), and those that consider the influence that the structure of ties has on shaping outcomes, at either the individual level (e.g., grade point average [GPA] or socioeconomic status) or the population level (e.g., graduation rates or retention in science, technology, engineering, and mathematics [STEM] disciplines)."" ""SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of actors, and what, if any, the impacts are of these relationships on actors. Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actor"" ""Networks that consist of only one type of actor (e.g., students) are referred to as unipartite (or sometimes monopartite or one-mode). While not discussed in detail here, bipartite (or sometimes two-mode) networks are also possible, linking actors with the groups to which they belong"" ""Collecting network data requires deciding on a time frame for the relationships of interest. Realworld networks are rarely static; ties form, break, strengthen and weaken over time."" ""Degree centrality represents the total number of connections a node has. In networks in which relations are directional, this includes measures ofindegree and outdegree, or the number of edges pointing to or away from an actor, respectively. Degree centrality is often useful for examining the equity or inequity in the number of ties between individuals and can be done by looking at the degree distribution, which shows the distribution of degrees over an entire network. Betweenness centrality focuses on whether actors serve as bridges in the shortest paths between two actors. Actors with high betweenness centrality have a high probability of existing as a link on the shortest path (geodesic) between any two actors in a network. If one were to look at an airport network (airports connected by flights), airports serving as main hubs, such as Chicago O’Hare and London Heathrow, would have high betweenness, as they connect many cities with no direct flights between them""",0,3,-3,4
"936","Why Students Should Own Their Educational Data","""We’re looking for personal patterns across what we call dimensions."" ""you’ve got to have a third party who is responsible for protecting learner data"" ""education is decidedly not a functional market right now. There’s not enough transparency.""",3,0,3,2
"937","Knowledge tracing: Modeling the acquisition of procedural knowledge","""This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called the ideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process called knowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has 'mastered' each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels."" ""The core idea is that virtually all students can achieve expertise in a domain if two conditions are met: (1) the domain knowledge is appropriately analyzed into a hierarchy of component skills and (2) learning experiences are structured to ensure that students master prerequisite skills before tackling higher level skills in the hierarchy."" ""A simple two-state learning model enables us to estimate the student's knowledge state from performance and predict performance from that knowledge state. Successive evaluations led us to (1) abandon an initial ideal student model and to model a sufficient set of rules, (2) to model differences in rule difficulty and (3) to model individual differences among students in learning and performance.""",14,0,14,3
"938","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","“Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.” Learning Analytics as: “… the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.” ""Both communities have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education."" ""EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment."" ""EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners.""",2,1,1,2
"939","Evaluating Machine Learning Models","Evaluation Metrics""Chapter 2 focuses on evaluation metrics. Different machine learning tasks have different performance metrics. If I build a classifier to detect spam emails versus normal emails, then I can use classificationperformance metrics such as average accuracy, log-loss, and area under the curve (AUC). If I’m trying to predict a numeric score, such as Apple’s daily stock price, then I might consider the root-mean-square error (RMSE). If I am ranking items by relevance to a query submitted to a search engine, then there are ranking losses such as precision-recall (also popular as a classification metric) or normalized discounted cumulative gain (NDCG). These are examples of performance metrics for various tasks.""",2,2,0,5
"940","Why Is Measuring Learning So Difficult?","""Learning is multidimensional, we have to simplify learning too much to capture data to understand something."" ""Learning Analytic: Should reveal to the learner what kind of connections he/she is making that they are not aware of.""",0,0,0,1
"941","Saturday Morning Breakfast Cereal","Clock Yeah!",0,0,0,2
"942","The Data Wrangling Cheatsheet","Favorite: dplyr::mutate(iris, sepal = Sepal.Length + Sepal. Width) Compute and append one or more new columns.",1,0,1,1
"943","Data wranglers: human interpreters to help close the feedback loop","""students and teachers are closest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact.""",2,0,2,1
"944","Zuckerberg is ploughing billions into 'personalised learning' – why?","""The dangers of personalised learning Zuckerberg’s idea of personalised learning has three major flaws. First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. Finally, children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher. In subcontracting out teaching to technology, the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced. Where personalised learning could help Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective.""",5,6,-1,2
"945","Feature Selection","-Knowledge Discovery Interpretability and Insight -Cures of Dimensionality",1,0,1,5
"946","RStudio Cheat Sheets","""The R Markdown cheat sheet is a quick reference guide for writing reports with R Markdown.w""",0,1,-1,1
"947","Translating Learning into Numbers: A Generic Framework for Learning Analytics","""It is expected that personalised learning has the potential to reduce delivery costs while at the same time creating more effective learning experiences, accelerating competence development, and increasing collaboration between learners."" ""The fundamental question legislators need to ask is: who does a person’s life data belong to?"" ""provides a tool for HEIs, companies, or governments to increase manipulative control over students, employees, and citizens, thereby abusing LA as a means to reinforce segregation, peer pressure, and conformism rather than to help construct a needs-driven learning society."" ""LA processes that data can be interpreted in many ways and lead to very different consequent actions. To give a drastic example, imagine being confronted with the insight that children from an immigrant background show reading difficulties, backed by supportive data analysis. This may lead to a wide ranging variety of responses, from developing extracurricular support mechanisms, to segregated classes, up to bluntly racist abuse of various kinds."" ""In a recent survey we conducted among LA experts, only 21% of the 111 respondents felt that learners would possess the required competences to interpret LA results themselves and determine appropriate actions/interventions from it"" ""To judge a learner’s performance merely on, e.g., LMS quantitative data is like looking at a single puzzle piece.""",5,5,0,1
"948","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","""Predicting course completion is hard—about the only precourse factor that we found to be highly predictive is intention, and even this predictive power is probably dominated by the fact that those who do not intend to complete usually do not. Predicting knowledge gains is even harder. The good news is that we found knowledge gains did not correlate significantly with age, sex, student level, or motivation for taking the course. The factors that were predictive all relate to effort, prior courses, and baseline knowledge (in what appears to be only a negative effect resulting from ceiling effects).""",3,0,3,4
"949","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","""How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester’s worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability.""",17,2,15,5
"950","Chapter 1: Social Network Data","""Network analysis focuses on the relations among actors, and not individual actors and their attributes. This means that the actors are usually not sampled independently, as in many other kinds of studies (most typically, surveys)."" ""network approaches tend to study whole populations by means of census, rather than by sample"" ""Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal."""" ""Given a set of actors or nodes, there are several strategies for deciding how to go about collecting measurements on the relations among them. At one end of the spectrum of approaches are ""full network"" methods. This approach yields the maximum of information, but can also be costly and difficult to execute, and may be difficult to generalize. At the other end of the spectrum are methods that look quite like those used in conventional survey research. These approaches yield considerably less information about network structure, but are often less costly, and often allow easier generalization from the observations in the sample to some larger population. There is no one ""right"" method for all research questions and problems.""",3,5,-2,4
"951","Learning Analytics Dashboards","""As for what can be incorporated into a dashboard, this lists the following kinds of data:"" 1. ""Artefacts produced by learners, including blog posts, shared documents, software, and other..."" 2. ""Social interaction, including speech in face-to-face group work, blog comments, Twitter or discussion forum interactions."" 3. ""Resource use can include consultation of documents (manuals, web pages, slides) views of videos...) 4. ""Time spent can be useful for teachers to identify students at risk..."" 5. ""Test and self-assessment results can provide an indication of learning progress.""   ""Information visualization concepts and methodologies are key enablers for 1. Learners to gain insight into their learning actions and the effects these have. 2. Teachers to stay aware of the subtle interactions in their courses. 3. Researchers to discover patterns in large data sets of users traces and to communicated these data to their peers.""",3,1,2,2
"952","Measurement and its Uses in Learning Analytics","""It can be said that psychological measurement comprises the following: defining a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome.""",0,2,-2,5
"953","Predictive Modelling in Teaching and Learning","""We identify three areas that could use investment in order to increase the impact that predictive modelling techniques can have: 1. Supporting non-computer scientists in predictive modelling activities is highly interdisciplinary and educational researchers, psychometricians, cognitive and social H modelling techniques, whether through the innovation of user-friendly tools or the development of educational resources on predictive modelling, could further diversify the set of educational researchers using these techniques. 2. Creating community-led educational data science challenge initiatives. It is not uncommon for researchers to address the same general theme of work but use slightly different datasets, implementations, and outcomes and, as such, have results in recent predictive modelling research regarding dropout in massive open online courses, where a number of different authors all done work with different datasets, outcome variables, and approaches. Moving towards a common and clear set of outcomes, open data, and shared implementations and the suitability of modelling methods for given. This approach has been valuable in similar research we believe that educational data science challenges could help to disseminate predictive modelling knowledge throughout the educational research community while also providing an opportunity for the development of novel interdisciplinary methods, especially related to feature engineering. 3. Engaging in second order predictive modelling Creating community-led educational data science challenge initiatives. It is not uncommon for researchers to address the same general theme of work but use slightly different datasets, implementations, and outcomes and, as such, have results in recent predictive modelling research regarding dropout in massive open online courses, where a number of different authors all done work with different datasets, outcome variables, and approaches. Moving towards a common and clear set of outcomes, open data, and shared implementations and the suitability of modelling methods for given. This approach has been valuable in similar research we believe that educational data science challenges could help to disseminate predictive modelling knowledge throughout the educational research community while also providing an opportunity for the development of novel interdisciplinary methods, especially related to feature engineering.""",9,2,7,3
"954","Ethics and Learning Analytics: Charting the (Un)Charted","“The University will not engage in Learning Analytics practices that use data sources: (a) not directly related to learning and teaching; and/or (b) where users may not reasonably expect such data collection by the University to occur” ""Sclater, Peasgood, and Mullan (2016), for example, review practices within higher education in the United States, Australia, and the United Kingdom. They summarize their findings by indicating that learning analytics makes significant contributions for 1) quality assurance and quality improvement; 2) boosting retention rates; 3) assessing and acting upon differential outcomes among the student population; and 4) the development and introduction of adaptive learning. The report acknowledges the many opportunities, but also highlights threats such as “ethical and data privacy issues, ‘over-analysis’ and the lack of generalizability of the results, possibilities for misclassification of patterns, and contradictory findings”.""",2,3,-1,2
"955","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","""In the statistical modelling of educational data, approaches vary depending on whether the goal is to build a predictive or an explanatory model. Predictive models aim to find a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data. Explanatory models seek to identify interpertable causal relationships between constructs that can be either observed or inferred from the data. The vast majority of educational data mining research has focused on achieving predictive accuracy, but we argue that the field could benefit from more focus on developing explanatory models. We review examples of educational data mining efforts that have produced explanatory models and led to improvements to learning outcomes and/or learning theory. We also summarize some of the common characteristics of explanatory models, such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process."" ""Learning Factors Analysis was developed to automate the data-driven method of KC model refinement to further alleviate demands on human time. LFA searches across hypothesized knowledge components drawn from different existing KC models, evaluates different models based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model. As such, LFA greatly reduces demands on human effort while simultaneously easing the burden of interpretation, even if it does not automatically accomplish it.""",5,1,4,5
"956","Statistical graphics: making information clear – and beautiful","""When producing-quality figures, every decision needs to be made consciously and with intent. Improving figures requires two key decisions:"" ""Who is your target audience?"" ""What are you trying to show?""",0,0,0,2
"957","How to display data badly","""If we wish to display data badly, we have three avenues to follow. These are (a) showing data, (b) showing data accurately, and (c) showing data clearly."" ""Rule 1 - Show as Few Data as Possible (Minimize the Data Density) Rule 2 - Hide What Data You Do Show (Minimize the Data-Ink Ratio) Rule 3 - Ignore the Visual Metaphor Altogether Rule 4 - Only Order Matters Rule 5 - Graph Data Out of Context Rule 6 - Change Scales in Mid-Axis Rule 7 - Emphasize the Trivial (Ignore the Important) Rule 8 - Jiggle the Baseline Rule 9 - Austria First! Rule 10 - Label (a) Illegibly, (b) Incompletely, (c) Incorrectly, and (d) Ambiguously Rule 11 - More is Murkier: (a) More Decimal Places and (b) More Dimensions Rule 12 - If It Has Been Done Well in the Past, Think of Another Way to Do It""    ",4,3,1,3
"958","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","""The present article explores two related but distinct practices which we define in ideal forms: (1) Statistical data visualization, which is focused not on visual appeal but on facilitating an understanding of patterns in an applied problem (recall the Discovery goals listed above), both in directing readers to specific information and allowing the readers to see for themselves. (2) Infographics, which ideally should be attractive, grab one’s attention, tell a story and encourage the viewer to think about a particular dataset, both as individual measurements and as a representation of larger patterns (as in our Communication goals).""",4,1,3,2
"959","Junkcharts Trifecta Checkup: The Definitive Guide","""The Question occupies the top corner because any data visualization project needs a worthy cause. I'd like the Question to be well-posed, and interesting; the former focuses the search for appropriate data while the latter ensures an engaged audience. The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly. ""  ",4,2,2,2
"960","Measurement and its Uses in Learning Analytics","This chapter indicates the use of learning analytics tools is always consistent with the evaluation system, which is intentional or unintentional, and the evaluation system is based on epistemological assumptions and teaching practices. Therefore, fundamentally, we beblieve that the deployment of a specific learning analysis tool expresses a commitment to a specific educational worldview aimed at training specific types of learners. This paper outline some of the critical issues in the development of learning analytics technology and put forward the purpose and assumptions of learning analysis.",0,1,-1,2
"961","Ethics and Learning Analytics: Charting the (Un)Charted","Combining analysis of learning and growth in practice and an introduction to educational analysis policy, the challenge in understanding how theory and analysis are linked is to ""go from click to build"" in a principled way. Learning analysis is a concrete manifestation. From a larger society to the popularization of algorithms, their extensive influence on education needs to be carefully considered. In this chapter, the paper believe that the use of learning analysis tools is always consistent with the evaluation system.  The evaluation system is intentional or unintentional. The evaluation system is based on epistemological assumptions and teaching practices.  Therefore the use of specific learning analysis tools expresses a specific learning analysis tools expresses a specific educational worldview dedicated to training specific types of learners.",1,0,1,2
"962","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Learning analytics is a concrete manifestation of the shift from a larger society to the popularity of algorithms, and their wider impact on education needs to be carefully considered. In this chapter, we believe that the use of learning analysis tools is always consistent with the evaluation system, which is intentional or unintentional, and the evaluation system is based on epistemological assumptions and teaching practices. Therefore, fundamentally, this paper believes that the deployment of a specific learning analysis tool expresses a commitment to a specific educational worldview aimed at training specific types of learners.",1,0,1,2
"963","Statistical graphics: making information clear – and beautiful","Guiding principles for small multiple plots:   Keep the X and Y axes on the same scale. Eliminate repetitive information. Maintain consistency across plots  Guiding principles:  Avoid distracting elements. Use informative informative color to visually associate elements. Keep the figure simple (and therefore interpretable) ",0,2,-2,2
"964","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This paper presents a set of graphically displayed goals and explore some inherent contradictions in these goals from a statistical perspective. Communication between intrusion statistics and information systems. For practitioner and statisticians, the constructive suggestion is to try not to do this and stuff in one chart what can be better displayed in two or more charts. Although this paper only provides a perspective, here is a starting point for an extensive discussion of statistical methods among graphic designers, statisticians, and users. The purpose of this article is not to criticize, or even explore, different goals that lead researchers in different fields to different data visualization methods.",2,2,0,2
"965","Junkcharts Trifecta Checkup: The Definitive Guide"," Graphical Integrity  The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities represented. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on other graphic itself. Label important events in the data. Show data variation, not design variation   Chart junk  Intriguing &amp; curiosity-provok Narrative Power Immense detail   ",2,3,-1,5
"966","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," Inform decision making Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. Teacher-Assigned Grades as Useful Data in Schools  An emerging line of research has begun to ask why teacher-assigned grades are predictive of overall student outcomes, but are a weak indicator of academic knowledge when compared to standardized test scores.   Visualizing Data for  3DM in Schools  cross-sectional means and standard deviations. aggregated descriptive statistics give only an overview of the central tendency of a sample early failure in reading or mathematics has been shown to be highly predictive of student schooling outcomes much of the past research has focused on using logistic regression to predict the likelihood of dropping out of school given if a student has failed a core course.   ",1,3,-2,3
"967","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This paper encourages researches interested in biology education and broader education research to analyze, use relevant data, and consider the importance of learning relationships for  undergraduate education. In the process, this paper first introduces some of the basic concepts and terminology in SNA, outlining the methods and concerns of data collection, including the importance of getting approval from a local agency review board (IRB). Secondly, it briefly discusses a simple method to organize the data for analysis, and then briefly analyzes the classroom network through the following three ways: descriptive analysis of the network, exploration of network evolution, and analysis of network location as a predictor of individual results.",0,1,-1,4
"968","Why Students Should Own Their Educational Data","The truly transformational potential of the technology [is hard for venture-backed companies] to do. What this system need to know about customer is the contextualized profile of your performance and what kind of support you’ll need to be able to model your learner profile across contexts. There’s this default thing right now which is that everybody but the user owns their data. Then the student could have, say, a decade of data about the way that they’re learning.",2,1,1,2
"969","Knowledge tracing: Modeling the acquisition of procedural knowledge","The goal of this research was to implement a simple student modeling process that would allow the tutor to monitor the student's knowledge state and tailor the sequence of practice excersies to the student's needs. The resulting knowledge tracing process models the student as an overlay of the production rules and the mastery-based curriculum structure allows us to associate each programming action with a single production rule. A simple two-state learning model enables us to estimate the student's knowledge state from performance and predict performance from that knowledge state.",0,0,0,3
"970","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Terms: EDM : Educational Data Mining LAK : Learning Analytics and knowledge   1. Introduction   The conference declares ""technical, pedagogical, and social domains must be brought into dialogue with each other to ensure that interventions and organizational systems serve the needs of all stakeholders.""   While LAK and EDM share many attributes and have similar goals and interests, they have distinct technological, ideological, and methodological orientations.   2. Similarities between communities  EDM and LAK both reflect the emergence of data-intensive approached to education.  3. Key distinctions between communities (Comparition of the two fields)  LAK:  (Discovery) Leveraging human judgement is key ; (Reduction &amp; Holism) understanding systems as wholes (Origins) semantic web; outcome prediction and systemic intervention (Adaption &amp; Personalization) inform and empower ubsreyctors and learners (Techniques &amp; Methods) social network; sentiment analysis; influence analysis; discourse analysis, learner success prediction, concept analysis; sense-making models  EDM:  (Discovery) Automated discovery is key (Reduction &amp; Holism) reduce to component and analyze individual components and relationship between them (Origins)educational software and student modeling (Adaption &amp; Personalization) automated adaption (Techniques &amp; Methods) classification, clustering, bayesian modeling, relationship mining, discovery with models, visualization  4. Call for communication and collaboration: EDM and LAK  EDM: focus on issues of model generalizability LAK: address needs of multiple stakeholders with information drawn from data ",2,0,2,2
"971","Evaluating Machine Learning Models","Evaluation Metrics  Classification Metrics Accuracy - (correct predictions) / (total data points)  Confusion Matrix  How many examples failed for class 0 versus class 1, because the cost of mis-classification might differ for the two classes.  Unpacking the prototyping phase: Training, validation, model selection  Historical data  Training data ; model training; training evaluation results Validation data; model ; validation evaluation results; hyperprameter tuner    A/B testing   This machinery is know as statistical hypothesis testing. It decides between a null hypothesis and an alternate hypothesis.   split into randomized control/ experimentation groups Observe behavior of both groups on the proposed methods compute test statistics compute p-value output decision   ",1,2,-1,5
"972","Why Opting Out of Student Data Collection Isn’t the Solution","This articles uses data to understand how students progress through time, how school systems serve different populations, and how different education strategies succeed. Although sometimes the meeting argues the accuracy or validity of the data, assessing performance through data analysis is often an essential step to improving education and addressing areas of concern. And the parents' expectations that teachers and administrators have access to the data they need to make informed decisions to manage our education system.",2,1,1,2
"973","Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult?  Learning is a very multi-dimensional thing - we have to simplify data so much to capture Learning is so board What people know and what people learn Depend to the definition of learning Culture, social, individual psychology we have to consider Wild range of the students Measurement of competence is different from scores in the class What kinds of connection of failing or drop out the school Learning is magic, it is a collaborate thing   ",1,3,-2,1
"974","Saturday Morning Breakfast Cereal","When we adopt education reform, we should fully realize that the cause and effect is not an inversion of cause and effect, or it will bring very serious negative effects. As the comic said, scholars have researched and found that 90% of the elites have the act of disassembling alarm clocks when they were young. Causality should not be imposed at this time. T his phenomenon does not mean that the act of disassembling alarm clocks has become elite Necessary, so it should not be taken blindly to have all students disassemble the alarm clock. In general, if the investigation finds two variables that have a high correlation, it should be distinguished whether there is a causal relationship between them and then take action on the actual problem.",1,5,-4,2
"975","Data wranglers: human interpreters to help close the feedback loop","The amount of data and the range of different data sources can make it difficult to take systematic action on this data. The plan to introduce human data personnel are deployed at the Open University. The United Kingdom is responsible for understanding and studying various relevant data sources, analyzing data to understand personal practice capabilities and production reports, summarizing the main points, and putting forward operational recommendations. The evaluation and experience of this work plan strongly support the meaning of humans - the value analysis process of maker learning and show that obstacles to organizational transformation in this area can be substituted by working within the strategic environment of embedded analysis, learning and working at an appropriate level Granularity analysis.",6,1,5,1
"976","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning is defined as all outstanding teachers modify learning materials and teaching styles to suit students' different learning styles. Zuckerberg has a clear definition. Human work is replaced by technology, and algorithms provide content based on analysis of users' past behaviors and interests. This is similar to how Facebook news feeds and other business personalization models based on text and behavioral analysis work.There is hype about the potential of new technologies or methods to undermine education, and there is a legitimate concern that investments in personalized learning may power Silicon Valley and teachers. There are three main flaws in Zuckerberg's personalized learning philosophy. First, education has always been about acquiring professional-related knowledge and skills, but also about acquiring common sense. By providing children only with what they are interested in, we may get many experts and few generalists. Second, although learners may cope with learning in ways that are not suitable for them, in the real world, life is not always so adaptive. Their lack of compensation may mean that they have suffered losses. Finally, children's preferences are not fixed-in fact, they often change in their direct response to the environment.",6,6,0,2
"977","Feature Selection"," Feature Selection  Why?  Knowledge Discovery Interpretability Insight   Curse of dimensionality  Among the data, if we want more features of the data, we should obtain more dimensions of the data.     ",0,0,0,5
"978","Chapter 1: Social Network Data"," Conventional social science data consist of a rectangular array of measurements. Nodes:  Network data are defined by actors and by relations (or nodes and edges) The nodes or actors included in non-network studies tend to be the result of independent probability   Population. sample and boundaries  social network analysts rarely draw samples in their work. The population that network analysts study are remarkably diverse The boundaries of the populations studies by network analysts are of two main types. Naturally predisposes that analyst to focus on multiple levels of analysis simultaneously. How the individual is embedded within a structure and how the structure emerges from the micro-relations between individual parts.   Sampling ties  full-network : maximum of information but costly and difficult to execute. Spectrum: less information; less costly and allow easier generalization from the observations in the sample to some larger population.   Snowball  Business contact networks, community elites, deviant sub-cultures, avid stamp collectors, kinship networks, and many other structures can be pretty effectively located and described by snowball methods.   Ego-centric networks (with alter connections)  collecting a form of relational data from very large populations Alter connections as a whole, as much as snowball of census approaches. focus on individual, rather than on the network as a whole.   Ordinal scales of measurement contain more information than nominal. ",3,1,2,4
"979","RStudio Cheat Sheets"," Data Transformation with dplyr  Summarise Case  Summarise (data) count (x) summarise_all() summarise_at() summarise_if()   Group Case  mtcars %&gt;%  group_by(cyl) %&gt;% summarise(avg = mean(mpg))   Manipulate Cases  filter(data) distinct(data) sample_n() slice(data) top_n()   Arrange / Add cases  arrange(data) desc()   Mutating join  left_join() right_join() inner_join() full_join()     ",0,0,0,1
"980","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Many factors influence a student's decision to enroll in college. A lot of the external or social factors: financial reasons, parental support, and school support. Another major factor, however, is one's ability and engagement, which develops over the early years and begin to manifest strongly during the middle school years. In this paper, we apply fine-grained models of student knowledge, student effect and behavior to data from 3747 students using educational software over the course of a year of middle school to understand how the development of student learning an engagement during this phase of learning, can predict college enrollment. This paper support existing theories about indicators of college enrollment. More importantly, it further sheds light on behavioral factors the student experiences in classrooms. As the results here suggest, affect and disengagement are associated with college enrollment, suggesting that in the moment interventions.",4,0,4,3
"981","Translating Learning into Numbers: A Generic Framework for Learning Analytics","# From HUDK405019-L6-Wrangling2.pdf Exercise 2  Consider the fake data you generated and the diagram on page 44 of Greller &amp; Draschler Work your way through each of the boxes Which would pose problems for you to actually acquire the data you want<U+FF1F> Write a note summarizing the article in Zotero, include thoughts based on your answers to the above.  #Can everyone understand the meaning #Are they going to accept the meaning #The norms -- some class do not provide grade #Very completed process to grade #When we apply this, we are sort people #different institutions and teachers can have different way to get the data.  ;  It is already evident that data in combination with information retrieval technologies are not only the basis for the emergent data economy, but also hold substantial promises for use in education The new data economy has made data collection very much an affordable activity. The renewed interest in data science and information retrieval technologies such as educational data mining, machine learning, or latent semantic analysis in Technology-Enhanced Learning(TEL) reveals itself through an increasing number of scientific conferences, workshops and projects combined under the new research term Learning Analytics. Proposed design framework for learning analytics  Stakeholders  Institution Teachers Learners Other   Internal Limitations  Competences Acceptance   External Constraints  Conventions Norms   Instruments  Technology Algorithm Theories   Data  Open Protected   Objectives  Reflection Prediction     ",3,4,-1,1
"982","The Big Five and Visualisations of Team Work Activity"," Two questions answered in this paper  How well do the visualizations capture information relevant in the context of the Big Five framework? Is there a relation between patterns indentifiable through these visualizations and group performance outcomes?   Big 5 theory  Team Leadership - Ticket Action  Facilitate problem solving: Wattle Tree Provide performance expectations and acceptable interaction patterns Synchronise and combine individual team member contributions see and evaluate information ht affects team functioning   Mutual performance monitoring - Interaction Networks  Identifying mistakes and lapses in other team members' actions   Backup behavior -IN/T  Recognition of a workload distribution problem n the team Shifting work to underutilised members   Adaptability - Wattle Tree  Identify cues of change, assign meaning to it , develop new plan to deal with it.   Team Orientation  Increase task involvement, information, sharing , strategies and goal settings.     Computer-supported collaborative learning (CSCL) Three coordinating mechanisms:  Shared mental models Mutual trust Closed-loop communication   Overview of Visualization  Activity Rader Interaction Network Wattle Tree   ",3,2,1,2
"983","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC"," Measures and Data  Pre-post student surveys (demographics, motivations) Pre-post knowledge test (recommender systems concepts) Process and result metrics from Coursera   Lessons Learned  Good teaching at scale, more time and effort Student leave Moocs Students claim they want short courses and videos Students really serious about ""grades"" Students hate peer grading Multiple choice reverses the effort function Demands not proportional to tuition paid Long format actually does work and many students preferred it The two-track approach worked   ",5,1,4,4
"984","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices"," Discuss one of the first two gaming detectors developed. Criteria for an ideal detector of gaming behavior  First, we propose that an ideal detector should accurately identify a category of behavior which is known to be associated with a meaningful difference in student experience or outcomes. Second, an ideal detector can predict not only which students engage in the behavior, but when they do so. Third, an ideal detector not only detects student behaviors but can help researchers understand those behaviors better Fourth, an ideal detector can generalize.   Conclusion  The game detector can accurately detects which students game the system; make predictions about when students game the system, which have been used to drive learning interventions which improve student learning expands our knowledge about behavioral construct of ""gaming the system"" can generalize between contexts   ",6,0,6,5
"985","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article finds that eEPIPHANY is an efficient, practical and fast way to automatically discover skill models from online course data. Our empirical research shows that eEPIPHANY always finds better skill models than the artificial skill models used in actual online courses. We also proved that with the help of text analysis technology, the skill model produced by eEPIPHANY is reasonably interpretable. Creating effective online courses often requires intensive, iterative systems engineering. Therefore, research on automatic skill model refinement technology and its application in evidence-based course refinement is a key research agenda for the future success of online education.",9,0,9,5
"986","Using data mining to predict secondary school student performance"," Good predictive accuracy can be achieved, provided that the first and/ or second school period grades are available. Education is the key factor for achieving a long-term economic progress. On the other hand, the interest in Business Intelligence arose due to the advances of Information Technology, leading to an exponential growth of business and organizational databases. Analyze recent real-world data from two Portuguese secondary schools. Classification and regression are two important DM goals. Three different DM goals (binary/ 5-level classfication and regression) Four DM methods: Decision Tree (DT) ; Random Forest (RF); Neural Networks (NN); and Suport Vector Machines (SVM) ",4,2,2,3
"987","Developing a generalizable detector of when students game the system"," Criteria for an ideal detector of gaming behavior  First, we propose that an ideal detector should accurately identify a category of behavior which is know to be associated with a meaningful difference in student experience or outcomes. Second, an ideal detector can predict not only which students engage in the behavior, but when do so. Third, an ideal detector not only detects student behavior but can help researchers understand those behavior better. Fourth, an ideal detector can generalize.   Developing systems that can reliably identify differences in how students choose to use interactive learning environments , and the attitudes and goals which underlie these decisions, is an interesting and challenging problem which has received considerable attention in recent years. Attempting to succeed in an educational environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. ",8,2,6,5
"988","Big Data in Education","Prediction can be used to  Improve educational design Automated decisions by software Informing teachers, instructors and other stakeholders Develop a model which can infer a single aspect of the data from some combination of other aspects of the data Used to predict the future Used to make inferences about the present ;  Types of EDM/LA method  Prediction  classification regression latent knowledge estimation   Structure Discovery  Clustering Factor Analysis Domain Structure Discovery Network analysis   Relationship mining  Association rule mining Correlation mining Sequential pattern mining Casual data mining   Distillation of data for human judgement Discovery with models   ",0,1,-1,5
"989","Cross Validation"," Cross Validation  Train set : draw a line  If it does not fit so perfect, then we will fit this with higher order polynomial.   We believe that the system is ultimately going to be used We want the data to be independent and identically distributed. -- Fundamental Assumption. Use a model that is complex enough to actually model the structure that is in the data that we are training on   ",2,1,1,5
"990","Hands-On Programming with R"," Show factors -- ls() Calculate  %o%    %*%   Repeat r command  replicate(10,roll())   Tip  R will not run anything that follows a hashtag on a line (#) First, a name cannot start with a number. Second, a name cannot use some special symbols   write csv(deck, file = ""cards.csv"", row.names = FALSE) If  if (this) {Plan A} else {Plan B}   While  plays_till_broke &lt;- function(start_with){ cash &lt;- start_with n &lt;- 0 while (cash &gt; 0) {cash &lt;- cash -1 +play() n &lt;- n+1 } n} plays_till_broke(100) # 260   Repeat  plays_till_broke &lt;- function(start_with){ cash &lt;- start_with n &lt;-0 repeat{ cash &lt;- cash -1 +play() n &lt;- n +1 if (cash &lt;=0){ break} } n } plays_till_broke(100)   ",0,2,-2,1
"991","Principal Component Analysis explained visually"," 2D example  If there are only two dimensions, like height and weight, then it can be plotted as points.   3D example  With three dimension, PCA is more useful, becuase it is hard to see through a could of data.   ",2,2,0,2
"992","Theory and Learning Analytics","Tools can be used in many ways, and should not be isolated from their context of use. Interactional affordances, like beauty, are to some degree ""in the eye of the beholder"". This paper offer these provocation as a pragmatic tool for thinking, for designers, educators,researcher, and students - whether considering how one currently makes use of analytical tools, how one might do in the future, or indeed when designing new tools for new contexts. This paper propose that it is productive to consider these provocations in order to reflect on the EPA claims being made through the deployment of a learning analytic tool within a given context.",2,0,2,2
"993","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","**The purpose of this study is to combine the two emerging research domains of 3DM and the usefulness of teacher-assigned grades using a novel form of data mining, patterning and visualization known as hierarchical cluster analysis (HCA), to provide school leaders, researchers and policy makers a method to make better informed decisions in schools earlier, using data already collected on students. HCA --&gt;a multivariate statistical method that uses nested correlations to reorder a dataset so that clusters (patterns within the data) are closer together. (seems like a type of clustering...) 2 types of clustering: supervised --&gt;starts with a defined set of assumptions about the categorization of the data?? unsupervised --&gt; assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the data set - detectable patterns, visually (higher grade students together, middle, and lower...etc)??    ",2,0,2,3
"994","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","SNA aims to understand the determinants, structure, and consequences of relationships between actors. In other words, SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of actors, and what, if any, the impacts are of these relationships on actors. Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.",0,0,0,4
"995","Why Students Should Own Their Educational Data","""the market only works if you have a functional market. And education is decidedly not a functional market right now. There’s not enough transparency."" - Todd Rose Confused, is it that we need to be giving individualized achievement info to the institutions or to the students? What's weird is that we use educational data in separate sectors - kind of goes along with the graphic from 9/21 about the clocks.  ",3,2,1,2
"996","Knowledge tracing: Modeling the acquisition of procedural knowledge","APT is constructed around a production rule cognitive model of programming knowledge, called the ""ideal student model"". This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process called knowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. ",3,0,3,3
"997","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Overall comparison of the 2 fields (Learning Analytics and Knowledge = LAK and Educational Data Mining = EDM). LAK    ",0,0,0,2
"998","Why Is Measuring Learning So Difficult?","We have to simplify learning too much in order to capture it... --&gt;generalizability is difficult Learning a personal...cultural construct? You can't measure the concept inside a person fully. Everything is externalized and not necessarily rooted in what has changed due to the/a learning experience. ""there are no reliable simple proxy indicators that we can trust"" Seeing as the cognitive construct of ""learning"" is not something that can be seen and therefore, measured, we instead go for measuring externalized manifestations of that learning. Which may not be the best or most reliable measure of learning across populations.",2,1,1,1
"999","Saturday Morning Breakfast Cereal","This was hilarious... Funny depiction of correlation is not causation. Specifically thinking about how educational markers are always changing based on the new must have skills of society. That's not to say that pushes like these aren't important, the read to your child campaign to increase word exposure is a great push and one that I enjoy myself. But there's another one now with regards to how children are forming ""21st century's"" skills that I current fumble with when determining the how for developing those skills at a young age.  ",9,0,9,2
"1000","Data wranglers: human interpreters to help close the feedback loop","The Data Wranglers are a group of academics who analyze data about student learning and prepare reports with actionable recommendations based on that data.    Their role is to translate the theory described above in to practice: to act as human sense-makers, facilitating action on feedback from learners, making better sense of what that feedback means and how the data can be improved (double-loop learning), and helping to develop the Community of Practice around the use of learning analytics.   The Data Wranglers work with four main data sources: 1. Survey feedback data from students, gathered at the end of their course. 2. Activity data from the VLE/LMS (Moodle). 3. Delivery data about the mode of delivery and structure of courses  4. Aggregated completion, pass rate and demographic data. In practical terms,    ",3,0,3,1
"1001","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning--&gt; meaning to adapt and modify the material in class to cater to the specific learning styles of the students? --&gt; user-centered, student-centered, individualized teaching Zuckerberg's definition: ""personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests” Interesting points against personalized learning--&gt;  1. too much specialized attention to interests rather than a broader scope of learning to encourage interests and studies in new fields genrerally 2. Customized working environments in education are an unrealistic expectation as in a real working environment there are not such accommodations made for employees 3. Children change their interests and preferences in the bloink of an eye. There needs to be direction. 3.      ",3,0,3,2
"1002","Chapter 1: Social Network Data","Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches.  Scales of measurement: Binary measures of relations Multiple-category nominal measures of relationsGrouped ordinal measures of relationsFull-rank ordinal measures of relations Interval measures of relations",0,0,0,4
"1003","Learning Analytics Dashboards","Couldn't find.",0,0,0,1
"1004","Ethics and Learning Analytics: Charting the (Un)Charted","Framework Principles (Slade and Prinsloo, 2016) 1. Learning analytics as moral practice — focusing not only on what is effective, but on what is appropriate and morally necessary 2. Students as agents — to be engaged as collaborators and not as mere recipients of interventions and services 3. Student identity and performance as temporal dynamic constructs - provides a snapshot view of a learner at a particular time and context 4. Student success as a complex, multidimensional phenomenon 5. Transparency as important — regarding the purposes for which data will be used, under what conditions, access to data, and the protection of an individual’s identity That higher education cannot afford not to use data  Reading through...not sure how TC uses our information, same is true of my undergrad info...and primary school education. List of student-centered ""code?"" for how data should be collected and analyzed with the input and informed contribution of the student. 1. The use of aggregated, non-personalized data is essential in delivering effective and appropriate teaching and learning, but students should be able to make informed opt in/out decisions 2. Students should have full(er) knowledge of which data is collected and how it is used 3. Students should ensure that their personal data records are complete and up to date 4. The surveillance of activities and the harvesting of data must not harm student progress 5. Algorithmic output should be subject to (potential) human review, and corrected if needed 6. Learning analytics essentially provides context and time-specific, provisional, incomplete pictures of students, and algorithms should be frequently reviewed and validated  ",7,2,5,2
"1005","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","--&gt; Predictive models aim to find a combination of features that best predict outcomes. --&gt; Explanatory models aim to identify interpretable causal relationships between constructs that can be observed or inferred from the data (behavior/treatment to outcome?) However, EDM has focused on developing 2 types of models; statistical and cognitive. Statistical models run the loop of an intelligent tutoring system, using student performance features that the system can observe to improve their learning. While cognitive models are more a representation of the a knowledge space of a specific educational domain, more so focused on the concepts or skill sets. Cognitive models map knowledge components (is this like externalizing mental models that a participant/student might have??) and align that map to steps in a problem or set tasks as observational data on a students' performance. --&gt; Cog. models are important to intelligent tutoring systems and the better they are constructed the better they are at predicting student knowledge and adapting to best fit the needs of the student. Knowledge component (KC) - a fact, concept, or skill required to succeed at a particular task or problem step. (specialized form of a cognitive model, KC model or Q-matrix --&gt; Barnes, 2005). LFA? (Learning Factors Analysis) searches across the hypothesized knowledge components drawn from different existing KC models, evaluates different models based on their fit to data and outputs the bet fitting KC model in the form of a symbolic model....(not 100% sure on this...?)  ",8,2,6,5
"1006","Statistical graphics: making information clear – and beautiful","Questions to answer: -Who is your target audience? -What are you trying to show? Tips: -Avoid distracting elements. -Use informative color to visually associate elements. -Keep the figure simple (and therefore interpretable).  ",0,1,-1,2
"1007","How to display data badly","Graphic display is about having a set of numbers both with magnitudes and and order represented by an appropriate visual manifestation. Rules for poorly displaying data: 1. Show as few data as possible (minimize data density) 2. Hide what data you do show (minimize the data-ink ratio) 3. Ignore the visual metaphor altogether 4.  Only order matters 5. Graph data out of context 6. Change scales in mid-axis 7. emphasize the trivial (ignore the important) 8. Jiggle the baseline 9. Alphabetizing graphs (influences importance) 10. Label (a) illegibly, (b) incompletely, (c) incorrectly and (d) ambiguously 11. More is murlier: (a) more decimal places and (2) more dimensions 12. If it has been done well in the past, think of another way to do it.",2,3,-1,3
"1008","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","-there's a lack of interaction between the worlds of statistical graphics and information visualization -designers of non-statistical data graphics are not so focused on conveying information and that the very beauty of many professionally-produced images may, paradoxically, stand in the way of better understanding of data in many situations -An important part of statistical practice is graphical communication of data and models -the correct comparisons are important -readers should be able to use graphics (outside the numbers) to make their own informed understanding",2,2,0,2
"1009","Junkcharts Trifecta Checkup: The Definitive Guide","What is the QUESTION? What does the DATA say? What does the VISUAL say? All 3 parts should be in sync and match the message across the infographic.",0,0,0,2
"1010","Measurement and its Uses in Learning Analytics"," The use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. Using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies ",0,0,0,2
"1011","Predictive Modelling in Teaching and Learning","Introduce the terms and workflow related to predictive modelling, with a particular emphasis on how these techniques are being applied in teaching and learning. Methods for Building Predictive Models  Linear Regression Logistic Regression Nearest Neighbours Classifiers Decision Trees Naïve Bayes Classifiers Bayesian Networks Support Vector Machines Neural Networks Ensemble Methods   ",1,2,-1,3
"1012","Statistical graphics: making information clear – and beautiful","Improving""figures""requires""two"" key"" decisions: s  Who is your target audience? What are you trying to show?  guiding principles  Avoid distracting elements. Use informative colour to visually associate elements. Keep the figure simple (and therefore interpretable). Keep the x- and y-axes on the same scale. Eliminate repetitive information. Maintain consistency across plots. ",0,1,-1,2
"1013","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This paper present a set of goals for graphical displays discussed primarily from the statistical point of view. The author also discussed some inherent contradictions in these goals that may be impeding communication between the fields of statistics.",0,1,-1,2
"1014","Junkcharts Trifecta Checkup: The Definitive Guide","Helpful do's and don'ts of data visualization Good visualizations should not only accurately reflect the data but also unveil underlying structures and reveal patterns of distribution, clusters, anomalies and correlations, in a format that is clear and easy to read and understand.",2,0,2,2
"1015","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","The central purpose of this study is to introduce hierarchical cluster analysis and pattern visualization methods from the data mining literature and demonstrate the method’s utility through one example, identification of student dropout from student K-12 longitudinal grades.",0,1,-1,3
"1016","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Networks are a relatively simple but powerful way of looking at the small and vital communities in every school and college. Empirical research of undergraduate learning communities is sparse, and instructors are thus limited to anecdotal evidence to inform decisions that may impact student relations. This primer helps to guide educational researchers into a growing field that can help investigate classroom-scale hypotheses, and ultimately inform for better instruction.",1,1,0,4
"1017","Why Students Should Own Their Educational Data","Technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.”",0,0,0,2
"1018","Knowledge tracing: Modeling the acquisition of procedural knowledge","The goal of the research was to implement a simple student modeling process that would allow the tutor to monitor the student's knowledge state and tailor the sequence of practice exercises to the student's needs.",0,0,0,3
"1019","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Given the overlaps in research interests, goals, and approaches between the EDM and LAK communities, the authors of this paper recommend that the executive committees of SoLAR and IEDMS formalize approaches for dissemination of research and enacting cross-community ties. A formal relationship will allow each community to continue developing their specialized and distinct research methods and tools, while simultaneously increasing opportunities for collaborative research and sharing of research findings between the communities.",2,0,2,2
"1020","Why Opting Out of Student Data Collection Isn’t the Solution","Policymakers seeking to set privacy rules for student data need to consider both the privacy rights of parents and students and the expectations of parents that teachers and administrators have access to the data needed to make smart decisions about managing our educational system. Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.",3,0,3,2
"1021","Why Is Measuring Learning So Difficult?"," learning is one of the most multi-dimensional things/too broad cannot be measured in a psychometrically meaningful way sometimes we have to simplify it too much to capture the data and the understandings cultural contruct ",0,0,0,1
"1022","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg considers that personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”.  danger:  By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Their lack of ability to compensate may mean they suffer as a result. children’s preferences are not fixed issue of ensuring that children’s data is not misused ",1,3,-2,2
"1023","Feature Selection","why?  knowledge discovery (interpretability &amp; insight)          (e.g. 1000 patterns, only 10 matters)  curse of dimensionality          (more features, more data needed)",0,0,0,5
"1024","Chapter 1: Social Network Data"," Introduction: What's different about social network data? Nodes  Populations, samples, and boundaries Modality and levels of analysis   Relations  Sampling ties Multiple relations   Scales of measurement A note on statistics and social network data ",0,0,0,4
"1025","RStudio Cheat Sheets","All the RStudio Cheat Sheets we need!!!!!",0,1,-1,1
"1026","Translating Learning into Numbers: A Generic Framework for Learning Analytics","LA shows facets of a double nature: In its most optimistic outlook, learners will be provided with personal information about their current needs, while, at the same time, the educational system will be evolved from a “onesize-fits-all” approach into a highly personal competence-driven educational experience. But this view is not without flaws, because of the real dangers that the extended and organized collection of learner data may not so much bring added benefits to the individual, but instead provides a tool for HEIs, companies, or governments to increase manipulative control over students, employees, and citizens, thereby abusing LA as a means to reinforce segregation, peer pressure, and conformism rather than to help construct a needs-driven learning society. ",1,2,-1,1
"1027","The Big Five and Visualisations of Team Work Activity","This paper visualized team interactions with the Big5 model of teamwork, and demonstrated that the visualizations can express various aspects of the components of teamwork.",0,0,0,2
"1028","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","The authors performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent. They also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course.",1,0,1,4
"1029","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","The ALS factorization method  One important advantage: it lends itself to an unambiguous comparison with the initial expert Q-matrix, and consequently to a clear interpretation. A small number of errors will not affect the method’s capacity to derive “better” Q-matrices (as defined by their predictive power) and make useful hints for enhancements. ",2,1,1,5
"1030","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction.  eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique. ",6,0,6,5
"1031","Using data mining to predict secondary school student performance","A prediction of secondary student grades of two core classes (Mathematics and Portuguese) by using past school grades (first and second periods), demographic, social and other school related data. Three different DM goals (i.e. binary/5- level classification and regression) and four DM methods, i.e. Decision Trees (DT), Random Forests (RF), Neural Networks (NN) and Support Vector Machines (SVM), were tested.  Business Intelligence (BI)/Data Mining (DM) techniques   ",1,1,0,3
"1032","Developing a generalizable detector of when students game the system","Background: Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly.  Present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula    An example of how to develop a system (detector) and how it can help improve learning procedures.  ",3,1,2,5
"1033","Big Data in Education","Big Data in Education is a massive online open textbook. It can be found on EdX(2015) https://courses.edx.org/courses/course-v1:TeachersCollegeX+BDE1x+2T2015/course/ Chapter 1: Prediction Modeling Chapter 2: Model Goodness and Validation Chapter 3: Behavior Detection Chapter 4: Knowledge Inference Chapter 5: Relationship Mining Chapter 6: Visualization Chapter 7: Structure Discovery Chapter 8: Advanced Topics  ",1,0,1,5
"1034","Hands-On Programming with R","Good book for R learners",1,0,1,2
"1035","Principal Component Analysis explained visually","Great visualization for learning PCA!",1,0,1,2
"1036","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data driven decision making (3DM)  Primarily has focused on test scores, he’s looking at grade assignment too aggregated descriptive statistics give only an overview of the central tendency of a sample, obscuring the actual trends in individual student achievement that may provide the clues to inform teachers and school leaders that a student has shifted from on-track performance to significantly challenged with school.  An alternative is to inspect every data element individually for each student, but  understanding and interpreting trends becomes impossible.  a third option, single student course failures could be used, since early failure in reading or mathematics has been shown to be highly predictive of student schooling outcomes  However, this issue returns to the problem of reducing the data represented by individual student achievement trends to aggregated means and fitted regression slope equations that are generalizable to the population, but less useful for making data driven decisions for individual students and schools. Author combines hierarchical cluster analysis (HCA) and heatmaps to pattern and interpret longitudinal trends in student data, such as teacher-assigned grades ",0,3,-3,3
"1037","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Network Types: Unipartite: consist of only one type of actor Bipartite: two mode Directional: one way or two way Egocentric studies focus on a sample of individuals (called “egos”) and the local social environment surrounding them without explicitly attempting to “connect the dots” in the network further. census networks, sometimes referred to as whole networks, collect data from an entire bounded population of actors, including identifiable information about the respondents’ relational partners. These alters are then identified among the set of respondents, yielding a complete picture of the network. network density. The density of a network is a measurement of how many links are ob- served in a whole network divided by the total number of links that could exist if every actor were connected to every other actor. homophily: a propensity for similar actors to be disproportionately connected in a relation of interest. Social selection occurs when a relationship is more likely to occur due to two actors having the same attributes Social influence occurs when individuals change their attributes to match those of their relational partners, due to influence from those partners. Triads and transitivity: Transitivity is a simple, local measure of a more general set of concepts related to clustering or cohesion, which may extend to much larger groups beyond size three. a preponderance of transitive triads is considered an indicator of hierarchy (with A always giving and C always receiving), while a preponderance of cyclical triads is an indicator of egalitarianism (with everyone giving and everyone receiving). degree centrality - the total number of connections a node has. In networks in which relations are directional, this includes measures of inde- gree and outdegree closeness centrality - how close one actor is to other actors on average, measured along geodesics. betweenness centrality - focuses on whether actors serve as bridges in the shortest paths between two actors. eigenvector centrality - being connected to other well-connected individuals Timing of data collection is important; can do it over a period of time IRB: Data used solely for curricular improvement and not for gen- eralizable research often do not require consent, but any use of the data for generalizable research does (Martin and In- wood, 2012) Because social networks often describe vulnerable populations, talking with IRB is important; this can be especially true for educational network research, when researchers are often also acting as instructors or supervisors to the student subjects and are thus in a position of authority. This may create the impression in students’ minds that re- search participation is linked to student assessment. In many scenarios, re- searchers must plan on anonymizing or removing identifiers on data opt-in and opt-out procedures: a standard opt-in procedure would use an individual not involved with the course to talk students through a consent script, answer questions, and retrieve signed consent forms from consenting subjects. While the opt-in procedures are more common and foreground subject protection, they tend to omit data with a bias toward underserved and less successful populations. An opt-out procedure would provide the same opportunities for student information and questions but ask subjects to opt out by signing a centrally located and easily accessible form kept confidential from researchers until after the research is completed. commonly leads to higher rates of data return.Matrices: sociomatrix or adjacency matrix - A unipartite sociomatrix will always be square, with as many rows and columns as there are respondents. For undirected networks, the sociomatrix will be symmetric along the main diagonal; for undirected, the upper and lower triangles will instead store different information. Matrices for binary networks will be filled with 1s and 0s, indicating the existence of a tie or not, respectively. edgelist, a two-column matrix with each row identifying a pair of nodes in a relationship Matrices for binary networks will be filled with 1s and 0s, indicating the existence of a tie or not, respectively. In cases of nonbinary ties (e.g., how many hours each student studied together) the numbers within the matrix may exceed one. The matrix storing nodal attribute information need not be square; it will have a row for each respondent and a column for each attribute measured. ",8,2,6,4
"1038","Why Students Should Own Their Educational Data","historically, learning data has been presented and digested on a meta level, because that is the only way that it could be presented now, there are opportunities to collect and retrieve data on more individualized and contextualized bases The more granular and more specific the data can be, particularly in terms of context, the better the analysis can be, which could lead to better learning Organizations can be developed which can secure and provide to students their data, for better learning outcomes",4,0,4,2
"1039","Knowledge tracing: Modeling the acquisition of procedural knowledge","Examines the use of a programming tutor and its effectiveness on student learning in a self-paced environment Only an abstract and short stub   ",0,0,0,3
"1040","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","“big data” + computation = improving learning processes Two communities: Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment. EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners LAK researchers typically place a stronger emphasis on attempting to understand systems as wholes, in their full complexity. ",1,0,1,2
"1041","Evaluating Machine Learning Models","Classification is about predicting class labels given input data.  In binary classification, there are two possible output classes. In multi- class classification, there are more than two possible classes.  Accuracy simply measures how often the classifier makes the correct prediction.  False negatives can be worse than false positives (look at the situation) - e.g., diagnosing no cancer when there is, v. Diagnosing cancer when there isn’t.Per-class accuracy Log-loss is a “soft” measurement of accuracy that incorporates this idea of probabilistic confidence.  AUC stands for area under the curve. Here, the curve is the receiver operating characteristic curve, or ROC curve for short. The ROC curve shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives. In other words, it shows you how many correct positive classifications can be gained as you allow for more and more false positives. The ROC curve is not just a single number; it is a whole curve.  Precision answers the question, “Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant?”  Recall answers the question, “Out of all the items that are truly relevant, how many are found by the ranker/classifier?”  precision = # happy correct answers / # total items returned by ranker  recall = # happy correct answers / # total relevant items  harmonic mean: F1 = 2(precision*recall / precision + recall)  NDCG - normalized discounted cumulative gain. There are three closely related metrics here: cumulative gain (CG), discounted cumulative gain (DCG), and finally, normalized discounted cumulative gain.  Cumulative gain sums up the relevance of the top k items.  Discounted cumulative gain discounts items that are further down the list.  Normalized discounted cumulative gain is a normalized version of discounted cumulative gain. It divides the DCG by the perfect DCG score, so that the normalized score always lies between 0.0 and 1.0. regression: RMSE (root-mean-square error), also known as RMSD (root-mean-square deviation). This is defined as the square root of the average squared distance between the actual score and the predicted score  RMSE, because it is an average, it is sensitive to large outliers. If the regressor performs really badly on a single data point, the average error could be very big.In statistical terms, we say that the mean is not robust (to large outliers).  median absolute percentage: MAPE = median (of absolute value of)yi - yi /yi Look out for data outliers which could skew the overall data",19,9,10,5
"1042","Why Is Measuring Learning So Difficult?","simplification waters down meaning can't measure, too contextual in meaningful way weak tools in humanities learning is personal; construct of learning is difficult but can measure behavior no reliable simple proxy indicators that we can trust ranges from curiosity to memory can measure indicators of understanding but not understanding itself cultural, social, psychological factors to consider need to measure pre competencies learning is the growth in competence measure constructs or achievement analytics for the learner would be interesting hard to define learning",1,3,-2,1
"1043","Saturday Morning Breakfast Cereal","cute cartoon need to understand data better before reaching conclusions. ",2,0,2,2
"1044","The Data Wrangling Cheatsheet","essential tips on sorting data  ",0,0,0,1
"1045","Data wranglers: human interpreters to help close the feedback loop","Because learning is complex, need people to be interpreting the data, engaging in sense-making activities to mediate the information in ways that enable intelligent action. need to connect data wranglers/analysts with the practitioners that could benefit from the data Open University example where it is being done Gains have been made in certain areas, although the funding structure has changed which has correlated with reduced metrics, so they can't gauge the effectiveness of the program.  They think it is working, however.",2,1,1,1
"1046","Zuckerberg is ploughing billions into 'personalised learning' – why?","personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”.human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests. This is similar to how Facebook’s news feed works, and other commercial personalisation models based on text and behaviour analysis.Dangers:1. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists.2. learners need to cope to learn in a way that’s not suited to them3. children’s preferences  change as immediate responses to the environment.Could work, though, if teachers are involved.",5,0,5,2
"1047","Feature Selection","Good for interpretability and insight Maybe only a few items really matter in the overall analysis Less features = less curse of dimensionality",1,0,1,5
"1048","RStudio Cheat Sheets","nice intro to markdown use shiny in header to get tables",1,0,1,1
"1049","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Not much to gain here, as I was only able to see the first page Indicates that it is much easier to get data these days",2,0,2,1
"1050","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Online Recommender Systems program offered through Coursera They learned that the effort expended in the course was a predictor of knowledge gain. Abstract only.",2,0,2,4
"1051","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Making an effective course with explicit associations between a necessary set of skills and course contents requires intensive cognitive task analysis and time- consuming evidence-based iterative engineering  Learning Factor Analysis (LFA) works only when meaningful “features” are given, which (usually) requires cognitive task analysis by subject domain experts. Q-matrix (matrix factorization methods for automatic skill set) use discovery from students’ response data. However, these methods often face the issue of interpretability—i.e., providing meaningful feedback to course designers and developers based on the machine-generated skill set is often troublesome.  eEPIPHANY - a method developed to fully and automatically discover skill sets from online course data, which are the combination of the assessment item text data (i.e., problem and feedback text sentences for assessment items) and student learning interaction data. goal of eEPIPHANY is to provide constructive feedback to online course designers and developers for iterative course improvement. ",6,2,4,5
"1052","Chapter 1: Social Network Data","network approaches tend to study whole populations by means of census, rather than by sample because network methods focus on relations among actors; if one actor happens to be selected, then we must also include all other actors to whom our ego has (or could have) ties. Boundaries: two main typesnaturally occurring clusters, or networks; drawing the boundaries around a population that is known, a priori, to be a network. Or, ""demographic"" or ""ecological"" approach to defining population boundaries.""multi-modal"" -  Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Data collection:Full network: best, but may be impracticalSnowball: starting incrementally and then gathering more as people are named; this may overstate data and may leave some outliers outEgocentric (with alter connections) - collects on chunks of the network and connections; can be usefulEgocentric (ego only) - collects on individuals, and not the network; can be good, but may miss some important network connectionsMeasurement scales:BinaryMultiple, nominal - categorical, but assigning numbersGrouped, ordinal - degrees assignedFull-rank - ranking between actorsInterval - where the numbers have real meaning (I.e., the difference between 1 and 2 is the same as the difference between 9 and 10)In general, social networks are limited to a particular group at a particular time and are not generalizable, but if a scenario were replicated many times, there could be some probability of the network occurring which could be somewhat more generalizable.",2,2,0,4
"1053","Learning Analytics Dashboards","visualization has the potential to be more precise and revealing than conventional statistical computations (Tufte, 2001). Because static visualizations usually lead to more questions, adding dynamic interaction techniques to the visualization can lead to meaningful visualization tools that encourage exploratory data analysis. The first step is getting to know the problem domain, the data set, the intended end-users of the tool, the typical tasks they should be able to perform, and so on. The following questions need to be answered at this stage: Why: What is the goal of the visualization? What questions about the data should it answer? For whom: For whom is the visualization intended? Are the people involved specialists in the domain, or in visualization? What: What data will the visualization display? Do these data exhibit a specific internal structure, like time, a hierarchy, or a network? How: How will the visualization support the goal? How will people be able to interact with the visualization? What is the intended output device? Visual properties ranked:For quantitative data:PositionLengthAngleSlopeAreaVolumeLightnessSaturationHueTextureConnectionContainmentShapeFor categorical dataPositionHueTextureConnectionContainmentLightnessSaturationShapeLengthAngleSlopeAreaVolumeBar charts good, pie charts badScatter plots good for correlations ",6,3,3,2
"1054","Measurement and its Uses in Learning Analytics","operationalization, the repeatability or precision of measurements, sources of error, and the interpretation of the measure itself. Model-based reasoning: accepting a simplified representation of a system that captures salient aspects (e.g., patterns) and allows us to explain or predict phenomena In learning analytics, efficient collection of data is usually not the problem, but the lack of standardization can make it challenging to account for measurement error.  A measurement model is a formal mathematical relationship between a latent variable or set of variables and an observable variable or set of variables.  learning analytics and educational data mining  explores relationships between psychological scales, behavior, and performance in digital learning environments  Factor analysis (Mulaik, 2009) models the correlations among observed variables through a linear relationship to a set of latent variables known as factors.  Factor analysis is:Exploratory factor analysis (EFA) - used to determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development (note: don’t use EFA with PCA) and confirmatory factor analysis (CFA) is a complementary set of techniques to test a theoretically proposed factor model by examining residuals between expected and observed correlations. CFA can be used to reject a model.  Predictive modelling v. Measurement theory“in explanatory modelling the focus is on minimizing bias to obtain the most accurate representation of the underlying theory. In contrast, predictive modelling seeks to minimize the combination of bias and variance, occasionally sacrificing theoretical accuracy for improved empirical precision”  data modelling culture (98%) vs the algorithmic modelling culture (2%)",1,7,-6,5
"1055","Predictive Modelling in Teaching and Learning","In predictive modelling, the purpose is to create a model that will predict the values (or class if the prediction does not deal with numeric data) of new data based on observations. the principal difference between explanatory modelling and predictive modelling is with the application of the model to future events, where explanatory modelling does not aim to make any claims about the future, while predictive modelling does. In explanatory modelling, all of the data collected from a sample (e.g., students enrolled in a given course) is used to describe a population more generally (e.g., all students who could or might enroll in a given course). In a predictive model, a hold out dataset is used to evaluate the suitability of a model for prediction, and to protect against the overfitting of models to data being used for training With educational data, it is common to see models built using methods such as these:     1.    Linear Regression predicts a continuous numeric output from a linear combination of attributes.     2.    Logistic Regression predicts the odds of two or more outcomes, allowing for categorical predictions.     3.    Nearest Neighbours Classifiers use only the closest labelled data points in the training dataset to determine the appropriate predicted labels for new data.     4.    Decision Trees (e.g., C4.5 algorithm) are repeated partitions of the data based on a series of single attribute “tests.” Each test is chosen algorithmically to maximize the purity of the classifications in each partition.     5.    Naïve Bayes Classifiers assume the statistical independence of each attribute given the classification, and provide probabilistic interpretations of classifications.     6.    Bayesian Networks feature manually constructed graphical models and provide probabilistic interpretations of classifications.     7.    Support Vector Machines use a high dimensional data projection in order to find a hyperplane of greatest separation between the various classes.     8.    Neural Networks are biologically inspired algorithms that propagate data input through a series of sparsely interconnected layers of computational nodes (neurons) to produce an output. Increased interest has been shown in neural network approaches under the label of deep learning.     9.     Ensemble Methods use a voting pool of either homogeneous or heterogeneous classifiers. Two prominent techniques are bootstrap aggregating, in which several predictive models are built from random sub-samples of the dataset, and boosting, in which successive predictive models are designed to account for the misclassifications of the prior models. ",4,4,0,3
"1056","Ethics and Learning Analytics: Charting the (Un)Charted","with all of the data, we need some sort of an ethical framework to guide further research and activities",0,0,0,2
"1057","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Explanatory models seek to identify interpretable constructs that are causally related to outcomes The focus is on why a model fits the data well rather than only that it fits well.  A knowledge component (KC) is a fact, concept, or skill required to succeed at a particular task or problem step. We refer to this specialized form of a cognitive model as a KC model or, alternatively, a Q-matrix (Barnes, 2005).  Cognitive models map knowledge components (i.e., concepts, skills, and facts; Koedinger, Corbett, &amp; Perfetti, 2012) to problem steps or tasks on which student performance can be observed.  Difficulty factors assessment (DFA; e.g., Koedinger &amp; Nathan, 2004) moves beyond expert intuition by using a data-driven knowledge decomposition process to identify problematic elements of a defined task.  LFA searches across hypothesized knowledge components drawn from different existing KC models, evaluates different models based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model. As such, LFA greatly reduces demands on human effort while simultaneously easing the burden of interpretation, even if it does not automatically accomplish it.  SimStudent, a state-of-the-art machine-learning agent,  to discover cognitive models automatically without requiring existing ones. SimStudent is an intelligent agent that inductively learns knowledge, in the form of rules, by observing a tutor solve sample problems and by solving problems on its own and receiving feedback. SimStudent can be used to test alternative models of human learning to see which best predicts human behaviour  Both LFA and SimStudent are capable of producing cognitive model discoveries that not only significantly improve predictive accuracy but are readily interpretable and, thus, explanatory  The fact that methods like LFA are “human-in-the-loop” — that is, requiring input from a domain expert — has been cited as a limitation. In the case of LFA, one or more expert-tagged cognitive models are required initially in order to produce new model discoveries.  For a model to be explanatory, one should be able to understand why the model achieves better predictive accuracy than alternatives. In addition, the understanding of this why should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both.  Explanatory modelling efforts tend to start with “clean” independent variables that have either simple functions or map to clearly defined constructs. For example, LFA derives new variables from existing, expert-labelled variables using simple split, merge, or add operators.  Another feature of explanatory models, one that relates most to actionability, is that the dependent variable maps to a well-defined construct. The work on learning rate groups is an example of this: since the groups to which students are classified are defined up front, it is clear what it means for a student to be in the “flat” learning curve group, as opposed to the “steep” one.  explanatory models tend to be characterized by fewer estimated parameters (independent variables, or features). For example, the AFM has only one parameter for each student and two parameters for each knowledge component. Adding learning rate groups extends the model by only one additional parameter, group membership. This makes the contribution of the added parameter easy to attribute and interpret. Having fewer parameters also allows each parameter’s estimates to have more explanatory power, alleviating issues of indeterminacy.",14,7,7,5
"1058","Statistical graphics: making information clear – and beautiful","Avoid distracting elements.Use informative colour to visually associate elements.Keep the figure simple (and therefore interpretable).  Keep the x- and y-axes on the same scale. Eliminate repetitive information.Maintain consistency across plots.",0,1,-1,2
"1059","How to display data badly","1. Show as few data elements as possible (data density)2. Minimize the Data to Ink Ratio3. Be consistent with visual metaphors4. Show data accurately; remember that order is not the only variable5. Maintain context6. Consistency of scale7. Emphasize the important8. Maintain the baseline9. Avoid alphabetical unless it helps10. Label clearly11. Simplify (particularly numbers)12. Don’t need to improve on a good thing",4,0,4,3
"1060","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Don’t put too much into the graph papers in the Journal of Computational and Graphical Statistics are about 80% computation and 20% graphics  Graphics is typically thought of as a way to help with simple tasks such as data cleaning and exploration, before getting to the serious task of inference.  lack of interaction between the worlds of statistical graphics and information visualization  Infovis - Information Visualization  the statistical approach concentrates on what can be got out of the available data and the Infovis approach uses the data to draw attention to wider issues. Both approaches have their value and it would probably be best if both could be combined.  Modern exploratory data analysis involves using interactive graphics, and such tools are also frequently used for Infovis graphics in web displays, along with sound and video.  Statistical graphics references:Bertin and WilkinsonCleveland Tufte Infovis references:HeerKosaraMunznerShneiderman Kosara’s blog, eagereyes.orgShneiderman (1996): Overview first, zoom and filter, then details-on-demand  Infovis workshops, BELIV (BEyond time and errors: novel evaLuation methods for Information Visualization)  Discovery goals:         -  Giving an overview        -  Conveying the sense of the scale and complexity of a dataset.         -  flexible displays to discover unexpected aspects of the data<U+2028> Communication goals         -  readily understandable        -  Telling a story        -  Attracting attention and stimulating interest.  Best: WordleDecision TreeSteamgraphDisplay in a way that people can easily digest",4,4,0,2
"1061","Junkcharts Trifecta Checkup: The Definitive Guide","    •    What is the QUESTION?    •    What does the DATA say?    •    What does the VISUAL say? Multiple examples of how the blogger sees charts as either being good in all three categories or missing the mark in one or more categories.",1,1,0,2
"1062","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Kay words Longitudinal study. Novel application of hierarchical cluster analysis and pattern visualization: all data points patterned, visualized and interpreted. Usefulness - but is a 80% correct prediction good enough?",3,0,3,3
"1063","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Key words Learning relationships - formation and impacts on learning outcomes. Social network analysis (SNA) - tool kit. Introduction and example.",0,0,0,4
"1064","Why Students Should Own Their Educational Data","Main ideas: - Population studies does not tell you anything about any individual in that group. - Most learners have a ""jagged profile"" (not average) of traits when it comes to learning, highly contextualized. Technology may help, by giving educators detailed data on students and the ability to customize teaching materials per individual. - User should own their data.",0,0,0,2
"1065","Knowledge tracing: Modeling the acquisition of procedural knowledge","Example of modelling Students' changing knowledge state during skill acquisition. Students learning to write short programs with the ACT Programming Tutor (APT). APT constructed the ""ideal student model"" - allows tutor to solve exercises along with student and provide assistance. Model maintains estimate of probability of successful learning of rules in the model - knowledge tracing. Individualized sequence of excercises based on estimate until mastery.",4,0,4,3
"1066","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","EDM vs. LAK EDM: focuses on automated discovery; models often used as the basis of automated adaptation, conducted by a computer system; reduces phenomena to components and analyze individual components and their relationships. LAK: leverages human judgement; models often inform and empower instructors and learners; emphasize on attempting to understand systems as wholes in their full complexity.  ",0,0,0,2
"1067","Evaluating Machine Learning Models","Key words Stages; metrics for supervised models; evaluation mechanisms",0,0,0,5
"1068","Why Is Measuring Learning So Difficult?","Key words/Main points: Learning is multidimensional/too broad (social, cultural, individual elements)/contextual/idiosyncratic/personal/private It's hard to simplify or to find proxy indicators/observable behaviorally only. Lack tools to measure and to measure at different time points including the learners' competency prior to learning. Measurement shouldn't be diagnostic, but suggesting what could be learned.      ",0,2,-2,1
"1069","Saturday Morning Breakfast Cereal","Direction of causality. Over-generalization of research results.",0,0,0,2
"1070","The Data Wrangling Cheatsheet","Reshaping, subset, summarize, group, combine, create new.",0,0,0,1
"1071","Data wranglers: human interpreters to help close the feedback loop","Key words: - Feedback loop: where actionable intelligence is produced from data about learners and their contexts, and interventions are made with the aim of improving learning. - Gap: between data and academics who need to act - Data Wranglers: deployed to engage in sense-making activity with learning analytics data, to produce reports with actionable recommendations and increase academics' familiarity with data sources.",1,0,1,1
"1072","Zuckerberg is ploughing billions into 'personalised learning' – why?","Main idea Personalized learning: Teachers working with students to customize instruction to meet the student's individual needs and interests. Human work replaced by technology, algorithms provide users with content based on an analysis of their past behavior and demonstrated interests. Flaws: Impairs general knowledge acquirement; real world does not accommodate; children's preferences subject to change; data misuse. Combine different approaches.",5,3,2,2
"1073","Feature Selection","Why feature selection? Knowledge discovery - interpretability != insight Curse of dimensionality: the amount of data you need grows exponentially in the number of features you have.",0,0,0,5
"1074","RStudio Cheat Sheets","The R Markdown cheat sheet: ""R markdown is an authoring format that makes it easy to write resuable reports with R. You combine your R code with narration written in markdown (plain text) and then export the results as an html, pdf, or Word file. You can even use R markdown to build interactive documents and slideshows.""",0,1,-1,1
"1075","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Two structures: - Dimensions of learning analytics; stakeholders; objectives; data; instruments; internal limitations; external constraints. - LA and pedagogy; Pedagogic behavior -&gt; LA -&gt; Pedagogic consequences -&gt; Pedagogic behavior.",0,1,-1,1
"1076","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Results Knowledge gain: significant across all levels of prior knowledge and demographic categories. Main predictor is effort. Significant knowledge retention. Both limited to who chose to complete knowledge tests. Completion: hard to predict. Min predictor was intent to complete.",1,2,-1,4
"1077","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Innovative method Automatic discovery of skill models for successful completion of online course from MOOC data. Assumption: online courses have a pre-defined skill map; skills associated with formative assessment items. Evaluation of method.",4,0,4,5
"1078","Chapter 1: Social Network Data","Features Data: The rows and columns of the array are the same. Nodes - actors; relations - edges. Actors are usually not sampled independently, but all occur within some boundary. Multi-modal: individuals embedded in networks embedded in networks embedded in networks. Scales of measurement.",0,0,0,4
"1079","Learning Analytics Dashboards","Data visualization tool Types: face-to-face lectures, face-to-face group work and classroom orchestration, online or blended learning. Data: artifacts produced by learners, social interaction, resource use, time spent, test and self-assessment results Procedure/techniques  ",1,0,1,4
"1080","Measurement and its Uses in Learning Analytics","Use this article as a checklist to prep for Cert.",0,0,0,5
"1081","Predictive Modelling in Teaching and Learning","Contents of interest Workflow: Problem identification; Data collection; Classification and Regression; Feature selection; Model building; Model evaluation. Model-building methods: Linear regression; logistic regression; nearest neighbours classifiers; decision trees; naive bayes classifiers; bayesian networks; support vector machines; neural networks; ensemble methods.    ",1,4,-3,3
"1082","Ethics and Learning Analytics: Charting the (Un)Charted","Development of learning analytics. Concerns: Surveillance, algorithms. Ethics and privacy.",0,1,-1,2
"1083","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Contents Predictive: Finds combination of features that best predict outcomes; assessed by predictive accuracy. Explanatory: Seeks to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. Examples Characteristics of explanatory models: having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process.",1,0,1,5
"1084","Statistical graphics: making information clear – and beautiful"," Clear and Beautiful Info Default graphs in Excel and R: basic, not visually appealing, possibly problematic scaling to fit the entire screen. Key decisions: audience, what you are trying to show Use R. Guiding principles: avoid distracting elements, informative color, keep the figure simple Comparison of multiple plots: Keep the x- and y-axes on the same scale; eliminate repetitive information; maintain consistency across plots  ",3,2,1,2
"1085","How to display data badly","To do Efficiency of transmission of information. Accuracy of information: visual metaphor - magnitudes and order; graph-context correspondence. Clarity of information: keep same scale through data set; emphasize critical aspect only; make comparison between plots easy; baseline/total makes comparison easy; order smart; label clearly; less is more; adopt well-done version in the past;",4,2,2,2
"1086","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Goals for graphical displays (static presentation graphics) Balance between statistical clearness and aesthetic beauty. Discovery goals: Qualitative overview; conveying sense of scale and complexity of data set; exploration. Communication goals: Readily understandable; story-telling; attracting attention and stimulating interest.  ",3,2,1,2
"1087","Junkcharts Trifecta Checkup: The Definitive Guide","Question vs. data vs. visual What is the question? What does the data say? What does the visual say? Should be the same ideally.",1,0,1,2
"1088","Cluster","K-Means Clustering Use and Limitations Use 1. Start with arbitrary random 2 centroids; separating points above and below the mean; compute centroids by averaging coordinates. 2. Do an entire k-means cycle - move to computing three centroids; split the cluster with the largest range on a variable into two clusters (above and below mean). 3. New centroids are computed and another k-means cycle is performed. Continue this process until we reach the desired number (k) of centroids. Limitations",0,3,-3,1
"1089","Introduction to Social Network Methods:  Chapter 1: Social Network Data","Features Data: The rows and columns of the array are the same. Nodes - actors; relations - edges. Actors are usually not sampled independently, but all occur within some boundary. Multi-modal: individuals embedded in networks embedded in networks embedded in networks. Scales of measurement.",0,0,0,4
"1090","Big Data in Education 7.1 Clustering","Contents Clustering tries to find data points that ""group together"". Example. Simplest method: k-means clustering algorithm. Centroids usually chosen randomly to start, try to find better centroids with the algorithm until centroids stop moving. Sometimes there are good reasons to start with specific initial values. Run several times with different starting points.    ",3,1,2,1
"1091","Big Data in Education 7.2 Validation and Selection","Validating and choosing value of k Distortion (Mean Squared Deviation). Euclidean distance. Works for choosing between randomized restarts. Does not work for choosing cluster size because more clusters almost always leads to smaller distortion. Cross-validation can't solve this problem. Instead, penalize models with more clusters. Could also use BIC and AIC.",3,4,-1,1
"1092","Big Data in Education 7.6 Knowledge Inference: Q-Matrix Knowledge Structure","Q-matrix Rows are items, columns are skills - whether item requires a skill. Automated model discovery. Hand development and refinement.  ",3,0,3,5
"1093","Big Data in Education 1.1 Introduction","Contents of interest Types of EDM: Prediction; structure discovery; relationship mining. Resource: PSLC DataShop",0,0,0,5
"1094","Big Data in Education 4.2 Bayesian Knowledge Tracing","Contents Goal: Measuring how well a student knows a specific skill/knowledge component at a specific time, based on their past history of performance with that skill/KC. ""Performance"": A sequence of items that are dichotomously scored where each item corresponds to a single skill. Assumptions: Each item must involve a single latent trait or skill; each skill has four parameters; students could make mistakes/guesses while answering Compute latent knowledge (likelihood of knowledge, P(Ln)) and the probability that the learner will get the item correct (P(CORR)). P(CORR)=P(Ln)*P(-S)+P(-Ln)*P(G): knowing*slipping answer+not knowing*guessing. Whenever the student has an opportunity to use a skill, P(Ln), is updated using Baye's Theorem. Constraints apply to avoid model degeneracy. Public tools.  ",6,0,6,3
"1095","Big Data in Education 1.3 Classifiers, Part 1","Contents Categorical prediction. To determine which features, in which combination, can predict the label. Some algorithms are useful for specific domains. Step Regression: binary prediction, != step-wise regression, fits a linear regression function. Logistic Regression: Fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable. Decision Trees: Categorical and numerical prediction. Good when",1,4,-3,5
"1096","Big Data in Education 1.4 Classifiers Part 2","More Algorithms Decision Rules: Sets of if-then rules. K*: K-means Bagged Stumps Common Thread Support Vector Machines Genetic Algorithms Neural Networks: Composes extremely complex relationships through combining ""perceptrons"". Finds very complicated models",1,2,-1,5
"1097","Big Data in Education 2.2 Diagnostic Metrics Part 1","Metrics for classifiers Accuracy/Agreement: Easiest measures of model goodness, but not good metric when there is non-even categories. Kappa (Interpretation): Kappa=0, agreement is at chance; Kappa=1, agreement is perfect; Kappa=-1, perfectly inverse; &gt;1, messed up somewhere; &lt;0, worse than chance. Kappa is scaled by the proportion of each category, hard to compare between data sets.",5,2,3,1
"1098","Big Data in Education 2.3  Diagnostic Metrics Part 2","More metrics Receiver-Operating Characteristic (ROC) Curve: Binary prediction with probability. Take a threshold below which would be 0 and above be 1. X axis = false positives, Y axis = true positives, diagonal - chance. A': The probability that if the model is given an example from each category, it will accurately identify which is which. Can compare two models, but assumes independence of data point. Precision Recall",2,0,2,5
"1099","Big Data in Education 2.4 Diagnostic Metrics: Correlation","Metrics for Regressors Linear Correlation (Pearson's Correlation) R square: correlation squared. What percentage of variance in dependent measure is explained by a model. MAD/RMSE: Mean absolute deviation, root mean squared error Information Criteria: - BiC: Bayesian information Criteria, makes trade-off between goodness of fit and number of parameters, = k-fold cross validation - AiC: = leave-one-out cross validation",1,2,-1,5
"1100","Big Data in Education 2.5 Cross-Validation and Over-Fitting","Notes Overfitting: Fitting to noise, to specific context Cross-validation: Train on all groups but one, test on the one, for each possible combination. K-fold, leave-out-one. Flat cross-validation, stratified cross-validation; student/school/demographic-level cross-validation - cross validate on the level the model is going to generalize to.",0,1,-1,5
"1101","Cross Validation","Way it works Split training data into different folds, train on all folds except one, on all possible combinations. The model that performs the best will be kept and tested on the testing data.",2,1,1,5
"1102","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This article talks about that the school personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study mainly relies on the data of the longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district.  The main method used is the Hierarchical cluster analysis.",0,1,-1,3
"1103","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article demonstrates the study of social interactions between students. It argues that learning relationships form in undergraduate classrooms can inform educators in unique ways and improve educational reform. It introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. I really like this text, because it contains the unique aspects of humanities. ",2,0,2,4
"1104","Why Students Should Own Their Educational Data","I believe the most effective learning approach, based on extensive research, remains the self-paced, individually guided strategy (ie, the apprentice or tutoring model). However, that model is too expensive and impractical for all but the 1%. Maybe with enough data and design, the model can be replicated through technology.",1,0,1,2
"1105","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called the ideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. ",2,0,2,3
"1106","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) are heavily discussed in this article and are the two main approaches. It argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.",0,0,0,2
"1107","Evaluating Machine Learning Models","Data science is very useful in a lot of fields and relied heavily on statistics. Some of the commonly used machine learning techniques or methods contain bootstrapping, cross-validation, random tree, forests, best subset selection, clustering. In all, the field of learning analytics and machine learning are closed related and discussed together.",1,0,1,1
"1108","Why Is Measuring Learning So Difficult?","I wonder what this means for Ryan Baker and his students at EdX (not to pick on any one group of interested scholars in particular), but also the OLI at Carnegie Mellon and the recent exciting winning of crucial funding for Acrobatiq. Overall, this video is interesting and inspiring.",3,0,3,2
"1109","Saturday Morning Breakfast Cereal","To be honest, I didn't get the point of this comic series. All I notice is that the author is making fun of engineering and data science. I mean, it did make sense on certain degree. But the culture difference might be a hinder.",2,1,1,2
"1110","The Data Wrangling Cheatsheet","The data wrangling cheat sheet is a comprehensive summary of commonly used functions in succinct forms that are ready for us to use. It is really convenient and helpful to people who work in the field of data science and analytics to deal with huge data sets. ",1,1,0,1
"1111","Data wranglers: human interpreters to help close the feedback loop","This paper describes a programme of human Data Wranglers deployed at the Open University, UK, charged with making sense of a range of data sources related to learning, analysing that data in the light of their understanding of practice in individual faculties/departments, and producing reports that summarise the key points and make actionable recommendations.",1,0,1,1
"1112","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article talks about Zuckerburg's story and conveys that his's way ay not be the right way. Zuckerburg wants to plough billions into personalised learning, but from a technical perspective, more factors need to be taken into account. ",1,0,1,2
"1113","Feature Selection","This video talks about the feature selection in machine learning from two perspectives. One is the knowledge discovery that explains the interpretability and insight. The other is called the curse of dimensionality. These two tools are extremely useful in solving problems that involve data datasets.",0,1,-1,5
"1114","RStudio Cheat Sheets","Shiny and the r markdown cheat sheet is a comprehensive summary of commonly used functions in succinct forms that are ready for us to use. It is really convenient.",1,1,0,1
"1115","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This paper examines the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. It discusses a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. It's interesting how it talks about policy guidelines and best practice examples.",4,4,0,2
"1116","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This study performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent.Based on the limited data, face-to-face students performed as well as the online-only students or better. They preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace.",4,1,3,4
"1117","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article's main method focuses on correlations between various parts of student performance, as well as in the text of assessment items, and builds a superior statistical model that outperforms human experts. The results show that (1) their method outperforms human-engineered skill models, (2) skill models discovered by their method are interpretable, and (3) their method is remarkably faster than existing methods. 'These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. "" However, I don't think these methods and results are enough to reach to the above conclusion, because more factors need to be taken in to considerations",8,0,8,5
"1118","Chapter 1: Social Network Data","After reading this article, I'm more interested in the application of statistics to social network data. This text focuses on more basic and commonplace uses of network analysis,  the dealing with the ""descriptive"" side of statistics. They include developing index numbers to describe certain aspects of the distribution of relational ties among actors in networks. On the other side, the second half of the text is helpful for people who are interested in the inferential side,",0,0,0,4
"1119","Learning Analytics Dashboards","This website serves as the society for learning analytics research and post a large number of related articles, essay and researches. For example, 2020 Call for Executive Committee Nominations is a very recent research that was posted on November 19, 2019. There are a lot of interesting topics and data to learn from by using the resources on the society for learning analytics research.",0,0,0,2
"1120","Measurement and its Uses in Learning Analytics","This article talks about the Psychological measurement, a process for making warranted claims about states of mind. The method of measuring latent variables is interesting. The focus of this paper is also worth praising, because it focuses on thematical rather than historical aspects, from more conceptual material about constructs, instruments, and sources of measurement error toward increasing technical detail about particular measurement models and their uses.",3,1,2,5
"1121","Predictive Modelling in Teaching and Learning","This article describes the process, practice, and challenges of using predictive modelling in teaching and learning. In both the elds of educational data mining (EDM) and learning analytics (LA) predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic achievement. This essay is very useful for people who are interested in studying predictive models for practice uses.",2,0,2,3
"1122","Ethics and Learning Analytics: Charting the (Un)Charted","This chapter provides an overview of how our own thinking has developed and maps our journey against broader developments in the field. It should be noticed and  emphasized that ethics and privacy are crucial enablers n learning analytics. It briefly locates ethics in learning analytics in the broader context of the forces shaping higher education and the roles of data and evidence. I think its argument is crucial in the future development of learning analytics.",0,0,0,2
"1123","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The vast majority of educational data mining research has focused on achieving predictive accuracy, but this study argues that the field could benefit from more focus on developing explanatory models. By reviewing examples of educational data mining efforts that have produced explanatory models, we reach improvements to learning outcomes and/or learning theory. This study is comprehensive and interesting in terms of the educational uses of data mining.",1,0,1,5
"1124","Statistical graphics: making information clear – and beautiful","The take-away message here is that he obvious way to present information is in a graph. But not all graphs are created equal. A well-designed graph can make clear what an ill-thought-out one conceals. Jarad Niemi and Andrew Gelman present visualisations of a measles epidemic. To me, plotting and making beautiful and efficient graphs are really important in presenting information in statistics, economics, and other related subjects. ",1,2,-1,2
"1125","How to display data badly","This article talks about methods for displaying data and gives examples of a wide variety of interesting and inventive schemes. Three parts: showing data, showing data accurately, and showing data clearly are the key elements in creating good graphs.",3,0,3,2
"1126","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This article emphasizes the importance of graphical displays in statistical practice. Tukey’s Exploratory Data Analysis (1977) and Tufte’s books are two main contributors. However, exploratory and graphical methods represent a minor subfield and are not wellintegrated with larger themes of modeling and inference. Infographics is used widely, but their purveyors and enthusiasts appear to be uninterested in statistical principles.",1,0,1,2
"1127","Junkcharts Trifecta Checkup: The Definitive Guide","This web page talks about eh junkcharts. They give several examples of junk charts that have one or more kinds of errors. Some graphs have unnecessary labeling or decorations. Others may contain distorted scaling or dimensions. This webpage serves well in creating future more useful plots.",1,4,-3,2
"1128","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","network analysis can be used to describe the structure of seemingly ethereal concepts such as reputation, charisma, and teaching ability through the social assessment of peers and stakeholders. With a better understanding of the formation and importance of classroom networks, instructors may wish to understand how their teaching fosters or hinders these networks, potentially as part of formative assessment. Reducing the achievement gaps along many demographic lines is likely to involve social engineering at some granular level, and the success or failure of interventions represents rich opportunities for network assessment.",6,1,5,2
"1129","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Summary &amp; Reflection  Similarity between EDM and LAK     LAK and EDM share the goals of improving education by improving assessment, how problems in education are understood, and how interventions are planned and selected.     The difference between EDM and LAK    EDM researchers have placed greater focus on issues of model generalizability (e.g. multi-level cross-validation, replication across data sets). By contrast, LAK researchers have placed greater focus on addressing needs of multiple stakeholders with information drawn from data.    Questions  1. How EDM and LAK collaborates with each other and get the benefits of it 2. Does big data really bring in positive impacts in education fields? I think it depends. Big data also can be like the large messy data. How to ask a good question will be a key. 3. How to deal with the privacy issues since some educational data may be sensitive?  ",4,1,3,2
"1130","Why Is Measuring Learning So Difficult?","Summary &amp; Reflection 1. Learning is one of the most multi-dimensional things. The problem of measurement is sometimes we need to simply it too much in order to capture data that we could use. 2. Learning is too board that means so many different things. (too contextual, too idiosyncratic to measure it in the psychometric meaningful way) 3. Learning is most personal thing we do, nobody can do learning for us. The construct of culture construct is really difficult to define its measure (e.g, particular behavior patterns or output). Can only see the results but not the mind. 4. Probably there is no reliable, simple, proxy indicators for learning that we can trust. Learning is everything from curiosity to memory, everything from imagination to be able to paraphrase and say it yourself. 5. Certain concepts can represent ""understanding"", e.g, when students teach each other, that increases transfer across domains, reinforces memory. 6. Think about culture things, social implications, individual psychological things. 7. Don't know what people's competence were coming into learning problems. e.g, subject master get perfect scores on MOOCS does not mean they learn anything from the class. Learning is like multiple competence strung together. (should be longitudinal study) 8. Measuring is long with self-efficacy and achievement 9. Build connections, narrate stories as students go through learning. 10. Analytic should not be only a diagnosis of what is happening now, but should be a doorway to suggest what else is possible.",5,3,2,1
"1131","Saturday Morning Breakfast Cereal","Summary &amp; Reflection The relationship between resembling clock and increase of engineers Issues (may be problematic): 1. Comparing with people in different cultural backgrounds 2. Simplify the relationship 3. Do not have solid validation for the causal relationship 4. Based on the clock-based metrics, everything is great! --&gt; may be useful in the lab, but not in the real-world setting. 5. Need to consider more factors.",2,1,1,4
"1132","Zuckerberg is ploughing billions into 'personalised learning' – why?","Facebook founder Mark Zuckerberg believes personalised learning is the answer to many of education’s current woes. For him, personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. ",0,0,0,2
"1133","Statistical graphics-making information clear and beautiful.pdf","    Who is your target audience? What are you trying to show?     Avoid distracting elements. Use informative colour to visually associate elements. Keep the figure simple (and therefore interpretable).        ",0,1,-1,2
"1134","How to display data badly.pdf","Bad Rules - Rule 1: Show as few data as possible (Minimize the Data Density) - Rule 2: Hide what data you do show (Minimize the Data-ink ratio) http://www.infovis-wiki.net/index.php/Data-Ink_Ratio - Rule 3: Ignore visual metaphor altogether  A visual metaphor is an image that the viewer is meant to understand as a symbol for something else. http://study.com/academy/lesson/visual-metaphors-definition-examples.html - Rule 4: Only order matters - Rule 5: Graph data out of context - Rule 6: Change scales in mid-axis - Rule 7: Emphasize the trivial (Ignore the important) - Rule 8: Jiggle the baseline - Rule 9: Austria First (alphabetically) - Rule 10: Label a)illegibly, b) incompletely, c)incorrectly, d)ambiguously - Rule 11: More is murkier: a) more decimal places, b) more dimensions - Rule 12: If it has been done well in the past, think of the another way to do it.",2,2,0,3
"1135","Chapter 5","        This article describes the process, practice, and challenges of using predictive modelling  analytics (LA) predictive modelling has become a core practice of researchers, largely with  chapter, we provide a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process.     Methods for Building Predictive Model      1. Linear Regression predicts a continuous numeric output from a linear combination of attributes.  2. Logistic Regression predicts the odds of two or more outcomes, allowing for categorical predictions.  3. Nearest Neighbours Classifiers use only the closest labelled data points in the training dataset to determine the appropriate predicted labels for new data.  4. Decision Trees (e.g., C4.5 algorithm) are repeated partitions of the data based on a series of single  -  in each partition.  5.  assume the statistical independence of each attribute given the classification, and provide probabilistic interpretations of classification.      6. Bayesian Networks feature manually constructed graphical models and provide probabilistic inter-  7. Support Vector Machines use a high dimensional  greatest separation between the various classes.  8. Neural Networks are biologically inspired algorithms that propagate data input through a series of sparsely interconnected layers of computational nodes (neurons) to produce an output. Increased interest has been shown in neural network approaches under the label of deep learning.  9. Ensemble Methods use a voting pool of either  prominent techniques are bootstrap aggregating, in which several predictive models are built from random sub-samples of the dataset, and boosting, in which successive predictive models are  the prior models.                       ",3,4,-1,3
"1136","Infovis and Statistical Graphics: Different Goals, Different Looks","   1. Graphics are for the qualitative/descriptive—conceivably the semiquantitative—never for the carefully quantitative (tables do that better).  2. Graphics are for comparison—comparison of one kind or another—not for access to individual amounts.  3. Graphics are for impact—interocular impact if possible, swinging-finger impact if that is the best one can do, or impact for the unexpected as a minimum—but almost never for something that has to be worked at hard to be perceived.  4. Finally, graphics should report the results of careful data analysis—rather than be an attempt to replace it. (Exploration—to guide data analysis—can make essential interim use of graphics, but unless we are describing the exploration process rather than its results, the final graphic should build on the data analysis rather than the reverse.)    ",3,1,2,2
"1137","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping Out and Hierarchical Cluster Analysis.","On one hand, there really isn't anything about social network data that is all that unusual. Social network analysts do use a specialized language for describing the structure and contents of the sets of observations that they use. But, network data can also be described and understood using the ideas and concepts of more familiar methods, like cross-sectional survey research. On the other hand, the data sets that social network analysts develop usually end up looking quite different from the conventional rectangular data array so familiar to survey researchers and statistical analysts. The differences are quite important because they lead us to look at our data in a different way -- and even lead us to think differently about how to apply statistics. ""Conventional"" social science data consist of a rectangular array of measurements. The rows of the array are the cases, or subjects, or observations. The columns consist of scores (quantitative or qualitative) on attributes, or variables, or measures. A simple example is shown as figure 1.1.  Each cell of the array then describes the score of some actor (row) on some attribute (column). In some cases, there may be a third dimension to these arrays, representing panels of observations or multiple groups.",3,1,2,4
"1138","Introduction to Social Network Methods:  Chapter 1: Social Network Data","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8.",1,3,-2,3
"1139","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   The most important goal of the skill-model discovery and refinement proposed in the current paper is to improve online courses. Providing interpretable feedback based on a machine- discovered skill model and model refinement is therefore crucial. We hypothesize that to achieve this goal, two subgoals must be met: (1) to identify what part of the default skill model has been improved the most, and (2) to understand the improvement from a domain perspective.    ",2,0,2,5
"1140","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This article mainly focuses on the concept verification study, which can identify the whole educational achievement from the data pattern, such as dropping out of school or taking part in the college entrance examination and comparing it with the past drop-out identification method as an example of the effectiveness of the method.",0,0,0,3
"1141","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","I understand the formation of learning relationships in undergraduate classroom and the influence of these relationships on learning results. Snail can provide information for educators in a unique way and improve educational reform.",1,0,1,4
"1142","Why Students Should Own Their Educational Data","Because I think most learners have the characteristic of ""uneven"" when learning. A student may have an interest in science, but his reading ability is below average.",0,1,-1,2
"1143","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper describes a work of modeling students' changing knowledge state in the process of skill acquisition. It is concluded that the model is very successful in predicting test performance, and other modifications in the modeling process are discussed, which can improve the performance level.",3,0,3,3
"1144","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This paper proposes to strengthen and formalize communication and collaboration among these communities in order to share research, methods and tools for data mining and analysis in the development of LAK and EDM domains. At the same time, I learned two communities, education data mining (EDM), and learning analysis and knowledge (LAK).",0,0,0,2
"1145","Evaluating Machine Learning Models","In this overview, the author first introduces the machine learning workflow, and then discusses the evaluation index and model selection. I learned a lot about indicators used to monitor learning models, including classification, regression, and ranking.",0,1,-1,5
"1146","Why Is Measuring Learning So Difficult?","This video allows several higher education learning and evaluation professionals to discuss measuring learning difficulties.",0,2,-2,1
"1147","Saturday Morning Breakfast Cereal","It's a very interesting caricature.",0,1,-1,2
"1148","The Data Wrangling Cheatsheet","I learned a lot from this cheat sheet such as how to use the function select().",0,1,-1,1
"1149","Data wranglers: human interpreters to help close the feedback loop","This paper emphasizes the needs and values of human meaning in the process of interpreting data to transform it into operable information, and embeds the study and analysis work into the strategic environment and at the appropriate analysis level and granularity.",1,0,1,1
"1150","Zuckerberg is ploughing billions into 'personalised learning' – why?","I think individualized learning is the thing that all excellent teachers should do. Teachers should modify their learning materials and teaching styles to adapt to students' different learning styles.",1,0,1,2
"1151","Feature Selection","The video explaining the idea behind feature selection,I learning about the how to select the features.",0,0,0,5
"1152","RStudio Cheat Sheets","R cheatsheet gave me a better understanding of R and learned a lot about R, such as R markdown",1,0,1,1
"1153","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The article offers and discusses a generic design framework that can be used as a useful guide for setting up learning analysis services to support educational practices and learner guidance, quality assurance, curriculum development, and improving teacher efficiency and efficiency. let me learn about the key problem areas from the key dimensions of learning analysis (la) and the potential harm to the beneficial use of educational data.",3,2,1,2
"1154","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","The study designed a knowledge assessment tool for the topics of the online course, managed before and after the course to assess the learning situation, and evaluated it again five months later to assess the retention rate. However, the results are unpredictable. The article says that the courses completed by students are difficult to predict, and there are few factors that can provide predictive ability.",0,2,-2,5
"1155","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This paper assumes that the online course has a predefined skill diagram, and the skills of the skill diagram are related to the formative evaluation projects embedded in the entire online course. Our approach makes careful use of the correlation between the various parts of student performance and the evaluation of the project in order to establish an advanced statistical model that is even superior to human experts. I think this result is quite extensible.",4,0,4,5
"1156","Chapter 1: Social Network Data","I learned how to distinguish between the nominal, ordinal, and interval levels of the measurement, for example, based on the actual purpose, and the ratio level may be the same as the interval. At the same time, the nominal measurement is further divided into binary and multi-class variations.",0,0,0,4
"1157","Learning Analytics Dashboards","This website introduces the Learning Analysis and Research Association (SoLAR), an interdisciplinary network of top international researchers who are exploring the role and impact of analysis in teaching, learning, training and development.",1,0,1,2
"1158","Measurement and its Uses in Learning Analytics","This paper summarizes some key provocation and key problems in the development of learning analysis technology, in order to put forward the purpose and hypothesis of construction in learning analysis.",0,1,-1,2
"1159","Predictive Modelling in Teaching and Learning","This paper introduces the process, practice and challenge of using prediction model in teaching. Let me know about the field of educational data mining (EDM) and learning analysis (LA)",0,0,0,2
"1160","Ethics and Learning Analytics: Charting the (Un)Charted","This paper outlines how our own ideas develop and corresponds our journey to the broader development of the field. I learned the position of ethics in learning analysis under the background of various factors affecting higher education and the role of data and evidence.",0,0,0,2
"1161","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","An example of an educational data mining effort that produces an interpretative model and results in improvements in learning outcomes and/or learning theories. I have found that interpretative models attempt to determine the interpretable causal relationships between structures and can observe or infer their causal relationships from data.",0,0,0,5
"1162","Statistical graphics: making information clear – and beautiful","This article is a discussion of the visualization of information, which in many respects is an eye-catching map of the public display of modern statistics.",3,0,3,2
"1163","How to display data badly","This paper is an introduction to a method to deal with poor display data, which has been developed for many years and has produced many interesting inventions",0,1,-1,2
"1164","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This paper discusses some inherent contradictions in these graphics from a statistical point of view, which may hinder the communication between the statistical field and Infovis. This article is what I learned about the different goals that researchers in different fields attach importance to all aspects of data visualization.",0,2,-2,2
"1165","Junkcharts Trifecta Checkup: The Definitive Guide","The garbage graph Trifecta Checkup is a general framework for data visualization criticism. I understand that the visual elements of the icons should represent the data in a clear and concise manner and solve the problem directly.",1,2,-1,2
"1166","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis"," The article made me understand how similar methods (clustering and data visualization) can be used in HR analytics, to predict turnover and absenteeism. Learning data mining in education can help me make sense of how data analytics can also be used in HR analytics / organization analysis. The pictures in this article already contains a lot of useful information and implications for intervention.  Some basic concepts:   3DM: data driven decision making SSF: success at school factor cluster tree / dendrogram — based on the distance calculation [uncentered correlation was used as the distance measure here]   shorter horizontal lines indicates more similarity;  vertical lines connect the closest rows to form the clusters. each data row is clustered by similarity.   heatmap: hotter color indicates a higher score (red); cooler color indicates a lower score (blue); neural color indicates a central score (grey) hierarchical cluster analysis (HCA): supervised clustering — begins with a defined set of assumptions about the categorization of the data; unsupervised clustering — assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the dataset, a procedure well suited to discovering the underlying patterns within student data in education. missing data might have patterns (average linkage can help to address the missing data issue) combination of the cluster analysis, cluster tree, and heat map, creates the clustergram can compared with categorical data as well   Some interesting things worth notice:   teacher-assigned grades is a weak indicator of academic knowledge when compared to standardized test score — 75% of teacher-assigned grades appear to assess a student’s ability to negotiate the social processes of school don’t forget the goal of the study. this is very important.   ",5,4,1,3
"1167","Why Students Should Own Their Educational Data"," Even there is not much details in this article, I love the idea that students should own their education data. We still face the core question - Who should own the data? Traditional standard teaching practice assumes at least average skills across the board. However, it failed to take the individual differences into consideration. For a group of people, statistics patterns might have some implications on adjustment in policies, design of teach activities. Sometimes those general implications try to satisfy most people, but actually they fit nobody. The aggregate statistics means nothing towards an individual. However, if we start from an individual pattern perspective (like IRT, CDM), it could provide more insights towards each individual.  I agree that personality and learning varies across contexts. That’s why when we make attribution or interpretation through data, we need to be very careful about the assumptions and limitation that we might have. This article also raises a very interesting question - what is your value proposition of 4-year education, considering the trend of MOOCs. Some people might think it is the climate of the school, also the network or soft resources in school. From my perspective, these face-to-face things still can be done through the internet as long as we have proper platform and regulation, have something to support from a system perspective. At the end of the day, the question should be answered by individual differences - who am I? what kind of study suits me better? what do I want to be in the future? That’s why even from learning perspective, educational data should contain individual patterns, and it should be owned by students, to stimulate their awareness, ownership, engagement towards their life. The interviewee did understand this phenomena from a  relative objective perspective - business model, and he did not anti-company as well. Instead, he thinks that market needs an innovative solution in order to become a functional market. I am surprised to see that the interviewee also pointed out the phenomena - everyone is trying to innovate in their platform, and there is lack of interoperability standards or formate standards from a long-term sustainable development perspective. This is “a lack of appreciation that data is the thing”. ",8,5,3,2
"1168","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Questions:  Do you think EDM and LAK will become one in the future?    Notes:  Similarities  are defined in relatively similar ways both reflect the emergency of data-intensive approaches to education; both have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education   Key Distinctions  Discovery: LAK - leverage human judgement; EDM - automated discovery. Adaptation &amp; Personalization: LAK - informing and empowering instructors and learners; EDM - automated adaptation (by computer with no human in the loop) Reduction &amp; Holism: LAK - understand systems as wholes, in their full complexity; EDM - reduce to components and analyze individual components and relationships between them Origins: LAK - semantic web, ""intelligent curriculum"", outcome prediction, and systemic interventions; EDM - educational software and student modeling, predicting course outcomes Technique &amp; Methods: LAK - social network analysis, sentiment analysis, influence analytics, learner success prediction, concept analysis, sensemaking models; EDM - classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization   collaboration allows creativity and advancement that might not otherwise occur in a single, monolithic research culture formalize approaches for dissemination of research and enacting cross-community ties; strengthen opportunities to influence non-academic research and practice ",2,0,2,2
"1169","Why Is Measuring Learning So Difficult?","Conclusion: 1.The core reason why learning is difficult to measure comes from its controversial definition/construct. - WHAT  Oversimplify not good, too complex not good. Need to find a point somethere in the middle Clarify what things(like what behaviors) happen that could indicate learning, or what specifically care about  2.Another important reason is the difficulty to measure competencies - HOW  Competencies and Learning are latent variables, psychological construct. hard to measure may because of the controversial definition Ability to assess competencies -&gt; need new technology Contextual - some fields tend to have weaker tools to measure and some not  3.Measure learning is not just for diagnosis, but for revealing more possibilities to the learner - WHY   Note - Why measuring learning is difficult:  multi-dimensional: simplify it too much to capture the data / the understanding of the data learning is too board: too much, too contextual and idiosyncratic in some fields like computer science, have impressive tools to figure out; but in other fields especially humanities and professions we have much weaker tools for measuring learning learning is very personal thing: culture construct is hard to define and measure, but behaviors patterns/outputs can ask a wrong question - depends on what you mean by ""measure"": maybe no reliable simple proxy indicators of learning. learning is curiosity -&gt; memory; imagination -&gt; paraphrase. U word is understanding, cant's used because it is cognition word, things that we can't measure. certain kinds of things could indicate learning. culture and social implication, individual psychology. learning is complex and blackbox, which makes more difficult to respond to the data. 1.ability to assess any competencies is problems. 2.Like MOOC, we don't know what people's competencies are. learning is kind of multiple measures of competence strung together that can associate with a particular experience. need to have new technologies to assess learning, people's learning at different time points. say what you want, measure efficiently and precisely. constructs. when talk about measure, really talking about either psychological constructs like self-efficacy or achievement. analytic is for the learner as well, be conscious. not to answer a question right or wrong, but reflection their learning process. analytic to reveal more possibilities for their own connected learning, not just diagnosis. be a doorway to suggest what else is possible. both oversimplify and too complex to understand are problems. maybe somewhere in the middle can find a good definition.   ",11,15,-4,1
"1170","Saturday Morning Breakfast Cereal"," This is a funny but thought-provoking comic. Undoubtedly, what we care (educational concept or psychological construct) plays an important role in the policy, and then education process of the students. Cause-and-effect relationship is not correlation. The direction of correction can be two sides. We should not over-interpret the statistics results. Statistics is dead until it is connected with the context, the theory etc. How we organize and interpret the data is much more important. ",2,1,1,2
"1171","Data wranglers: human interpreters to help close the feedback loop"," After reading this article I started to realize and appreciate the idea that “closing the feedback loop to improve learning is at the heart of good learning analytics practice”. Human meaning-making plays an important role to support the learning analytics process. In fact, I am deeply impressed by the good case practice of human Data Wranglers at the Open University, UK, because of the systematic approach they are adopting in the organization. No matter for which organization in education area, the trend of data is a huge change that impact on nearly everyone. From an organization psychology perspective, how to manage the change from a systematic approach is very important, and it can influence the actual results. That’s why I appreciate the organization practice of Open University, like ""academic staff/faculty and researchers need to be supported to learn to interpret and design learning analytics”, “establishment of a contextual framework”, “developing a culture of data use as part of increasing organizational capacity”. I am also excited to see that data wranglers “building up relationships with key stakeholders toenable the reports to focus on areas where they can be of most value” and “seek opportunities to engage withFaculty academics”. By doing this, every stakeholder can have proper communication with each other, and can “steer the agenda towards richer conceptions of learning than a naive quantitative view”, to make sure synergy can happen between learning analytics and learning design. I appreciate this systematic approach. Just like what it mentioned at the end of the paper: “present data 'to those involved in strategic institutional planning in ways that have the power to motivate organizational adoption and cultural change’”. I feel strongly inspired by this as a social-organizational psychology student. They also utilize a human resource development approach to build learning analytics capacity as part of a Community of Practice, breaking the general assumption that the role of data wrangler is only to analyze the data. Additionally, all data is available to academics directly, which can stimulate their autonomy to a larger degree. The article makes it clear by presenting three scenarios clearly and concisely in the pictures. Meanwhile, we also have to admit that this is a high cost approach in terms of time.    Now it is an institution-wide top-down analytics strategy in place, and this is built on a bottom-up understanding of at least some of the potential of the data to improve learning.  A bottom-up, grounded approach is necessary for sense making. However, as Macfadyen &amp; Dawson powerfully argue, organisational change is hard to achieve without meaningful engagement at the strategic, top-down level as well. Students and teachers areclosest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact.   Transformatory change is likely to take substantial amounts of time. It is only through the detailed processof engagement and dialogue between analysts, stakeholders andthe data that insight and organisational change are developed.    other important notes:  A learning analytics system may be used simply to attempt toachieve set goals (single-loop learning); greater value and insight will come if those goals themselves can be interrogated, challenged, and developed (double-loop learning) goals of data wrangler   immediate goal: producing reports with actionable recommendations overall aim: drive systematic improvement through single-and double-loop learning, and through the support and development of a Community of Practice at the Open UniversityUK (OU)   data wranglers work with four main data sources: Survey feedback data; Activity data; Delivery data; Aggregated completion, pass rate and demographic data. good practice   concerns the importance of assessment students' enjoyment of different learning activities data wrangler process at its best   feedback   positive: value the process, iterative, conversational nature; stimulate productive reflection and discussion with many stakeholders. less positive: desire for more data to be included; unevenness of the process across faculties; data quality   ",27,4,23,1
"1172","RStudio Cheat Sheets"," workflow: open a new .Rmd file -&gt; write document -&gt; knit document to create report -&gt; preview output -&gt; publish -&gt; examine build log -&gt; use output file embed code with knit syntax: inline code, code chunks, global options parameters:    add parameters: params call parameters: param$&lt;name&gt; set parameters: knit with parameters / render()   Pandora’s Markdown: check the cheatsheet. a useful way to edit the document Set render options with YAML: very confused… will work on it very soon. create a reusable template   create a new package with a inst/rmarkdown/teamplates directory in the directory, place a folder that contains   `template.yaml skeleton.Rmd any supporting files   install the package access template in wizard at File -&gt; New File -&gt; R Markdown   table suggestions:    knit::kable() print(xtable::xtable(),type=“html”,html.table.attributes=“border=0”)) stargazer::stargazer(data,type=“html”,title=“table with stargazer”)   citations and bibliographies:    set bibliography file use citation keys in tex render   ",2,0,2,1
"1173","Translating Learning into Numbers: A Generic Framework for Learning Analytics"," Thanks to this generic framework, I have a general understanding towards learning analytics. The framework contains both technically-focused research questions and softer issues and problem areas. There are six critical dimensions of LA, including stakeholders, objectives, data, instruments, external constrains, internal limitation. It is very impressive that the generic framework also includes soft issues - challenges that depend on assumptions being made about humans or the society in general. The framework can be used as a checklist when designing a purposeful LA process; or as a sharable description framework to compare context parameters with other similar approaches in other contexts. I agree that the framework is more like “both a descriptive approach as well as a guide to the design process of LA applications”, and that “development should not happen without a guiding framework that combines use of educational data with theprotection of individuals and their learning.”. Personally for me, this is more like a standardized process and materials, and it is qualitative instead of quantitative. We are not sure how the inherent connections among the six dimensions are connected. The general preference of this article is more soft issues focused, and less technically-focused. I am most impressed by the assumption of this framework - “responsible designers of analytic processes will not only implement what is technically possible to do and legally allowed (or at least not prohibited), but to consider holistically the outcomes for stakeholders and, even more importantly, the consequences for the data subjects.” Other insights that I’ve got are   I never thought of this perspective until seeing this article - ""by comparison, still seem somewhat bizarre that in the commercial worldwith clicking the “register” button, the default access to all user data becomes owned by some company, whereas educational institutions operate on the default that everything is protected from virtually everyone.” “Using statistical analytic findings is a quantitative not a qualitative support agent to such decision making.” “aligning and regulating performance and behaviour of individual teachers or learners against a statisticalnorm without investigating the reasons for their divergence may strongly stifle innovation, individuality, creativityand experimentation"" “From a technical point of view, idealised datasets probably remain the biggest challenge for analytics” “users ‘pollute' databases by producing erroneous or incomplete datasets."" “High drop-out rates are a challenging problem in education, especially distance education."" “Competing methods, technologies and algorithms applied to the same set of data, will result in different outcomes, and thus may lead to different consequences in terms of decision making based on these outcomes."" ""The fundamental question legislators need to ask is: who does a person’s lifedata belong to?"" ""the extent of a student’s data contract with an institution and its individual staff representatives indifferent roles (teacher, administrator, secretary, researcher, IT support staff, Deans and management, etc.) needs to be urgently clarified.""   “data economy” is a current trend and it made collecting data an affordable activity, and it can reflect real and un interrupted user behavior. ",17,6,11,1
"1174","Big Data in Education","video 1 - clustering  the biggest takeaway from this video is to understand how k-means clustering algorithm work through different examples clustering: have a large number of data points; want to find what structure there is among the data points; don’t know anything a priori about the structure. clustering tries to find data points that “group together” clustering works for (and is effective in) large features spaces k-means clustering algorithm is the simplest one   first, decide how many clusters we wanted pick starting values for the “centroids” of the clusters   usually chosen randomly sometimes there are good reasons to start with specific initial values, like insights from old data set   classify every point as to which centroid it’s closest to   this defines the clusters typically visualized as a voronoi diagram   refit the centroids as the center of the points in each cluster repeat the process until the centroids stop moving “converge"" - no points switched   outliers. starting points might be in a strong place. (cluster might be empty as well)   one solution: run several times, including different    a lot depends on initial positioning and on the number of clusters    video 2 - Validation and Selection of K  distortion / mean squared deviation    steps   take each point P find the centroids of P’s cluster C find the distance D from C to P square D to get D’ sum all D’ to get Distortion   works for choosing between randomized restarts not works for choosing cluster size, because more clusters almost always leads to smaller distortion   distance to nearest cluster center should almost always be smaller with more clusters it only isn’t when you have bad luck in your randomization cross-validation can’t solve this problem   a different problem than prediction modeling   you are not trying to predict specific values you are determining whether any center is close to a given point   more clusters cover the space more thoroughly so distortion will often be smaller with more clusters, even if you cross-validate   solution:    penalize models with more clusters, according to how much extra fit would be expected from the additional clusters can use the Bayesian Information Criterion or Akaike Information Criterion (not just cross-validation) using an informational criterion   assess how much fit would be spuriously expected from a random N centroids (without allowing the centroids to move) assess how much fit you actually had find the difference   so how many clusters?   try several values of k find “best-fitting” set of clusters for each value of k choose k with best value of BIC (or AIC) alternate approach (not data driven): “why am I conducting cluster analysis?”   if your goal is to just discover qualitatively interesting patterns in the data, you may want to do something simpler than using an information criterion — add clusters until you don’t get interesting new clusters anymore           distance   usually Euclidean distance  distance from A to B in two dimensions Euclidean distance can be computed for an arbitrary number of dimensions   ",13,10,3,1
"1175","Data wrangling cheatsheet.pdf"," dplyr::tbl_df() dplyr::glimpse() dplyr::%&gt;% tidy data: each variable is saved in its own column. each observation is saved in its own row. reshape the data   tidyr: gather(), spread(), separate(), unite() dplyr: data_frame(), arrange(), rename()   subset observations (dplyr)   filter(), distinct(), sample_frac(), sample_n(), slice(), top_n() %in%: group membership   subset variables (dplyr)   select() some helper functions: contains(): ends_with(), everything(), matches(). num_range(), one_of(), starts_with().   summaries data (dplyr)   summarise(): summarise_each(): count() first(), last(), nth(), n(), n_distinct(), min(), max(), mean(), median(), var(), sd()   make new variables (dplyr)   mutate() mutate_each() transmute()   combine data sets (dplyr)   mutating joins: left_join(), right_join(), inner_join(), full_join() filtering joins: semi_join(), anti_join() set operations: intersect(), union(), setdiff() binding: bind_rows(), bind_cols()   group data (dplyr)   group_by() ungroup() .. %&gt;% group_by() %&gt;% summarise() .. %&gt;% group_by() %&gt;% mutate()   ",0,0,0,1
"1176","Ethics and Learning Analytics: Charting the (Un)Charted.pdf","Thoughts and Feelings:  It is good to see some people take ethic in learning analytics seriously. I am deeply impressed by that learning analytics is a MORAL practice, and the problems are not only privacy as we usually thought. The “moral practice"" has shown the respectiveness towards data, and more importantly, the people/intention behind the usage of data. It has to be student-centered without doubt, and they are supposed to have choices to opt-in or opt-out. Central to this issue is the question of “who benefits?” A lot of other issues will also concern on the technical aspects (including interpretation of the data etc.) and current policy / organization culture. It will be great if more people from different areas their attention could be attracted on this essential issue, and collaborate to solve it.    Notes:   consensus of future learning: digital, distributed, data-driven. ethical concerns: data governance, data security, privacy issues   location and interpretation of data informed consent, privacy, and the de-identification of data the management, classification, and storage of data   Learning analytics in future will be essentially based on and driven by algorithms and machine learning and we therefore have to consider how algorithms “reinforce, maintain, or even reshape visions of the social world, knowledge, and encounters with information”   Accountability, transparency, andregulatory frameworks will be essential elements   ",4,5,-1,2
"1177","Measurement and its Uses in Learning Analytics.pdf","Thoughts and Feelings:  I love this paper. I’ve studied several psychometric classes during my undergraduate study, and this article reminds me of lots of important concepts in a nutshell. However, i hope to see some connections between psychometric methods and learning analytics, or the implications for future learning analytics / psychometric development. I am interested in the multidimensional construct. It is true that     Notes:  question on P37 P38 P39 GROW MODEL prediction and explanation  The use of tests and questionnaires is a matter of both efficiency and standardization. In learninganalytics, efficient collection of data is usually not the problem, but the lack of standardization can make it challenging to account for measurement error. reliability: sample-dependent (in true score theory), model-dependent (more complicated models)   reliability coefficient - Cronbach’s alpha test-retest reliability inter-rater reliability - Cohen’s kappa   validity: evidence and theory support the interpretationsof test scores for proposed uses of tests   response process internal structure of the instrument convergent and discriminant evidence criterion references (including predictive criteria) generalizability types of response bias: acquiescence bias. social desirability bias, bias from extreme and moderate types of responders, intentional rapid guessing behavior   measurement models factor analysis   true score theory / classical test theory EFA, PCA, CFA, path analysis, later growth models, SEM   latent dirichlet allocation (LDA), model-based cluster analysis item response theory (IRT) growth models: Bayesian knowledge tracking (BKT), Additive factors models (AFM), Learning curve analysis cognitive diagnosis models (CDM) explanation and prediction   “in explanatory modelling the focus is on minimizing bias to obtain the most accurate representation of theunderlying theory. In contrast, predictive modellingseeks to minimize the combination of bias and vari-ance, occasionally sacri cing theoretical accuracyfor improved empirical precision”   learning analytics as a “middle space” between learning scienceand analytics; Perhaps it may also be thought of asoccupying a methodological middle space between explanatory and predictive approaches. ",4,10,-6,5
"1178","k-Means Clustering","use of K-means clustering:  The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. / If n points are embedded in a p-dimensional space, then k clusters are summarized by their respective centroids (average of the cluster members' coordinates) in that space. k-means is most suited for separating convex clusters (clusters in which any line passing through a cluster intersects its boundary only twice). finding a satisfactory set of centroids given a set of data.  The simplest is to pick an initial set of centroid seeds randomly (assuming we know how many clusters we want) and to assign each point to its closest seed. If there really are blobs of points, we do much better to begin with locations that are relatively close to the center of these blobs. [stagewise method]   “we need to know k to find clusters and we need to identify clusters to determine k.” - Hartigan gives an approximate F statistic that can be used to test the ""significance"" of this reduction, but a simple method that works well for most datasets is to look for a proportional reduction in error (PRE) of about .4 or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares. Use the PRE method to determine the number of clusters present.  limitations of K-means clustering:  If your data contain doughnut-shaped or wormy-shaped clusters, don't expect k-means to find them. There will also be rare instances when clearly separated blobs are not identified. These are cases where the PRE statistic misses the cutoff (.4) by a small amount. There is always a tradeoff between false positives and false negatives, but we could improve this situation a bit by using more information than simple sums of squares. Data mining programs incorporating k-means sometimes ignore the subtleties of the algorithm. However, it might find nice clusters even when they don't exist in the data. ",8,5,3,1
"1179","Measurement and its Uses in Learning Analytics","measurement: define construct, specify measurement model, develop reliable instrument, analyze/account for errors, frame valid argument for use of the outcome  construct: i.e math ability instrument: intelligence(scale), scholastic aptitude(SAT), academic achievement(test/course exam) source of error: random error(unbiased) due to non-repeat systematic error(biased) reliability: used to describe instrument, consistency of scores  % of total variance in scores attributed to latent variable reliability of coefficients alpha [0,1] statistical power increases with high alpha   validity: evidence, factors that challenge interpretation measurement models: function relationship between factors   Factor Analysis: exploratory factor analysis(common part of scale but no strong assumption) + confirmatory factor analysis(test theoretically proposed factor model by examine residuals between expected and observed correlation Latent Class and Latent Mixture Models: distributions of physics misconceptions based on wrong answers in a test Item Response Theory: model independent person-item interactions rather than total test scores, describe item by parameter Growth Model: apply when latent trait is changing systematically between measurements Cognitive Diagnostic Models: generalized ",1,3,-2,5
"1180","Ethics and Learning Analytics: Charting the (Un)Charted"," exceptional quality research sophisticated data collection advanced machine learning &amp; human analysis/support  complex issue:  balance between respecting students autonomy long term sustainability of institution notion of beneficence (act in students best interests) need for non-maleficence distribute justice (demographic characteristic &amp; assumption) fiduciary duty in context of asymmetrical info  algorithm should be monitored by human opt in/out students remove irrelevant info/update new info teachers don't get access to full data set to make it too reliable data is collected for specific purpose   accountability+transparency+regulatory frameworks=ethical LA   ",3,2,1,2
"1181","Predictive Modelling in Teaching and Learning","Difference between explanatory and predictive modelling: whether it involves future, generalizability, post-hoc and reflective vs response to change Predictive Modelling Workflow:  problem identification: data sparsity, noisy data (inaccurate IP), ethical or equitable practice data collection: choose only those correlates available at or before the time in which an intervention might be deployed feature engineering: obtaining access to event data and creating the necessary features required for the predictive modelling process classification and regression: ordinal (categorical, uses classification), interval and ratio (numeric, uses regression)  feature selection: correlation, independence, and missing data issues should be considered methods for building predictive models: always consider whether patterns discovered in historical data should be expected in future data  Linear Reg Log Reg Nearest Neighbor Classifiers Decision Trees Naive Bayes Classifiers: assume independence  Bayesian Networks Support Vector Machines Neural Networks Ensemble Methods: voting pool, bootstrap aggregating, in which several predictive models are built from random sub-samples of the dataset, and boosting, in which successive predictive models are designed to account for the misclassifications of the prior models   evaluate a model: a test dataset with known labels; use k-fold cross validation in which the dataset is partitioned at random into k segments; k distinct predictive models are constructed, with each model training on all but one of the segments, and testing on the single held out segment; The test results are then pooled from all k test segments, and an assessment of model quality can be performed increase the impact of predictive modelling:  Supporting non-computer scientists in predictive modelling activities:  through the innovation of user-friendly tools or the development of educational resources on predictive modelling, could further diversify the set of educational researchers using these techniques. Creating community-led educational data science challenge initiatives: people use different datasets to address the same general theme, so using open, shared dataset to compare the efficacy of techniques and suitability of modelling methods for given problem could be beneficial Engaging in second order predictive modelling:  include historical knowledge as to the effects of and intervention in the model itself.   ",3,6,-3,3
"1182","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","EDM focuses on developing two types of model:  Statistical Model: drive the outer loop of intelligent tutoring systems based on observable features on students' performances as they learn Cognitive Model: representations of the knowledge space (facts, concepts, space) underlying a particular educational domain  Cognitive Model:  mapping knowledge space with problem steps or tasks knowledge component (KC), cognitive model: Q-matrix, statistical model: logistic regression-additive factors model (AFM) Data-Driven Cognitive Model Improvement:  difficulty factors assessment (DFA), split KC   Learning Factor Analysis (LFA):  automate above model refinement, searches across hypothesized knowledge components drawn from existing KC models, evaluates different models based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model.    SimStudent: intelligent agent that inductively learns knowledge, good at simulating features of novice students, can be used to test alternative models of human learning to see which best predicts human behavior ",4,2,2,5
"1183","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Topic: explore different goals among statisticians, graphic designers, and users of statistical models and value different aspects of visualization  Statistics: providing the right comparisons is crucial, concentrates on what can be get out of data Computer scientists: grabbing readers' attention and expands to wider issues  Some visualizations that don't serve statistical goals: presentation graphics&gt;exploratory graphics characteristics of a graph:  qualitative/descriptive comparison impact report results of data analysis  goals of graph:  discovery (give overview, sense of scale and complexity of data set, flexible displays to discover unexpected aspects of data) communication (understandable, storytelling, attractive)  some examples that look cool but fail to convey the data because they try to put everything within one graph:  wordle decision tree radiohead music video box office streamgraphs plane crushes florence nightingale's coxcomb health spending and life expectancy how to win in Afghanistan  good example that combines eye-catching beauty of Infovis with directness and simplicity of statistical data visualizations  the baby name wizard  colors used sparingly axes go down to zero and are labeled clearly but gently names are labeled directly on graph and each name can be individually located by running the cursor over the interactive version of the graph allow people to make inference from the graph     ",8,3,5,2
"1184","Junkcharts Trifecta Checkup: The Definitive Guide","junk chart is a framework for data visualization criticism, captures how I like to organize the thinking behind my critique pieces  what is the QUESTION:  provides worthy cause well-posed and interesting   what does the DATA say:  relevant to question reduce noise and remove errors or transformations   what does the VISUAL say:  represent the data in a clear and concise manner address the question directly    8 types of critiques:  trifecta: everything is in sync, chart has no weakness singles  Q: poorly defined objective or unengaging premise, why question is interesting D: data fails to illuminate the question, quality concern V: visual design hides or confuses the message   doubles:  QD: poor data quality and unclear objective QV: question not clearly defined and graphical design fails to bring out the key features of the data DV: date fails to convince and cause is not helped by poor execution of graphical elements   triple: nothing correct ",4,14,-10,2
"1185","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Teacher's assigned grades predict students' outcomes more accurately than standardized test scores because only 25% of the grade is related to academic knowledge while the rest of them are related to students' ""success"" in school-participation, behavior, and attendance. Goal: de-aggregate data and display individual information for interpretation of large longitudinal datasets - hierarchical cluster analysis(HCA) Case Study:  standardize data using z-scoring to prevent overweight calculate distance measure and a similarity matrix apply cluster algorithm ",1,1,0,3
"1186","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Understanding how learning relationships form in undergraduate classrooms and its impacts on learning outcome helps improve educational reform. It inspired future educational research to incorporate relational data. SNA focuses on how individuals may have similar network positions due to shared attributes while  traditional analyses may separate students into groups based on their attributes and search for disproportional outcomes based on those attributes.  Case Study: 10-wk introductory biology course with 187 students   data collected: who students studied with for the first three exams all of their class grades the lecture and lab sections to which they belonged  general demographic information from the registrar  key words: egocentric(not attending to connect dots); census network(comprehensive)  degree eigenvector centrality closeness (bad for disconnected)  tools:  statnet igraph RSiena   ",1,2,-1,4
"1187","Why Students Should Own Their Educational Data"," customize teaching materials so students truly can nurture the potential of every single individual center for individual opportunity=science of individual average only over 7% of population learning styles fall, people vary across contexts MOOC:  no interoperability standards/format need transparency, 3rd party protect data, but students need to own data to know their possible ways of reaching potential   ",1,1,0,2
"1188","Knowledge tracing: Modeling the acquisition of procedural knowledge","Theme: to monitor students' changing knowledge skill during skill acquisition, to individualize the practice sequence to enable students to master the skills efficiently and to accurately predicts students' performance. Knowledge tracing: estimate the probability that the student has learned each of the rules in an ideal model In order to achieve expertise:  domain knowledge is appropriately analyzed into a hierarchy of component skills learning experiences are structured to ensure that students master prerequisite skills before tackling higher levels skills in hierarchy  Intelligent Tutoring Environment (ACT programming tutor)  ideal student model to interpret students actions students action is compares to applicable rules in the model (model tracing)  Curriculum   Cognitive Model  declarative knowledge (fact) vs procedural knowledge (goal oriented and mediates problem-solving behavior knowledge tracing Bayesian computational procedure for knowledge tracing to update estimate of knowledge state:  P(Ln)=p(Ln-1|evidence)+(1-p(Ln-1|evidence))*p(T) posterior opportunity that ideal rule was already in learned state contingent on evidence + probability the rule will make transition to the learned state    Learning and Performance Assumptions Predictive Validity:  correlate the actual accuracy and predicted accuracy estimates across goals compute the mean error in prediction (expected accuracy-actual accuracy) calculate the mean absolute error in prediction (average absolute value of predicted accuracy minus actual accuracy) ",11,2,9,3
"1189","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Collaboration between EDM and LAK because ""different standards and values for “good research” and “important research” exist in each community, allowing creativity and advancement that might not otherwise occur in a single, monolithic research culture"".   Discovery: LAK(Leveraging human judgement is key; automated discovery is a tool to accomplish this goal); EDM(Automated discovery is key; leveraging human judgment is a tool to accomplish this goal)   Reduction &amp; Holism: LAK(Stronger emphasis on understanding systems as wholes, in their full complexity); EDM(Stronger emphasis on reducing to components and analyzing individual components and relationships between them)   Adapation &amp; Personalization: LAK(Greater focus on informing and empowering instructors and learners); EDM(Greater focus on automated adaption (e.g. by the computer with no human in the loop)   Techniques &amp; Methods: LAK(Social network analysis, sentiment analysis, influence analytics, discourse analysis, learner success prediction, concept analysis, sensemaking models); EDM(Classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization)  ",3,0,3,2
"1190","Evaluating Machine Learning Models","Evaluation Metrics - Binary Classification example:  spam detection  Popular Metrics:  Accuracy=num correct predictions/num total data points per-class accuracy: average of the accuracy for each class Confusion matrix: false positive etc Log-loss: used when output is numeric probability instead of 0 or 1, soft measurement of accuracy; it is the cross entropy between the distribution of the true labels and the predictions, and by minimizing the cross entropy, we maximize the accuracy of the classifier. AUC: the curve is called ROC which shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives, and shows how many correct positive classifications can be gained as you allow for more and more false positives Ranking metrics:  a binary classification of “relevant to the query” versus “irrelevant to the query” personalized recommendation: recommender acts as a ranker or score predictor Precision: Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant? = happy correct answers/total items Recall: Out of all the items that are truly relevant, how many are found by the ranker/classifier? = happy correct answers/total relevant items combine two terms via harmonic mean: F1 = 2[(precision*recall)/(precision+recall)] NDCG: normalized discounted cumulative gain, sums up the relevance of the top k items, discounts items that are further down the list, and normalize it   Regression metrics:  RMSE: the square root of the average squared distance between the actual score and the predicted score, sensitive to outliers Quantiles of errors: robust, look at median absolute percentage that gives us a relative measure of the typical error ""Almost-Correct"" predictions: the percent of estimates that differ from the true value by no more than X%, |(yi – yi)/yi| &lt; 0.1    Cautions:  The Difference Between Training Metrics and Evaluation Metrics Skewed Datasets—Imbalanced Classes, Outliers, and Rare Data ",13,4,9,5
"1191","Why Opting Out of Student Data Collection Isn’t the Solution","Fair Information Privacy Principles (FIPPS): specify the purpose for which they are collecting data, and seed to informed consent for the collection and use of data In education:  administrative and educational purposes as primary purposes of a school system where data collection is necessary  risks: without data that accurately represents all sectors of the school community, we create the risk that decisions will be made in response to those who lobby the hardest or shout the loudest, rather than in response to the needs of all students misuse of opt-out option: Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students how to solve: Policymakers seeking to set privacy rules for student data need to consider both the privacy rights of parents and students ",3,2,1,2
"1192","Saturday Morning Breakfast Cereal","Very funny cartoon! I think the problem is that those who are exceptional experts are only a small portion of the population, and thus inferences made based on them are not representative of the whole population. Students are guided toward a specific path that is not necessarily the best.  ",1,1,0,2
"1193","Data wranglers: human interpreters to help close the feedback loop","Since learning is a complex social activity, institution-wide efforts (interaction with educational system, leaders, and stakeholders) need to take place in order for human sense-making efforts to be implemented. Immediate goal: produce reports with actionable recommendations with an overall aim of driving systematic improvement through single (achieve a set of goals) and double (greater value and insight come when goals interrogated, challenged, and developed) loop learning. Data Wranglers: human interpreters to help close the feedback loop  familiar with data sources present data from all sources to all users increase capacity to act on LA data   ",1,1,0,1
"1194","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg's definition of personalized learning: working with students to customise instruction to meet the student’s individual needs and interests 4 Major Flaws:  By feeding children only the content they’re interested in, we may end up with many specialists and few generalists Real life is not so accommodating, students with no ability to compensate may suffer Children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced Recording children’s personal progress, preferences and needs poses a privacy risk if it is not managed properly.  Benefits:  Personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective. Personalised learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment could be a very powerful combination. But this requires developing the strategies which can marry the needs of children and teachers in education. ",9,4,5,2
"1195","Feature Selection"," Interpretability/Insight: use algorithms to get important features Curse of Dimensionality: amount of data we need growth exponentially to the amount of features we have   ",0,0,0,1
"1196","Chapter 1: Social Network Data","Network Analysis vs Conventional Analysis  square array of measurements actors are described by their relations instead of attributes rarely draw sample two main boundaries: create by actors themselves, demographic or ecological approach  Full network method:  collect information about all ties gives complete picture of relations in the population necessary to measure structural concepts such as between-ness most groups have limited ties due to limited resources, energy, time and cognitive capacity costly in time and money  Snowball method:  begin with a focal actor track down all named actors until no new actors are identified good for special groups (business contact, community elites, etc) isolated actors won't be tracked, starting point may cause the loss of sub-sets of actors  Ego-centric network (with alter connections):  begin with a selection of focal nodes and identify to which they are connected determine which of the nodes identified in the first stage connected to each other good to collect relational data cannot asses distance, centrality, or positional data  Ego-centric network (ego only):  know which actors have more or few connection make prediction in how location affect behaviors cannot measure macro-structure of whole network ",2,3,-1,4
"1197","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Number I Participate in Panel Talks or Conferences  number of participation means I acquire more knowledge in this field  external constraint: it is a voluntary action, and increase in number not necessarily means I broadened my horizon, people in general might go if there want to grab a lunch and just left immediately internal constraint: there are others ways that can help me achieve my goal, people might not accept my way of evaluating my improvement objectives: it is hard to predict my behavior based on number of panel talks I joined, if I am busy this month, I might not go as much as in other months when I have more time stakeholders: teachers use how students perform in their class to assess their progress, and my approach will be restricted based on that traditional assessing method ",1,2,-1,1
"1198","The Big Five and Visualisations of Team Work Activity","Big Five Components of Teamwork:  Team Leadership: direct and coordinate other team members' activities (assess performances, assign tasks, develop team knowledge and skills, motivate team members, plan and organize, establish positive atmosphere) Mutual Performance Monitoring: develop common understandings of the team environment and apply appropriate tasks strategies to monitor performances Backup Behavior: anticipate other team members' needs through knowledge about their responsibilities (shift workload to achieve balance) Adaptability: adjust strategies based on info gathered from environment through the use of backup behavior and reallocation of intra-team resources in response to changing conditions Team Orientation: propensity to take others' behavior into account during group interaction and belief in importance team goal over individual goals  Three coordinating mechanisms need to be in place to realize potential:  shared mental models: organizing knowledge structure of the relationships among the tasks the team is engaged in and how the team members will interact mutual trust: shared belief that team members will perform their roles and protect the interests of their teammates closed-loop communication: exchange of info between a sender and a receiver irrespective of the medium  Not providing feedback or identifying differences but to mirror info pertaining to the components of teamwork for the groups",2,0,2,2
"1199","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Issue related to this research:  limited sample size hard to predict whether students can successfully complete the program ",1,2,-1,4
"1200","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Right now, we aim to determine the number of skills and common skills between items. Factorization method incorporates compensatory models of skills: each skill required adds to the chances of success of an item and conjunctive models of skills, where any required skill missing will induce a failure to the item",8,1,7,5
"1201","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","MOOCs determine skills that are needed in order to complete the course + having individual skills associated with particular part of course content LFA, learning factor analysis  can successfully discover a set of skills for online courses; however, it requires cognitive task analysis by subject domain experts, which have an issue in accuracy and scalability  Matrix factorization method  issue of interpretability, ie providing meaningful feedback to course designers and developers based on machine-generated skill set is troublesome  eEPIPHANY  combination of assessment item text data and student learning interaction data goal: provide constructive feedback to online course designers and developers for iterative course improvement  a new problem formulation: integrate diverse information a new algorithm: scalable and effective evaluation: human experts   skill model/skill map: instead of Q-matrix, skill-item association is used, mapping between single skills and multiple assessments items method: find a skill model (Q-matrix) to best predict A-matrix, whether students get the answer right or wrong  clustering assessment items with latent features that would best characterize the similarity in the difficulties of assessment items  proposing a new skill model by assuming that the above-mentioned cluster of assessment items provides a hint for new skills searching for the best skill model by comparing multiple skill model candidates   Feature Extraction:  Matrix Factorization:   A transformed to D (difficulty matrix id=i-1/d)  D-matrix is then factorized into U and V matrices (i.e., D = U × V) by the Non-Negative Matrix Factorization method; V matrix is assessment item by latent feature Assessment items in the V-matrix are then clustered by the k-means method, resulting in an F-matrix, each cluster in the F-matrix represents a “skill candidate” that can be used to construct the P-Matrix  P-Matrix is a two-dimensional binary matrix showing which assessment item belongs to which skill candidate. The P-matrix represents the association of each assessment item to a skill candidate   Bag-of-Words:  creates the F-matrix directly from a collection of item stems (i.e., assessment item text data showing problem and feedback texts) for assessment items, the assessment items are clustered by the bag-of-words method using item stems first transform each assessment item into a set of component words from a collection of item stems using a part-of-speech tagger, TreeTagger  apply the Latent Dirichlet Allocation model (LDA) [15] to cluster assessment items, based on  the probability of topic distribution results in F-matrix     ",18,3,15,5
"1202","Using data mining to predict secondary school student performance","In this research, two different sources were used: mark reports and questionnaires.  binary classification (pass/fail) classification with five levels (from I very good or excellent to V - insufficient) regression, with a numeric output that ranges be- tween zero (0%) and twenty (100%).  Example codes: source(""rminer.R"") # read the RMiner library # load the data: data=read.table(""a-por-bin.dat"",sep="";"",header=T) K=c(""kfold"",10) # 10-fold cross-validation # execute 10 runs of a DT classification: DT=mining(y~.,data,model=""dt"",Runs=20,method=K) # show mean classification error on test set: print(mean(DT$error)) # save the results (predictions, ...): saveMining(DT,""DT-results"")  ",2,3,-1,5
"1203","Developing a generalizable detector of when students game the system","Detect whether students are ""gaming the system"" and distinguish between  two distinct types of gaming which are associated with different learning outcomes",0,0,0,5
"1204","Big Data in Education","Bayesian Knowledge Tracing: classic approach for measuring tightly defined skill in online learning, how well a student knows a specific skill or knowledge component at a specific time based on their past history of performance with that skill or KC  each item must involve a single latent trait or skill each skill has four parameters we can compute Latent Knowledge P(Ln) and the probability P(CORR) that the learner will get the item correct two states: learned and not learned PCORR=P(Ln)*P(~S)+P(~Ln)*P(G): know and don't slip plus don't know and guess parameter constraints: to avoid model degeneracy, we should be able to trust that if the student performs correctly, then she knows the skill goal is to predict knowledge (latent trait), so we instead check our knowledge predictions by checking how well the model predicts performance     ; Classifiers (1):  the thing you want to predict is categorical definition: which feature in which combination can predict the label Domain-Specificity:  Step Regression: binary classification, fits a linear regression function with an arbitrary cut-off, lack of closed-form expression such as standard error, has lower over-fitting Logistic Regression: binary classification, find frequency/odds of a specific value of the dependent variable, good for cases where changes in value of predictor variables have predictable effects on probability of predicted variable class J48/C4.5 Decision Trees: explicitly dealing with interaction effects, repeatedly looks for variable which best splits the data in terms of predictive power for each variable, then prune out branches, goo when construct can be arrived at in multiple ways, when data has natural splits, and when multi-level interactions are common JRip Decision Rules K* Instance-Based Classifiers   ; Classifiers (2):  Decision Rules: check in order, leads to simpler models than most decision trees, very interpretable K*: predicts a data point from neighboring data points, weights points more strongly if they are nearby, good when data is very divergent, detect emotions from log files, need to have whole dataset Bagged Stumps: related to decision trees, lots of trees with only the first feature  Common Thread:  educational data has lots of systematic noise conservative ; Cross-Validation and Over-Fitting: Over-Fitting:  reduce by using fewer models and less complex functions control over-fit by assessing generalizability, whether transfer to new contexts  Cross-Validation:  split data points intro N equal size groups, train on all groups but one, test on last group Flat Cross-Validation:  each points has equal chance of being placed into each fold   Stratified Cross-Validation:  biases fold selection so that some variable is equally represented in each fold variable we are trying to predict or is thought to be an important context   Student-Level Cross-Validation:  folds are selected so that no students' data is represented in two folds allow test model generalizability to new students opposed to testing model generalizability to new data from the same students   ; Diagnostic Metrics (1): Metric for Classifiers:  accuracy  does poorly when there is non-even assignment to categories   Kappa (related to expected agreement, deal with unbalance)  kappa=0, agreement is at chance kappa=1, agreement is perfect kappa=-1, agreement is perfectly inverse kappa&gt;1, messed up somewhere kappa&lt;0, model is worse than chance   ; Diagnostic Metrics (2):  ROC (Receiver-Operating Characteristic Curve):  probability true positive, false positive, ...   A':  probability that if the model is given an example from each category, it will accurately identify which is which assumes independence, compute A' and significance for each student and then integrate across students, otherwise do not perform stats test or will violate assumption of independence   Precision: when model says true, how often it is right Recall: successfully capture the true value ; Diagnostic Metrics Correlation: Metric for Regressors:  Linear Correlation  when A's value chages, does B change in the same direction? assumes a linear relationship   RMSE/MAD  MAD: absolute value of actual value minus predicted value  tells the average amount to which the predictions deviate from the actual value, very interpretable   RMSE: square root of average of (actual value minus predicted value)^2  penalizes large deviation more than small deviation     Information Criteria:  BiC: makes trade-off between goodness of fit and flexibility of fit (number of parameters)  values under 0: better tan expected given number of variables can be used to understand significance of difference between models   AIC: statistically equivalent to Leave-Out-One-Cross_Validation   ; Introduction: Types of EDM/LA Method:  prediction  classification regression latent knowledge estimation   structure discovery  clustering factor analysis domain structure discovery network analysis   relationship mining  association rule mining correlation mining sequential pattern mining causal data mining   distillation of data for human judgment discovery with models  use pre-existing model developed with above methods and apply to data and use as a component in another analysis   ; Q-Matrix/Knowledge Component Model/Skill-Item Mapping rows: items columns: skills  for each number of skills, the algorithm will be run a certain number of times, with a different (random) initial assignment of items to skills - avoid local minima take a set of passes through table, systematically look at whether flipping each 1 to 0 or vice versa produces a better model; continue this process a predetermined number of times or until a pass results in no changes no learning: getting item 1 right not indicate a better chance of getting item 2 right spikes in learning curve (y-error rate, x-opportunities to practice skill) indicate 2 learning curves (2 or more skills)  Definition of a better model: if student knows skill X, and item 1 and item 2 both have skill X, then a student who gets item 1 right will be more likely to get item 2 right, performances of items involved with same skill should be connected    ",40,16,24,5
"1205","Cross Validation","Representative  How to pick a model that is complex enough to fit the data without causing problems on the test set? in training set, hold out a test set, average all the errors, pick the model with lowest errors   ",1,4,-3,5
"1206","Hands-On Programming with R"," random sample: sample(x=1:4, size=2) packages: install(), library() integer: int &lt;- c(1L, 2L) give attribute: name(die) &lt;- c(""one"", ""two"") remove: name(die) &lt;- NULL dimension: dim(die) &lt;- c(2,3) matrices: m&lt;- matrix(die, nrow=2, byrow=T) array: ar &lt;- array(c(11:14, 21:24, 31:34), dim=c(2,2,3)) data frame: df &lt;- data.frame(face=c(""ace"", ""two"", ""six""), suite=c(""club"", ""clubs"", ""clubs""), value=c(1,2,3))  face suite value  ace  clubs   1  two  clubs   2  six   clubs   3  open file: data &lt;- read.csv(""FILEPATH.csv"", header=TRUE)  example: dim(die) &lt;- c(2,3) typeof(die): double class(die): double attributes(die): dim",0,1,-1,1
"1207","Principal Component Analysis explained visually","Watched 2D and 3D demonstration of PCA",0,0,0,2
"1208","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8.",1,2,-1,3
"1209","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection,data processing,and data analysis,using  a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships.We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.",4,1,3,4
"1210","Why Students Should Own Their Educational Data"," 	 	 	     The idea of average learner is challenged.Why Students Should Own Their Educational Data – Wired Campus - Blogs - The Chronicle of Higher Education  	 	 	      You can’t actually tell anything in population studies about any individual in that group.   Technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.” Why Students Should Own Their Educational Data – Wired Campus - Blogs - The Chronicle of Higher Education  	 	 	        A nonprofit organization called Center for Individual Opportunity has supported research on the “science of the individual.”          ",1,0,1,2
"1211","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called the ideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process called knowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.",6,0,6,3
"1212","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","1. Similarities btw LA and EDM. Both reflect the emergence of data-intensiveapproaches to education.   Both communities have the goal ofimproving the quality of analysis of large-scale educational data, to support both basic research and practice in education.  2. Distinctions EDM has a considerably greater focus on automateddiscovery, and LAK has a considerably greater focus onleveraging human judgment.    EDM models are more often used as the basis of automated adaptation, such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners.  Competition as well as collaboration  ",2,0,2,2
"1213","Evaluating Machine Learning Models","evaluation metrics: Classification Metrics Ranking Metrics Regression Metrics Offline Evaluation Mechanisms: Hold-Out Validation, CrossValidation, and Bootstrapping Hold-Out Validation  Cross-Validation Bootstrap and Jackknife",0,1,-1,5
"1214","Why Is Measuring Learning So Difficult?","multidimensional -&gt; have to simplify too much different definitions of learning - some are difficult to measure some fields could measure - e.g., CS weaker tools for humanities, etc. a personal thing how to define 'measure' cultural, social stuffs",0,2,-2,1
"1215","Saturday Morning Breakfast Cereal","make sure you know whether it is a causation or opposite or just related!",0,0,0,1
"1216","The Data Wrangling Cheatsheet","dplyr dplyr::tbl_df(iris) Converts data to tbl class. tbl’s are easier to examine than data frames. R displays only the data that fits onscreen dplyr::%&gt;% Passes object on left hand side as first argument (or . argument) of function on righthand side tidyr",1,1,0,1
"1217","Data wranglers: human interpreters to help close the feedback loop","An article about data wranglers, a group of academics who analyse data about student learning and prepare reports with actionable recommendations based on that data. The data being analysed is the study data of Open University.   The role of the Data Wrangler is not only to analyse the data, but to increase the familiarity of academics with the data sources, to build learning analytics capacity as part of a Community of Practice.   ",1,0,1,1
"1218","Zuckerberg is ploughing billions into 'personalised learning' – why?","Mark Zuckerberg believes personalised learning is the answer to many of education’s current woes. For him, personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”.  Zuckerberg’s idea of personalised learning has three major flaws. First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating.  Finally, children’s preferences are not fixed.   Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective.    ",4,2,2,2
"1219","Feature Selection","knowledge discovery - interpretability and insight curse of dimensionality  ",0,0,0,5
"1220","RStudio Cheat Sheets","knit to produce document text &amp; code separate add parameters more online",0,0,0,1
"1221","Translating Learning into Numbers: A Generic Framework for Learning Analytics","data for personalized services personalized learning experience electronic data mining of people's digital footprints   six dimensions of LA: stakeholders - data clients as well as data subjects.   objectives - reflection and prediction  data, instruments, external constraints internal limitations - competences and acceptance  ",1,2,-1,1
"1222","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","We offered an open online Introduction to Recommender Systems through Coursera, while simultaneously offering a for-credit version of the course on-campus using the Coursera platform and a flipped classroom instruction model. As the goal of offering this course was to experiment with this type of instruction, we performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course. Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). ",11,4,7,4
"1223","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement"," We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability.",11,1,10,5
"1224","Chapter 1: Social Network Data"," Introduction: What's different about social network data? Nodes  Populations, samples, and boundaries Modality and levels of analysis   Relations  Sampling ties Multiple relations   Scales of measurement A note on statistics and social network data ",0,0,0,4
"1225","Learning Analytics Dashboards","Learning analytics dashboards - visualize learning traces to give users insight into the learning process. Also include examples and guidelines on how to get started with the development of learning analytics dashboards.",0,0,0,2
"1226","Measurement and its Uses in Learning Analytics","psychological measurement: defining a construct - latent variable, trait specifying a measurement model and a reliable instrument -  tests or questionnaires; efficiency and standardization;  analyzing and accounting for various sources of error (including operator error) - random error, systematical error and framing a valid argument for particular uses of the outcome.   models used in LA: Factor analysis Latent Class and Latent Mixture Models IRT Growth Model Cognitive Diagnostic Models  ",0,4,-4,5
"1227","Predictive Modelling in Teaching and Learning","work flow: Problem Identification data collection Classification and Regression feature selection Methods for Building Predictive Models: 1. Linear Regression2. Logistic Regression3. Nearest Neighbours4. Decision Trees 5. naive Bayesian classifiers6. Bayesian Networks7. Support Vector Machines8. Neural Networks9. Ensemble Methods",2,4,-2,3
"1228","Ethics and Learning Analytics: Charting the (Un)Charted","In the field of LA, use of student data has expanded rapidly.  policies relating to institutional useof student data had not kept pace, nor taken accountof the growing need of to recognize ethical concerns.  surveillance problem OU  ""Policy on ethical use of student data for LA"" opt out question  ",0,2,-2,2
"1229","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The vast majority of educational data mining research has focused on achieving predictive accuracy, but we argue that the field could benefit more focus on developing explanatory  models. We review examples of educational data mining efforts that have produced explanatory models and led to improvements to learning outcomes or theory. We also summarize some of the common characteristics of explanatory models such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process. ",2,0,2,5
"1230","Statistical graphics: making information clear – and beautiful","Making good graphs Default in excel and R are not good. Improving  <U+FB01>gures  requires  two  key decisions: s Who is your target audience? s What are you trying to show?   some guiding principles: s Avoid distracting elements. s Use informative colour to visually associate elements. s Keep the <U+FB01>gure simple (and therefore interpretable).",3,1,2,2
"1231","How to display data badly","12 rules for displaying data badly show as few data as possible hide what data you do show ignore the visual metaphor altogether only order matters graph data out of context change scales in mid-axis emphasize the trivial jiggle the baseline Austria first Labels more is murkier if it has been down well, think of another way to do it",1,2,-1,3
"1232","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","We present here a set of goals for graphical displays discussed primarily from the statistical point of view and discuss some inherent contradictions in these goals that may be impeding communication between the fields of statistics and Infovis.  One of our constructive suggestions, to Infovis practitioners and statisticians alike, is to try not to cram into a single graph what can be better displayed in two or more.",1,1,0,2
"1233","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?  Ideally, the results of all three investigations are one and the same. The Question occupies the top corner because any data visualization project needs a worthy cause. I'd like the Question to be well-posed, and interesting; the former focuses the search for appropriate data while the latter ensures an engaged audience. The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly.  The tradition of Tufte is heavily focused on the Visual corner of the Trifecta, including its linkage to the Data corner. As will be discussed later, it is possible to select the right graph for the data but the project to fail because the data do not solve the posed question.",6,5,1,2
"1234","k-Means Clustering","Cluster The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. The algorithm computes these assignments iteratively, until reassigning points and recomputing averages (over all points in a cluster) produces no changes.  ",0,0,0,1
"1235","Measurement and its Uses in Learning Analytics","The article presents an exciting view of the future, where education is ""on the threshold of a data-intensive revolution"". By equipping policymakers and researchers with new powerful forms of evidence gathering analytics, they are given access to a new array of information that has the potential to change the world we live in. But as the author makes clear, such tool also is grounded by epistemological assumptions and pedagogical practices, meaning that we should also be wary of biases and ethical implications concerned with such analytics.    ",1,2,-1,2
"1236","Ethics and Learning Analytics: Charting the (Un)Charted","The chapter, which details the perils of ""big data"", might sound cliched by now - but it still contains a few food for thought. I am particularly interested by its presentation of the various approaches and guidelines set forth to ensure ethical data usage, of which I believe transparency is key - so that the students are not only aware of the data being collected but are ensured full access. While there is no easy answer here, I think as frameworks and codes regarding data usage develop we can eventually arrive at a win-win scenario that will benefit all parties.",2,1,1,2
"1237","Predictive Modelling in Teaching and Learning","    Chapter 1: Theory and Learning Analytics  Learning analytics By design (by accident?) use of LA tools is always aligned with assessment regimes, which are grounded in epistemological assumptions and pedagogical practices Claim analysis  analysis of the implicit or explicit stances taken in the design and developing of technologies productive human-centered method to address key questinos        Anderson (2008) envisaged the death of theory, models, and scientific methods- data will tell us directly as we discern     when people become aware that their behavior is under surveillance, with potentially important consequences, they may choose to adapt to game the system         for educators and learners, the interest turns on the ability to gain insight in a timely manner that could improve outcomes.   Theory into practice Epistemology-assessment-pedagogy (EPA) tirad EPA Provocations Epistemology   what are we measuring how are we measuring  Pedagogy  why is the knowledge important to us who is the assessment/analytics for  Assessment  where does the assessment happen when does the assessment and feedback occur               ",1,1,0,2
"1238","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","    Chapter 6: Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data  Predictive vs. Explanatory Model  predictive model  aim to find a combination of features that best predict outcomes assessed by accuracy in predicting held-out data   explanatory model  seeks to identify interpretable causal relationships between constructs that can be either observed or inferred from the data   vast majority of educational data mining research has focused on achieving predictive accuracy, but the field could benefit from more focus on developing explanatory model  COGNITIVE MODEL DISCOVERY      cognitive models are an important basis for the instructional design of automated tutors and are important for accurate assessment of learning and knowledge traditional methods requires human input/time consuming  structured interviews, think-aloud protocols, rational analysis, and   THEREFORE: models based on data-driven techniques that alleviate  Data-driven cognitive model improvement Learning Factor Analysis      developed to automate the data-driven method of KC model refinement to further alleviate the problem of time consuming factor  Automated Cognitive Model Discovery Using SimStudent STUDENT GROUPING            ",3,1,2,5
"1239","Statistical graphics: making information clear – and beautiful","Statistical graphics: making information clear – and beautiful Information visualization (InfoVis)  Statistical graphics  importance shifted from making the graphic beautiful to making it clear    Visualizations of measles epidemic  Harare, Zimbabwe in the face of measles outbreak from autumn 2009 to 2010  Default graphs in Excel and R      plots of the time series of cumulative confirmed measles cases they are labelled and scaled to fill an entire screen. The time series presented here is uncomplicated and could easily fit on a small portion of the page, if the labelling were sized appropriately      Constructing a more beautiful and informative summary of data and inferences  2 key decisions  who is target audience what are you trying to show   guiding principles  avoid distracting elements use informative color keep the figure simple    Further graphs for data exploration  another guiding principles  keep the x-and y-axes on the same scale eliminate repetitive info maintain consistency across plots             ",3,4,-1,2
"1240","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The word ""statistics"" carries with it the old world, boring, archaic, rule-based; the word ""information visualization"", however, sounds exciting, flashy, albeit a bit fraudulent. In visualizing our data as practitioners, we must do our best to meet somewhere at the middle, to show the best of both worlds, and in doing so the Gelman article will be a great handbook. Our graphics must take into account the two pillars of discovery and communication goals, being both intuitive and truthful; it must be interesting but not overly flashy. They must be founded by deeply rooted statistical principles while also presenting an attractive and easy-to-understand illustration to the layman audience.",7,3,4,2
"1241","Junkcharts Trifecta Checkup: The Definitive Guide","I laughed out loud at the last type presented in the Trifeca checklist, ""graphical disasters"" that fail at all three pillars - the Citibike Chart is very poorly designed both graphically and statistically, and it is impossible to know what question the chart is supposed to be answering. I agree that the three elements presented here - the question, the data, and the visual - are the keys to visual presentation and we should always keep these in mind as practitioners.",0,3,-3,2
"1242","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis Longitudinal K-12 teacher assigned grading histories for entire cohorts of students from school district hierarchical cluster analysis pattern visualization For the aid in data-driven decision making by teachers and administrators Overall schooling outcomes (student dropout, college entrance exam)  - identified from data patterns and compared to past methods of the identification   Result: hierarchical cluster analysis correctly identified over 80 percent of students who dropped out using entire student grade history patterns",1,1,0,3
"1243","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","   Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research     Social relationships/interactions How learning relationships form in undergraduate classrooms Impacts that these relationships have on learning outcomes Social Network Analysis (SNA)  tool for investigating questions involving relational data Using SNA in classroom setting allows rich and informative analyses to provide initial tools Can inform our understanding of student network formation in classrooms and the types of impacts these networks have on students Can give a baseline understanding of classroom net- work norms and illuminate major aspects of undergraduate learning Basics:  aims to understand the determinants, structure, and consequences of relationships between actors/nodes    Network Types  Unipartite/ monopartite/ one-mode  network consist of only one type of actor   Bipartite/ two-mode  network consist of 2 types of actor   Undirected   ties between actors are inherently bidirectional   Directed  relational interest of network as an associated direction   Binary ties  represents whether or not a relation exists   Valued ties  include additional quantitative info about the relation       Network Data Collection  requires deciding on a time frame for the relationships of interest (changing overtime) how to sample from population  egocentric  focus on sample of individuals and local social environment without explicit attempt to connect the dots   census network  whole networks collect data from bounded population of actors complete picture of the network      Network Level Concepts and Measures  Network density  measurement of how many links are observed in a whole network divided by the total number of links that could exist if every actor were connected to every other actor   homophily triad census  simple count of how many different triad types are in network   transitivity  simple local measure of more general set of concepts related to clustering or cohesion  transitive triad cyclical triad      Actor-level variables   centrality degree closeness betweeness eigen-vector centrailty  10-wk introductory biology course with 187 students    Descriptive analyses of the structure of the network of costudying relationships    generative processes that create observed study networks between students and also test for an association between network position and success on exams. Practical issues  unique aspects of human subjects review for network studies    ",3,0,3,4
"1244","Why Students Should Own Their Educational Data","Why Students Should Own Their Educational Data Personalized study materials sounds like every learning analyst's dream - as Todd Rose states, the ""average learner"" is but a myth, and tailored learning may solve for discrepancies such as students with high science aptitude but low reading skills. However, sadly as of right now such tailored learning process and its adaptive textbooks sounds cost-prohibitive and difficult to implement in a classroom setting (for a teacher won't be able to tailor to all these individual student skills). Work remains to be done in the area.",3,3,0,2
"1245","Knowledge tracing: Modeling the acquisition of procedural knowledge","   Knowledge Tracing: Modeling the Acquisition of Procedural Knowledge  Modeling students' changing knowledge state during skill acquisition - goals of mastery learning 1. ACT Programing Tutor (APT)  constructed around production rule cognitive model of programming knowledge = ideal student model allows tutor to solve exercises along the student and provide assistance as necessary tutor maintains an estimate of prob that the student has learned each of the rules in the ideal model knowledge tracing tutor presents individualized sequence of exercises to student based on prob estimates until students master each rule  2. Cognitive Model  ACT-R theory of skill knowledge  fundamental distinction between declarative and procedural knowledge  declarative: factual/ experiential/ goal-independent procedural: goal-oriented/ mediates problem solving   assumes  procedural knowledge can be represented as a set of independent production rules that associate problem states and problem solving goals with actions and consequent state changes    3. Knowledge Tracing and Mastery Learning  Knowledge tracing  assumes 2-state learning model employed in tutor to implement mastery learning    4. Empirical Evaluations of Knowledge Tracing  internal validity external validity      ",5,3,2,3
"1246","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Although Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) overlap in numerous areas as they share the same goal of “improving education by improving assessments, how problems in education are understood, and how interventions are planned and selected”,  there is a clear distinction between Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK).",1,1,0,2
"1247","Evaluating Machine Learning Models","Zheng, A. 2015. Evaluating Machine Learning Models. O’Reily Media. Chapter 2: Evaluation Metrics p.7-1 Evaluation metrics Classification metrics  accuracy confusion matrix per-class accuracy log-loss AUC  Ranking metrics  precision-recall precision-recall curve and F1 score NDCG  Regression metrics  RMSE quantiles of errors ""almost correct"" predictions ",1,2,-1,5
"1248","Why Opting Out of Student Data Collection Isn’t the Solution","Why Opting Out of Student Data Collection Isn’t the Solution Rights of individuals to ""opt-out"" of their data being collected or used Fair Information Privacy Principles (FIPPS)  the basis for most privacy laws in the US and around the world requires data collectors to specify the purpose of data collection and get informed consent  How data collection helps students  ""primary use"" categories  needed for school to function - data collection is necessary, expected parents have no choice but to provide them because not providing would have their children deprived of educational services basic info about students and parents  grades eligibility for subsidized lunch   Assessing performance through data analysis an essential step to improve education and address areas of concern    Opt-out Policies  cons:  prevent schools from getting accurate picture of how good of provided education is lack of understanding about challenges and barriers faced by students of diverse backgrounds cannot address the comprehensive needs of all students    Opting-out is not the solution  providing individual parents with options that disrupt the ability of data to be used for essential educational purposes isn’t the best option Legitimate education policy concerns need to be addressed by fixing these problems for all students, not just the minority who protest by opting out Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.   ",5,7,-2,2
"1249","Why Is Measuring Learning So Difficult?","Why Is Measuring Learning So Difficult? Learning is multidimensional, but to capture data we have to simplify it Learning is too broad Learning is personal No reliable, simple indicator that can trust - understanding cannot be measured, but example of things that can be measured is to have students teach other students Social implications/ emotional aspects that is hard for LA platform to capture Measuring competencies is difficult - students taking MOOCs class with all different background levels Achievement and self-efficacy Analytics - devising a medium, reveal to learning what kinds of connections that they are making that they might not be aware of - doorway to suggest what there is possible    ",2,3,-1,1
"1250","Saturday Morning Breakfast Cereal","The comic, while hilarious on its own, also raises the society's increasing trend to conflate correlation with causation. ""Correlation is not causation"" is is one of the basic tenets of statistics and we, as practitioners, should always not let our excitement lead us awry as was the case here with the clocks and engineers.",1,0,1,2
"1251","Data wranglers: human interpreters to help close the feedback loop","   The paper shows how learning analytics can be used in creating real significant change as was the case of Open University. I found the wranglers' use of both single-loop and double-loop learning particularly interesting. What was ironic, however, was the fact that the overall evaluation of the learning experience - the key reason that the Wranglers were employed in the first place - actually declined slightly after the project (to no fault of the Wranglers, of course). It is a bit bittersweet, then, that learning analytics are fundamentally limited by the external circumstances that surround them, such as funding and other overall policy measures.   ",1,3,-2,1
"1252","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg is ploughing billions into 'personalised learning' – why? Zuckerberg's idea of personalized learning is working with students to customise instruction to meet the student’s individual needs and interests” which alludes to how ""human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests."" Flaws of Zuckerberg's personalized learning  Education is to acquire both general and specific knowledge and skills ""while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating"" Changing interests  Misuse of children's data - privacy risks Benefits of Personalized Learning Increase in motivation - gives children sense of ""ownership and relevance""",5,3,2,2
"1253","Feature Selection","Feature Selection - Georgia Tech - Machine Learning Feature Selection  Knowledge discovery  interpretability and insight   Curse of dimensionality  amount of data you need increase exponentially as you increase the number of features   ",0,0,0,5
"1254","Chapter 1: Social Network Data","Introduction to social network methods Social Network Data Nodes  actors  Edges  relations  Populations, samples, and boundaries Modality and levels of analysis  Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal."" how the individual is embedded within a structure and how the structure emerges from the micro-relations between individual parts. The ability of network methods to map such multi-modal relations is, at least potentially, a step forward in rigor  Relations  Problems  sampling ties  full network methods  we collect information about each actor's ties with all other actors. In essence, this approach is taking a census of ties in a population of actors -- rather than a sample   Snowball methods   begin with a focal actor or set of actors. Each of these actors is asked to name some or all of their ties to other actors. Then, all the actors named (who were not part of the original list) are tracked down and asked for some or all of their ties. The process continues until no new actors are identified, or until we decide to stop   Ego-centric networks (with alter connections) Ego-centric networks (ego only)      Social network data tend to differ from more ""conventional"" survey data in some key ways: network data are often not probability samples, and the observations of individual nodes are not independent. These differences are quite consequential for both the questions of generalization of findings, and for the mechanics of hypothesis testing.  ",0,1,-1,4
"1255","RStudio Cheat Sheets","The R Markdown sheet The R Markdown sheet introduced me to the workings of R and R Studio. I am excited to see how the program functions as I work with it hands-on - the cheat sheet shows that the program is endlessly versatile, with integration to various other platforms (e.g. Latex).",3,1,2,1
"1256","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school Indicative of student's choice to attend college:  financial resources family background career aspirations academic ability  Not necessarily give sufficient actionable info to intervene educational software and detectors of specific aspects of student learning and engagement = ASSISTment System in NE  can be used to predict college attendance provide more actionable info ",0,0,0,3
"1257","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Translating Learning into Numbers: A Generic Framework for Learning Analytics The paper is interesting in its presentation of the new design framework for learning analytics. Of the six dimensions mentioned, I find the internal limitations to be a critical, but often overlooked, part of the learning analytics process. The competencies involved in interpretation of the data, both immediate and its far-reaching implications, are pivotal, as is the open mind for the policymakers to accept the outcome of the studies. The six dimensions are inherently connected and so it is important to realize that they work in conjunction and not in isolation.",1,3,-2,1
"1258","The Big Five and Visualisations of Team Work Activity","The Big Five and Visualisations of Team Work Activity Visualizations of group activity - mirroring activity of individuals and their interactions Computer-supported collaborative learning (CSCL)  expected beneficial outcomes of teamwork - high motivation, deep involvement in learning, and substantial knowledge gain - often do not materialize  Evaluation of the visualizations in context of a semester long software development project course  Theoretical analysis of design of visualizations using the framework from the ""Big 5"" theory of team work as well as quantitative study of the visualizations and students' reflective reports  Big 5 component of teamwork  team leadership  facilitate team problem solving provide performance expectations and acceptable interaction patterns synchronize and combine individual team member contributions see and evaluate information that affects team functioning   mutual performance monitoring  identifying mistakes and lapses in other team member's actions   backup behavior  recognition of workload distribution problem in the team shifting work to underutilized members   adaptability  identify cues of change, assign meaning to it, develop new plan to deal with it   team orientation  increased task involvement, information sharing, strategising and goal setting     3 coordinating mechanisms  shared mental models mutual trust closed-loop communication    Overview of Visualizations  Activity Radar Interaction Network   based on Social Network Analysis capturing relationships and flows between entities nodes (users) and edges(interaction)   Wattle Tree   each user's activity shown in climbing vertical tree  tree start: when user performs an action size = size of contribution      Conclusion:   Visualizations provide powerful and valuable mirroring role with potential to help groups learn to improve their effectiveness ",6,2,4,2
"1259","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","   Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC      Open online Introduction to Recommender Systems through Coursera For-credit version of the course on-campus using the Coursera platform Flipped classroom instruction model.  Methods:  surveys of demographics self-assessed skills learning intent knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course  Result:  Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests.  Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion = intent to complete Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge.   Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers).       ",13,4,9,4
"1260","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices data driven, matrix factorization approach Intro Mapping items to latent skills - difficult Skills Modeling, Q-Matrices and Matrix Factorization 2 mappings of items to skills (1) expert and 2) matrix factorization) are compared in terms of discrepancies and in terms of their performance when used in a linear model of skills assessment and item outcome prediction  Linear Models  put to the task of assessing student skills mastery factorization methods   Results Matrix, Q matrix, and skills matrix  Comparing Q-matrix induced from data with an expert defined matrix  Comparison issues and principle of the proposed method Alternate Least-Square Factorization (ALS)  Result  relatively small pattern between expert and the factorized mapping (although differences arise) factorization approach performs slightly better than the original expert Q matrix  supporting evidence to the belief that the factorization mapping is valid   ",9,1,8,5
"1261","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   Machine beats experts: Automatic discovery of skill models for data-driven online course refinement  Large-scale online courses  contain a broad range of contents frequently intended to be semester's worth of materials  difficult to articulate accurate set of skills and knowledge  Q-matrix      So developed innovative method to discover skill models from data of online courses  assumption:  online courses have pre-defined skill map for which skills are associated with formative assessment items   Exploits correlations between parts of student performance Compared existing method (LFA) and human engineered skill models on Open Learning Initiative (OLI)  Result:  the method proposed better than human-engineered skill models skill models discovered by the model can be interpreted method is faster than existing methods      ",11,2,9,5
"1262","Using data mining to predict secondary school student performance","Using data mining to predict secondary school student performance Automated tools to analyze the raw data and extract interesting high-level information for decision maker Education good for Business Intelligence (BI)/Data Mining (DM) techniques - multiple sources of data (traditional data bases + online web pages) + diverse interest groups (students, teachers, administrators, alumni) Real-world data (student grades, demographic, social and school related features) from Portuguese secondary schools collected by using school reports and questionnaire Mathematics and Portuguese class (core classes) modeled under  3 DM goals  binary classification (pass/fail) classification with 5 levels regression - numeric output ranging between 0 and 20    For each of these approaches:  4 DM models - Decision Trees, Random Forest, Neural Networks and Support Vector Machines 3 Input selections: with and without previous grades  Result:  student achievement highly influenced by past evaluations  other relevant features such as number of absences, parents' education and job, alcohol consumption affect the achievement as well   ",3,1,2,3
"1263","Developing a generalizable detector of when students game the system","Developing a generalizable detector of when students game the system  game the system  attempt to succeed in the environment by exploiting properties of the system rather than learning the material gaming behavior is associated with significantly poorer learning in Cognitive Tutor classes gaming is a fairly robust construct, present across many intelligent tutoring systems.  Developed a system that can   accurately detect whether a student is gaming the system within Cognitive Tutor mathematics curricula distinguish between two distinct types of gaming associated with different learning outcomes generalize to new tutor system examples: Baker et al.’s (2004) Gaming Detector, and Aleven et al.’s (2004) Help-Seeking Tutor Agent  ",3,2,1,5
"1264","Big Data in Education","1.1 Introduction Educational Data Mining and Learning Analytics Where do methods come from  Data mining or machine learning Psychometrics or traditional statistics  Prediction  Develop a model which can infer a single aspect of the data predictive variable from some combination of other aspects of the data predictor variables  Structure Discovery Relationship Mining Discovery with Model PSLC DataShop; 1.3 Classifiers 1  Prediction Classification  a type of prediction model labels thing you want to predict is categorical  correct/long help request/ worked example request/ attempt to solve etc.   Labels come from various sources associated with each label are set of features which maybe you can use to predict the label Basic idea: determine which features, in which combination, can predict the label  Domain Specificity  specific algorithms work better for specific domains and problems  Useful algorithms  step regression logistic regression J48/C4.5 Decision Trees JRip Decision rules K* Instance-Based Classifiers  Step Regression  used for binary classification (0,1) Fits a linear regression function  select parameters assign weight to each parameter computes a numerical values then all values below 0.5 are treated as 0 and all values greater or equal to 0.5 are treated as 1   Cons:  lack of closed form expression   Pros  conservative    Logistic Regression  used for binary classification (0,1) given a specific set of values of predictor variables fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable Pros:  conservative good for cases where changes in predictor value have predictable effects on probability of predicted variable class   Interaction effect?  logistic and step regression are good when interactions are not particularly common Decision Trees  more cut out for interaction effect J 48 and C4.5  can handle both numerical and categorical predictor variables   Pros:  relatively conservative due to pruning   good when  data has natural splits multi-level interactions are common same construct can be arrived in multiple ways         ; 1.4 Classifiers 2 Decision Rules  if-then rules which you check in order JRip and PART Decision Tree if, if else, otherwise Pros:  relatively conservative unlike most other DM approaches good when multi-level interactions are common    K*  predicts a data point from neighboring data points (weights points) good when  data is very divergent  intractable to find general rules     Pros:  sometimes works when nothing else works   Cons:  to use the model, need to have whole data set    Bagged Stumps  Related to decision tree lots of trees with only first feature relatively conesrvative random forest is a close variant (less conservative)  Common Thread  conservative  simple model, don't over fit    Difficult Models/ Not too successful 1) Support Vector Machines  Conducts demensionality reduction on data space and then fits hyperplane which splits classes creates sophisticated models good for  text mining sensor data   Not good for most of other educational data  logs, grades, interactions with software    2) Genetic Algorithms  inconsistent answers mutation, combination, and natural selection to search space for possible models  3) Neural Networks  perceptrons combined complicated models Soller &amp; Stevens (2007) difficulty of interpretation ; 2.2 Diagnostic Metrics Part 1 Metrics for Classifiers Accuracy  = Agreement (number of agreements)/ (total number of codes/assessments) Not as good metrics  non-even assignment to categories    Kappa  Cohen's Kappa (Agreement -Expected Agreement)/(1-Expected Agreement) Interpretation  0  agreement is at chance   1  agreement is perfect   -1  agreement is perfectly inverse (opposite)   &gt;1  messed up somewhere   &lt;0  model is worse than chance very rare unless using cross-validation   0&lt;kappa&lt;1  0.3-0.5 good enough lower is still often OK in affective computing     Reason for no standard  kappa scaled by proportion of each cateogry harder to get kappa in imbalanced data   comparing kappa values between 2 data sets are different - OK to compare within a data set   ; 2.3 Diagnostic Metrics Part 2 Classifiers Classifier goodness Receiver-Operating Characteristic Curve (ROC)  predicting something that has two values prediction model outputs a probability or other real value Method:  take any number and use it as a cutoff 0 or 1 if smaller or greater than threshold   4 possibilities  true positive false positive true negative false negative   ROC curve  X axis = percent false positives versus true negatives  false positives to the right, true negatives to the left   Y axis = percent true positives versus false negative  true positives go up, true negatives go down   dash line = chance  the more above dash line the better you are doing   above dash good stair steps good below dash so bad it is good    A'  probability that if model is given an example from each category, it will accurately identify which is which Wilcoxon statistics not really a good way to compute A' for 3+ categories z test to compare two models A' Complication  assumes independence   closely mathematically approximates the area under the ROC curve called AUC  A' and Kappa  A'  more difficult to compute almost always higher than kappa  because takes confidence into account      Precision  TP/ (TP+FP) the probability that the data point classified as true is actually true  Recall  TP/ (TP+FN) the probability that the data point that is actually true is classified as true  limitation of precision and recall  do not take confidence into account ; 2.4 Diagnostic Metrics: Correlation https://www.youtube.com/watch?v=7r3hfJW1gz0&amp;feature=youtu.be Metrics for Regressors Linear Correlation  when A's value change, does B change direction assumes linear relationship correlation  good correlation  1 perfect 0 non -1 perfectly negatively correlated   small correlation OK in education correlation vulnerable to outliers   r squared  correlation squared measure of goodness    Root Mean Squared Error (RMSE)  Mean absolute deviation  average of absolute value (actual value-predicted value)   RMSE  square root of average of (actual value-predicted value) squared large deviations    Good model  Low RMSE/MAD is good high correlation is good  Bad model  high RMSE/MAD low correlation high RMSE/MAD and high correlation - Systematically biased model Low RMSE/MAD and low correlation - model values are in the right range, but model does not capture relative change  Information Criteria  Bayesian Information Criterion BIC'  over 0 = worse than expected given number of variables under 0 = better   BIC  statistically equivalent to k-fold cross validation for optimal k   AIC  alternative to BIC     ; 2.5 Cross-Validation and Over-Fitting https://www.youtube.com/watch?v=1P34cxpEdKA&amp;feature=youtu.be Overfitting  fitting to noise as well as the signal Reduce overfitting  simpler models  fewer variables (BIC, AIC, Occam's Razor) less complex functions     every model is over-fit in some fashion assessing generalizability  transferrable to new context? over-fit to a specific context?   Training set/test set  Cross-validation  split data points into n equal size groups train all groups but one test on last group for each possible combination How many groups?  k-fold  quicker   leave-out-one  more stable     Variants  flat cross-validation  each point has equal chance of being placed into each fold   stratified cross validation  biases fold selection     Student level cross-validation  test model generalization minimum cross-validation needed   Other levels  lesson school demographic software package   important consideration  where do you want to be able to use your model?   ; 4.2 Bayesian Knowledge Tracing https://www.youtube.com/watch?v=_7CtthPZJ70&amp;feature=youtu.be Knowledge Inference: Bayesian Knowledge Tracing (BKT) BKT  classic approach for measuring tightly defined skill in online learning skills should be tightly defined typical use  assess a students knowledge of skill KC X   key assumptions  each item must involve single latent trait or skill each skill has four parameters two state learning models  each skill - learned or unlearned   problem solving, students can learn a skill at each opportunity to apply the skill student does not forget a skill   Model performance assumptions  slip - make mistake guess correctly    Classical BKT  2 learning and 2 performance parameters  BKT  only uses first problem attempt on each item  Parameter Constraint model degeneracy Constraints proposed Knowledge Tracing  how well does model predicts performance  Fitting a knowledge tracing  Fit methods        ; 7.1 Clustering  Structure discovery algorithm large number of data points - find structure among the data points don't know anything apriori about the structure ties to find data points to group them together  K-means clustering algorithms  simplest  Getting Clusters  decides number of clusters pick starting values for the ""centroids"" of the clusters   chosen randomly   classify every point as to which centroid it is close to  defines clusters visualized as: voronoi diagram   refit the centroids as the center of the points in each cluster  Note:  outliers getting into cluster regardless    If the starting points are in strange places,  run several times - involving several different starting points         ; 7.2 Validation and Selection of K Distortion = Mean Squared Deviation  take each point P find the centroid of P's cluster C find the distance D from C to P square D to get D' sum all D' to get Distortion  Distance  Euclidean distance  Distortion works for choosing between randomized restarts, but does not work for choosing cluster size  More clusters almost always leads to smaller Distortion distance to the nearest cluster center should almost always be smaller with more clusters  Cross-validation cannot solve this problem Solution   Penalize models with more clusters according to how much extra fit would be expected from the additional clusters Bayesian Info Criterion or Akaike Information Criteria  Using Information Criterion  assess how much fit would be spuriously expected from a random N centroids without allowing the centroids to move assess how much fit you actually had find the difference  So how many clusters?  Try several values of k find ""best-fitting"" set of clusters for each value of k choose k with best value of BiC or AIC  Alternate approach Distance to nearest; 7.6 Knowledge Inference - Q matrix Q-Matrix  Table rows = items columns = skills AKA: KC = Knowledge component model or Skill-item mapping  Methods to get Q-Matrix  Automatic model discovery Hand-development and refinements Hybrid approaches  Automatic model discovery (Barnes)  Learn mapping between items and skills solely from data Empirically determine the number of skills Pseudocode  for each number of skills, the algorithm will run a certain number of times with a different, random, initial assignment of items to skills avoids local minima    Better models?  performance on two items that involve the same skill should be connected  Subtlety  Is skill conjunctive? Compensatory?  Assumption  no learning  Hand Development and Refinement   try smooth learning curves  number of opportunities vs. error rate    look for skills with no apparent learning look for problems with unexpected error rates     ",70,39,31,5
"1265","Cross Validation","Cross Validation Train vs. Test Representative of how the system is ultimately going to be used Data being independent and identically distributed (IID) Fundamental assumption Use a model that is complex enough to fit the data without causing problem on the test set Training set that can act like test set: hold out some of the test set (pretend trial test set = cross validation set) To Pick a Model  Take our training data and split them into folds Train on folds and check average all the errors (goodness of fit) to see how well we have done Pick lowest error ",4,6,-2,5
"1266","Hands-On Programming with R","Atomic Vectors:  - simple vector of a data - one-dimensional vector  - each atomic vector can only store 2 type of data - types of atomic vectors: doubles, integers, characters, logicals, complex and raws Doubles - stores regular numbers (positive, negative) Integers - R won’t save a number as an integer unless you include the L. Integer numbers without the L will be saved as doubles. Characters - create a character vector in R by typing a character or string of characters surrounded by quotes Logicals -  TRUE and FALSE Complex and Raw  - complex: add an imaginary term to a number with i - Raw vectors store raw bytes of data - raw()   attributes() names() dim()   Matrices - store values in a two-dimensional array - matrix will organize your vector of values into a matrix with the specified number of rows - m &lt;- matrix(die, nrow = 2, byrow = TRUE) - matrix will fill up the matrix column by column by default, but you can fill the matrix row by row if you include the argument byrow = TRUE Array - ar &lt;- array(c(11:14, 21:24, 31:34), dim = c(2, 2, 3))    - array is not as customizeable as matrix and basically does the same thing as setting the dim attribute Class Dates and Times - Sys.time() Factor - way of storing categorical information  - convert a factor to a character string with the as.character function    Coercion - R always uses the same rules to coerce data to a single type: If character strings are present, everything will be coerced to a character string. Otherwise, logicals are coerced to numerics. List    - list creates a list the same way c creates a vector - Groups data into 1-D set Data Frames - two-dimensional version of a list - group vectors together into a two-dimensional table   Loading Data Saving Data - save any data frame in R into a .csv file: write.csv(deck, file = ""cards.csv"", row.names = FALSE) - Where is my working directory: getwd()       ",2,9,-7,1
"1267","Principal Component Analysis explained visually","Principal Component Analysis - Explained Visually PCA  technique used to emphasize variation and bring out strong patterns in a data set makes data easy to explore and visualize  2D Example  PCA finds a new coordinate system in which every point has a new (x,y) value Axes  don't actually mean anything physical combinations of height and weight called ""principal components"" that are chosen to give one axes lots of variation    3D Example 17D Example",1,0,1,2
"1268","Measurement and its Uses in Learning Analytics","   Bergner (2017): Measurement and its Uses in Learning Analytics    This is a primer on psychometrics for Learning Analytics/EDM (see Psychological Measurement) Psychological measurement often involves the measurement of an latent variable, which is always noisy  Instead of directly observable variables like height/weight, educators are focused on latent variables like  Knowledge Skills Aptitudes Attitudes Abilities Emotions   In education, small errors of psychometric measurement even at the individual level can have large consequences   EDM/LA have the potential of replacing separate assessments as a measurement tool of learning  Thus, it is imperative that practitioners learn the basics of psychometrics   What is measurement? Philosophy and Basic Ideas  Psychometrics typically comprises  Defining a construct Defining a measurement model Developing a reliable instrument Analysing and accounting for sources of error Framing a valid argument for the particular uses of the outcome of measurement   Constructs in Psychometrics  Unlike height/weight that are directly observed (manifest variables), psychological variables (AKA constructs) are latent - only indirectly observable Trait vs variable - Traits are variables, but tend to be stable over time   Operationalist vs Constructivist-realist positions of measurement  Operationalist view (e.g. Bridgman, 1927; Stevens, 1946) - variable = outcome of measurement by a measurement tool  Eventually rejected for a number of reasons, especially since operationalism suggests that a construct is effectively redefined each time an instrument is changed   Constructivist-realist position - Use model-based reasoning, where the model supposes that a construct exists for discussion's sake  Model-based reasoning necessarily means accepting a simplified representation of a system that captures only its most salient aspects - ""All models are wrong, but some are useful"" Model elements are then emphasised in prediction/explanation of phenomena     Since psychological constructs are theoretical, there is no empirical limit to their number  Hence why there are far less physical than psychological theories, and physical theories are more comprehensive than psychological theories, which are usually very narrowly specified   A construct can be posited without a measurement tool, but measurement tools always exist to measure a construct - otherwise they have no meaning   Measurement Instruments  In psychology, usually tests or questionnaires (AKA surveys/inventories)  Made up of items/indicators Allows efficiency and standardisation, compared to observation methods   The 'test' usually requires participants to try and maximise their performance, whereas questionnaires/surveys/inventories usually require participants to answer honestly, with no right/wrong answers Measurement scales  Dichotomous (0/1) Likert, Rating, and Visual-analogue scales - discrete or continuous range of numerical values   Scoring  Often, the sum of scores for individual items are added up to get a raw score for the variable, but other procedures for scoring exist Reverse coding Weighted sums Use of Item Response theory to determine ability     Sources of Error in Measurements  Can tell that there is error in the psychological measures given  Lack of fully repeatable measurements People's responses may not fully reflect the latent construct posited to lay within them   Random error - unbiased error Systematic error - biased error More precise statements about error are specified by specific measurement frameworks  E.g. True Score Theory and Factor analysis - reliability is thought of in terms of parallel tests or equivalent form tests However, additional sources of error can be introduced by using models with the wrong parameters, the wrong models, or using models wrongly Use of a model itself may depend on parameters that are also subject to error     Reliability (of an instrument)  Measure of the consistency of scores - the proportion of the total variance in scores attributed to the latent variable Can be sample-dependent or model-dependent Term is usually taken to mean Cronbach's alpha, but can also be taken as test-retest reliability or inter-rater reliability   Validity  The degree to which evidence and theory supports the interpretation of a measure for the proposed uses of the measure Among other things, Validity can be threatened by response bias  E.g.  Acquiescence bias (e.g. Answer 4 for everything) Social desirability bias Bias from extreme type responders who tend to choose the ends of Likert-scales Guessing       Measurement models  Measurement Model - A formal mathematical relationship between latent variable(s) and observable variable(s) like test scores Functional relationships between a set of observed and latent models can be developed through statistical means (e.g. Path analysis, Structural Equation Modelling)  The latent variables are taken as causally explaining the observations, which are subject to error   Models make assumptions about the data and relationships (e.g. that they are linear, that error terms are not related)   Specific Uses of Measurement Models in Learning Analytics  Work in LA/EDM exposes the complicated relations between  Psychological scales Behaviour Performance   Factor Analysis  Models correlations among observed variables through linear relationships to latent variables (factors) An early example is Spearman's model of general intelligence, g, used to explain correlations between scores on unrelated subject tests 2 main types  Exploratory Factor Analysis  Often used in scale development Determines number of latent factors from data without strong theoretical assumptions   Confirmatory Factor Analysis  Tests a proposed factor model based on data       Latent Class and Latent Mixture Models Item Response Theory  Models individual person-item interactions rather than total test scores, unlike in Classical Test Theory Meant to describe ""items by item parameters and examinees by examinee parameters""  Allows probabilistic prediction of an examinee's response to any item   See Psych Measurement for the Item Characteristic Curve/Item Response Function   Growth models  Apply when a latent trait is changing systematically between measurements Applied in ITS/Cognitive Tutors  Sequences of practice items are designed to support mastery learning of fine-grained knowledge components, according to a cognitive model (ACT-R) Use Bayesian knowledge training (BKT) or additive factors models (AFM) - have similar prediction ccuracy  BKT's latent variable is mastery of a procedural knowledge component, valued as a binary 0 or 1  Students have a prior probability of mastery and move towards mastery in each practice opportunity   AFM follows power law of practice       Cognitive Diagnostic models  E.g. Q-matrix, where there is a discrete mapping of items to sub-skills     Explanation and Prediction  Predictive Modelling is prominent in Educational Data Mining However, Psychometrics and Measurement Theory are mostly explanatory Explanatory models can be used to make predictions (e.g. Regression), and an error-free explanatory model will make perfect predictions  However, predictive models (e.g. Algorithmic prediction) are not necessarily explanatory   Design of statistical modelling can be divided into explanation or prediction  Among other differences, the interpretability (or lack thereof) of predictors in a prediction model is one distinction between the two Affects handling of error and uncertainty  Predictive view - models are best evaluated in terms of predictive accuracy  Assumes that predictive power points to the 'truest' model  Model assumptions are best challenged by testing models with different assumptions  Best assumptions yield models that out-predict the others     Explanatory modelling - models seek to minimise bias to produce the most accurate representation of underlying theory            ",15,30,-15,5
"1269","Ethics and Learning Analytics: Charting the (Un)Charted","   Prinsloo &amp; Slade (2017): Ethics and Learning Analytics: Charting the Uncharted      The ethical issues associated with Learning Analytics have advanced with  The development of the field itself into a distinct field of both research and practice  Some consensus that the 'future of learning'  Will be  Digital Distributed Data-driven   Should be supported by  High Quality Research Sophisticated data collection Advanced Machine and Human learning analysis/support       Technological advances Increasing concerns around surveillance and the unintended consequences of algorithms   Ethics and privacy increasingly seen as crucial enablers within learning analytics The Relevance of Ethics  Where it is potential for economic benefit to learner and institutions from improving learner experience through data, data can also disadvantage learners Ethical implications around the collection, analysis, and use of student data should take into account potential conflicts of interest between stakeholders (e.g. Students and institutions)   Progress in Ethical Thinking in Learning Analytics  Ethics was originally on the margins of the field, but is increasingly coming to the fore Work in Ethics began relatively recently (LAK 2012) in exploratory workshops and as a minor point in some presentations In 2013, work progressed to examine existing institutional policy frameworks on data use and management Slade &amp; Prinsloo (2013) considered a range of ethical issues in LA  Grouped into  Location and Interpretation of the data Informed consent, privacy, and de-identification of data Management, classification, and storage of data   Proposed 6 principle framework as a starting point to consider ethics in LA  Learning Analytics as a moral practice  Focus on not just what is effective, but also what is appropriate and morally necessary   Students as agents  Students as collaborators rather than just recipients of interventions and services   Student identity and performance as temporal performance constructs  Analytics often provides just a snapshot of a learner in a particular time and context   Student success as a complex, multidimensional phenomenon Transparency as important  Purposes for data use Conditions for data use Access to data Protection of individuals' identities   Higher Education cannot afford not to use data     This framework needs to be supported by practical considerations, such as  Understanding who benefits, and under what conditions, from data use Establishment of institutional positions on  Consent De-identification Opting-out Vulnerability and harm (e.g. Inadvertent labelling) Systems of redress (for both individuals and institutions) Data collection, analyses, access, and storage (e.g. Security issues and avoiding perpetuation of bias) Governance and resource allocation - where best to direct support resources and on what basis are decisions made  Examined further in the concept of Educational Triage  Direct support towards students most likely to ""survive"" rather than drop out Brings with it further issues E.g.  Respecting student autonomy vs ensuring institutional survivability Upholding Beneficence (acting in the student's best interest) Upholding Non-maleficence (inflict the least harm possible to reach a beneficial outcome) Maintaining Distributive justice (understanding that demographic characteristics impact support provided and assumptions made, and trying to address this)           Surveillance, Student privacy and Institutional accountability  Learning Analytics does not produce entirely objective, accurate, or in any way 'complete' pictures of student learning The use of LA brings with it an unequal institution student relationship Prinsloo &amp; Slade (2014) raised these issues and suggested 6 elements as a basis of student-centred Learning Analytics  Use of Aggregated, non-personalised data to deliver more effective and appropriate teaching/learning  Must have opt in/out option for students Students should have as much knowledge of as possible on what data is collected and how it is used Students should ensure that their personal data are complete and updated LA processes must not harm student progress Algorithmic output should be subject to potential human review and correction Acknowledgement that LA  Provides context- and time-specific, provisional, incomplete pictures of students Should require frequent review and validation of systems/algorithms       At present, few Higher Education Institutions (HEIs) have regulatory frameworks/transparency around the scope of data collected, analysed, used, and shared by their LA systems     Recent developments in Ethical Frameworks  Broadly accepted that deep economic pressures (the rapidly increasing value of data) are driving the intensification of connection and monitoring online  The rapid ascent of data's value has overtaken traditional legal and ethical frameworks   Need for stronger reflection on the costs of data in current capitalist society and our own possibilities of ethical life Sclater, Peasgood &amp; Muillan (2016) review Higher Education practices in US, UK, and Australia  LA has significant benefits for  Quality assurance and quality improvement Boosting retention rates Assessing and acting on differential student outcomes Development of adaptive student learning   Threats  Ethical and data privacy issues Over-analysis and lack of generalisability of results Possible misclassification of patterns Contradictory findings     Open University UK (2014) published an 8-principle policy on ethical use of student data  Learning Analytics is an ethical practice that should align with core organisational principles  For OU, that is open entry to undergraduate studies   Responsibility to all stakeholders in use and extraction of meaning from student data for the benefit of students Students should not be wholly defined by their visible data or its interpretation Purpose and boundaries regarding the use of learning analytics should be well-defined and visible Transparency regarding data collection and support for students to update their own data Students should be active agents in implementing Learning Analytics  Informed consent  Here specifically meaning students should be aware of the purposes of their data use, and provide consent for those uses   Personalised learning paths Interventions   Modelling and interventions based on analysis of data should be methodologically sound and free from bias Adoption of LA requires broad organisational acceptance of its values and benefits, and requisite organisational skill development   Welsh &amp; McKinney (2015) proposed a Code of Practice in LA in Australian context  Acknowledged immaturity in the field, with vendors, institutions, and stakeholders all trying to figure out what works and the boundaries of acceptable practice Argue for commitment that institutions do not engage in LA practices using data sources  Not directly related to teaching and learning Users may not reasonably expect such data collection to occur     Engelfriet et al. (2015)   Suggest 4 principles in Dutch context  Personal information should be used only in the context and purpose for which it was provided Subsequent use of data should be reconcilable to the original context and purpose Data should be carefully collected and analysed  The process It should be transparent, with student consultation and support   Data may only be collected when the purpose/use of collected data is clear   Humans must take responsibility for and have oversight over any algorithmic decision making  In cases where institutions subcontract analytics to vendors, decisions and oversight over data use cannot be outsourced       Sone Future Considerations  Developing consensus around consent practices/standards Research in potential conflicts between student concerns, right to opt-out, and implications for institutions seeking to use LA to make adaptive, individual-level interventions Research in mitigating costs of analytics  Mitigating algorithmic discrimination Encouraging development and use of robust and transparent algorithms, algorithmic auditing Improvement in data science 'fluency'  Roles of government and private sector in setting codes of practice              ",44,15,29,2
"1270","Predictive Modelling in Teaching and Learning","   Brooks &amp; Thompson (2017): Predictive Modelling in Teaching and Learning  In both LA and EDM, predictive modelling has become a core practice of researchers  Mostly, people are focusing on predicting student success, operationalised as academic achievement   Predictive Analytics  Make inferences about uncertain future events In education, interests in   Predicting learning measures Predicting teaching method effectiveness Predicting administrative metrics like course registration or retention     Predictive modelling vs explanatory modelling  Purpose  Explanatory modelling - use all available evidence to provide explanation for a given outcome  E.g. Multiple linear regression to explain contribution of various factors to an outcome variable Intent of these explanations is generally to be causal, vs merely correlative  Although studies using these methods may rely on theoretical interpretation to imply causation rather than controlled experiments     Predictive modelling  Purpose is to create a model that will predict the values/class (for categorical data) of new data based on observations Based on the assumption that a set of known data (training instances) can be used to predict the value or class of new data based on observed variables/features     Pragmatic differences  Explanatory modelling is post-hoc and reflective, aimed at understanding a phenomenon  Can take action based on review of models by experts   Predictive modelling is an in-situ activity intended to make systems responsive to changes in the underlying data  Can take action based on system predictions     On generalisability  Explanatory modelling - data collected from a sample is used to describe a population more generally  Generalisability is based on sampling  Random or stratified sampling to reduce selection bias and maximise the chance that the sample is representative of the population of interest Power analysis to determine the size of an appropriate sample     Predictive modelling  Test data is withheld from model training  To evaluate the suitability of a model for prediction Protect against overfitting of models to training data Several strategies for producing training/test data splits  K-fold cross validation Leave-one-out cross validation Randomised subsampling Application specific strategies           Predictive modelling workflow  Problem identification  Predictive modelling in education tends to live within larger, action-oriented educational policy and technology contexts Interest in using predictive modelling to react to student needs in real-time Aim to predict outcomes of given learners, assuming no new interventions  E.g. Predicting when someone will finish their degree   Predictive modelling works well with problems where there are  Clear outcomes of interest Quantifiable characteristics of the subject being modelled Ability to intervene in situ Large set of data Recurring need for the prediction (e.g. New class every year where training set, past students, is indicative of the test set, future students)   Predictive modelling works less well when  There is sparse and noisy data - students not answering questions, measures with high error When modelling techniques and outcomes present issues of ethics or equitability     Data Collection  Historical data is used to generate models of relationships between features First step is to identify the outcome variable and its suspected correlates  For practicality, choose variables available at or before the time of intervention - otherwise you wouldn't have the data you need to run the model when it is time to run it for the intervention Creating multiple models is common   Data sources  State-based data - demographics, relationships (e.g. Course enrolments), psychological measures, performance Event-based data - student activities, drawn from learning technologies that students interact with  Derived from LMS, discussion forums, learning technologies, and video-based instruction tools     Feature Engineering  Converting complex data such as event-data into features suitable for predictive modelling     Classification and Regression  In statistical modelling, there are 4 types of data considered  Categorical, ordinal, interval, and ratio In predictive modelling practice  Ordinal variables are often treated as categorical Interval and ratio are considered as numeric   Categorical values may be binary or multivalued   Classification algorithms are used to predict categorical values Regression algorithms are used to predict numeric values   Feature Selection  Features that correlate with the outcome to be predicted must be created During data collection, one should try to collect more rather than less data, as it is much harder to get new data than to remove extra data Some algorithms use all available attributes to make predictions, whether they are informative or not, whereas others select certain features and eliminate others from the model  By selecting an informative subset of features  Reduce the computational complexity of the predictive model Reduce data storage and collection requirements Simplify predictive models for explanation     Dealing with multicollinearity  Applying an algorithm that naively assumes independence of attributes can result in predictions with an over-emphasis on repeated or correlated features It may be useful to remove highly correlated attributes or transform them to eliminate the correlation Some techniques rely upon an assumption of independence (e.g. Multiple regression) #I presume PCA handles multicollinearity since it captures most of the covariance between variables as a single component?   Dealing with missing values  Missing values may arise because the field is unknown or not applicable Techniques  Simplest way is to remove the attributes (columns) or instances (rows) with the missing values  Especially when the data is small, removing any amount of data can have a significant effect on the outcome  Even more so when the removal exacerbates an existing imbalance   If all attributes/instances have some missing values, removing them means getting rid of all the data   Another way is to replace missing values with a 'normal' value, such as the mean Fill in missing values by finding other similar records in the dataset, and copying the missing values from their records   Impact of missing data is heavily tied to the choice of algorithm  Some can make predictions even when some attributes are unknown Naive Bayes Classifier  The missing attributes simply are not used in making a prediction   Nearest neighbours relies on computing distance between two data points  Assume that NA = largest possible distance for that attribute   C4.5 decision tree  Instance is divided into fractional parts that are propagated down the tree and used for weighted voting         Methods for Building Predictive Models  Remember that a predictive model is meant to make predictions of some unknown quantity/attribute given some related known information A fundamental assumption of predictive modelling is that relationships that exist in the data gathered will still exist in the future  This may not be true, and it is important to consider if it holds in a given situation   Linear Regression  Predicts a continuous numeric output form a linear combination of attributes   Logistic Regression  Predicts the odds of two or more outcomes, allowing for categorical predictions   Nearest Neighbours Classifiers  Uses the closest labelled data points in the training dataset to determine the appropriate predicted labels for new data   Decision Trees  E.g. C4.5 algorithm Repeated partitions of the data based on a series of single attribute tests Each tests is chosen algorithmically to maximise 'purity' of the classifications in each partition   Naive Bayes Classifiers  Assume statistical independence of each attribute given the classification Provide probabilistic interpretations of classifications   Bayesian Networks  Manually constructed graphical models Provide probabilistic interpretations of classifications   Support Vector Machines  High dimensional data projection to find a hyperplane of greatest separation between the various classes   Neural Networks/Deep Learning  Propagate data input through a series of computational nodes (neurons) to produce an output   Ensemble Methods  Use a voting pool of either homogeneous or heterogeneous classifiers Bootstrap aggregating  Several predictive models are built from sub-samples of the dataset   Bootstrapping  Successive predictive models are designed to account for misclassifications of prior models     Most methods and their software implementations have tuneable parameters  These change the way the algorithm works  E.g. Minimum leaf size or maximum depth of tree in decision trees, number of hidden layers in neural networks       Model Evaluation  Use a test dataset with known labels Predictions made by the model on the test set can be compared to the known, true labels of the test set to assess the model Several possible metrics   Accuracy - total correct prediction/total predictions Precision - True positives/(True positives + False Positive)  How precise/accurate model is in predicting positive  Best used when cost of false positive is high   Recall - Calculates how many actual positives the model captures as labelling as positive  Best used when cost of false negative is high     Hold-out validation - reserve a portion of the initial dataset to use as a test set to assess model quality  Simplest approach - 50-50 split between training and test data  Issues  Halves the data available for model fitting, often reducing model performance Assessment of model quality only made based on predictions for half the data  Increasing the number of instances in the test set would increase the reliability of the results       K-fold cross validation  Dataset is partitioned at random into k segments k distinct predictive models are constructed, being trained on all but one of the segments  Test on the remaining segment   Repeat, holding out a different segment each time Assess model quality by taking the average of results from all k test segments Benefits  Every available data point can be used as part of the test set No data point is ever used in both training and test at the same time Training sets used are nearly as large as all the available data       Similarity between training data and data available for when predictions are being made  In education, training data usually come from a few semesters or years ago  This might not be representative of the real data the model will be deployed on   Would be better to train the model on data from one year, then test it on data the following year  Rather than splitting data from one year alone This better represents how the model will be used         Predictive Analytics in Practice  Identifying students at risk in their academic program Predicting student achievement based on interactions with ITS Predicting learner drop-out in MOOCs Detect learners engaging in off-task behaviour   Challenges and Opportunities  Supporting non-computer scientists in predictive modelling activities  LA is highly interdisciplinary, bringing together researchers, psychometricians, cognitive and social psychologists, and policy experts with strong backgrounds in explanatory modelling Allowing them to access predictive modelling could increase the use of these techniques in education   Creating community-led educational data science challenge initiatives  Moving towards common outcomes, open data, and shared implementations would lead to better knowledge emerging in the community   Engaging in second-order predictive modelling  Second-order predictive models - model that includes an older version's impact  Include historical knowledge on the effects of and intervention in the model itself          ",25,34,-9,3
"1271","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","   Liu &amp; Koedinger (2017): Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data    Most EDM models focus on evaluation based on predictive accuracy  Often involves success/failure at predicting student response outcomes At other times, this involves predicting post-test outcomes or pre-test/post-test gains   Another approach is to build explanatory models  Aim to find interpretable constructs causally related to outcomes Explain data and relate it to existing theory and practice   Most EDM research has focused on developing two types of models  Statistical Models and Cognitive models  Statistical models drive ITS, based on observable features of student performance in using the system Cognitive models are used as representations of the knowledge space that underlies a particular educational domain     Cognitive Model Discovery  Cognitive models map knowledge components (concepts, skills, facts) to problem steps/tasks where we can observe student behaviour  This mapping enables statistical models to make inferences about students' underlying knowledge based on their behaviour   Cognitive models are important for ITS design and accurate assessment of knowledge/learning  Better cognitive models lead to better predictions of what a student knows, aiding adaptive learning systems   Traditional ways of constructing cognitive models are time consuming, require human input, and are subjective  Expert labelling, Think aloud protocols, Rational analysis Expert created cognitive models also often ignore content distinctions important for novice learners   Alternative ways of Cognitive Model Discovery involve using data-driven techniques e.g. Q-matrices (KC model)  Can evaluate fit using logistic regression models like additive factors model (AFM)     Data-Driven Cognitive Model Improvement  Difficulty Factors assessment (DFA)  Uses data-driven knowledge decomposition to identify problematic elements of a defined task If two otherwise similar tasks have one that is much harder, this implies that the harder task has a knowledge demand not present in the simpler task Steps  Visualise learning curves and fitted AFM estimates for a given KC model Identify problematic KCs and hypothesise changes to the KC model Refit the AFM to the new model and see if it works better   Geometry Dataset example  Most KCs show smooth learning curves with consistent declines in error rate One KC, compose-by-addition, showed a noisy curve with large error rate spikes at certain places  AFM for this KC suggested no apparent learning, without ceiling effects These characteristics suggest a poorly designed KC  Often this is caused by some items mapped to the KC involving additional knowledge demands that the others do not   Splitting the single KC into 3 KCs and remapping the items yielded better predictions than the original model that improved later ITS implementations       Learning Factors Analysis (LFA)  LFA searches across hypothesised knowledge components from existing KC models, evaluates these models based on their fit to data, and outputs the best-fitting model Reduces human effort in searching for the best model and eases burden of interpretation When used across DataShop datasets, the automated discovery process improved KC models' fit to data beyond human-tagged KC models  Koedinger's group also demonstrated human interpretability for one of these cases, and better performance of the LFA model over human-developed models for a novel dataset with new question types     Automated Cognitive Model Discovery using SimStudent, a Machine-Learning agent  Discovers cognitive models automatically without using existing models Learns production rules inductively by observing a tutor solve sample problems and by solving problems on its own and receiving feedback  Outputs production rules that correspond to one KC in a KC model Simulates novice learning trajectories, identifying blindspots that experts might miss in novice learning   Outperforms human-generated cognitive models for several datasets across knowledge domains and can be generalisable beyond a training ITS dataset Comparing human-generated models and the SimStudent model can reveal interpretable features of the SimStudent model, and insights on how it is defining KCs and mapping items to them relative to how the human models are doing it   Both LFA and SimStudent present cognitive model discoveries that  Significantly improve predictive accuracy Are interpretable, and hence explanatory  Even better, they generalise to novel problem types not present in the data   Present clear recommendations for revising instruction Although LFA has been criticised for needing human involvement, this feature is what allows LFA to yield explanatory insights  Fully automating cognitive model discovery saves human time and effort without much cost to predictive accuracy However, there is no guarantee anyone understands the cognitive models that result  Model may not be interpreted or used to improve instruction         Student grouping  Techniques like K-means and spectral clustering have been used to group students based on features in educational datasets  Used to generate student clusters predictive of post-test performance Yield predictive accuracy improvements when clusters are fit with different parameters   Clustering techniques tend to result in groupings that are hard to interpret  However, interpretability is important if clustering is to inform improvements in instructional policy, such as individualised instruction   Using AFM, Liu &amp; Koedinger developed a method to improve predictive accuracy but also produce meaningful student groups  Those who had faster, slower, or on par learning curves relative to the AFM model prediction These groups are readily interpretable and potentially actionable     Towards Building Explanatory Models  Must understand why a model achieves better predictive accuracy compared to alternatives  Understanding of this why should either advance our understanding of learners' learning of the material or have clear implications for instruction, or both   Features tending to characterise explanatory models  Tend to start with clean independent variables that map to clearly defined constructs or have simple functions  E.g. LFA begins with clean expert-labelled KC models and performs simple split, merge, or add operations   Dependent variable maps to a well-defined construct (e.g. Learning rate, or theoretical constructs from psychology)  Makes the model readily actionable   Explanatory models tend to have fewer estimated parameters (AKA variables/features)  Makes parameters easy to attribute and interpret Allows parameter estimates to have more explanatory power              ",24,15,9,5
"1272","Statistical graphics: making information clear – and beautiful","Niemi &amp; Gelman (2011): Statistical graphics: Making information clear—and beautiful  Default plotting tools in Excel/R are useful for explanatory data analysis, but insufficient for production-quality figures Improving figures requires two key decisions  Who is the target audience?  Put yourselves in the shoes of the target audience and ask what is important to them   What are you trying to show?   Rules of thumb  Avoid distracting elements Use informative colour Keep the figure simple   When creating small multiple plots (e.g. Facet wrap)  Keep axes on the same scale for each plot Eliminate repetitive information Maintain consistency across plots Think about whether a horizontal or vertical arrangement of the plots would be more useful   ",0,6,-6,2
"1273","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Gelman &amp; Unwin (2012): Infovis and Statistical Graphics: Different Goals, Different Looks  Interest in statistical graphics  In statistics, most work has been on modelling rather than graphics In applied fields, visualisation was applied for data exploration and communication, but the main interest was inference However, outside statistics, visualisations (called infographics) are very popular and often applied by publications There is not a lot of dialogue between academia and the outside world in statistical visualisation standards  The risk is that without understanding best principles of graphical communication from academia, designers may obscure rather than reveal information in their visualisations that are built to look nice, while at the same time purporting to reveal information     Conflicting goals between Information Visualisation and Statisticians  Statistical POV  Visuals should  Facilitate understanding of patterns in an applied problem Effectively and precisely present data - whether raw data, summary statistics, or model data Providing the right comparisons matters  Numbers on their own make little sense Graphics should enable readers to form their own insights and draw their own conclusions       Information Visualisation POV  Visuals should  Grab reader attention  Tell a story Encourage the reader to think about the dataset as individual measurements and a representation of larger patterns   Often, they provide contextual information to garner interest and guide the narrative   In Infovis, data is used to draw attention to wider issues, whereas in statistics, visualisations concentrate on understanding the available data Both approaches have value, and it would be best if they can be combined  For infovis, the public often gets a pretty graph or raw data with nothing in between  Once attention has been grabbed, the audience may see value in line plots or scatterplots that help them further explore the data   For stats, one has to wonder why only academics do things they way they do   Key differences between the approaches   Take on what is 'good visual use'  Statisticians prefer generic method that look and feel the same across a wide array of applications  They stick to well-tried tools, providing recognisability, facilitating inference   Infovis prefers unique, distinctive displays that provide novelty and attention   Audience  Statisticians assume that viewers are already interested and want to present structured information Infovis designers want to draw attention to the graphics and hence the subject matter - graphics is the way in       Exploratory vs Presentation Graphics  Exploratory graphics are viewed only by yourself to help you understand the data  Multiple explanatory graphics are made Prioritise speed, flexibility, and alternative views Aesthetic quality is unimportant   Presentation graphics are for publication  Only a few graphics are made Prioritise care, specifics, and a single view Aesthetic quality is valuable   The paper focuses on static (vs interactive) presentation graphics   The goals of visual presentation of quantitative information  Tukey (1993) for small datasets - Graphics  Are for the 'semiquantitative'   Tables are better for specific quantitative presentation   Are for comparison, not access to individual amounts (again, use tables) Graphics are for impact, but not for something that has to be worked hard for to be perceived Graphics should report results of careful data analysis rather than replace it   Gelman &amp; Unwin for bigger datasets that are more common nowadays  Discovery Goals  Giving an overview  A qualitative sense of what's in the dataset Checking assumptions Confirming known results Looking for distinct patterns   Conveying the sense of scale and complexity in the dataset Exploration  Flexible displays to discover unexpected parts of the data Use smaller breakdowns or interactive graphics to make comparisons     Communication Goals  Communication to self and others - display information in a readily understandable way Telling a story - i.e. Communicating well Attracting attention and stimulating interest   ""we communicate when we display a convincing pattern, and we discover when we observe deviations from our expectations""  Sometimes, these can be complementary, but at other times we may have to pick between the goals  They may also benefit each other - grabbing attention may invite a desire to discover the data   Audience and viewer expectations affect how a graphic will be perceived  E.g. Someone knowledgeable on the topic will view a visualisation differently from someone who isn't knowledgeable       Ultimately, data visualisations must present relevant data fairly and effectively  Should use appropriate scaling and encourage informative comparisons Design should be harnessed to make the graphic more attractive and interesting     ",17,9,8,2
"1274","Junkcharts Trifecta Checkup: The Definitive Guide","Fung (2014): Junk Charts Trifecta Checkup: The Definitive Guide  3 investigations to check if a visualisation is good  What is the Question?  Any visualisation needs to have an aim, a question it sheds light on The question should be  Interesting - ensuring an engaged audience Well-posed - Focuses search on the appropriate data     What does the data say?  Data should be relevant to the question being asked As far as possible, remove noise, error, or transformations     ",1,3,-2,2
"1275","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Bowers  (2010): Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping Out and Hierarchical Cluster Analysis  Much research on data driven decision making (3DM) in schools has been focused on standardised test scores, despite  Vast array of data from other learning activities and evaluations Literature urging teachers and schools to leverage on varied data sources to improve student achievement   Teacher Assigned Grades as Useful Data in Schools  Teachers tend to award grades based on a variety of factors  Academic knowledge Attendance Participation Behaviour   Research on grades have criticised this approach as a poor gauge of academic knowledge, encouraging the used of standardised assessment  While administrators like standardised assessment, they show little criterion validity to overall student school or life outcomes Teachers have traditionally resisted reform to their grading practices Standardised assessment is then administered on top of these practices Research suggests that 25% of variance in school grades is attributable to academic knowledge, and the rest seems to be mapped onto a 'School success factor' (SSF)  Attendance, behaviour, participation Provides fairly accurate assessment of overall student outcomes  Hence, teacher grades are still useful for 3DM, especially if administrators are interested in these outcomes         Visualising Data for 3DM in schools  Provide summary statistics  Less useful for individual student- and school-level decisions   Inspect each student data point  Impossible for larger institutions   Depending on single course failures which are highly predictive of schooling outcomes  May be too late for students, since the failure already occurred, and they then need to play catch up Goal should be early identification for early intervention     Hierarchical Cluster Analysis (HCA)  Provides a means to analyse all student data without aggregating it Uses a series of nested correlation calculations (distance measures) to reorder a dataset, such that clusters of data patterns are closest to each other in a list Method  Each case is first defined as an individual cluster - in the case study it is the student's grades from K-12 Distance measure then calculated for each case, resulting in a similarity/dissimiarity matrix Clustering algorithm is then applied iteratively at each level of clustering in a hierarchical fashion  Two most similar cases are joined into a cluster   List is then ordered based on the cluster hierarchy, with cases in the list presented near those they were joined with in a cluster earlier on Dealing with missing data  ""Fortunately, average linkage, as the clustering algorithm, helps to address this missing data issue. In average linkage the distance measure between two cases is the mean pairwise distances between all items contained in the two cases, here uncentered correlation. Hence, if a student drops out and is thus missing data for the later grades the algorithm uses the average of the pairwise distances between that student and the next student to compare for possible cluster inclusion. ""     Visualisation  Dendrogram (cluster tree)  Visual representation of similarity or dissimilarity For each iteration of the algorithm, the cluster tree grows as levels of clusters are connected to each other in a hierarchical manner, until the whole dataset is encompassed by a single cluster Shorter lines (horizontal for left to right, vertical for top-down) indicate more similarity and longer lines indicate more dissimilarity   Heatmap  Transform data points into colours along a gradient corresponding to scale of the measure     Types  Supervised - begins with a defined set of assumptions about the categorisation of the data Unsupervised - assumes nothing about the categorisation a priori, relying on underlying statistical structure in the data     Case study  Collected longitudinal grading histories of students in two mid-west US school districts from K-12 (n = 188)  Mean GPA (calculated from subject grades and standardised through z-scoring) Gender Student transfer into or out of districts Whether the student took ACT/college entrance exam Graduated on time Drop out     ",9,5,4,3
"1276","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Grunspan, Wiggins &amp; Goodreau (2014): Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research       Social interaction between students are a major and underexplored part of undergraduate education  SNA provides a theoretical and methodological toolkit to answer questions about pedagogy, equity, learning, educational policy, and organisation SNA has been applied in many other fields, such has  Social Sciences Epidemiology Scientific Collaboration Social Contagion   There is a growing body of work in SNA involving educational questions  Has raised important issues such as the importance of randomly determined relationships like roommate or lab partner on undergrads' behaviour and hence, their college experiences     SNA has two broad classes of hypotheses  Hypotheses that seek to understand what influences the formation of relational ties in a population  For education - e.g. Major, mutual friends   Hypotheses that consider the influence that the structure has on shaping outcomes at either the individual level (e.g. GPA, eventual SES), or population level (e.g. Graduation rates, retention)   One key direction for education is to investigate network formation in classrooms  They can then study how these networks affect learning outcomes   Network Concepts  Social network Basics  SNA aims to understand   How relationships form What kind of relational structure emerge from the formation of individual relationships What are the impacts of these relationships on actors/nodes/agents   SNA focuses on relationships and emergent structures  This sets it apart from other methodologies that focus on attributes of actors Also, unlike other methods that stress independence of observations, SNA data points are inherently related to each other     Network Types  Networks can be characterised by the number of types of actors they contain  Unipartite - networks that consist of only one type of actor Bipartite - two types of actor   Nature of the ties they contain  Undirected Directed   Description of ties  Binary - specify whether or not a relation exists  Easier to collect and analyse   Valued - includes additional quantitative information about the relation  More information, but increased analytical and methodological complexity       Network Data collection  Temporality - Need to decide on a time frame for the relationships of interest  A network is inherently dynamic, but data collected represents the network at a certain point in time Network data collection and analysis can then be categorised as   Static Cross-sectional realisation of a dynamic network Explicitly dynamic  Consists of multiple cross sections OR Continuous data collection     Choice of collection time frame and analysis should be driven by the research question   Sampling  Ego-centric - focus on a sample of individuals and the social environment surrounding them, with little explicit attempts to further construct the network  Typically, Ss are asked  Number and nature of their relationships  The attributes of their relational partners   Tend to be easier to implement, in terms of data collection, ethics, and IRB   Census Networks - collect data from an entire bounded population of actors, including identifiable information on the respondents' relational partners  Alters are identified from the set of respondents and used to build a complete picture of the network More comprehensive data allows more hypotheses to be tested Issues  Rare, since it is hard to collect data this way May miss information on potentially influential relations with actors that were not part of the population of interest  E.g. In a student-student network, TAs would be missing   In longitudinal designs, also faces problems with attrition and new entrants to the network Nonresponse  A bigger problem here, since the methods assume that the entire network structure is an interactive system, and it has been completely observed           Network level concepts and measures  How many ties are present  Network density - number of actual links in the network as a proportion of the total number of possible links   Who is connected to whom?  Homophily - a propensity for similar actors (over a variety of traits) to be disproportionately connected in a relation of interest  Homophily can emerge from multiple processes  Social Selection - relationship is more likely to occur due to two actors having the same attributes Social Influence - individuals change their attributes to match those of their partners Disentangling the two is easier when longitudinal data is available, allowing for event sequences to be determined       Dyad and triad-level analysis  Dyad level analysis - analysing ties between two individuals independently Triad and higher levels of analysis is more feasible in a census network  Triads garner greater interest in network theory, given that they afford more variation in structural dynamics  One node brokering the formation of a tie between two other nodes One node acting as a conduit of information from one node to another   Can look at  Number of triads in the network, and of what type Transitivity - likelihood that if A -- B and B -- C, that A also -- C  Serves as a simple, local measure of more general concepts - clustering or cohesion Can be A--&gt;C/C--&gt;A (transitive triad) or A&lt;--&gt;C (cyclical triad)           Node/Actor-level variables  Include the exogenously defined attributes often used in other analyses  Race, Gender, Major, Age, etc.   Metrics of Node position in the network  Centrality metrics  Degree - total number of connections the node has Closeness - average distance between the node and other nodes in the network, measured along geodesics  Poorly suited for disconnected networks   Betweenness - Whether actors serve as bridges in the shortest paths (called geodesics) between two actors Eigenvector - places importance on being connected to other well-connected individuals         Data Collection in SNA  Surveys  Can be used to collect relational and nodal attribute data Subject to all the problems with surveys in other types of research Particularly challenging for SNA since Ss report on relational partners, in addition to themselves   Databases  Student databases can give administrative information   Interviews  Possible with smaller communities, communities with less online capability, or particularly well-funded studies     Data Management  Often use matrices One or more matrices containing nodal attributes AND  Sociomatrix/adjacency matrix - One or more containing relational data   Unipartite sociomatrix will be square - as many rows and columns as there are respondents  This will be symmetric along the main diagonal for undirected networks For directed networks, the bottom and top diagonals will store information for the different directions   Rows of sociomatrices should be kept in the same order as, and linkable to, the aattribute data  Use IDs     Edgelist - two-column matrix, with each row identifying a pair of nodes in a relationship     Data Analysis  As with other methods, it is always good to have a priori hypotheses before data collection Exploratory Data Analysis  SNA affords visualisation of networks in the form of sociographs  These offer a lot of qualitative information about the network   Visualising the network  Qualitative analysis is aided by representing relational and nodal attributes using  Colours Shapes Sizes     Investigating network and vertex measures  Using measures such as density, triad censuses, and transitivity can help shed light on the network structure Can look at degree distribution     Ties as predictors of outcomes  Use network/vertex measures as predictors of outcome variables  This cannot be done in the usual ways in SNA since independence of observations cannot be assumed One way of dealing with this is to use the permutation correlation test  Create large distribution of correlations by randomly sampling values of one variable and pairing them randomly to a value of the other variable Statistical significance of the observed value can be tested against this distribution       More sophisticated models  Other methods also exist for SNA  Specific models for network structure (e.g. Small-world networks) and their implications Identifying endogenous clusters in networks (e.g. Study group) that are not reducible to exogenous variables (e.g. Major/lab group) More general approaches for specifying competing models of network structure have emerged based on maximum likelihood          ",13,10,3,4
"1277","Why Students Should Own Their Educational Data","Young (2014): Why Students Should Own Their Own Educational Data    Interview with L. Todd Rose, Educational Neuroscientist at Harvard GSE The problem with the concept of the average learner  Population studies, which provide indicators of central tendency like the mean and median (i.e. Averages), are often unable to say anything meaningful about any individual in the group In areas of research like medicine, where big data has to reconcile with individual nuance, the approach to data is more towards individual patterns instead of aggregate data  This has led to discovery/acknowledgement of different manifestations/pathways of disease that result in more effective treatments tailored to each pathway     Aggregate Data and Learning   In the past, without enough data, we had to use aggregate data - drawing inferences about a population from a sample However, it is more effective to look for personal patterns that can potentially provide personalised learning  This is now possible with more data Can look at variations in an individual's learning across contexts     MOOCs  MOOCs have forced a conversation in Higher Ed - what value do 4-year colleges really provide? However, they are a long way from transforming education with personalised learning  MOOCs are still an immature field, without interoperability capability or format standards To succeed, providers need to be able to build individual, contextualised profiles of learners and what kind of support would serve them best across contexts     ",7,1,6,2
"1278","Knowledge tracing: Modeling the acquisition of procedural knowledge","Corbett &amp; Anderson (1994): Knowledge Tracing: Modelling the Acquisition of Procedural Knowledge  Paper describes knowledge change as students engage with ACT Programming Tutor (APT)  APT builds a ideal student model based on production rules to solve problems alongside students and provide assistance Tutor also performs knowledge tracing to assess probability that student has mastered a skill in the ideal model   Mastery learning  Core idea is that all students can achieve mastery in a domain if  The domain is appropriately analysed into a hierarchy of component skills Learning experiences are structured so prerequisite skills are mastered before tackling higher skills in a knowledge hierarchy   Influential in American education in the 1970s Wide support in reviews, though effects tended to be smaller than predicted   ACT Programming Tutor (APT)  Students write programs in LISP, Prolog, or Pascal Based on the ideal student model, which enables model tracing to interpret student actions  This is a set of production rules built into the tutor Enables the tutor to attempt problems alongside the student At each step, student actions are compared against the model to move on to the next step (coherence between model and action) or provide a hint (no rule for student action in model) Skill mastery assessed based on p(student knows the production rule in the ideal model) Knowledge Tracing as this estimate for each rules in the model     Cognitive Model - ACT-R  Distinction between declarative and procedural knowledge Procedural Knowledge is goal oriented and mediates problem solving behaviour  In ACT-R, represented as production rules   Practice strengthens declarative and procedural knowledge, such that subsequent performance is faster and more reliable   Support for ACT-R procedural knowledge assumptions - that procedural knowledge is representable by production rules  Systematic learning curves observed across problems mapped to the same production rule  This is not seen as clearly for other skill mappings like exercises or problem-solving goals   Production rule analysis has been successful for predicting transfer between programming languages and text editors Evidence suggests that procedural knowledge is goal-specific  Use-specificity (no transfer) of procedural knowledge for different goals despite mapping onto the same declarative knowledge By contrast declarative knowledge is goal-independent     Knowledge Tracing and Mastery Learning  Knowledge Tracing and model tracing are not the same thing  Model Tracing - follow student through task step-by-step to provide feedback Knowledge Tracing - monitor changing knowledge state during practice   Knowledge Tracing assumes a two state learning model - unlearned or learned  No forgetting, can only go from unlearned to learned 2 learning parameters  Initial learning - P(rule learned prior to first opportunity to practice) Acquisition - P(unlearned to learned)   2 Performance parameters  Guess - P(correct | unlearned) Slip - P(incorrect | learned)   P(Learned) calculated with reference to these parameters and the evidence at practice (correct/incorrect) in a Bayesian framework  Hence practice and assessment are concurrent   Knowledge Tracing used to implement mastery learning  Student reads text, then practices a skill until reaching p(learned) = 0.95, then moves on to next skill       Empirical Evaluation of Knowledge Tracing  Usefulness of knowledge tracing is dependent on validity of the ideal student model  Internal validity in modelling actual student behaviour External validity in predicting test performance Knowledge tracing is useful only if it can predict students' performance when they are working on their own   4 studies, 3 on external validity  All use first chapter of LISP tutor on lists, symbols (seems like objects), and functions   Internal validity - predicting tutor performance  Use knowledge tracing model to predict p(correct action), averaged across students Compare to actual p(correct) averaged across students Exclude remedial exercises from analysis since they are different across students - only required exercises are taken 3 metrics  Correlation between actual and predicted accuracy across goals Mean error in prediction across goals Mean absolute error in prediction across goals   Corbett &amp; Anderson (1993)  R = 0.85, mean error = 0.01, mean absolute error = 0.07 Found that some rules were to general for some students, and were not well fit by the model  E.g. rule for setting parameters for each argument - pattern suggests that many students failed to generalise when number of arguments increased from 1 to many   Model better represents data when rule is split into two - declare one variable for the first argument, and an additional variable for each additional argument     External validity - predicting test performance  Can the model predict student independent performance once they have achieved mastery Differs from Internal validity assessment in two ways  Unit of analysis is the whole exercise rather than individual goals Interested in between student rather than between programming task differences   Calculate p(correct) across exercises and actual p(correct)  Calculate correlation, mean error, and mean absolute error across students between these measures   Corbett, Anderson, O'Brien (1995)  Validated internal validity as above - r = 0.75, mean error = 0.01, mean absolute error = 0.07 External validity - r = 0.69 for intermediate level test Predictions for earlier tests on basic concepts questionable  Model suggested that all students are in the same learning state for both tests, with differences attributed to random noise  But there was high variability in supplementary exercises, suggesting otherwise Correlation of tutor errors and test accuracy for 2nd test (of basic concepts) is problematic  Model indicates that there are no differences after remediation However, for both basic and intermediate concepts, worse performance on the tutor exercises tended to accompany worse test performance, despite tutor remediation     Individual Differences in Learning and Performance  Corbett, Anderson, O'Brien (1995) did not reflect individual differences among students in learning and performance  Tended to underestimate learning and performance for above-average students and overestimate learning and performance for below-average students   When individual differences among students was incorporated using individual difference weights, correlation between actual and expected accuracy for test 2 became reliable at r = 0.51       Corbett et al. (1994) dynamic estimation of individual differences  Same material as Corbett, Anderson &amp; O'Brien (1995) Students' error rate on required exercises used to estimate student-specific learning and performance weights using regression equations and weighted parameter estimates Correlation between actual and predicted accuracy  - r = 0.79, p &lt; 0.001 Mean error in prediction - 0.001 Mean absolute error in prediction across goals - 0.06 First and third test results similar to experiment 2 Test 2 negative correlation between post-test two performance and error rate persists at r = -0.63  Suggests that there are genuine individual differences despite students nominally working 'to mastery'  Difference unlikely to be due to mastery, since the permitted variation in p(learned) is only between 0.95 to 1.0, which is too small to produce such a strong correlation Likely due to individual differences in the slip parameter (p(mistake | learned))       Experiment 4  Difference from experiments 2 and 3 - students worked to mastery for all tests, rather than just test 3 Correlation between actual and predicted accuracy  - r = 0.791, p &lt; 0.001 Mean error in prediction - 0.001 Mean absolute error in prediction across goals - 0.06 Aside from quality of model fit, can also ask how successful the model is in enabling students to master the curriculum based on their actual test performance  Define mastery as 90% correct on test 3 - 56% of students reached mastery performance  Contrast to students who only completed required exercises, without model's supplementary exercises - only 24% of students reached this definition of mastery   Difference is significant (p &lt; 0.05)         Future Directions  The slip parameter  As noted earlier, may explain differences in test performance despite all students supposedly learning the skill to mastery   Individual differences in slip weight may reflect pure performance effect - e.g. How careful students perform the task  Suggests that additional gains may be observed by increasing the incentive to perform well on the task   Another possibility is that there are true learning state differences reflected in individual differences in the slip parameter  ACT-R model prescribes that each production rule has a strength parameter that increases with practice, influencing the speed and reliability of the rule triggering when the needed condition is encountered The approximation of the BKT framework to ACT-R does not include this strength parameter - it may have surfaced within the slip parameter   A third possibility is that the differences in the slip parameter may reflect differences in students' acquired production rules  Students who form a rule that is highly correlated with the ideal rule may appear to know the ideal rule, but slip from time to time If this is true, additional practice may not have a pronounced impact on test performance To uncover this, would need to monitor students' rules more closely, and make sure their declarative concepts are correct prior to practice           ",40,22,18,3
"1279","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","   Siemens &amp; Baker (2010): Learning Analytics and Educational Data Mining: Towards Communication and Collaboration  Abstract/Summary  Learners' use of new educational media and the big data it brings, combined with advances in computation has potential to help improve learning  Growing interest in data and analytics in education, teaching and learning Greater priority for research into the models, methods, technologies, and impact of analytics in education   Existing research in this area comes from two communities  Educational Data Mining (EDM) Learning Analytics and Knowledge (LAK)   Aim of paper: Argue for increased communication and collaboration between EDM and LAK communities  Increase opportunities for creativity and advancement Increase friendly competition that will benefit both fields Increase their collective capacity to influence non-academic research and practice     Educational Data Mining  Interdisciplinary community of computer scientists, learning scientists, psychometricians, and other researchers 1st Workshop in 2005 Followed quickly by annual conferences 1st publication of Journal of Educational Data Mining in 2009, 1st handbook in 2010 International Educational Data Mining Society (IEDMS) started in 2011   Learning Analytics and Knowledge  Conference in 2010, emphasising bridging computer science and sociology/psychology of learning  Proceedings published in ACM - suggests interest in interdisciplinary approach to analytics in learning   Society for Learning Analytics (SoLAR) formed in 2011   Broad Similarities between the Communities  Both communities reflect the emergence of data-intensive approaches to education  Includes use of data to support the design and running of educational systems  Problem conceptualisation Intervention - Planning and Decision-making Assessment     Both communities seek to improve the quality of analysis of large-scale educational data, supporting research and practice Similar researcher and data skill sets used in both communities   Broad Distinctions between the Communities  Knowledge Discovery  Both communities may use automated discovery, human judgement (through visualisation and other methods), or both EDM emphasises automated discovery - use human judgement to create labels for classification LAK emphasises human judgement - use automated discovery to support final human judgements   Adaptation and Personalisation  Related to difference in emphasis in knowledge discovery In EDM, models more often serve as the basis for more automated adaptation LAK models are intended to support human judgement   Holistic and Reductionistic Frameworks  EDM research tends to reduce phenomena to individual components, find relationships between them LAK emphasises holistic understanding of systems   Origins of researchers  EDM - Origins in educational software and student modelling  Significant community interested in predicting course outcomes   LAK - Origins in semantic web, intelligent curriculum, outcome prediction, systemic interventions   Preferred Methods  EDM - Bayesian modelling, classification, clustering, relationship mining, discovery with models, visualisation LAK - Social Network analysis, sentiment analysis, influence analytics, discourse analytics, learner success prediction, concept analysis, sensemaking models     Why collaboration?  Collaboration creates more opportunities for creativity and advancement  While there are different emphases and traditions, methods and issues at play in both are important for long-term success of both fields   Friendly competition will benefit both fields' advancement, but this can only happen with open communication between the communities Interaction between communities may improve their ability to influence non-academic research and practice by jointly establishing and disseminating quality standards   SoLAR and IEDMS should formalise approaches to disseminate research and establish/grow cross-community ties  This will preserve each communities' research tradition while increasing collaborative opportunities to reap their fruits          ",10,1,9,2
"1280","Evaluating Machine Learning Models","Zheng (2015):  Evaluating Machine Learning models    Different metrics for different tasks  Different for supervised and unsupervised learning Often different for classification, regression, ranking, clustering, topic modelling, etc. Some can be used for multiple tasks - e.g. Precision and recall   Classification Metrics  Classification models aim to predict class labels given input data  Binary classification - two possible output classes Multi-class classification - More than 2 possible classes   Accuracy  How often the classifier makes the correct prediction # Correct predictions/Total predictions Makes no distinction between classes - correct answers for any label are treated equally   Confusion Matrix  Accuracy may be insufficient if the costs of misclassification for positives and negatives are unequal Confusion matrix shows a more detailed breakdown of correct and incorrect classifications for each class Rows - ground truth labels/labels from data Columns - model/predicted labels           Predicted A   Predicted B     Actual A   True A (Positive)   False Negative     Actual B   False Positive   True B (Negative)         Average per-class Accuracy  Per-class accuracy - accuracy for each class Mean(TP/(TP + FN), TN/(FP + TN)) Will differ from accuracy when classes are imbalanced (different numbers of instances per class)  Better than accuracy at dealing with class imbalances   Problems  Taking average of all classes obscures measurement of individual classes When there are few examples of one class, there is high variance in test statistics for that class, including per-class accuracy  Hence lower reliability in these metrics       Logarithmic Loss (Log-loss)  Deals with probability of label rather than predicted label itself 'Soft' measure of accuracy that incorporates this idea of probabilistic confidence Mean(yi log pi + (1 - yi) log(1-pi)  Where yi is the true label and pi is the probability of label as predicted by the model   Intimately tied to information theory  Log-loss is the cross entropy between the distribution of true labels and predictions  Cross entropy Incorporates the entropy (which measures unpredictability of something) of the true distribution with that of a different distribution Effectively, log-loss gauges the extra noise from the prediction vs the true labels     Lower log-less means better model   AUC  ROC curve shows sensitivity of classifier by plotting TP rate against FP rate for all probability thresholds for a binary classification ROCs provide many nuanced details about a classifier, but is not a quantifiable score that would be useful for a hyperparameter search like gridsearch AUC provides a summary of ROC that works across models     Ranking Metrics  Ranking returns a ranked list  Related to binary classification, and classifiers may be harnessed for the task   Precision and recall  Often used together, and also for classification tasks Precision - TP/(TP+FP)  True positives as a proportion of predicted positives   Recall - TP/(TP + FN)  True positives as a proportion of actual positives     Precision-Recall curve and F1-score  In a ranking model, a value k may be assigned - the top k ranks returned by the model If precision/recall is calculated on models that restrict predictions to the top k ranks, changing k will change the precision/recall scores  This can be plotted on a graph, like ROC   Can also summarise precision recall in a single metric - F1-score  This is the harmonic mean of precision and recall  (Precision * recall)/(precision + recall)   Tends towards the smaller of the two elements     Normalised Discount Cumulative Gain (NDCG)  In ranking models, precision and recall treat all retrieved items equally  Any item in any position is treated equally to any other item   Unlike precision and recall, NDCG favours higher ranked items Cumulative gain (CG) - Sum of relevance of the top k items Discounted  CG - Discounts items further down on the list NDCG - Normalised DCG, dividing DCG by the perfect DCG score for the scenario to get a normalised 0-1 metric     Regression Metrics  In regression tasks, the model predicts numeric outcomes RMSE/RMSD (D stands for deviation)  Square root of average squared distance between actual and predicted score (Sum of ((Observed val - predicted val) ^2)) ^ 0.5 Popular, but has problems  Sensitive to outliers, since it is a mean     Quantiles of errors  More robust to outliers than RMSE Median Absolute Percentage Error (MAPE) = median(|(yi - predicted yi)/yi|)  Gives relative measure of typical error Can also compute at 90th percentile to get an indication of almost worst case behaviour     Almost correct predictions  % of estimates that differ from the true value by no more than X%     The difference between training metrics and evaluation metrics  Sometimes a model may be trained on one prediction task and deployed for another prediction task  E.g. Classification of ratings as training, Ranking in deployment     Models should be compared against a baseline of what a 'dumb' model might achieve Data Skew  Imbalanced Classes, Outliers, Rare Data All metrics that give equal weight to each data point are more susceptible to outliers and class imbalances   ",22,18,4,5
"1281","Why Opting Out of Student Data Collection Isn’t the Solution","Leong &amp; Polonetsky (2015) Why Opting Out of Student Data Collection Isn't the Solution    When and how of parent/student opt-outs have become a focus of attention in privacy debates Fair Information Privacy Principles - basis of most privacy laws in the US and the world  Data collectors need to specify the purposes for which they are collecting data, and use of the data Consent is implied when purpose of collecting the data is obvious, and the primary reason for collecting the data More permission is needed for unrelated uses   How Data Collection Helps Students  Schools need to collect student information to function - collect grades, eligibility for subsidised lunches, and special needs  Consent might be cumbersome as it would prevent schools from performing basic services   Aside from that, there is the use of data to understand how students perform over time, how well the system is doing, etc.  Opting out of these use cases prevents schools and education systems from evaluating and improving their services     When to Opt-out  Student data use for non-educational purposes Uses beyond basic educational permission  Anything with sensitive information, marketing, or publicising data should require some sort of informed consent     Why Opting Out Isn't the Solution  Debates over opting-out are often mired in argument that have little to do with privacy - people may want to opt-out when they  Don't trust vendors with data Object to school practices Have concerns over state/federal policies, and want more choices   In these cases, opt-outs are used as a form of protest, and are not constructive for the broader education policy/provision efforts that need to address problems for all students, not just the vocal minority   Policymakers for student data privacy rules need to consider  Privacy rights of parents and children Expectations of parents that teachers and administrators have access to the data needed to make decisions regarding the educational system   ",5,5,0,2
"1282","Why Is Measuring Learning So Difficult?","Difficulties with measuring learning  Learning is  Complex Multidimensional Often context dependent Personal Variable across cultures, societies Implicit and Explicit   Measurement is reductive  Learning as a phenomenon cannot be fully encompassed with psychometric methods   In many disciplines, no clear metrics for quality, let alone change in quality, of knowledge No proxy metrics of learning that provide high reliability + validity Hard to get information on previous knowledge to assess knowledge gain High variability in learner profiles ",2,2,0,5
"1283","Saturday Morning Breakfast Cereal","SMBC 3978   (See Stats notes on Correlation != Causation) We believe and take action on stories that we find compelling, which has problems - among other things, this gave us those infant brain training cons (an increase in sensory stimuli as an infant causes an increase in brain function/IQ/whatever). Thankfully, I couldn't think of many other examples of this. More dangerous though, is the fetishisation of metrics as equivalent to the measured attribute (here that clock assembly skill = future success in an engineering career). This is in far more places, with many dangerous consequences.  GDP = Societal Happiness Stock Price = Company Strength PISA score = Educational Quality (there, I said it)  However, it is a difficult problem to solve. Even basic statistical thinking is difficult. it is also unintuitive even for those with the requisite training, especially in contexts where it typically is not applied (at the dinner table). Furthermore, statistical thinking is just one item in a long list of important things that humans need to get educated on (basic first aid/CPR, your legal rights, basic medical terminology, what's in those T&amp;Cs that you agreed to). So I don't think we're ever going to have an ""ideal solution"" where everyone is talking about covariances and statistical assumptions at dinner tables (which would also be quite sad, and a dystopian environment that might be worth exploring in an XKCD/SMBC strip). Bullshit will persist in society. The most we can do is ensure that journalists and policymakers have basic statistical literacy, and colleagues who can provide more detail on what's going on and ensure they have the right idea. I think we're already pretty close to that state, and so we aren't doing that bad",5,9,-4,2
"1284","Data wranglers: human interpreters to help close the feedback loop","Chow (2014): Data Wranglers: Human Interpreters to Help Close the Feedback Loop  Learning Analytics involves a feedback loop  Data on learners and learning --&gt; 'Actionable intelligence' --&gt; Interventions   Previous literature in LA has emphasised multidisciplinary teams, with humans playing a key role in  Sense-making/Interpretation of the data Mediate the information for decision makers Sense making and social processes are important because the data is complex and learning is a complex social activity Sense-making of data analytics are best effected through institution wide efforts with the following thought out  Institutional support for academic staff for design and interpretation of analytics, and the development of a culture of data uuse for increasing organisational capacity     Single and Double Loop Learning  Single loop learning - use of LA to achieve set goals Double loop learning - Single loop learning, + Goals can be challenged and developed through LA   Case Study: Data Wrangling in Open University UK  OU is a distance-learning university with 250,000 students studying largely part-time Deal largely with electronic data Large student body required centralisation and administrative systems that removed academics (who had to take action to improve the programmes) from the data  Data wrangling project started to bridge this gap, ensuring that data being collected was interpreted and turned into actionalble insight   Data Wranglers  Academics themselves who had backgrounds similar to the faculties they were attached with Data Wranglers develop an understanding of the situation and needs of the faculty, build relationships with key stakeholders, and adapt their reports to be valuable to the faculty  They als oseek opportunities to engage with the academics to support the use of the data   The Data Wranglers also support learning design, given the high synergy between learning design and analytics  Learning design can provide an account of pedagogical goals that contextualise the interpretation of data, while LA can also provide useful insight that underpins the process of Learning Design   Accessed 4 main data sources  Post-course survey feedback from students Activity from LMS (Moodle) Delivery data about mode of delivery and course structure (e.g. Which courses use forums) Aggregated completion, pass rate, and demographic data   The academics could also access the data directly themselves  Aside from helping to analyse the data, the data wranglers thus served to familiarise academics with using the data and develop a community of practice in LA  The end goal was for the data wranglers to support LA efforts, but also for academics to access the data themselves       Evaluation of their work  Hard metrics of their value are not really available - metrics like student retention, completion, etc. are affected by other factors like student demographics and policy changes Anecdotally  There are some positive examples of the data wranglers' contributions Subjectively it also appears that faculty members' direct use of the data had improved, though there was no log data to back this up   An internal evaluation was carried out by obtaining feedback from report recepients and other stakeholders via email and face-to-face discussions  Feedback was generally positive  Some mentioned that the reports stimulating productive reflection and discussion Another theme was that the reports should include more fine grained data, more data sources, more historical data, and more data related to new OU processes and systems   Less positive feedback  Inconsistency of processes between faculties  Variation in naalysis and recommendations provided, and the quality of conversation between data wranglers and faculty members   Data quality was sometimes poor, and resulted in misinterpretation, poor quality and resolution of delivered data  However, this could be seen as positive for the data wranglers, since this issue was not known when the data wasn't being used, and has only emerged once attempts were made to use the data Raising this issue starts a conversation about data and how it can be improved and integrated into processes - key to double-loop learning This issue illustrates the value of sense-making activity - only by trying to make sense of data can you realise that it might not make sense, and begin to identify steps to make sure data delivered makes sense       In general, the approach had a high time cost, but yielded better understanding of data use that drove further developments in an institutional analytics strategy in a bottom-up fashion     ",12,5,7,1
"1285","Zuckerberg is ploughing billions into 'personalised learning' – why?","Kucirkova &amp; Fitzgerald (2015): Zuckerberg is Ploughing Billions into 'Personalised Learning' - Why?  Personalised learning  Considered ""Learner-centred or customised learning"" by some Some may see this as what all good teachers do anyway For Zuckerberg, personalised learning is teachers working with students to customise instruction to meet their needs and interests  Algorithms would have to provide users with content based on analysis of their behaviour and demonstrated interests     The dangers of personalised learning  Associated with issues of children's agency, power, collaboration, and dialogue (or lack thereof) General knowledge as a goal of education  By giving every kid only knowledge they care about, there would be many specialists but few generalists   Learners do not learn to compensate to learn in ways and paces not suited to them  This may be relevant in the real world where things are no longer personalised   Learners have changing preferences  People's interests tend to change as immediate responses to the environment Predicting content relevant to learners required sensitive, human-directed input   Privacy risks with collecting learning data   Where personalised learning can help  Motivation - personalisation gives children a sense of ownership and relevance Pitching content and delivery to students' ability to improve learning Still unclear on whether personalisation helps on these issues, and how much   A compromise approach  Combine user data with standard educational content  E.g. Course-ware platforms where teachers can choose between adaptive or customised study plans  Adaptive - topics are adapted to match a learner's pace Customised - teacher modifies the course him/herself       ",4,5,-1,2
"1286","Feature Selection","Dimensionality Reduction  Reduce the number of variables/columns to the relevant dimensions to make analysis manageable Two strategies  Feature Selection - select a subset of dimensions  Feature extraction - transform lots of dimensions into fewer dimensions   Why?  Knowledge Discovery  Interpretability and Insight - Of the features that we have in this dataset, which are the most important?  E.g. A lot of features in email, but a few matter much more in determining what is spam - sender address, whether they ask for money, etc. May realise that some things that you thought were important actually were not May also realise that some things you didn't think were important actually are     Avoid the ""curse of dimensionality""  An algorithmic problem of sparsity  Relationship between data and variables spanning fields that deal with a high number of dimensions/features/variables As you add more features, you will need exponentially more data  Hence, would be great to have less features   Expressed spatially, when you increase the number of dimensions, the volume of the space grows exponentially  Hence, the same quantity of data points is sparser as the number of dimensions increases   Combinatorically, each dimension added increases the full set of possible combinations of values that can be held by a data point  To healthily perform any form of prediction using ML, you need enough data to account for the breath of possible values - hence, you need more data Inferentially, for the same amount of data - the more dimensions we add  Less data points per box, since there are more boxes and the same amount of data points The greater the proportion of possible comparisons we will not be able to do     There are more possible comparisons as there are more variables (and hence room for variation), and hence, relatively less data to make meaningful comparisons across these variations     ",3,1,2,1
"1287","Chapter 1: Social Network Data","Hannerman &amp; Riddle (2005): Social Network Data  What's different about social network data?  Conventional social science data usually consists of a rectangular array  Rows are cases/subjects/observations Columns are scores/variables/attributes/measures - qualitative or quantitative There may be a third dimension for longitudinal data or multiple groupings Conducive for  Comparison of cases across variables - row-wise comparisons Comparing variables across cases - column-wise comparisons     Network data, in its purest form, can be expressed in a square array/adjacency matrix  Both rows and columns are cases/subjects/observations Can be analysed in the same way as social science data  Rows can be agents, and columns seen as attributes of the actors Row-wise comparisons and column-wise comparisons can illustrate in-degree/out-degree similarities/differences between cases in a directed network Correlations and distances used in conventional statistical analysis are also applied to network data   Conducive to seeing how actors are located/embedded in the network The analyst may also want to see the data holistically, to see how the pattern of individual choices gives rise to emergent patterns - e.g.  Network Density Reciprocity across the network     Major difference - Conventional social science focuses on actors and attributes while SNA focuses on actors and relations  This difference has implications on research design, sampling, measurement, and analysis  Differences in samples and populations that are studied       Network data are defined by   Actors - nodes Their relations - edges   Nodes  Populations, Samples, and Boundaries  Actors are usually not sampled independently and definitely cannot be assumed to be so, unlike in most social science research  Network studies are more likely to try to include all actors occurring within some naturally occurring boundary, rather than doing independent random sampling  Often, network studies avoid sampling to go for population data in a bounded group - e.g. Everyone in a classroom   Important to define the boundaries for the population and how to select individual units of organisation   Network analysts will often identify a population and conduct a census of all elements of the population  As opposed to survey methods, where individual elements are selected using probability  Individual cases are considered a ""replication"" of an underlying phenomenon   Actors cannot be sampled independently as relations between actors are of interest   Network analysis has diverse applications  Relations between Nation states Relations between people Relations between sounds in verbalisations   Boundaries of populations are either  Naturally occurring - neighbourhood, classroom, club, etc. Demographically/ecologically defined - geofence, ultra high-net worth individuals   Replication and hypothesis testing is conducted by replicating the study on different populations  E.g. Study several similar neighbourhoods     Modality and levels of analysis  Network designs can be described as nested  Actors are the lowest level of analysis, with the full network as the highest   Networks are multi-modal - Individual agents are embedded in networks that are embedded in networks...  Each level is a mode of analysis Data sets can be characterised by the number of modes it contains information about  However, few data sets and analyses work at more than two modes - the individual and network level - simultaneously Most try to examine these two modes separately as well   Similar to hierarchical/nested designs in traditional statistics in social science, and the levels of analysis often found in social theory       Edges  Sampling Ties  Full network methods   Appeal  Census studies will give all the ties of given types among all the nodes studied Collect information about ties between all dyads Necessary to properly define and measure many structural concepts of network analysis  E.g. Centrality     Problems  Allows powerful descriptions and analyses of social structures Expensive Difficult to collect Impossible for large groups like cities     Sometimes sample ties are collected for purposes of generalisability or cost  Snowball Sampling  Begin with focal actor or set of actors - ask them to name some/all of their ties to other actors, then contact those people Continue until   No new actors are identified Researchers decide to stop  People mentioned are marginal to the study Time/resource cost     Problems  Actors who are isolated are not located by this method No guarantee of finding all connected individuals - potential to miss sub-sets of actors that are connected, but isolated from the starting group   Problems can be mitigated by being more careful about selecting the individual nodes  E.g. Start with individuals likely to be central, like CEOs, in a study of elite networks     Ego-centric networks (with alter connections)  Contact focal nodes (egos), find their alters, then contact the alters   Use information from these nodes to determine relations in the network   Can estimate some network properties  Network density Amount of reciprocity, cliques   Problems  Cannot assess many network properties - centrality, distance, positional equivalence     Ego-centric networks (ego only)  Collect information only from focal ego Still allows pretty good picture of local networks or neighbourhoods of individuals Can give general texture of network as a whole, and potentially some information on network features and differences among actors in the network If it is reasonable to think of alters in their social roles rather than as individuals, ego-centric networks can tell us a bit about social structures Cannot infer the macro-structure and nature of the whole network       Multiple Relations  There could be different kinds of ties that connect actors in a network Positions in one set of relations may contradict or complement positions in another - colleagues may or may not be friends Usually theory and the RQ will indicate which relations take precedence for the study - use these to select the relevant relations  Systems Theory presents a conceptual approach to this problem  Distinguish between material and informational domains  Material things are conserved - a material object like money can only be at one node at a time Informational things are non-conserved - informational objects can be shared, and once shared are possessed by both parties simultaneously     Methods for working with multi-relational data are not as well developed for those used to work with single relations     Scales of measurement  Binary - exists or not  Can convert other data to binary by setting a cut-off and defining everything above/below it as a 0  This is done as many of the tools and algorithms for measuring properties of actors and networks work better with binary data     Multiple-category nominal measures  E.g. Different types of relationships Often handled by creating series of binary measures from the nominal measures - Like dummy coding Can also ignore the type of tie and simply code the response as binary   Grouped Ordinal Measures of relations  People may be asked to rate others with like/dislike/neutral Can also reflect strength of ties  Frequency of interaction Intensity of emotional arousal associated with the relationship Number of overlapping types of ties   Although ordinal data has more information than nominal data, it is frequently hard to handle ordinal data given that most of the tools deal with binary data   Full-rank ordinal measures  People may be asked to rank ties from strongest to weakest Uncommon in social network research - few methods to analyse such data Often treated as interval data although this is not necessarily true (difference between 1 and 2 might not be the same as difference between 2 and 3)   Interval measures  Easy to construct - e.g. Frequency or intensity of ties  However, it may be difficult to elicit accurate data on these variables in surveys or interviews  Often collect behavioural data instead - email frequency, phone calls, etc.   Most network analysis does not operate at the interval level even though it contains the most information  Given that most tools available work best with binary, undirected networks Used in cut-offs, but there is no perfect way of choosing a cut-off value         Statistics and Social Network Data  Unlike in much of social science, inferential statistics and generalisability is not necessarily of interest to social network research  Samples are not drawn using probability methods, so generalisability is difficult anyway   Hypothesis testing  Notion of standard error is hardly observed in social network research given that there is usually only one network, with no replications  SE can be estimated, but without independence of observations sampling variability will likely be underestimated   Hypothesis testing is thus often conducted using simulation  Simulate alternative network structures between the nodes by randomising connections Then comparing the likelihood of the given network structure compared to all the random structures This is not too different from traditional statistical analysis - sort of like conducting a one-sample t-test       ",24,16,8,4
"1288","RStudio Cheat Sheets","R Markdown  Works in a R markdown (.Rmd) document  Supports markdown formatting outside of code chunks   Markdown tips  # - Headers  Use more hashes for smaller headers   ** Bold ** *Italic*       &gt; - Block quote Support for latex is included - embed latex in $$ $$ * - lists  + - Sub-items in list     YAML header  The portion at the top of the document between  --- --- Include information on   Title Author Date Publishing information (output format)       Knitr syntax  Tells the code what to do in the chunk In the curly brackets at the start of each chunk engine - the language you want to run in  {r} runs in R - this is almost always what we want   eval - Run the code in the chunk  Defaults to TRUE If FALSE  Skipped over during knitting and when asked to run all code You have to manually run it by going to the chunk and hitting run     echo - display code chunk that produced the output in the knitted document  Defaults to TRUE, but may want to disable to communicate with non code users     Shortcuts   Ctrl + Alt + I - create new code chunk Ctrl + Shift + Enter - Run current chunk Ctrl + Enter - Run current line Ctrl + Alt + P - Run all chunks above Ctrl + Alt + R - Run all   Knitting and Previewing  Output file will be the first one in the YAML header Knitting runs all the code to produce an output file  Preview produces a .nb.html file - for R notebook output files  It will not run the code but use the most recent output chunks available Must run the code before previewing     ; Tidyverse  Use skimr:skim() to get a nice summary of the dataset - tells you if there are missing values and descriptive statistics The Core Tidyverse  ggplot2 (graphics) tibble (data frames and tables) tidyr (make tidy) readr (read in tabular formats) purrr (functional programming) dplyr (manipulate data)   In R, the tidyverse is your friend for data wrangling  Pipes %&gt;%  Take whatever comes before the pipe and pass it as the first argument to what comes after the pipe E.g. My_dataframe %&gt;% filter(year ==2007) is the same as filter(My_dataframe, year == 2007) Pipes make things easier to read   dplyr::  View  Print tibbles to view them, but stuff that don't fit on the screen will be cut off Use dplyr::glimpse() to get a summary   Subset  Splitting Data Frames  Use dplyr::filter() to filter only to the data that you want  Can use logical operators - | and &amp; to chain together logical statements Can use anything that gives a boolean as the argument (e.g. Use !is.na(variableName) to get rid of NAs)   Use dplyr:: group_by() to group data according to a particular variable Use dplyr::select() to select columns in the dataset  Also can rename columns by using ""New Name"" = ""Old Name"" Instead of specifying all columns you want to select, you can also select variables based on their names - can use RegEx to describe names for flexibility  starts_with(): starts with a prefix ends_with(): ends with a prefix contains(): contains a literal string matches(): matches a regular expression num_range(): a numerical range like x01, x02, x03. one_of(): variables in character vector. everything(): all variables.         Arranging (Sorting in excel)  Use dplyr::arrange(variableName) - this sorts data by the value in their columns  Defaults to ascending order. Use arrange(desc(variableName)) to get descending order     Variable Generation  Create a new variable from current variables Use dplyr::mutate() to transform data and add it as a new column into the data.frame/tibble   Summarise  Collapse data into a limited number of values according to functions (e.g. Calculating averages) Use dplyr::summarize() to generate summary statistics  Can pass arguments to get measures of central tendency and distribution  Center: mean(), median() Spread: sd(), IQR() Range: min(), max(), quantile() Position: first(), last(), nth() Count: n(), n_distinct() Logical: any(), all()       Counting  Use dplyr::distinct() and dplyr::count()     tidyr::  Package focused on reshaping the layout of dataframes Tidy data  Each variable should have its own column. Each observation of that variable should be in its own row One table for each ""kind"" of variable (e.g. data on finance and health) Multiple tables should have an identifier column to let you join them together.   Tidy data makes it easier to  Manipulate into different forms Join with other tidy data Visualise Load into databases   Essentially, tidying data is similar to generating pivot tables Long format &lt;--&gt; Wide format  Spread - long to wide  tidyr::spread() accepts  Dataframe - the dataframe that the function will work on Key: The column that contains the variable names (the new column names) Value - the column whose values will populate the cells in the new columns Fill -  If there isn't a value for every combination of the other variables and the key column, this value will be substituted Convert - if TRUE will automatically convert values to logical, integer, numeric, complex or factor as appropriate     Gather - wide to long  tidyr::gather()  Dataframe Key - the new column that the reshape will be based on  The name of the variable whose values form the column names   Value - the new column to store the values that will be generated for the new data frame  The name of the variable whose values are spread over the cells   gather_cols: the columns that are reshaped to accommodate the new structure table4a %&gt;%   gather(`1999`, `2000`, key = ""year"", value = ""cases"")       Splitting and combining data into multiple/single columns (variables)  Use tidyr::separate() to split columns  By default, it separates based on any alphanumeric character, but you can also specify what the separator is   Use tidyr::unite() to merge columns       Combine and Splitting  Merge and bind or split datasets     ",13,8,5,1
"1289","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","San Pedro et al. (2013): Predicting college enrollment from student interaction with an intelligent tutoring system in middle school  Developed ASSISTment system to predict if students will attend college from middle school educational software use  Financial resources, family background, career aspirations, and academic ability are indicative of college attendance  However, they may not give enough actionable information for instructors or guidance counsellors to intervene for individual students Middle schoolers often think about going to college but fail to get assistance in planning     Middle School and College attendance  Process of choosing to attend college may start to solidify around Middle School in the US Developing self perception based on academic experiences, interests, beliefs, goals/actions influence students' seeking out and planning for higher education Students may find themselves engaged or disengaged from school and learning at around middle school  They either start to value academic achievement or go off track, becoming frustrated and disengaged in school Disengagement leads to negative attitudes about higher education and poorer learning that has implications in high school such as dropping out Students who have already made college plans are more likely to attend college despite challenges  Tend to have plans to take the appropriate high school courses, get involved in activities that will boost their application, etc.     Past research has tended to identify changes in student engagement using strong indicators of disengagement  Failing grades Problem behaviours in school like violence Truancy It is likely that once these behaviours show, intervention could be too late  Beneficial to identify useful and actionable antecedents to intervene earlier and more effectively       Method  ASSISTment System  Free web-based tutoring system for middle school mathematics Assesses knowledge while assisting learning  Mapping of each problem to skills Scaffolding problems to scaffold students in solving a question they got wrong Multi-level hints, with the last level just being the answer with an explanation Feedback on incorrect answers   Provides teachers with detailed reports on student knowledge   Data  N = 3747 students from 3 New England middle school districts who used the system between 2004-2009 College enrolment status (yes/no) of the students was drawn from the National Student Clearinghouse   Creation of model features  Student knowledge features computed using BKT  BKT is used in several ITSs to estimate students' latent knowledge based on their observable performance Model can tell if the student's current skill exceeds current difficulty,  vice versa, or if they're equal Fit BKT parameters using ASSISTment data through brute force grid search   Affect and Behaviour features  Used detectors of student affect and engaged/disengaged behaviour derived from ASSISTMent measures from previous study  Developed detectors indicators in two-stage process  Obtain affect labels from observing students Train/test ASSISTments data to predict affect labels, and use the best models as the detectors     Measured engaged concentration, boredom, and confusion  Detectors were better than chance, but not that great     Carelessness Detection  Created a model designed to assess slips using BKT  P(slip) is assessed depending on the context of the student error BKT used as baseline model to estimate P(slip) - used BKT estimate of whether the student knew the skill at each step Refined p(slip) using Bayesian equations using student performance on successive opportunities to apply the rule From this a linear regression model that can predict slips contextually is generated   6-fold CV of model trained with ASSISTments data showed r = 0.458 on average     Logistic regression  Using these features as predictors, a multi-predictor logistic regression was fit to predict whether students would enrol in college Odds ratio  ""Odds ratio in logistic regression is the odds of an event occurring given a particular predictor, divided by the odds of an event occurring given the absence of that particular predictor"" Odds ratio &gt; 1.0 - predictor's presence increases the odds of the dependent variable occurring Odds ratio &lt; 1.0 - predictor's presence decreases the odds of the dependent variable occurring       Results  Group comparisons  College vs no college Higher average knowledge estimate, average correct, number of first actions, average engaged concentration, average slips/carelessness had higher mean values for students who attended college Average boredom, confusion, off-task, and gaming (the system) had higher means for those who did not attend college In all cases except average off-task,  group differences measured using a T-test was statistically significant (p &lt; .01)   Logistic regression  Positive relationships between college enrolment and   Average correct answers Student knowledge estimate Engaged concentration Use of ASSISTments Carelessness   Negative relationships between college enrolment and  Boredom Confusion Gaming the system   Model using all features and data, without CV, achieved A' = 0.686 and Kappa = 0.239  Statistically significantly better than a null model   Model using only statistically significant predictors, without CV, achieve A' = 0.686 and Kappa - 0.247  Also statistically significantly better than a null model More parsimonious and interpretable than full model In this model, boredom was positively correlated with college attendance after controlling for student knowledge, software use, and other forms of disengagement  May be because these controlled for unsuccessful bored students, leaving just the students who were bored because of ceiling effect   Carelessness was also negatively related to college attendance once other factors were controlled  This makes sense, unlike before where carelessness was positively related to college attendance         Discussion and conclusion  A lot of other social and external factors not in the model - financial reasons, parental support, school support However, the model accounts for an important factor - students' ability and engagement  Model can distinguish between students who will and will not enrol in college 68.6% of the time   Model supports existing theories about indicators of college enrolment (academic achievement is important) Also provides more actionable insights for interventions by teachers and guidance counsellors  Should address negative affect and disengagement when noticed More guidance to students who feel confused Try to engage bored students more Give students who game the system more opportunities to learn material   Future research  Including additional possible interaction features in the model Use other classifiers  Although while other models like SVM or decision trees may have done better than logistic regression, interpretability would suffer   Refine design considerations for educational software to promote college interest and readiness in middle schoolers     ",28,40,-12,3
"1290","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Greller &amp; Drachsler (2012) Translating Learning into Numbers: A Generic Framework for Learning Analytics  The increased availability of educational data suggests that Learning Analytics has the potential to improve understanding and prediction of learning needs and performance However, we still do not know the processes and requirements needed for learning analytics to yield these benefits Outline  Propose a design framework that may serve as a guide for setting up learning analytics services to support educational practice and learner guidance in the following aspects  Quality assurance Curriculum development Teaching effectiveness and efficiency   Also propose barriers and limitations of LA, privacy and ethics   Data + Information retrieval technology can offer personalised data products targeted at individual users  In education, the aim is to achieve improvements in quality while reducing delivery costs  Quality includes  Effectiveness and efficiency in learning experiences, competence development Collaborative experiences       Growth in data mining/analytics today (including education) driven by  Cost - Data collection becoming more affordable Authenticity of data - data collected is synonymous to regular user behaviour, rather than apart from it  This will enhance understanding in addition to questionnaires/surveys May also highlight inconsistencies between user behaviour and perception   Scope - population/individual level rather than sampling Automation   While there are now many interactive learning environments, LMSs, ITSs, e-portfolio systems, and personal learning environments which automatically track user data, the use of that data to inform teaching and learning remains underutilised  Possible applications include  Evaluation of learning theories Learner feedback and support Early warning systems Learning technology Development of future learning applications     Critical dimensions of Learning Analytics  Soft vs Hard issues distinction  Soft - challenges that depend on assumptions about humans or society (e.g. Ethics, competencies)  Softer issues - acceptance and impact of learning analytics  Data Ownership and Openness Ethical use, dangers of abuse Demand for new key competencies to interpret and act on LA results     Hard - data/fact related challenges, aside from people/society  Hard research issues  Compatibility of educational datasets for research Comparability and adequacy of algorithmic and technological approaches to educational research         Proposed Design Framework for Learning Analytics  Formed based on literature review and clustering analysis of papers in LA/EDM, discussions in academic groups, which were then evaluated by commercial and academic experts Stakeholders  Includes data clients and data subjects  Data clients - beneficiaries of the LA process, who are entitled and meant to act on the outcome (E.g. Learners, Teachers, Researchers, Educational Institutions) Data Subjects - the suppliers of data, normally through their browsing and interaction behaviour (E.g. Learners)   Information flow between stakeholders typically follows a hierarchical structure  Students --&gt; Teachers --&gt; Institution LA also affords self-reflection at each level of data client, using data made available However, hierarchy is not the only way information can flow - peer relationships are also possible, as in peer review or peer evaluations   Opportunities for different stakeholder groups  Students  Specific learning process and reflection visualisations comparing their performance to peers Personalised recommendations for learning resources, learning paths, or peers to collaborate with       Objectives  Main opportunity for LA is to unveil and contextualise otherwise hidden information from educational data, and prepare it for different stakeholders Two different objectives  Reflection  Critical self-evaluation of a data client based on data, to gain self-knowledge/knowledge about the data client  E.g. Student learning about him/herself from the data, or teacher learning about his/her students from the data   LA as support technology for decision making processes   Prediction  Predicting and modelling learner activities  Enables earlier intervention, building adaptive services/curricula E.g. ML techniques to build learner profiles   Limitations  Prediction runs into ethical problems as judgements about a person are inevitably based on limited parameters that could limit a learner's potential The diversity of learning also makes it difficult to judge which learning activity was beneficial to a learner, and when in the process it was beneficial, let alone whether that activity will benefit others       Relation to pedagogic theory  LA neither supports nor ignores specific pedagogic theories - in itself it is pedagogically neutral  However, LA can be used to evaluate different pedagogic strategies and their effects on learning and teaching Certain technologies are also not pedagogically neutral, influencing the analysis process       Educational Data  Schools already possess large amounts of student data, used for different purposes  Reporting and administering student progress   Learning management systems complement the availability of school data Linking available datasets can facilitate more learner-oriented services, and improve personalisation LA relies strongly on learner data, which is an obstacles on LA as much of these are protected  More data is becoming available through anonymisation   Data protection challenges  Distinguishing educational data by access rights is complicated by a particular quirk in education where data is heavily protected rather than immediately owned by the service provider (everywhere else in tech) Technical systems are typically owned by the institution, but unlike in most other industries, they often do not own the data Students, different types of employees of the provider and other stakeholders, may have differing access rights - this is still an unresolved issue This constrains inner-institutional research or wider institutional use of data   LA datasets create new technical challenges for research and practice  Lack of common dataset formats Need for version control and a common reference system Methods to anonymise and pre-process data according to privacy and legal protection rights Standardised documentation of datasets to make it usable by others Data policies regulating using and sharing of data   Other challenges  Messy data - e.g. test accounts Enmeshed identities - datasets cannot distinguish between individuals and shared presences (e.g. Groupwork on one computer) Formulating indicators from available data that can be used to evaluate the learning process     Instruments  Conceptual instruments - Ways of approaching the data  E.g. Theoretical constructs, weightings, algorithms   Technical instruments - Information retrieval and processing technologies  ML, EDM, NLP, SNA, Classical statistical analysis   All instruments are reductive by nature, and will result in different outcomes even when used with the same data  Designers and developers must understand the consequences of decision making based on these outcomes     External Constraints on application of LA  Conventions - should follow  Social Ethics Managerial Process   Norms - Must follow  Legal Organisational   Idea of informed consent is threatened given the dramatic increase in ambient data collection - people might not be aware that data is being gathered on them in every moment that it is being gathered In education, separation between student information (registration data kept by admin staff) and educational data (kept by educational staff) prevents maximal use of LA Ethical risks  Exploitation of data for commercial and similar purposes Data surveillance - social sorting, cumulative disadvantages, digital stalking     Internal Constraints on application of LA  Competences  For LA to be effective for educational practice, data clients must have the necessary interpretation skills to reap the benefits of the data presented   Acceptance  Data clients must accept the value of insights that can be drawn from LA - they are of no use if they are immediately dismissed     The Place of Pedagogy in the LA framework  More empirical evidence is needed to identify which pedagogic theories LA serves best LA has been found effective for behaviourist-instructivist approaches, but have not really been found useful for constructivist approaches (where learning is seen as an active cognitive process where learners construct their own concepts about the world around them) In this model, no specific learning theory is upheld - pedagogies are seen through the data  Pedagogies are not in the analytic process, but embedded implicitly within the data through the pedagogic behaviour of students in the learning situation Pedagogy can be explicitly addressed in the goals and objectives that the LA designer sets       ; In this semester, I would like to become a more precise programmer.   I can count towards this goal by counting the number of 'stupid bugs' (defined as bugs which I end up fixing while thinking 'that was dumb, should never have done that') in my code, divided by total number of lines written in each assignment.   From this, I can derive meaning that I am less haphazard and more competent as a programmer, who can be relied on to deliver code that works and gives precisely what people want (which I think I can do, aside from the stupid mistakes, which is why they need to be fixed)   Action taken: I can say I met this goal at job interviews. Consider the diagram on page 44 of Greller &amp; Draschler. Which would pose problems for you to actually acquire the data you want? Write a note summarising the article in Zotero, include thoughts based on your answers to above. * Objectives - Reflection. I don't make any predictions based on this data.* Stakeholders - no issue - I am the only stakeholder* Data - Protected, but since I am the only stakeholder I don't run into any issues.* Instruments+ Theories would pose a problem since my approach is not based strongly oin any theory of learning. + Technology poses a challenge as data gathering would be tedious, requiring a manual approach since it deals with data on my psychological state.+ No algorithmic isues, will not be relying on an algorithm.* Internal Limitations and External Constraints - No external constraints since I am the only stakeholder. I think that if the data is collected well, I will accept the findings given that the analysis is pretty basic and full proof. That the analysis is basic and full proof also means that I face few internal competency limitations.",33,34,-1,1
"1291","The Big Five and Visualisations of Team Work Activity","Kay et al. (2006): The Big Five and Visualisations of Team Work Activity  Studies in CSCL have shown that the expected beneficial outcomes of teamwork often don't materialise  Studies and observations show low participation rates, levels of communication and collaboration, small knowledge gains, and little satisfaction with the group learning situation   Students need to put effort not only in the task but in teamwork in order to learn to work collaboratively  Teamwork - ""set of interrelated thoughts, actions, and feelings of each team member that are needed to function as a team, and that combine to facilitate coordinated, adaptive performance and task objectives resulting in value-added outcomes"" Big Five components of Teamwork  Team leadership   Direct and coordinate other team members' activities Assess team performance Assign tasks Develop team knowledge and skills Motivate members Plan + organise Establish positive atmosphere   Mutual performance monitoring  Develop common understandings  of team environment Accurately monitor teammates' performances   Backup behaviour  Anticipate other team members' needs through accurate knowledge about their responsibilities Shift workload among members to achieve balance during high periods of workload/pressure   Adaptability  Adjust strategies based on information gathered  Reallocating resources and backup behaviour mustered to this end     Team Orientation  Propensity to take others' behaviour into account during group interactions Belief in importance of the team goal over individual members' goals     Three coordinating mechanisms needed to fully realise the Big 5 components  Shared mental models - organising knowledge structure of the relationships among the tasks the team is engaged in, and how the team members will interact Mutual trust - that team members will perform their roles and protect the interests of their teammates Closed-loop communication - between sender and receiver     The present work aims to support online learning teams in a CSCL situation  Trace students' interaction behaviour along the Big 5 dimensions  Provide visualisations mirrored to the groups     Visualisations used  Activity Radar - how much each student is participating on the CSCL platforms  Students as dots on a radial chart, with dots closer to the centre suggesting higher participation   Interaction network  Social network graph showing relationships and flows between coloured dots (students)   Wattle Tree  Each students' activity is show in a vertical tree/timeline  Day number on the X-axis, Y-axis is students (like a bar chart) Activity points are marked along these axes, with different activities represented in different colours  Point size reflects the size of the contribution   Task assignment represented as 'leaves', lines that extend as long as the issue remains in progress       Relation of visualisations to each Big 5 factor  Leadership  Tasks on wattle graph - leader should have continuous activity, and assign many tasks Leader should have high activity on the radar, and have thick connections on network graph   Mutual performance monitoring  High level of interactions in network graph, and gaps in time between team members' actions A monitoring team should be quick to respond to each other   Backup behaviour  Good team should show distributed activity on the activity radar Wattle Tree quickly shows the distribution of tasks and activity over time - good teams should have an even spread   Adaptability  Hard to assess, but may get some clues based on pattern of activity on Wattle Tree   Team Orientation  Degree of involvement of each team member seen in Wattle Tree     Relation to Group Performance  Assessed mostly in final reports  Each group submitted a 1-2 page reflective statement Each student also submitted an independent statement   Could also look at students' products Team Leadership  Facilitate Team problem solving  Good groups showed in high team leader activity on Wattle Graph, high interaction with all group members Poor leaders had no interactions with anyone   Provide performance expectations and acceptable interaction patterns  In all groups that referred to the diagrams, the group leader was among them They were concerned with the same aspects of performance and interaction   Synchronise and combine individual team member contributions  Visible in integration of student work in some groups     Mutual Performance monitoring  Identifying mistakes and lapses in other team members' actions  Wattle Tree made these things very clear Students tended to avoid criticising each other in submissions, but patterns in the diagrams were alluded to as clear indicators of failure to contribute Some mistakes, such as doing the wrong job, were not visible in the displays     Backup behaviour and Adaptability  Recognition of workload distribution problem in the team Shifting Work to underutilised members Wattle Graph showed these patterns clearly, but they could not be dealt with immediately since visualisations were only made available at the end   Team Orientation  Showed in high activity and interaction in the most successful groups, with all members having some interactions with all the others     Conclusion - visualisations are capable of expressing various aspects of teamwork quality  Interpretations are left to the team itself, rather than providing clear metrics that currently do not exist   ",20,8,12,2
"1292","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Konstan et al. (2015): Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC  Offered an Introduction to Recommender Systems as a full-semester course   2 formats  Online through Coursera 3-credit graduate-level course at University of Minnesota  Flipped-classroom model  Used Coursera course activities Included live sessions with faculty and TAs for additional support on course material and assignments  Half of these were recorded and made available to MOOC students         2 tracks  Concepts track - required just basic math background, no programming assignments Programming track - concepts track + programming lectures and assignments   Aimed to explore MOOCs as a vehicle for delivering in-depth advanced technical content typically associated with graduate-level courses Also looked at differences in student intent and performance between concepts and programming tracks   Course Overview - Introduction to Recommender Systems  Course Objectives  Introduce students to  Core algorithmic approaches to recommendation  Non-personalised approaches Content-based filtering User- and item-based collaborative filtering Dimensionality-reduction/matrix factorisation methods Case-based reasoning Social network/trust-based recommendation   Issues related to recommender systems  Implicit and explicit ratings Rating scales Data acquisition Data validity   UI and design issues   Wanted to introduce students to wide range of perspectives - invited experts for interviews in areas of their expertise or on systems they built   Course Format  Faculty encouraged designers to explore MOOCs  Explore how MOOCs may affect university education Explore how MOOCs affect department visibility and reputation worldwide Better understand the effort involved, technology, and teaching methods associated with MOOCs   The course was different from other MOOCs   It was a full graduate level course, offered both as a MOOC and a university course Had programmer and non-programmer tracks Designers developed the software platform that students used to experience recommender systems     Course Outline  1 week introduction and wrap up 8 Modules, 2 weeks each Total of 42 lectures with pop-up comprehension questions 14 recorded interviews 12 face to face class sessions, mostly Q&amp;A, some enrichment topics 7 nom-programming written assignments 6 programming assignments for programming track 2 MCQ exams on non-programming aspects Online readings and references - required and optional Face-to-face students had additional contact  Programming track compulsory 3 required classroom sessions - start of class overview, mid- and end-of-course feedback TA sessions (optional, with light turnup) Weekly Q&amp;A sessions with faculty Ability to contact faculty and TAs over email, office hours, etc. Option to have assignments graded by TA instead of peers     Enrolment  N  28,339 total, 21,357 active in some way (completed one activity during the course) Much smaller number participated in a substantial and regular basis High attrition rate throughout course based on video watches   Demographics - pre-class survey  87% male 68% under 35 68% outside the US, 76% proficient or advanced proficient English skills 70% from CS or related field 57% took more than 5 college-level CS courses 80% were very or moderately competent in programming skills 71% planned to complete the full course Mostly graduate students or working professionals in CS or related field Not surprising - subject matter is advanced and most MOOC students are educated professionals seeking practical skills       Research Questions  Do students learn in the MOOC? How much, and which students? What variables predict learning gains among MOOC students? Do students in face-to-face learn more than a comparable MOOC group? What demographic, background, and behavioural factors predict course completion, learning gains, and course grades in the MOOC? What is the interaction between learning and practicing concepts and learning and practicing programming of the subject matter in the MOOC? What are the different types of reasons for taking the MOOC? Do they correlate with demographics or learning gains? Do MOOC students retain what they learned 5 months after the course? Do face-to-face students retain more of what they learned than MOOC students do?   Methods  Design  RQs pertaining to MOOC students - single group design Comparing face-to-face with MOOC students - pre-test-post-test non-equivalent groups design No random assignment, given that students sign up for the class themselves Controlled course content, objectives, and assignments, aside from what is listed above   Participants  39 students in face-to-face course 4844 MOOC students who completed pre-course survey and pre-course recommender systems knowledge test Students all above 18 - younger students were excluded to comply with IRB   Measures  Pre- and post-class surveys on demographics/background, intentions for the MOOC, reactions to the MOOC experience 20-item instructor developed recommender systems knowledge test - MCQ  Beginning of course, end of course, 5 months after Pre-test showed low subject matter knowledge across most students     Preliminary Analyses  Examined set of questions asking students to rate strength of 15 different reasons for enrolling in a MOOC 4 factors were extracted from PCA with Eigenvectors &gt; 1 Underlying constructs for these factors  University/instructor-related reasons - e.g. course/instructor prestige Pragmatic/access reasons - e.g. access to university Professional reasons Interest/enjoyment       Results  Course Completion  Logistic regression showed that pre-test knowledge, prior MOOC experience, and strong intentions  to complete were related to course completion  Intention to complete had the highest odds ratio - largest effect   Completion is negatively related to introversion and number of courses one is taking concurrently  Likely suggests the role that time pressure plays in influencing completion     Recommender Systems Knowledge  Based on (post-test - pre-test)/(100% - pre-test) scores - face-to-face students learned at least as much as online-only students  Face-to-face students showed 8% more gains - NS effect, but may be due to small N of face-to-face students   Split based on student aptitude  Investigate notion that MOOCs are not as good for weaker students as they provide limited support Broadly, students with different levels of knowledge benefitted similarly from the course One-way ANOVA of knowledge gains between quartiles of students (split by pre-test scores)  Significant difference between two highest quartiles - might reflect ceiling effects of the best scoring group, who may know a lot more     Programming track vs concepts track  Similar gains in knowledge on final test across groups - NS difference in T-test But of course programming students got programming knowledge that was not assessed by the final test     Predicting Learning and Student Success  Regression model predicting knowledge gains highly significant, but R2 only .202  Knowledge gains significantly predicted by number of written assignments, programming vs concepts track, and pre-test  Pre-test of course had strongest effect, but number of written assignments completed had close to the same effect   Measures of relevant effort strongest predictors   Regression model predicting final grades  Concept track predictors - Forum posts, plans for completion, programming skills confidence   Model only accounted for 6.9% of the variance   Programming track predictors - hours per week on course, self-reported amount learned, amount of course completed, previous programming courses taken, pragmatic reasons  Adjusted R2 of .319       Knowledge Retention  Despite attrition, respondents to the 5-month follow-up were similar demographically to the initial sample  Significant differences emerged over - number of concurrent courses taken (fewer for respondents), and mean age (higher for follow-up respondents)   Most learning gains retained after 5 months based on follow-up test score comparison  NS differences in comparisons between Face-to-face vs MOOC, but Programming track students retained more than concepts students     Student Evaluation and Survey Results  Department and program reputation  Far less students responded ""don't know"" to questions on department quality Mean difference of .377 in questions on reputation of department between pre- and post-course survey - suggest boost in department reputation among students  Though may have selection bias, since post-course survey respondents are the ones that stuck through the whole course     Most students agreed or strongly agreed that the course was effective in helping them learn about recommender systems 60% felt the longer format was effective for course delivery, 19% preferred shorter courses, 21% no preference 84% said they chose the right track, 4% felt they chose the wrong track 54% had the opportunity to use what they learned in the course     Qualitative Results and Anecdotes  Class forums and private conversations suggest strong interest in ""use-it-now"" learning MOOCs create public visibility for the institution not associated with traditional classroom teaching Peer grading unpopular among students, but necessary for assignments which could not be multiple choice or NLP'd  Currently no solution to this in MOOCs which have large volumes of participants and limited grading bandwidth   Utility of MCQ based tests - time taken to make good MCQs is high, but time saved in grading is substantial   Discussion and Lessons  Key takeaway: Those who complete MOOCs learn a lot, with retention Diverse enrolment in MOOCs Predicting course completion is hard, with Intention to Complete being the only highly predictive factor    ",45,15,30,4
"1293","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Young (2014): Why Students Should Own Their Own Educational Data  Interview with L. Todd Rose, Educational Neuroscientist at Harvard GSE The problem with the concept of the average learner  Population studies, which provide indicators of central tendency like the mean and median (i.e. Averages), are often unable to say anything meaningful about any individual in the group In areas of research like medicine, where big data has to reconcile with individual nuance, the approach to data is more towards individual patterns instead of aggregate data  This has led to discovery/acknowledgement of different manifestations/pathways of disease that result in more effective treatments tailored to each pathway     Aggregate Data and Learning   In the past, without enough data, we had to use aggregate data - drawing inferences about a population from a sample However, it is more effective to look for personal patterns that can potentially provide personalised learning  This is now possible with more data Can look at variations in an individual's learning across contexts     MOOCs  MOOCs have forced a conversation in Higher Ed - what value do 4-year colleges really provide? However, they are a long way from transforming education with personalised learning  MOOCs are still an immature field, without interoperability capability or format standards To succeed, providers need to be able to build individual, contextualised profiles of learners and what kind of support would serve them best across contexts     ",7,1,6,2
"1294","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   Matsuda et al. (2015): Machine beats experts: Automatic discovery of skill models for data-driven online course refinement  Automated discovery of skills needed for successful completion of MOOCs which   Outperform human produced skill models Are interpretable Faster than existing methods   The challenge  MOOCs often contain a broad range of content Hard to define a set of skills to be learned, and cleanly associate these skills with particular parts of the course content  To do so often requires intensive cognitive task analysis and evidence-based iterative engineering from course feedback  Problems of accuracy and scalability       Responses  Learning Factor Analysis (LFA)  Semi-automatically refines a skill set Requires a set of meaningful features to be given   Matrix factorisation  Derive a Q-Matrix automatically from student response data Problems of interpretability - hard to provide meaningful feedback to course designers based on machine-generated skill set     eEPIPHANY  Authors' solution to automate skill set discovery  Starts with a human crafted set of skills, which automated processes refine   Aims to  Provide constructive feedback to course designers for iterative course improvement   Relies on  Student learning interaction data Assessment item text data Hypothesises that these data reflect latent skills to be learned, and assessment items can be clustered based on these latent skills   Assumptions  Courses have formative assessments at points in the course  To assess students' competency towards learning objectives Involves multiple items, each associated with one or more skills   Courses have a pre-defined skill map/model (Q-matrix) that maps skills to assessment items - skill-item association   Works by  Inputs - A-matrix  Matrix of chronological records of students' responses to assessment items Students as rows, Assessment items as columns 1/0 - Correct/Incorrect   Goal is to find a skill model that best predicts the A-matrix pattern  Predictive power measured by cross-validation   Replace/Refine an existing Q-matrix by  Clustering assessment items with latent features that would best characterise similarity in difficulties of assessment items Proposing a new skill model by assuming the clusters derived provide hints for new skills Searching for the best skill model from a set of candidates through comparisons     Feature Extraction  Goal is to generate a P-Matrix - mapping assessment items to skill candidates  P-matrix is like the Q-matrix, but skill candidates are the rows In LFA, this is generated manually by experts With eEPIPHANY, this is accomplished either by Matrix Factorisation or Bag-of-Words (BoW) strategy   Matrix Factorisation  A-matrix transformed into difficulty matrix (D-matrix)  D-matrix represents individual student difficulty for each assessment item  Item difficulty = 1 - (1/d) where d is the number of attempts made on an assessment item until the first correct answer is given Id = 0 for missing data - assumption is that students would skip questions that are too easy for them The idea is that   Performance on items represents difficulties in answering assessment items Students with a similar pattern of difficulties will share similar competencies on latent skills       D matrix factorised into U and V matrices  V matrix - assessment item by latent feature   Items in V matrix are then classified by K-means into the F-matrix  Each cluster is taken as a skill candidate that can be used to make the P matrix     Bag of Words  Create F-matrix directly from collection of item stems (assessment item text data showing problem and feedback texts) for assessment items  Tokenise and stem assessment items Run LDA to cluster assessment items based on probability of topic distribution   Individual assessment items are assigned to the topic with the highest topic probability, resulting in the F-Matrix P-matrix is generated in the same way as the F-matrix, as above   Trade-offs  BOW may present better interpretability  Item stems more closely reflect skills assessed, whereas student response data used in matrix factorisation may be distorted by student knowledge   Matrix factorisation may produce more accurate skill models     Skill model construction  Default skill model is either replaced or modified Feature extraction is used to propose skill candidates, then the best way to refine the initial model is found in terms of model fit to the data Derive a Q-matrix on its own  P-matrix automatically converted into Q-matrix   Append strategy  Original skill-item associations remains intact Add the associations suggested in the P-matrix to the initial model Thus, the append method effectively produces a Q-matrix that contains the skills-item in the original matrix + the skill candidate-item mapping in the P-matrix   Split strategy  Append, then delete redundant original skill-item associations     Model Search  Model fit assessment using Bayesian knowledge tracing as predictor Exhaustive search for best skill model by comparing all possible models with different combinations of 4 parameters  Number of components used for matrix factorisation - this determines a dimension of the V-matrix Number of clusters in K-means of V-matrix Number of topics used in LDA Threshold for split strategy  Skill-item association for skill s will be split into new skill-item associations using skill candidates if the number of assessment items associated with the skill candidate exceeds...       Model Interpretation  To achieve interpretable feedback, need to  Identify which part of the initial model has been improved the most  Find skills with largest Degree of Enhancement (DoE) score  Assumed to be maximised among skills for which the accuracy of students' performance prediction improved the most Prediction accuracy operationalised as root mean squared error in cross-validation of model-fit evaluation Increase of old skill relative to new skill(s) is the difference in RMSE between old and new skills     Understand the improvement from a domain perspective  Bag of Words analysis + Manual inspection of the assessment-item text Find keywords from item stems         Evaluation of eEPIPHANY  Applied to 3 CMU OLI courses vs LFA and Human experts  Courses  Statistics Biology Computing     Strategy comparison  Even when only using bag-of-words, eEPIPHANY always yields a better skill model than one created by human experts Replace always produced the best skill model in the study  Suggests that matrix factorisation efficiently discovers a latent skill model   Split always led to a worse model - split hardly improved human-crafted Q matrices   Interpretability possible by combining MF strategy to make good skill models with Degree of Enhancement analysis + BoW/Manual inspection after  MF + BoW alone to produce keywords as skills may allow for automated interpretation of new Q-matrices without need for manual work        ",60,16,44,5
"1295","Using data mining to predict secondary school student performance","Cortez &amp; Silva (2008): Using Data Mining to Predict Secondary School Student Performance  High student failure and drop out rates in Portugal  Particularly serious failures in Mathematics and Portuguese, especially since they provide fundamental knowledge for other school subjects   Education offers fertile ground for data mining/analytics given multiple sources of data (traditional databases, online webpages) and diverse interest groups (students, teachers, administrators, alumni)  Available data has trends and patterns which human experts may miss    Previous studies have shown promise in predicting student achievement and identifying factors affecting student performance The present study analyses Portuguese secondary school performance data  Predicted final grade outcome as  Binary classification - pass/fail 5 level classification Regression with numeric scores     Materials and methods  Data from 2 public schools in Portugal  School reports - grades and number of school absences Questionnaires with closed questions regarding demographic, socioemotional, and school-related variables  Some features were eventually discarded since they lacked variation - most students lived with their parents, had a computer at home, and did not answer the family income question   Data integrated into a dataset for math and one for Portuguese classes   Prediction Models  Evaluated using RMSE (for regression) and Accuracy (for classification) Decision tree - set of if-then rules that use featues to sort data and award the resulting groups labels Random Forest  Set of T decision trees, each based in a random feature selection from trainig samples Random forest predictions are built by averaging the outputs of the trees Harder to interpret when comared to the regular DT, but still can provide explanatiory knowledge in terms of input variable relevance   SVM Neural Networks   Model training  Fitted NN and SVM hyperparameters were optimised using a grid search Since previous exam scores before the final would likely be highly predictive of Final scores, the models were trained using 3 input configurations  With every available feature With every feature without first period grade With every feature without 2nd period grade   20 runs of 10-fold CV Also tested a naive predictor     Results  Of course, best models used every available feature Model evaluation  Binary Classification - best models had 91-93% accuracy  Best models that got rid of period grades had around 70% or 80% accuracy (1st/2nd period grade omitted)   5-level classification - best models had about 75-80% accuracy  Best models that got rid of period grades had around 60%/30% accuracy (1st/2nd period grade omitted)   Regression - Best models had RMSE of about 1.5   Descriptive Knowledge  Top 5 features account for about 77% of the variance Previous periods had high impact Without first and second period grades, number of past failures is the most important factor Other relevant factors  School related - Number of absences, extra school support, travel time Demographic - e.g. Mother's job Social - e.g. Going out with friends, alcohol consumption         ",11,5,6,3
"1296","Developing a generalizable detector of when students game the system","   Baker et al. (2008): Developing a Generalisable Detector of When Students Game the System  Introduction  When working in ILEs, some students may try to game the system Attempt to succeed in the environment by exploiting system properties rather than trying to learn the content and answer questions correctly Paper presents a system that can detect whether a student is gaming the system in a math ITS Also differentiates between two types of gaming the system In cognitive tutors, gaming the system is associated with poorer learning from the system Groups like Baker et al. (2004) and Aleven et al. (2004) developed system to detect gaming behaviour   Gaming the system in Cognitive tutors  Math cognitive tutors break down the steps to solve a problem to make a student's thinking visible  Tutor assesses misconceptions at every step Students can also get hints for a step in a multi-step manner Conceptual hint first, followed by more and more specific hints until the full answer is given   Hints are context sensitive to the problem As the student solves problems, Bayesian knowledge tracing is applied to determine what skills the student has mastered or has problems with  Calculates p(knows skill) based on history of responses to relevant questions   Material is usually structured as independent lessons covering a set of related skills and concepts Longer courses have later lessons build on earlier content   Gaming the System behaviours with cognitive tutors  Spam hints to get the answer Systematic guessing of options Working on material the student has already memorised Making irrelevant posts to discussion forums when they're automatically graded Categories of gaming behaviour are differentiable by whether students get  Low post-test scores OR High post-test scores As suggested by ML models  When trained on full data to detect all gaming students, could only pick up the low post-test group When trained on one or the other group could correctly identify other members of the same group but not those from the other group       The data  From cognitive tutors for geometry, probability and scatterplots Quantitative field observations - how often students were gaming the system vs distracted, talking on-task, or using the tutor Interactions log from the ITS 26 features, classifiable into  Details about the action (e.g. type of question - string or MCQ input, correct/incorrect) Knowledge assessment features (largely based on BKT) Previous interactions on the problem or similar problems Latency of actions     The Detector  Detector structure - Latent response model with two latent models and one observable level  Observable level gives predicted proportion of actions that are gaming Based on feature observations from the log, model makes binary assessment of whether each student action is an instance of gaming Then calculates proportion  Compare against observed frequency of gaming measured by observation Gaming behaviour classified into two groups based on learning gains  Gamed-not-hurt - games, but sizable post-test - pre-test gain Gamed-hurt       Detector selection  Used Fast Correlation-Based filtering , then Forward Selection to pick best model Fast Correlation-Based filtering  From all the single feature (parameter) models, filter based on two criteria More than 60% as good as the best single parameter detector Pick only the better of two single feature models if these features had more than r = .7   Forward Selection  From the set of models obtained from Fast Correlation-Based filtering, add additional parameters one-by-one Choose the addition that most improved the correlation between model prediction and actual data Continue until the models have 7 parameters   Finally model with best A' (AUC) was selected  Average A' of gamed-hurt vs non-gaming and gamed-hurt vs gamed-not-hurt       Model validation  Generalisation to new students  On training data  Gamed-hurt vs non-gaming - A' of 0.80, statistically significant at p &lt; 0.001 Gamed-hurt vs gamed-not-hurt - A' of 0.71, p &lt; 0.01   Leave one out CV used on scatterplot data  Gamed-hurt vs non-gaming - A' of 0.73, statistically significant at p &lt; 0.001  Difference from training set A' was NS   Gamed-hurt vs gamed-not-hurt - A' of 0.68, p &lt; 0.02  Difference from training set A' was NS       Generalisation across tutor lessons  Trained model on data from 3 lessons, test on a fourth lesson Took average of all possible combinations of train and test sets In this case data was not fully independent because students sometimes took more than 1 lesson Used Strube's adjusted Z - can be treated the same as any Z score, but accounts for inter-correlation between dependent measures Gamed-hurt vs non-gaming - Models had average A' of 0.85 in training set, 0.80 on test set. Difference between these is NS Gamed-hurt vs gamed-not-hurt - average A' of 0.86 in training set, 0.80 on test set. Difference between these is NS However, there was some variation across different model permutations  Models ranged from A' of 0.6 to 0.99 on test set in both cases   Results suggest that transfer is successful, but not necessarily even   Using the cognitive tutor model in anti-gaming interventions  Decision should be based not just on model accuracy but nature of intervention Scooter the tutor uses the model in anti-gaming interventions  Express negative emotions when student is gaming Add more exercises on steps where the student was found to game several times   Was successful at reducing gaming behaviour and improving learning     Behavioural analysis  Harmful gaming associated with consistently making errors on a specific problem step, across problems Evidence of harmful gaming is stronger if the student gets the step right on the first try in some problems, and makes more errors in other problems  Suggests high number of errors despite high chance that the student knows the skill Not all consistent errors suggest gaming - some skills like point plotting have high error rates despite skill mastery   Requesting help on several steps in short succession Time taken for actions  Quick actions suggest harmful gaming, but only if the student has already made an error on that step     Comparison to other gaming detector models  Criteria for an ideal detector of gaming behaviour  Should identify categories of behaviour that is known to be associated with a meaningful difference in student experience/outcomes  Any system that can identify gaming behaviour should satisfy this goal, since gaming is negatively associated with learning   Predict not only which students game, but when they do  This makes more, and more effective, interventions possible  Cognitive tutor does this indirectly, intervention shown to be effective   Ideally, should be direct to map time of gaming observations to timestamp in tutor log files to validate model prediction for specific actions at specific points in time   Should be explainable, to help researchers understand gaming behaviour  Cognitive tutor does this (see above)   Should be generalisable  See validation above       Conclusions  The existence of several models that detect gaming behaviour suggest it is a fairly robust construct  However it is not yet clear to what degree some features of gaming behaviour like the gamed-hurt and gamed-not-hurt distinction are general across ITSes   Future work should look at gaming behaviour beyond ITSes, where most of the work on gaming behaviour is concentrated Gaming behaviour detectors may be useful in developing techniques that can be applied to developing detectors for other types of behaviours  E.g. Fast Correlation-Based filtering   Detectors of user behaviour and strategies should focus on behaviours associated with a meaningful difference in user experience and outcomes A detector is useful, regardless of the domain it is in, when it  Captures important behaviours Identify when they occur Promote understanding of the behaviours Is generalisable        ",40,26,14,5
"1297","Big Data in Education","Bayesian Knowledge Tracing (BKT)  Classic approach for measuring tightly defined skills in online learning Most thoroughly articulated and studied by Corbett &amp; Anderson Measures how well a student knows a specific skill/knowledge component at a specific time  Based on their past performance with that skill/KC Uses sequences of past items, dichotomously scored as 0 or 1  Each item must correspond to a single skill     Skills need to be tightly defined  Unlike IRT, goal is not to measure overall skill for a broadly-defined construct (e.g. Arithmetic) Should measure a specific skill or KC (e.g. Addition of 2 digit numbers without carrying over numbers)   Assumptions  Two state learning model - each skill is either not learned or learned Each item maps to a single latent trait or skill Of course as a Bayesian model, the student is assumed to be able to learn the skill from each item where it is needed  Scaffolding, assistance, feedback, etc.   Students cannot forget a skill once it is learned Performance assumptions  If the student knows a skill, still some chance of getting item mapped to the skill wrong If the student does not know skill, still some chance of getting item mapped to the skill right     Each skill has 4 parameters   Learning Parameters  Probability that the skill is already known before the first opportunity to use the skill in problem solving (P(L0)) Probability that the skill will be learned at each opportunity to use the skill (P(T))  A good ITS should have high P(T)     Performance parameters  Probability of guessing correctly if the skill is not known (P(G)) Probability the student will get the item wrong if the skill is known (P(S))   Performance Parameters Using these parameters and the pattern of student responses (correct/incorrect), can derive  Latent knowledge P(CORR) on the target item - P(Ln) * P(1-S) + P(1-Ln) * P(G)     Bayes' theorem is used to update the probability that the student knows the skill each time the student has the chance to use the skill  Note  Classic BKT only uses the first problem attempt on each item  Lose information, but retains the clearest piece Other BKT methods try to incorporate more than the first problem   Typically, potential values of BKT parameters are constrained  To avoid model degeneracy - a knowledge model is degenerate when you cannot trust that if students are getting your items correct, it is more likely that the student has learned the skill Constraints proposed  Beck  P(G) + P(S) &lt; 1.0   Baker, Corbett &amp; Aleven (2008)  P(G) &lt; 0.5, P(S) &lt; 0.5   Corbett &amp; Anderson (1995)  P(G) &lt; 0.3, P(S) &lt; 0.1         Evaluating BKT models  Cannot assess knowledge, a latent trait Instead, check knowledge predictions by seeing how well the model predicts performance  Hence, parameters that predict student performance better (whether a student's action will be correct or wrong at a given time) are preferred     ; Classification - prediction of a categorical variable  Mapping an unlabelled instance to a discrete class by a classifier Associated with each label (outcome/predicted variable) are a set of features that may predict the label The objective of a classifier is to determine which combination of available features can predict the label with the best according to a given performance metric Domain-specificity A lot of different classifiers out there, but specific algorithms work better for specific domains and problems  The reason for this are elusive   In Education, the following classification algorithms tend to be useful  Step regression  Used for binary classification Fit (multiple) linear regression model to training data  Assign arbitrary cut-off value of predicted outcome Y for labels   Using regression equation, generate predicted outcome Y from known predictor variables of test data, then use cut-off to create predicted labels Problems   Lacks closed-form expression (Google this, refers to expression in terms of a general/common set of mathematical functions and operations) Not very good with interactions Makes evaluation of things like SE difficult   Benefits - low over-fitting   Logistic regression (see notes from HUDM 5122)  Also used for binary classification Fits logistic function (S-curve) to data to find frequency/odds of attaining a specific outcome value Good when cases where changes in predictor variables have predictable effects on probability of predicted class variables  E.g. Increase in variable X always leads to increase in probability of classification as Y1 instead of Y2   Problems  Data may not always conform nicely to a logistic function Not very good at interaction effects     Decision Trees  Decision trees are better at interactions given their step-by-step splitting approach which can use different predictors for each split Can handle both numerical and categorical predictor variables  Tries to find optimal split in numerical variables - based on predictive power   Prunes branches that have low predictive power  Can also be manually pruned   Can split based on more/less evidence Benefits  Relatively conservative, particularly because of pruning Performs well with bimodal data  Suited for situations with multi-level interactions  Suited for situations where the same label can be arrived at using different patterns in features     Decision Rules  Decision rules are a set of if-then rules executed in order  At the end of a series of decision rules is a label Differences in decision rule algorithms lies in how rules are generated and selected  JRip and PART create decision trees and distils the best rules based on them     JRip   Create decision tree  If there is at least one path worth keeping, take the best (however defined) single path from root to leaf, and make that path a rule  Remove all data points classified by that rule from the dataset, then create a new decision tree and start again   If there is no paths left worth keeping, take all remaining data points, find their most common label, and create a final ELSE statement using that label as the classifier     Benefits  Decision rules tend to lead to simpler models than decision trees - more conservative than decision trees Tend to result in more interpretable models Good with multi-level interactions, like decision trees     K* Instance Based Classifiers  Predicts data point from neighbouring data points  Weights points more strongly if they are nearby   Needs the whole dataset to use the model - cannot just save the model separate from training data since they're intrinsically tied  Computationally intensive     Bagged Stumps  Create a lot of decision trees using only one feature, then aggregate across them Similar to random forest     These models tend to work better with EDM probably because they're relatively simple and are less prone to overfitting to training data Other classifiers  Support Vector Machines  Conducts dimensionality reduction on the dataspace then fits hyperplane which splits classes Creates very sophisticated models Great for places with large troves of data - text mining, sensors But often not that good for educational data   Genetic algorithms  Use mutation, combination, and natural selection to search space of possible models Can produce inconsistent answers since randomness is leveraged in mutation and combination Often useful, but tends to overfit when used on educational data   Neural Networks  Creates complex relationships by combining 'perceptrons' Finds very complicated models Infamously difficult to interpret, like many other non-linear modelling techniques     ; Clustering Analysis  Why?  Have a large number of data points, want to know possible structure of data points, but know nothing a priori about them  Works with a large number of features (columns)   Group similar rows together K-means is a common way of doing cluster analysis  The K is just the number of clusters  Have to choose the number of clusters manually   Means - some mean is used to make the clustering decision - hence requires continuous variables Steps  Choose number of clusters Select random points =  number of clusters to be the ""centroids"" of clusters Associate data points with closest centroids - defines initial clusters  Visualised as a voronoi diagram   Move the centroids to the mean point in the cluster Convergence - Iterate, repeating the process with the new centroids as the starting points, defining new clusters and so on  Do so until the centroids stop moving     Issues  Very sensitive to starting values  Mitigated by running the analysis several times with different starting points (Conati &amp; Amershi, 2009) Not good at dealing with complex shapes   Assumes that there are K clusters to find  It will find K number of clusters regardless of whether or not there are any real clusters in the data   Do not work on some shapes Need uniform variance and scale (use z-scores)  A variable with larger variation will exert more influence over the clustering than variables with less variation   Doesn't work on categorical data of more than two categories  Works on means R will correct to turn factor levels to numbers, but  Might not make sense - especially for nominal data The scale will be difficult to interpret properly even if it does     Can get stuck on local ?minima   Applications  LMS Login Data  Clustered students by the pathways they took through the LMS     Validation of model  Distortion (Mean Squared Deviation)  Method  Take each point P Find the centroid of P's cluster, C D' = (Dist between P and C)2  Typically use Euclidian distance -    Sum all D's to get distortion   Works for choosing between randomised restarts - picking the best analysis out of a set of analysis (the workaround to dealing with skew based on initial centroid position) Does not work for choosing cluster size, since more clusters always leads to lower distortion     Selection of number of clusters  Qualitative assessment - add clusters until you no longer see anything interesting Information Criteria  E.g.   Bayesian information criterion Akaike information criterion   Penalise models with more clusters, according to the marginal increase in fitness expected from the additional clusters Steps to using information criteria  For several values of k, try  Assess how much fit would be spuriously expected from a random N centroids, without allowing them to move Assess how much fit you got with your model Find the difference   Find the best fitting set of clusters for each value of k Choose k with the best value of Bayesian/Akaike information criterion         K-modes works similar as K-means, but uses modal value instead of means  Hence, works for categorical data, but not recommended for continuous data Steps  Select some random points Associate those points with closest other points  Association of a given point to a chosen (random, from above ) point - based on the chosen point with the lowest difference in variables between given and chosen points   Move the selected point to the modal point in the cluster Iterate until no change   Issues  Assumes that there are K clusters to find  It will find clusters regardless of whether or not there are any   Do not work on some shapes Need uniform variance and scale (use z-scores)  A variable with larger variation will exert more influence over the clustering than variables with less variation Less of an issue than with K-means, but still exerts an influencCan get stuck on local ?minima       ; Introduction (Predictive Learning Analytics)  Machine Learning philosophy differs from explanatory modelling used in traditional science In explanatory modelling, you're trying to understand the black box process between the inputs and outputs, making it explainable  Model of the process tells us something about the world   In ML, concern is with model fit/accuracy  Inputs and initial outputs are fed into the ML process, yielding a model  Model possess a particular structure and weights for handling inputs to produce output, but its precise specification is not a core interest This model is then applied to predict new outputs from inputs   Want inputs to line up and predict the outputs accurately   Types of EDM/LA methods (Baker &amp; Siemens)  Prediction  Develop model to infer a predicted/outcome variable from some combination of other aspects of the data (predictor variables) Classification Regression Latent Knowledge Estimation   Structure Discovery  Find structure and patterns in the data that emerge naturally No specific target or predictor variables Clustering Factor Analysis Domain Structure Discovery Network Analysis   Relationship Mining  Discover relationships between variables in a dataset with many variables Association Rule Mining Correlation mining Sequential pattern mining Causal data mining   Distillation of data for human judgement Discovery with models  Pre-existing models applied to data and used as a component of another analysis     Some methods that are big in other areas of data mining/machine learning are underrepresented in LA  In some cases, they just haven't been applied, while in others, these methods have not shown utility unlike in other fields  Educational data is not as big as the massive datasets available to tech companies E.g. Neural networks - tends to overfit with educational data  Datasets not big enough Data is highly contextual       ; Model Evaluation Metrics  Evaluation Standards  Ground truth  The underlying absolute state of the information - Taken as the ""reality"" that you want your model to accurately predict In practice, a real-world/empirical measurement/evaluation against model predictions  Is a measurement, and hence can be wrong E.g. If your ""ground truth"" is a tornado watcher and your model is a doppler radar, the  radar may be right and the watcher may be wrong (saying no tornado when it's behind him or something?)     Gold Standard - a benchmark comparative measurement  The best test possible under reasonable conditions or without restrictions, depending on the context  Usually expensive to obtain   Again, not perfect - the gold standard can have error   Baseline - a 'baseline' simple model  Generally want to create a baseline model, then refine it to get a better result  Simple heuristics, summary statistics, randomness, and simple methods to churn out results that serve as a 'baseline' for further refinements Serves as a common-sense sanity check       Confusion Matrix and Evaluation Diagnostics for Classifiers  Contingency Table/Crosstab that is often used to describe the performance of a classification model on a set of test data           Predicted A   Predicted B     Actual A   True A (Positive)   False Negative     Actual B   False Positive   True B (Negative)       Similar as signal detection theory matrix, and based on the same underlying principles (see PBS4 notes on the topic)   From a confusion matrix, a number of performance metrics can be derived  Which one is used would depend on the use case and other factors Where possible, present the full matrix for more detailed analysis, rather than just one of the metrics  Accuracy might yield misleading results if the data set is unbalanced - number of observations in different classes differs greatly  E.g. If there were 95 X and 5 Y in the dataset and the classifier predicted everything was X, you get 95% accuracy  However, you have 100% sensitivity for X but 0% recognition rate for Y   Some version of this would exist in other manners of imbalances for the other metrics as well     Accuracy  Total correct predictions/total predictions Measure of % Correct - (True positives + True Negatives)/ Total observations Mostly the standard Best used when there is no cost trade-off Problems: can be misleading if there are unequal categories  E.g. Unequal/unbalanced samples will lead to majority class models that classify everything with the same label as the majority label in the training set may perform perhaps misleadingly well, with no real information This is almost always the case   E.g. ""All credit card transactions are non-fraudulent""       Precision/Positive Predictive Value  True positives/(True positives + False Positive) Ways of saying this  Of the cases that the model says are true, what probability did the model get right? How precise/accurate model is in predicting positive labels the proportion of positive evaluations that are correct (two ways of saying the same thing)   The proportion of predictions that are relevant Best used when cost of false positive is high   Sensitivity/Recall/Hit Rate/True Positive Rate  True Positives/(True Positives + False Negatives) Ways of saying this  Of the cases that are actually true, what probability did the model get right? How many actual positives the model captures as labelling as positive Proportion of correctly identified real positive values (two ways of saying the same thing)   The fraction of relevant instances that are predicted Best used when cost of false negative is high      F1 score/F-score/F-measure  (Precision * Recall)/(Precision + Recall) Harmonic mean of precision and sensitivity Calculates a balance between recall and precision, giving equal importance to both  This has been a subject of criticism, since the relative importance of precision and recall is often not equal - different types of mis-classifications will incur different costs    Specificity  True Negatives/(True Negatives + False Positives) Proportion of negative evaluations that are correctly predicted as negative  Cohen's Kappa  Compares an observed accuracy (from the confusion matrix) with an expected accuracy (random chance)  100% Kappa means that the classifier is in total agreement with a random classifier   Works with more than 1 category Calculated as (p(observed agreement) - p(expected agreement))/(1- p(expected agreement))  P(Observed agreement) - Just proportion of observations where model and data agree  Actual positive agreement + Actual negative agreement   P(Expected agreement) - Expected positive agreement + Expected negative agreement  Expected positive agreement - Proportion of observations classified as ""positive"" by model * same proportion for data  P(positive label) in both model and data, assuming they are independent   Expected negative agreement - same thing, but for ""negative"" classifications      Interpreting Kappa  Kappa = 1 - perfect agreement Kappa = 0 - agreement at chance Kappa &lt; 0 - model is worse than chance Kappa = -1 - agreement is perfectly inverse (model always gives completely opposite label compared to the data) No absolute standard of what is a good kappa value (so long as it isn't worse than chance)  Problems with Kappa  High prevalence of a single class leads to higher expected agreement than if classes are easily balanced  However, imbalanced data leads to lower kappa - worse performance, unlike with accuracy where imbalanced data may lead to better performance  This is not ideal but a better situation since it penalises imbalanced data   Thus difficult to compare kappa between datasets, though it is possible to compare kappa within a dataset  Still ok to do this informally if the proportions for each category are similar     Does the marginal probability actually represent random chance?  See https://en.wikipedia.org/wiki/Confusion_matrix for other metrics that are used Dealing with Probabilities and the Receiver Operating Characteristic (ROC) curve  Classifiers assign a probability of belonging to a class, rather than a class directly  Can choose a probability threshold to assign to a class Allows us to choose a preference based on the consequences of false positives/negatives  Works like alpha-values in hypothesis testing - in fact they're conceptually the same thing  Alpha-values are the threshold for classifying a result as ""statistically significant"" where one would accept that H0 can be rejected for H1   Can be more conservative in classifying positives (higher probability threshold) if false positives are a bigger problem Can be more liberal in classifying positives (lower probability threshold) if false negatives are a bigger problem, or false positives aren't that big of a deal     Receiver Operating Characteristic (see notes on Signal Detection Theory in PBS 4 that explains the concept and process of deriving this)  Relationship between false positive and true positive rates (for a model  X axis - TN/FP (FP = 0 at the origin; TN = 1-FP) Y-axis - TP/FN (TP = 0 at the origin; FN = 1-TP)    Originates in WWII for detecting enemy objects on radar Demonstrates the sensitivity vs specificity tradeoff Area Under the Curve (AUC)  Sometimes called A' (A Prime) Works as the collapsed metric to compare models Model that performs at chance will have AUC = 0.5 - want to be better than that AUC - The probability that a classifier will accurately classify a set of exemplars from each category Benefits  Meaning is the same across datasets - larger area is always better  Hence easy to interpret   Takes confidence into account  Rather than just labels at just one threshold you use labels at all possible thresholds Unlike Kappa, Accuracy, Recall, Precision   Actually equivalent to the Wilcoxon Sum-Rank test (Mann-Whitney U, see undergrad stats), hence can generate a hypothesis test of   Whether two A' values are significantly different Or whether one is statistically significantly different from chance However, note that the Wilcoxon Sum-Rank test still assumes independence of observations     Other cautions  Unfortunately not really a good way to compute AUC for 3 categories as yet For fringe cases, many statistical packages don't do a good job with plotting ROCs        Diagnostics for Regressors  Mean absolute deviation/error (MAD)  Mean of absolute value of observed values minus predicted values  i.e. (Sum of |observed val - predicted val|)/N     Root mean squared error (RMSE)  Square root of observed values minus predicted values squared  i.e. (Sum of ((Observed val - predicted val) ^2)) ^ 0.5 Rooting this returns the result to the original scale   Punishes larger deviations more harshly than smaller deviations compared to MAD   Low RMSE and MAD are good Pearson's correlation and R squared (see all the old stats notes) - for both, closer to 1 is good  Pearson's r - Measure of linear dependence between two variables  Covariance of two variables divided by product of the standard deviation of those variables   R2 - the proportion of the variance in the outcome variable that is predicted by the predictor variables  If it involves two variables, it is the square of the correlation Often used over r as the measure of model goodness-of-fit, especially when there are multiple predictors   Assume linear relationship Vulnerable to outliers   Using them together  Low MAD/RMSE, high correlation - good model High MAD/RMSE, low correlation - bad model High MAD/RMSE, high correlation - probably systematically biased model, though may still be detecting true effect Low MAD/RMSE, low correlation  Model predicted values are largely correct, but covariance is low Likely not a lot of variation in the data      Akaike Information Criterion (AIC)  Number of parameters - goodness of fit Developed by Akaike Hirotsugu in 1971 Based on thermodynamics Relative estimate of the information lost when a given model is used to represent the process that generates the data  Model with lowest AIC is deemed superior   Represents the trade off between goodness-of-fit with model complexity (number of variables) Criterion for model selection, cannot give an estimate of model fit in an absolute sense Said to be statistically equivalent to leave-one-out-cross validation Problematic as it was never well implemented in software  Bayesian Information Criterion (BIC)  Developed by Schwarz in 1979 Also calculates tradeoff between goodness-of-fit and model complexity (number of variables)  Represents the trade off between goodness-of-fit with model complexity as well, but the penalty for adding parameters is greater than in AIC   Uses Bayes Theorem to penalise the addition of parameters Like AIC, lowest BIC model is deemed superior  BIC' &gt; 0 - worse than expected given number of variables BIC' &lt; 0 - better than expected given number of variables   Can be used to understand significance of difference between models  Raftery (1995) BIC' difference of 6-10 between models is statistically significant   Said to be statistically significant to k-fold cross-validation for optimal k  Also easier to compute compared to cross-validation (but different formulas must be used for different modelling frameworks - no common formula across modelling frameworks)   Problematic as it does poorly when dealing with many parameters ; Q Matrices  ?The Q Matrix has questions as columns and concepts/skills as rows  Also called Knowledge Component Model or Skill-item mapping Skill-item mapping can be generated using  Manual development and refinement by domain experts  Refine by  Smoothing learning curves  Learning curves show relationship between amount of practice and performance (see Corbett &amp; Anderson, 1985) Spikes in learning curves often imply that two or more skills are being treated as a single skill  Actually a combination of two different learning curves     Look for skills with no apparent learning Look for problems with unexpected error rates     Automated model discovery  Use algorithms Often use non-negative matrix factorisation (like in the Matsuda et al., 2015) - see Desmarais (2011) Conditions for effectively deriving a Q-Matrix from data with Non-negative Matrix Factorisation    Hybrid approaches  ?LFA - see Matsuda et al. (2015)     Concepts are defined by experts Cells are filled based on whether each question needs the given concept in the row to correctly answer the question in the column  Filled with probabilities - P(correct | mastery of a concept) But don't you assess mastery of a concept based on whether you get questions correct, not the other way around?  Doing it this way creates a circular logic where you master a concept so you can answer a question, so you master a concept...       Barnes et al. (2005)  Used algorithm to derive Q-matrix To define how many skills, try models with one skill, then 2 skills...  For each number of skills, test all skill-item correspondences for that number of skills a pre-determined number of times, or until a pass results in no changes Once this is done, add more skills, and see if increase in number of skills leads to improvement in model performance Keep doing so until model performance does not improve Model performance (according to Barnes et al., 2015)  Items that share the same skills should have related performance Model degree of error is based on many item-student pairs the prediction gets wrong Skill is conjunctive - need all relevant skills to get an item right  As opposed to compensatory (Pardos et al., 2008) - possession of any relevant skill leads to getting the item correct   Assumes no learning from the items - getting item 1 right does not make it more likely that the student then gets item 2 right as a result       Problems  Correspondence between Q-matrices and student responses is not going to be 100% Does not take into account varied levels of conceptual mastery   ",165,77,88,5
"1298","Cross Validation","Cross-Validation methods  Estimate how accurately a predictive model will perform in practice Give an insight on how the model will generalise to an independent dataset  Of course this assumes that whatever is used as the test data is representative of the real-world data the model will be applied on   No validation  All available data used for training No way of finding out how the model performs on other data   Hold-out validation  Hold out x% of the data as a test dataset Problem - very dependent on which data are in each group   Hold one-out validation  Hold out one observation, train data on rest, see if it predicts the one Repeat, holding out another observation until all observations have been used as the hold-out  Use proportion of prediction error as metric of accuracy   Problem - Very computationally expensive   K-Fold Cross Validation - Calculate how accurate we are in each fold and average the answer  Typically what is used today Dataset is partitioned at random into k segments k distinct predictive models are constructed, being trained on all but one of the segments  Test on the remaining segment   Repeat, holding out a different segment each time Assess model quality by taking the average of results from all k test segments   ",0,3,-3,5
"1299","Hands-On Programming with R","     Grolemund (2014): Hands-On Programming with R Rstudio UI and R console  &gt; Denotes prompt (like python's &gt;&gt;&gt;) + Denotes a continuation of an incomplete command on the next line (press Esc to start a new prompt) [x] where x is a number indicates the index value of the first number of a row Ctrl + c terminates a set of code from running   R documentation Cheat Sheet - Organise and Update  ... - the ellipsis arguments allows variability in the arguments given to R functions  Allows  An arbitrary number and variety of arguments Passing arguments to other functions     # - comments ? - Pulls documentation for the function name that comes after ?? - Runs a search in the documentation for the text that comes after c() - Concatenate, accepting values to be concatenated as strings rm(list=ls()) - removes all variables currently loaded into memory in R paste(…, sep , collapse)  ... - the vectors to be combined (this happens element-wise with vector recycling if they aren't the same length) Sep adds items between the strings in the vectors to be combined Collapse, when defined, combines the vector into a single string, separated by the value in the argument   cat() - stands for concatenation and print round() - Rounds a number up/down  x - vector that the sample should be taken from digits - number of DPs (default is 0)   factorial() sum() - Calculates the sum of all elements of a vector mean() sample() - draws a random sample  x - vector that the sample should be taken from size - number of items taken from the vector as the sample replace - Sampling with (true) or without replacement (false). Defaults to false prob - vector of the same length as vector x, specifying the probability of each option  Probability in the vector does not need to add up to 1     seq() - Returns a vector with a sequence based on the following arguments  from - start number to - end number by - step/increment    rbinom() rnorm() args()  Takes a function as an argument and returns that function's arguments   [] ObjectA$ObjectB - Reference object B within object A order() - returns the indices of a vector in the order of lowest to highest  Can be used to reorder a vector (e.g. A[order(A)] gives an ordered list of whatever was in A)   library()  Imports a package accepted as an argument   load() - used to load a dataset file.choose() - opens a dialog box for you to choose the relevant file to open typeof() - accepts a vector as an argument and returns the data type it contains dim() - transforms an atomic vector into an n dimensional array  Accepts the vector as an argument, and is assigned a value of a vector. For this vector, each item specifies the size of one dimension.   names()  A names attribute can be added by  using the names() function and an assignment operator '='   matrix() initialises a matrix  will accept the following arguments  data - the vector that contains the data the matrix will be made from nrow - desired number of rows ncol - desired number of columns byrow - A boolean value that determines if the matrix is formed by rows or columns. Defaults to FALSE dimnames - defaults to null, but accepts a list of length 2 with the names of the rows and columns   as.matrix() also initialises a matrix, but is meant to convert a vector into a matrix   t() - transpose function  Transposes a matrix or data frame Rows --&gt; Columns, Columns --&gt; Rows Output is a matrix   diag() - Replace or extract the diagonal of a matrix factor() - creates factors  Accepts a string atomic vector as its argument is.ordered - specify as TRUE for ordinal data, FALSE for nominal data levels - to specify the levels for ordinal data (defaults to alphabetical order)  Can also be specified with the levels() function     data.frame() - initialises a data frame list() - initialises a list  names() - used to assign names to list elements   subset()  Data = Data set to be subsetted Subset = condition for subsetting   str() - shows the structure of a dataset  Output varies depending on the class of the object passed in   array() list() - creates a list data.frame() creates a data frame  Accepts vectors, separated by commas, as arguments Each vector should be set equal to the name of the column   as.character(), as.logical() and as.numeric() can be used to forcibly convert values between data types sys.time() returns the system time which() grep() gsub() format() - a bunch of functions that format R objects nicely  The base format() function is used to format numbers as strings  Digits - Number of significant figures (based on the smallest number in the vector, everything else matches the number of decimal places of this number) Scientific - whether the output uses scientific notation Trim - whether the output places spaces to make decimal points line up (False for yes (default), True for No) big.mark - A string to be used as a digit separator big.interval - Between how many digits should big.mark be used  E.g. format(1000000000, big.mark = "","", big.interval = 3, scientific = FALSE)  1,000,000,000     justify - left, right, center       Data Types  Integers - ""2L"" (The L indicates to store as integer rather than floats) Numeric (Floating Points) - 1.55  A numbers without an L are initialised as floating point atomic vectors   Character - ""A"" Logical - TRUE/FALSE  NA is considered a logical data type  NA tends to be contagious - any operation performed on an NA will return NA Use is.NA to find NA values - sampleVector == NA will return NA for all values in the vector     Complex - 1+4i NULL - indicates the absence of a vector - has length 0   Atomic Vectors  Every vector has two basic properties - length and data type (see above) Attributes - works as 'metadata' to an object  Dimensions - Vector is structured into an n dimensional array Names - labels for elements in the vector  These are assigned using the names() function e.g.  vec1 = (1,2,3,4,5) names(vec1) =  c(""One"", ""Two"", ""Three"", ""Four"", ""Five"")     Classes - Added to 'special cases' of atomic vector e.g. matrices. Use class() function to get class of object  Calling the class() function on a regular atomic vector will return the data type of that vector  Otherwise, it will return the class       Coercion Indexing  Use [] to indicate the index of a vector Unlike most other programming languages, counting starts at 1 Can pass a vector into the square brackets to select more than 1 element in the vector Also accepts index names When passing a boolean vector as an argument, [] returns the elements of the same index as the argument's elements which are TRUE   Element-wise execution and Vector Recycling  Unlike MATLAB, R does not use matrix rules for mathematical operations by default, including for matrices (see below)  Instead, it will apply the same operation between elements of the same index in involved vectors, looping the shorter vector until it is as long as the longer vector   To get traditional matrix multiplication, use %*% for inner multiplication and %o% for outer multiplication  Inner multiplication - rows of the first matrix multiplied by the columns of the second matrix Useful for Social Network Analysis     Matrices  A special case of vectors with rows and columns Rows and columns can be assigned names using the rownames() and colnames() functions. This allows referencing elements in the matrix rowSums() allows you to calculate the sum of rows, while colSums() does the same thing for columns cbind() allows concatenation of vectors/matrices to matrices by column. rbind() does the same thing for rows. diag() allows replacing or extraction of matrix diagonal Elements in a matrix can be selected using [row, column]. This can be done to select one element, or a range of elements (e.g. [1:3, 2:4])     Arithmetic and Binary Operators Logical Arguments Flow Control in R  For Loops  E.g.          v &lt;- letters[1:6]      for (i in 3:length(v)) {   ## Sequence   print(v[i])              ## Body}   Keeping output from loops  If you're keeping output from loops in a vector, always allocate sufficient space for the output - concatenating at each part of the loop is computational expensive     If Statements  E.g.        If {   } else if {   } else {   }        Functions  If a function is called without parentheses, the R console will output the function's source code Functions have 3 parts  Name Arguments Body   Arguments in R  In R, you can specify which term is passed as which argument Arguments may or may not come with a default value. Arguments without a default value must be given when the function is called. Otherwise, the default value is used   Defining functions using the function ""function""  functionName &lt;- function(arg1, arg2) {  Body of function }     Functions will return the result of the last line of code, even if no return statement is included  Hence, the only time you should be using a return statement is if you want to terminate the function early   Anatomy of a function  Formals - the arguments Body Environment - Usually in the global environment, but also package environments   In R, functions are objects  Can assign functions to an object  The object will then do the same thing that the function does (e.g. Take arguments etc)            Extract function in R studio You can highlight lines of code in an R script, then click Code &gt; Extract in the Rstudio menu Rstudio will then convert the highlighted code into a function, taking undefined variables as arguments    Anonymous functions  There isn't a need to assign function names To call an anonymous function, specify the function, then its arguments immediately after  E.g. (function(x) {x + 1})(2) Output: 3     Lazy evaluation  Arguments to functions are only evaluated when needed by the function body Hence, specifying an incorrect argument may not necessarily throw an error   Lexical Scoping  Each function call has its own environment, within which objects created within this environment are stored  Objects created in the function environment are not available outside the function, including to a second call of the same function   R looks for values of objects first within the function environment, then the global environment If it cannot find a value for the object locally or at higher levels, an error is thrown At best, try not to make a function operate based on objects outside the function body or arguments   R is a functional programming language. In R you can do anything with functions that you can do with vectors:  assign them to variables store them in lists pass them as arguments to other functions create them inside functions and even return them as the result of a function     Dates and Times  POSIXct and POSIXt are time conventions When these attributes are added to a numerical object, R knows to treat them as times, where the number reflects the number of seconds that have passed since UTC0000 Jan 1 1970  Thus, when printing the object, a timestamp will be reported     Factors  Used to store categorical data Used by passing an atomic vector with the category names into the factor() function  This will code the data as integers, and add a levels attribute to associate each integer with a category Printing the variable will print the category names, not the integers (can be seen using the unclass() function)     Data Frames  Data frames are 2D lists, with the class data.frame They are often the most useful data structure for data analysis Works like an excel spreadsheet (finally) In a data frame, each column is a vector. Between columns, there can be different data types, but within columns there is only one data type Data frames store strings as factors (i.e. categorical data) Selection of data frame elements can be done using [] in the same way as matrices (see above), using row/column indexes or names Selecting columns can also be done using $ (e.g. data_frame$name_of_column)   Lists  Opposite of an atomic vector is a generic vector, or list  Lists are made up of atomic vectors   Lists can also contain other lists     Lists are like atomic vectors as they store values in a 1D set However, unlike atomic vectors, lists do not group simple values, they group objects. Hence, they can store more than 1 form of data (including matrices and data.frames) When printed, the double brackets reflect which element (R object) in the list is being displayed. The single bracketed index says which sub-element of an element (index in a vector) is being displayed. Select list elements using double square brackets [[]], with the element number inside. Otherwise, use the name, with $, like in a data.frame Can add elements to a list using c(), like with atomic vectors     ",14,28,-14,1
"1300","Principal Component Analysis explained visually","Principal Component Analysis (PCA)  Works to find and define 'principal components'  With data within an n-dimensional space  Trying to find a new but smaller set of axes/directions/features/variables/dimensions That maximises the amount of variation maintained/captured about the data in this new space   These new axes/directions/features/variables/dimensions are called Principal Components Components can be conceived of as weighted combinations of the initial variables  Made to capture as much of the variance along the fewest variables so you can drop the rest Will almost never capture all the variance, since you have less dimensions  The idea is to MAXIMISE, not REPLICATE   Generate the best reconstruction of the data from the least number of dimensions If you want to replicate you would likely need the same number of dimensions, so just keep things as they are     Principal components are orthogonal (perpendicular) to each other  Any remaining variance that isn't captured by one component necessarily varies along an orthogonal dimension Components won't be correlated, since they capture variation that is entirely orthogonal to each other     Each component has an associated eigenvalue  ""Eigen"" - German for ""characteristic"" Created when linear transformations are applied to a matrix The size of the eigenvalue is relative to how well the component maximises variance Components can be expressed in terms of the sum of (initial variables * their associated eigenvectors)   Often applied as a dimensionality reduction technique  Feature Extraction - creating the components Feature Selection  If a component has an eigenvalue of 0, it is non-informative and can be dropped to reduce dimensions Elbow method  If the marginal increase in the number of components leads to a negligible increase in the amount of variance captured, stop increasing components - drop the rest       Issues  Data needs to be scaled Often centred such that the direction goes through 0 Outliers have an outsized impact on your result Needs continuous variables (or binary, but there might be problems with this) Better with larger samples, but no real way to test this Components will be uncorrelated  This may be a problem if you're trying to do correlations     ",6,2,4,3
"1301","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Bowers, A.J. (2010) Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping Out and Hierarchical Cluster Analysis. Practical Assessment, Research &amp; Evaluation (PARE), 15(7), 1-18. n = 188 Mentioned next steps is to gather more data to deduct hopefully more accurate clusterings.",0,0,0,3
"1302","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","""Perhaps one important change introduced by active learning is the facilitation of student net- works to be stronger, less centralized, or structured in some other new way to maximize student learning. Social network analysis (SNA) can help us assess these types of hypotheses"" (p.168).",2,0,2,4
"1303","Why Students Should Own Their Educational Data","""[Learning style theory] comes from analyzing a population and trying to parse out different ways of learning over a population. But when you apply it to one individual it doesn’t hold. You can’t start with averages, it doesn’t work."" ""If I had to push for one thing that I think is super important, that is that the user should own their data. There’s this default thing right now which is that everybody but the user owns their data. My vision that we’re going to push for in my organization is you’ve got to have a third party who is responsible for protecting learner data. Then the student could have, say, a decade of data about the way that they’re learning.""",5,0,5,2
"1304","Knowledge tracing: Modeling the acquisition of procedural knowledge","""The goal of the research was to implement a simple student modeling process that would allow the tutor to monitor the student's knowledge state and tailor the sequence of practice exercises to the student's needs."" ""Successful evaluations led us to (1) abandon an initial ideal student model and to model a sufficient set of rules, (2) to model difference in rule difficulty and (3) to model individual differences among students in learning and performance. The resulting model predicts student performance quite well and enables most students to reach a high level of task performance.""",4,0,4,3
"1305","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Educational Data Mining (EDM) versus Learning Analytics and Knoweldge (LAK) The International Educational Data Mining Society definesEDM  as  follows:  “Educational  Data  Mining  is  an  emergingdiscipline,  concerned  with  developing  methods  for  exploring  theunique  types  of  data  that  comefrom  educational  settings,  andusing those methods to better understand students, and the settingswhich they learn in.  The  Society  for  Learning  Analytics  Research  defines  LearningAnalytics   as:   “...   the   measurement,   collection,   analysis   and  reporting of data about learners and their contexts, for purposes ofunderstanding  and  optimizing  learning  and  the  environments  inwhich it occurs.”   ",1,1,0,2
"1306","Evaluating Machine Learning Models","Classification Metrics: predicting class labels given input data Accuracy: measures how often the classifier makes the correct prediction Confusion Matrix: to combat how accuracy makes no distinction between classes Per-Class Accuracy: avg per-class Log-loss: logarithmic loss gets into the finer details of a classifier AUC: area under the curve -- the curve is the receiver operation characteristic curve (ROC), the ROC shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives  ",2,2,0,5
"1307","Why Is Measuring Learning So Difficult?","Notes from Educause Video:  When measuring learning, you often have to simplify it to gather data, though it is a multidimensional activity. Knowledge is contextual. Multiple competencies to illustrate learning. [Mathematical] achievement is a construct. Divising a report for learners to show them what they are learning and what connections they are seeing without realizing it.  ",0,0,0,1
"1308","Saturday Morning Breakfast Cereal","Data cannot always speak for itself and what to do with it.",0,0,0,4
"1309","Data wranglers: human interpreters to help close the feedback loop","http://oro.open.ac.uk/40608/2/Clow-DataWranglers-final.pdf From Abstract: ""Closing the feedback loop to improve learning is at the heart of good learning analytics practice.""",1,0,1,1
"1310","Zuckerberg is ploughing billions into 'personalised learning' – why?","The dangers of personalised learningZuckerberg’s idea of personalised learning has three major flaws. First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists.Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result.People are different, and learn differently too. algogenius, CC BYFinally, children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher. In subcontracting out teaching to technology, the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced. There is also the issue of ensuring that children’s data is not misused. Recording children’s personal progress, preferences and needs poses a privacy risk if it is not managed properly. The recent example of Vtech, whose internet-connected childrens’ toys and gadgets were hacked revealing millions of images of children and chatlogs, illustrates the dangers – who’s going to decide what data is collected and how it is stored and used?Personalised learning brings with it all manner of complex issues involving children’s agency, power, collaboration and dialogue (or lack of them). But it also brings exciting prospects for the future.",6,11,-5,2
"1311","Translating Learning into Numbers: A Generic Framework for Learning Analytics","read pg. 42-57 9/15/17    Conclusion: ""It is still too early to base education fully on LA approachesalone, and we expect it never will be possible to do so.However, at the very least, opportunities this new discipline has to offer are to provide new support for learningactivities and stimuli for reflection. In our opinion, it is these opportunities that LA should pursue."" Greller, W., &amp; Drachsler, H. (2012). Translating Learning into Numbers: A Generic Framework for Learning Analytics. Journal of Educational Technology &amp; Society, 15(3), 42–57. http://www.ifets.info/journals/15_3/4.pdf  ",1,0,1,1
"1312","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Konstan, J. A., Walker, J. D., Brooks, D. C., Brown, K., &amp; Ekstrand, M. D. (2015). Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC. ACM Trans. Comput.-Hum. Interact., 22(2), 10:1–10:23. ""The factors that were predictive all relate to effort, prior courses, and baselineknowledge (in what appears to be only a negative effect resulting from ceiling effects)."" ""First, the course was simultaneously offered as a typical online-only MOOC and as a flipped-classroom face-to-face course"" ""Second, the course mixed programming and nonprogramming students together intoa two-track course model. "" ""Third, we have performed extensive evaluation of student learning outcomes, mea-suring baseline knowledge, knowledge at the end of the course, and knowledge 5 months thereafter. ""    ",1,0,1,4
"1313","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   ""We have developed an innovative method to discover skill models from the data of online courses.  Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts.  To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University.  The results show that  (1) our method outperforms human-engineered skill models,(2)skill models discovered by our method are interpretable, and (3)our method is remarkably faster than existing methods.  These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability""  ""6. CONCLUSIONWe found that eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction. Our empirical study showed that eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. We also demonstrated that eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique.     Creating effective online courses often requires intensive, iterative system engineering. Studying techniques for automatic skill model refinement and its application for evidence-based course refinement therefore is a critical research agenda for the successful future of online education.""       ",18,2,16,5
"1314","Chapter 1: Social Network Data","""Network"" data (in their purest form) consist of a square array of measurements. The rows of the array are the cases, or subjects, or observations. The columns of the array are -- and note the key difference from conventional data -- the same set of cases, subjects, or observations. In each cell of the array describes a relationship between the actors.  A simple example is shown as figure 1.2, which describes the network of friendship relations among four people.Figure 1.2.  Example of square array of network dataWho reports liking whom?",1,0,1,4
"1315","Learning Analytics Dashboards","Klerkx, J., Verbert, K., &amp; Duval, E. (2017). Learning Analytics Dashboards. In C. Lang, G. Siemens, A. F. Wise, &amp; D. Gaševic (Eds.),The Handbook of Learning Analytics (1st ed., pp. 143–150). Vancouver, BC: Society for Learning Analytics Research. https://solaresearch.org/hla-17/hla17-chapter12/  What kind of data can be visualized? For whom are the visualizations intended? Why? What is the goal of the visualization? How can the data be visualized?   ",1,0,1,2
"1316","Measurement and its Uses in Learning Analytics","What is measurement?  constructs measurement instruments validity reliability  Measurement models  factor analysis latent class and latent mixture models item response theory (IRT) growth models cognitive diagnostic models explanation and prediction ",0,0,0,5
"1317","Predictive Modelling in Teaching and Learning","    http://www.d2l.com/ 2 3 http://www.ellucian.com/ 4 http://www.blackboard.com/ 5 http://bluecanarydata.com/  http://www.civitaslearning.com/      Society for Learning Analytics and Research (SoLAR) and the International Educational Data Mining Society        ",0,0,0,2
"1318","Ethics and Learning Analytics: Charting the (Un)Charted","read page 49-57 9/15/17 Chapter 4: Ethics and Learning Analytics: Charting the (Un)Charted ""Gasevic et al. (2016) also suggest that further challenges remain ""to be addressed in order to further aid uptake and integration into educational practice,"" and see ethics and privacy as important enablers to the field of learning analytics ""rather than barriers""."" (p.49) A range of ethical issues was grouped within three broad, overlapping categories, namely: • The location and interpretation of data • informed consent privacy and the deidentifcation of data •the management classification and storage of data Prinsloo, P., &amp; Slade, S. (2017). Ethics and Learning Analytics: Charting the (Un)Charted. In C. Lang, G. Siemens, A. F. Wise, &amp; D. Gaševic (Eds.), The Handbook of Learning Analytics (1st ed., pp. 49–57). Vancouver, BC: Society for Learning Analytics Research.",1,0,1,2
"1319","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","""For a model to be explanatory, one should be able to understand - why the model achieves better predictive accuracy than alternatives.- in addition, the understanding of this why should either advance our understanding of how learners should either advance our understanding of how learners learn the relevant material or have clear implications for instructional improvements, or both.",3,0,3,5
"1320","Statistical graphics: making information clear – and beautiful","Gelman, A., &amp; Unwin, A. (2012). Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion) http://www.stat.columbia.edu/%7Egelman/research/published/vis14.pdf The purpose of this article is not to criticize but to explore the different goals that lead researchers in different fields to value different aspects of data visualization. Discovery goals (Statistical data visualization) v. communication (Infographics) goals of graphical design  http://www.wordle.net/ http://www.babynamewizard.com/ ^ Author considered babynamewizard the best visual.  Ultimately the interpretation of a graph is a joint product of the data, the designer, and the  viewer.",2,1,1,2
"1321","How to display data badly","Wainer, H. (1984). How to display data badly, The American Statistician, 38(2), 137-147 http://rci.rutgers.edu/%7Eroos/Courses/grstat502/wainer.pdf The aim of good data graphics is to display data accurately and clearly.  Showing data Showing data accurately Showing data clearly  Rules on showing data badly  Show as few data as possible (minimize the data density)  reflects on the efficiency of information transmission Tufte on ""Chartjunk""   Hide your data you do show (minimize the data-ink ratio)  Tufte on ""data-ink ratio"" - amount of ink used in graphing the data / total amount of ink in the graph Hiding data can be done either by using an overabundance of chartjunk or by cleverly choosing the scale so that the data disappears.   Ignore the visual metaphor altogether Only order matters   Tufte's measure of perceptual disortion (PD)   Graph data out of context Change scales in mid-axis Emphasize the trivial (ignore the important) Jiggle the baseline Austria first Label (a) ilegibly, (b) incompletely, (c) incorrectly, and (d) ambiguously More is Mruker: (a) More Decimal Places and b) More Dimensions If it has been done well in the past, think of another way to do it  Minard (1861) graph of the Frency Army's ill-fated foray into Russia Tufte (1983) Data Density Index (ddi) - the number of numbers plotted per square inch",6,5,1,3
"1322","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Gelman, A., &amp; Niemi, J. (2011). Statistical graphics: making information clear – and beautiful, Significance, September, 134-136 http://www.stat.columbia.edu/%7Egelman/research/published/niemi.pdf InfoVis - Information VisualizationShifting from making graphics beautiful, to making them clear.Example: Measles outbreak that began in autumn 2009 and continued throughout 2010.Data comes from WHO's Zimbabwe epidemiological bulletins. Key Questions:  Who is your target audience? What are you trying to show?   Guiding Principals for Statistical Graphics:  Avoid distracting elements. Use informative colour to visually associate elements. Keep the figure simple (and therefore in-terpretable).  Guiding Prinicpals for multiple plots:  Keep the x- and y-axes on the same scale. Eliminate repetitive information. Maintain consistency across plots.  Excel and R defaults are limiting, should be adjusted, if not through coding, then manually.",4,2,2,2
"1323","Junkcharts Trifecta Checkup: The Definitive Guide","Fung, K. (2014). Junkcharts Trifecta Checkup: The Definitive Guide http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html   Trifecta Checkup framework    heat map example - http://junkcharts.typepad.com/junk_charts/2014/05/how-effective-visualization-brings-data-alive.html   http://junkcharts.typepad.com/numbersruleyourworld/biography.html Kaiser Fung is a recognized expert, speaker, author and teacher in business analytics, and data visualization. He directs the Master of Science in Applied Analytics at Columbia University. He has built and managed data and analytics teams responsible for turning data into practical insights for Internet, entertainment and financial services companies, such as Vimeo, SiriusXM Radio, and American Express. He holds an MBA from Harvard Business School, in addition to engineering and statistics degrees from Princeton and Cambridge Universities. For over ten years, he has taught practical statistics, data visualization, and business analytics at New York University, various conferences, and corporations. He is the author of two books and two blogs. His most recent book is Numbersense: How to use Big Data to Your Advantage (McGraw-Hill, 2013). He also published Numbers Rule Your World: The Hidden Influence of Probability and Statistics on Everything You Do (McGraw-Hill, 2010). His acclaimed blog, Junk Charts, pioneered the critical examination of data and graphics in the mass media.  ",3,2,1,2
"1324","Cluster","The k-means clustering algorithm classifies n points into k clusters by assigning each point to the cluster whose average value on a set of p variables is nearest to it by some distance measure (usually Euclidean) on that set. The algorithm computes these assignments iteratively, until reassigning points and recomputing averages (over all points in a cluster) produces no changes.",0,0,0,1
"1325","Measurement and its Uses in Learning Analytics","This chapter provides the basis for educational data mining and learning analysis. This shows that we should not focus too much on coding techniques, but should follow the principles of learning theory and make full use of data mining techniques. The structures, main factors and theories that may be used in the EDM process are introduced.",0,0,0,2
"1326","Ethics and Learning Analytics: Charting the (Un)Charted","Since education data mining is not yet mature, we should follow some ethical principles to collect data. In order for our research to be appropriate, the introduction of ethical rules is necessary.",2,0,2,2
"1327","Predictive Modelling in Teaching and Learning","Chapter 5 introduces the application of predictive models in educational research. It involves data collection, feature engineering, common algorithms, diagnostic measures for model evaluation, and challenges and opportunities facing researchers in this field. It also helps us understand the differences in data and how to deal with missing data. ",0,1,-1,5
"1328","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Chapter 6 of this book introduces us to different educational data modeling methods, namely predictive models and interpretive models. This suggests that, although we always seek the accuracy of predictions, interpretation models may be better at explaining the behavior or outcome of educational data. This chapter also summarizes some common features of the interpretation model.",1,0,1,5
"1329","Statistical graphics: making information clear – and beautiful","It's important to make a neat and beautiful chart to show your results. There are basically three steps to building a beautiful graphic. First, understand who your audience is and who you want to show the chart to. Before drawing a chart, it is always important to understand their level of knowledge and expectations. Second, you should avoid irrelevant information and keep the diagram as simple as possible. Third, you should keep all graphics consistent and use the same scale to display comparisons.",1,0,1,2
"1330","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","NO LINKS",0,0,0,4
"1331","Junkcharts Trifecta Checkup: The Definitive Guide","Trifecta inspection is a universal framework for data visualization criticism. It captures the ideas behind how people organize their critical works. This is a clear framework that shows whether the chart is constructed correctly and well through three aspects: questions, data and visualization.",4,2,2,2
"1332","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This paper uses clustering methods, heat maps, and some categorical variables to analyze student data to analyze the characteristics of good / bad students. The results show that good students are less likely to drop out of school and more likely to take the ACT test. Red in the heat map indicates good students and blue indicates poor students. This picture is very intuitive and contains all the information. I really like it!    ",6,2,4,3
"1333","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article surveyed some students in the same class. First, I introduced some basic concepts of social networks. Then build a chart of interaction and communication between students. It can be very direct and helpful.",1,0,1,4
"1334","Why Students Should Own Their Educational Data","Because everyone's level is different, many students are in the same grade, but not everyone can understand the classroom content. Therefore, it is very important to have your own educational data. Of course, this also needs the cooperation of the education system. In many countries, students are not allowed to choose a course according to their preference, but all students take the course together. In my opinion, personal educational data can only become meaningful if the educational system is advanced.",1,0,1,2
"1335","Knowledge tracing: Modeling the acquisition of procedural knowledge","can't get in the page.(no account)",0,0,0,1
"1336","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This article is an inspiring research in the field of learning analytics. Since most of the previous study of learning analytics are qualitative research, it is important that we should use methods of data mining to do some quantitative research. Nowadays, there are many ways to get large amount of data. Educational data mining and learning analytics are different but correlated with each other. Therefore, it is important and necessary that we should have more knowledge of data mining. ",0,0,0,2
"1337","Evaluating Machine Learning Models","I really like this article because it introduces many useful measurement algorithm techniques in data mining. It includes classification, ranking, and regression, all of which are very useful, and each type has a different focus, strengths, and weaknesses. This article also provides us with some data issues that may cause problems with metrics. It also points out some important issues in using these methods to pursue our research goals.",2,3,-1,2
"1338","Why Opting Out of Student Data Collection Isn’t the Solution","In every privacy debate in every industry, the same question arises about the right of individuals to ""opt out"" of their data being collected or used. Therefore, it is not surprising that the “time” and “method” of parents and students choosing not to participate in the collection or use of educational data has become a sound trend",1,0,1,2
"1339","Why Is Measuring Learning So Difficult?","  Learning is one of the most dimensional problems.in the world.  The scope of knowledge and learning is too wide for anyone or any project.  Educational data mining is still immature. We have no specific encodings or packages for EDM.  The construction of learning in different cultural contexts is difficult to define.  It is difficult to find simple proxy indicators for our theme. Latent variables and various factors need to be considered in different areas including education, psychology and culture         ",0,4,-4,1
"1340","Saturday Morning Breakfast Cereal","Our research must be meaningful and reasonable. We can never overestimate or overly trust our mining results. It is also necessary to understand the basic theory and common sense of education so that we can interpret the results correctly.",3,0,3,5
"1341","Data wranglers: human interpreters to help close the feedback loop","NO LINK",0,0,0,4
"1342","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article discusses the dangers and potential of personalized learning. For danger: First, education is always about acquiring occupation-related knowledge and skills, but also about acquiring general knowledge. If we only let children learn what they are interested in, we may have many experts, but few generalists. Second, although learners may have difficulty adapting to learning styles that are not suitable for them, in the real world, life is not always so inclusive. Finally, children's preferences are not fixed. In addition, there is no evidence that personalized learning is more helpful than general education. Although this seems conservative, I think it's worth serious discussion.",2,3,-1,2
"1343","Feature Selection","Feature selection is a very useful and important research work. Generally, if there are many characteristics in our research, only a few of them are really important. For the first aspect, we need to choose a small number of features to make our results or models interpretable and reasonable to all our theories or studies. The second reason is to reduce the impact of the dimensional curse.",2,1,1,5
"1344","Chapter 1: Social Network Data","The first chapter of this book mainly introduces the concept of social network data and its difference from classic data. It also introduces some methods of analyzing these data and the work people have done in this field.",2,0,2,4
"1345","RStudio Cheat Sheets","This is very useful for every students who learning Rstudio.",0,0,0,1
"1346","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This article introduces several key dimensions and frameworks of educational data mining when designing educational research experiments. This article also introduces some limitations of EDM.",0,2,-2,2
"1347","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This report will evaluate courses by introducing a recommendation system. The goal of the project is to create a high-quality graduate program and MOOC recommendation system, and to explore MOOCs extensively through faculty and university interests. Then introduced some research methods, data and experimental results.",3,0,3,4
"1348","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Finding the right skills behind problem items is a daunting task. It requires a thorough understanding of the course content and the cognitive factors that determine student performance. Skill definitions and project-to-skill mapping require expert involvement. We study how to use data-driven matrix factorization to help experts accomplish this task. The two mappings of projects and skills are experts on the one hand and matrix factorization on the other. They compare their differences and performance in linear models of skill assessment and project outcome prediction. Visual analysis shows a relatively similar pattern between expert mapping and factor mapping, although there are differences. The comparison of the prediction results shows that the performance of the factorization method is slightly better than the original expert q matrix, which provides supporting evidence for the effectiveness of the factorization mapping. The implications of using factorization to design better project-to-skill mapping are discussed.",9,2,7,5
"1349","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This paper introduces a method to obtain the Q-matrix of project skill correspondence. The new method is more complicated than the currently popular LFA method. It incorporates multiple machine learning algorithms such as matrix factorization, bag of words modeling, and clustering. The research results show that the new method is superior to the artificial engineering skill model, the skill model found by the new method is interpretable, and the new method is significantly faster than the existing method.",6,0,6,5
"1350","Using data mining to predict secondary school student performance","These visualization methods provide a powerful and valuable mirror effect that, if used properly, can help teams become more efficient. The article methodically explains to the reader the advantages of this method. This is a science article, and I think it's very well written. But also triggered my thinking, how to use correctly? It's great to create something, but if not used properly, great technology can create darkness.",7,1,6,2
"1351","Developing a generalizable detector of when students game the system","Some students try to ""play around with the system"" in an interactive learning environment, trying to succeed in the environment by developing the characteristics of the system rather than by studying materials and trying to use that knowledge to answer questions correctly. In this article, we present a system that can accurately detect whether a student is in a game system or a math course in a cognitive tutor. Our detector also distinguishes between two different types of games, which are related to different learning outcomes. We explored the universality of this detector and found that it was successfully transferred to the curriculum for new students and mentors.",3,0,3,5
"1352","Big Data in Education","The link doesn't work.",1,0,1,4
"1353","Cross Validation","Good explanation. The part with averaging the valdations was really the part I missed, now I think I understood the general concept of this.",1,1,0,2
"1354","Hands-On Programming with R","This article gave me an introduction to Rstudio. In addition, the examples in this article aroused my great interest in R. Nobody likes boring articles. But this article shows you how to use R in a fun way. I love this article!",4,1,3,2
"1355","Principal Component Analysis explained visually","     Very useful! Would be neat to add something about how to analyze and understand the PCAs too. Like in the last example, how do we go from seeing that N Ireland is far away from the others to understanding why.         ",3,0,3,2
"1356","Measurement and its Uses in Learning Analytics","pp.34-48     An introduction to educational and psychological measurement for practitioners in learning analytics and educational data mining.  After reading, I have a better understanding of measurement. This chapter shows a complete process of constructing models and it would be a great example if we need to do the similar thing in the future.    ",2,0,2,2
"1357","Ethics and Learning Analytics: Charting the (Un)Charted","pp. 49-57 The focus of this chapter is on ethics in learning analysis. I haven't thought much about this before. The three main issues are 1) The location and interpretation of data, 2) Informed consent, privacy, and the de-identification of data, 3) The management, classification, and storage of data.  Based on the issues, they concluded some principles, then some elements for student-centred learning analytics. In 2014, eight principles were concluded based on the ""Policy on ethical use of student data for learning analytics"" published. To be honest, as a student, I don't care if my data is used for develop education, but I'll feel better if they ask for agreement.",2,1,1,2
"1358","Predictive Modelling in Teaching and Learning","pp. 61-68     This article describes the process, practice, and challenges of using predictive modelling in teaching and learning in both EDM and LA predictive model. The models has become a core practice of researchers, largely focus on predicting student success as operationalized byacademic achievement.  It provides a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process, and a brief overview of the most popular techniques in the field.    ",3,0,3,3
"1359","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","pp. 69-76 Usually, models are evaluated by the accuracy of their predicted results. This article focuses about cognitive models, showing the progress of discover cognitive models and how to improve them.",1,0,1,5
"1360","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The article makes me understand the difference between infovis and statistical graphics. It is true that people not in field of statistics appears not interested in theoretical graphs. They pretend more intuitive information that helps them with making decisions. The article shows and discusses different types of visualization. And they conclude that the Baby Name Wizard did the best because it interpret information in an attractive, interesting, and open-ended way, which is the way most people seek. I very much agree that ""the interpretation of a joint product of the data, the designer, and the viewer."" This is also our principle of data visualization.",3,1,2,2
"1361","Junkcharts Trifecta Checkup: The Definitive Guide","A guide to check if your graphs are ""chartjunk"". I first know this concept in Tufte's book. Comparing to the abstract principles in the book, this guide let you first clear your purpose, and it seems easier to understand. But it doesn't contain enough details and examples as Tufte's book. Though it's just a general framework for data visualization criticism, there are much more kinds of issues a data visualization could have. Combining both information should be better to check your graphs.",4,1,3,2
"1362","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","School lack an efficient way to patten and visually interpret disaggregated achievement data collected from students as a methods for helping decision making. Overall it is analyzing students by historical data. It describes how they collected data, analyzes different indicators including the scores graded by the teachers and hierarchical clusters, and makes data visualization. After they got conclusion and explained, they provides some suggestions.",0,1,-1,3
"1363","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","A great topic, at first. Social relationships could be very influential for students and classrooms are top priority. The article introduces network concept, how they collected the data, and explains their standard for measurements, which make sense and is easy to understand in my eyes. Including variations, they conclude that ""networks are a relatively simple but powerful way of looking at the small and vital communities in every school and college."" It's hard to say their measurements and standards is rigorous in this case, so their analysis temporarily could be reference only.",2,1,1,4
"1364","Why Students Should Own Their Educational Data","The author's main point is that custom made different study method for individuals is a good way to enhance the efficiency of study because different people have different levels of skills.Besides, users have the right to know about their behavioral data and analysis is  I would say their research sounds exciting after reading this article and I'm looking forward to their success. However, there are still many efforts to be done in the future (like data collecting and analyzing) and how could this work will still be problem. Since today’s society needs comprehensive talents, I don't think improving individual's ability of their talent is a absolutely correct choice. Their product might be properly used for targeted education rather than universal education. Also, though customize teaching is a relatively the most effective form of education, we don’t have as many educational resources for everyone.",9,1,8,2
"1365","Knowledge tracing: Modeling the acquisition of procedural knowledge","This article introduced a type of model constructing by obtaining students' changing learning/knowledge condition when they are studying. While the students are working, the director would maintains an estimate of the probability that students has learned each of the rules in the ideal model by a progress called knowledge tracing. The director changes the teaching methods by each student's progress until everyone get every idea. Through the research, knowledge tracing is proved effective and leads to improvement. And currently the model is working great in predicting test performance. The article also discusses how to improve the model.",7,0,7,3
"1366","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Improving teaching methods through big data will become a trend, and teachers can better understand students through data. From the article I can see scientists have made a lot of efforts to achieve this goal. The development of such projects also requires cooperation from people in multiple fields that data is a very important part. The two main things in this article is educational data mining (EDM) and learning analytics and knowledge (LAK). And I believe our class would focus more one EDM, which is described as ""developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in."" By comparison, the author clearly shows us different focus of the two fields.",3,0,3,2
"1367","Evaluating Machine Learning Models","There are infinite opportunities in data science, but also lots of confusion. Machine learning as an emerging technology, needs too many directions to develop, and at the same time leads to increased demand for talented people. Evaluating a machine-learning model is a new work from out branch, and it could be helpful but difficult at the same time.",3,2,1,2
"1368","Saturday Morning Breakfast Cereal","Hmm ... that's ironic and so true... So ever since media misinterpreted research results, everything is out of control. I think it's trying to tell us that interest and creativity are the most important factors to begin a career instead of mandatory training. And the research results should be interpreted in a proper way.",1,1,0,2
"1369","Data wranglers: human interpreters to help close the feedback loop","I totally agree that ""The quantity of data, and the range of different data sources, can make it difficult to take systematic action on that data."" So data wrangling is an effective way to organize our data, and data wranglers are necessary for various researches. The paper introduced how data wrangling works and provided some examples with visualization. They claims that ""The aim of the Data Wranglers is to improve the learning experience"" which I also agree with.",1,1,0,1
"1370","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personality does play an important role in students' achievement. Discovering potential features represented by personalities can help us to find what fits us better, and it's also helpful for teachers to teaching by aptitude. So I think Zuckerberg's action is overall beneficial. As for the dangers of personalized learning, I also agree with the potential risks. After all people are very resilient and people have great potential. General education could help making versatile person.",4,2,2,2
"1371","Feature Selection","Feature Selection: Why: 1) knowledge discovery, interpretability <U+2260> in sight. 2) curse of dimensionality. easier learning problem.  ",1,1,0,5
"1372","Chapter 1: Social Network Data","An easy to understand introduction. Differences between conventional and network data. Basically learned in statistics class",0,0,0,4
"1373","RStudio Cheat Sheets","Data wrangling: Functions used most frequently from this sheet: gather &amp; spread. Changing the structure of data, making them easier to be visualized or organized.",1,0,1,1
"1374","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This paper introduced the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching. More specifically, the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. The framework they constructed makes everything clear to see, and it's helpful for comprehensively analysis. And the visualized data allows teachers to make conclusion or find out issues easier.",3,4,-1,2
"1375","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Theoretical overviews of the field.",0,0,0,2
"1376","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article describes the comparison of a model the authors' team developed that find the accurate set of skills and knowledge for specific course, and the existing methods (LFA) and human engineered skill models. The results shows that the authors' model are interpretable, outperforms human-engineered skill models, also remarkably faster than existing methods. The authors first describe some of their assumptions and how they handle the data. Then building the model and apply it to the example, evaluating and analyze the results after they obtained.  After reading the paper, in general, the model's conclusions are still based on the information entered when the model was originally built. This kind of problem they have to solve is a bit subjective, so the evaluation criteria may not be unified, and I personally have some doubts about the efficiency of this model. However, it is undeniable that their research results will play a role in the education industry. I believe this will save some manpower.  ",5,2,3,5
"1377","Big Data in Education","CHAPTER7, video1: clustering. Trying to find data points that ""group together"", and is effective in large feature spaces. First, decide how many clusters we wanted, 4 for example; pick the starting values for the ""centroids"" of the clusters(usually chosen randomly). We classify every point as to which centroid it's closest to the defined cluster. Then re-fit the centroids as the center of the points in each cluster. Repeat the process until the centroid stop moving. (basically could do in R with simple codes like 2~3 lines)   Chapter7 video 2: Also clustering, validation and selection of K The value of k is which set of clusters to use, the more is not better. Try several values of k and chose the one with best value of AIC or BIC. Mean Squared Deviation/Distortion(A series of calculations): will often be smaller with more clusters. Cross-validation can't solve this problem. Because it's a different problem than prediction modeling, instead, determining whether any center is close to a given point. More clusters cover the space more thoroughly.   Chapter 7, video6: Q-Matrix(KC model: knowledge component model) A table where each row is an item and each column is a skill.   chapter one video1: Introduction of the class. educational data mining or learning analytics. escalating the speed of research on many problems in education. Unique learning trajectories of individuals &amp; the sophistication of the models of learning foes ip enormously. Great. Promote: 1) New scientific discoveries &amp; to advance learning sciences. 2) Better assessment of learners along multiple dimensions. 3) Better real-time support for learners. Will be focusing on the methods of broadest usefulness, not coolest newestness. Types of EDM/LA method<U+3001> prediction<U+3001>structure discovery<U+3001>relationship mining<U+3001>discovery with models.   Chapter 1 video3:Classifiers. Part 1 Prediction:Develop a model which can infer a single aspect of the data(predicted variable) from some combination of other aspects of the data. Sometimes used to predict the future. Sometimes used to make inferences about the present. Categories that you want to predict. Classifiers: RapidMiner, SAS Enterprise Miner, Weka, KEEL useful algorithms: step regression, logistic regression, J48/C4.5 Decision Trees, JRip Decision Rules, K* Instance-Based Classifiers.   Chapter1 video4:Classifiers, Part2 Explained remaining algorithms Part1 don' t have.      ",9,8,1,1
"1378","Cross Validation","Ultimately goal: find a way of predicting values and then testing them. Assessing how the results of a statistical analysis will generalize to an independent data set. Mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. Use a model that is complex enough to fit the data without causing problems on the test set.",1,2,-1,5
"1379","Hands-On Programming with R","chapter 1, learned: operation interface, settings and windows; how to do basic grammar and calculation in r; some functions (and their arguments) that simplify calculation. chapter2, learned: install packages and how to get detailed information of packages and function by using help page; features of some packages; chapter3: types of data; some properties of data sets; how to load and save data",0,0,0,1
"1380","Principal Component Analysis explained visually","Giving visualization examples from 2D to 3D and ND to explain principal component analysis, which is used to emphasize variation and bring out strong patterns in a data set.",1,0,1,2
"1381","Measurement and its Uses in Learning Analytics","Psychological measurements can provide us a relatively reliable standard to make claims about states of mind. From this article, we can learn a thematic introduction of constructs, instruments, and sources of measurement error toward increasing technical detail about particular measurement models and their uses ",0,1,-1,5
"1382","Ethics and Learning Analytics: Charting the (Un)Charted","This article tells us that as the learning analytics matures and becomes more pervasive in our society, how to deal ethics properly and protect privacy against surveillance have 9become important issues to consider. Also, the chapter provides an overview for us of how our own thinking has developed and maps our journey against broader developments in the field.",2,0,2,2
"1383","Predictive Modelling in Teaching and Learning","Predictive analytics are a group of techniques which can make predictions about uncertain future events based on the previous observations. As for now, computational and statistical methods for predictive modelling are pretty mature. As for statistical modeling, there are many types of data and predictive models can be considered. In order to choose the best prediction upon the models, there are many ways to evaluate and test the forecasting accuracy. With predictive models becoming increasingly complex and incomprehensible, it is very important to discuss more and make a better drive methodological choice between explanatory and predictive modelling techniques.",3,3,0,3
"1384","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","In order to get a better predict outcomes, more explanatory models can be built and developed. Educational data mining efforts are more focus on improving to learn outcomes/or theory which lad to on impelling two types of models: the statistical model and the cognitive model. From the model discovery and analysis, students can make a comparison from the resulting model. The relationship between educational data mining, learning theory, and the practice of education can produce a better explanatory power of model which can forecast accurate outcome than others.",2,0,2,5
"1385","Statistical graphics: making information clear – and beautiful","Making information clear and beautiful graphics is an obvious way to present information. But not all graphs are created equal. A well-designed graph can make clear what an ill-thought-out one conceals.The author provide default plots of the time series of cumulative confirmed measles cases in Excel and in the package familiar to all statisticians, R. The Excel and R graphs share an even more serious problem, which is that they are labelled and scaled to fill an entire screen. The time series presented here is uncomplicated and could easily fit on a small portion of the page, if the labeling were sized appropriately.The author offered means to create better graphs.To  construct a more beautiful and informative summary of data and inferences, every decision needs to be made consciously and with intent. Improving figures requires two key decisions:Who is your target audience? What are you trying to show? To create the small multiple plots, we utilized another set of guiding principles: Keep the x- and y-axes on the same scale. Eliminate repetitive information. Maintain consistency across plots.",5,2,3,2
"1386","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","School personnel currently lack an effective method to pattern and The importance of graphical displays in statistical practice has been recognized sporadically in the statistical literature over the past century. Outside of statistics, infographics (also called information visualization or Infovis) is huge, but their purveyors and enthusiasts appear largely to be uninterested in statistical principles. The purpose of the present article is to start a conversation between practitioners in statistical graphics and information visualization. The author wanted to get the best researchers in these fields to learn from each other by identifying the different goals that motivate work in these two areas. The paper discussed a lot about the different goals involved in creating statistical graphics, and so it is appropriate to end our discussion with a statement of our goals in writing this article. We would like to broaden the communication between graphic designers, software designers, statisticians, and users of statistical methods. This is an old point but one that bears repeating. By recognizing the diversity of goals involved in data graphics, developers and users alike might be in a better position to create eye-catching as well as informative visualizations of data and models, even if both these goals are not typically achieved in a single display. Ultimately the interpretation of a graph is a joint product of the data, the designer, and the viewer. With the increasing prominence of innovative infographics in the news media and the web, viewers are changing their expectations of data presentation, and, more than ever before, statisticians should consider the diversity of means to achieving the very different goals of attracting attention, displaying patterns, displaying data in a way that allows for discovery, and getting viewers intellectually involved with data. As is illustrated in the historical reviews such as Wainer (1997) and Friendly (2006), there is a centuries-long tradition of data graphics that are both informative and beautiful. We should seek to continue this collective endeavor, and we hope the present article sparks a discussion among statisticians, computer scientists, graphic designers, psychologists, and others who are interested in the graphical presentation of data and inferences.",8,1,7,2
"1387","Junkcharts Trifecta Checkup: The Definitive Guide","Explore the form of junk data from three questions :1. what is the question? 2. what does the data say? 3. what does the visual say. The lack of answer of any of three question will leads to a type of junk chart.",1,3,-2,2
"1388","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. The study design and the hierarchical clustering and visualization clustergram methods are adapted from the data mining literature detailed above. The central purpose of this study is to introduce hierarchical cluster analysis and pattern visualization methods from the data mining literature and demonstrate the method’s utility through one example, identification of student dropout from student K-12 longitudinal grades. This study details the application of HCA and visualization of subject-specific teacher assigned grades. While there is disagreement in the data mining literature over which distance measure and clustering algorithm are best for different applications, the uncentered correlation and average linkage methods were chosen here based on their known ability to provide distinctive clusters to provide an initial example application of the method.",1,2,-1,3
"1389","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This passage provides a very new perspective to help the performance in class. It tries to develop student performance from social network. Some researches show that their might be an inner relationship between the position in social network and class performance for students. It could be a new way to discover how could we use big data and users history and records to analysis student’s performance in class, could this be a way to help students get better performance can be discussed more.  ",1,0,1,4
"1390","Why Students Should Own Their Educational Data","Different students have different ways to study, owning their educational data could help students know themselves more, therefore improve their study performance. Nowadays, data analyzing is changing from groups to individuals. Group analyzing is useful but not applicable to everyone, behavior information should be analyzed based on each person. It is because different people are different, group analyzing may not be able to perfectly represent their study behavior. It could be great to have a more specific study methods for each student rather than a group.",2,0,2,2
"1391","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper describes an effort to model students’ changing knowledge state skill acquisition. Students build a model called Knowledge tracing with APT.  The tutor presents an individualized sequence of exercise to the student based on these probability estimates until the student has ‘mastered’ each rule. According to the research, effective learning environment can make students significantly accelerate the learning speed and master cognitive skills.",2,0,2,3
"1392","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","LAK (Analytics methods) and EDM (Software methods) are two different tools which can both increase and formal communication and collaboration through many fields. Although they both reflect the emergence of data-intensive approaches to education, LAK and EDM have different focus on discovery, reduction &amp; holism, origins, Adaption &amp; personalization, techniques &amp; methods. Friendly competition between the LAK and EDM communities can promote the growth of each community in science.",0,0,0,2
"1393","Evaluating Machine Learning Models","There are many indicators of supervised learning model, and we need to fully consider the diversity and accuracy of indicators when building the model. But at the same time, I think the development of the model should also be considered. With the change of objective factors, the importance of different indicators is constantly changing, so it is necessary to timely adjust the proportion of each indicator that affects the model, because no indicator is always important.",1,1,0,4
"1394","Why Opting Out of Student Data Collection Isn’t the Solution","Privacy choice is a very common option in browsing network, but should we use the data to analyse the behavior of students. The main concerns would be the policies and parents don’t trust the use of data. They are worrying that the data may be used to unproper ways. When analyzing data, parents’ choices should be respect and considered. We should looking for other ways to develop the data analyzing and use again.",2,1,1,2
"1395","Why Is Measuring Learning So Difficult?","Learning is very difficult to measuring because learning is multi-dimensional things and difficult to find the reliable simple indicators we can trust to measure it.",1,2,-1,1
"1396","Saturday Morning Breakfast Cereal","This comic is using an interesting way to explain how stupid is to find out a uniformly feature of engineering and provide the related education to the kids.",0,1,-1,2
"1397","Data wranglers: human interpreters to help close the feedback loop","The paper describes a programme of human Data Wranglers deployed at the Open University,UK,charged with making sense of a range of data sources related to learning,analyzing that data in the light of their understanding of practice in individual faculties/departments,and producing reports that summarize the key points and make actionable recommendations.The author has presented an account of Data Wranglers.Substantial progress has been made in establishing a Community of Practice in learning analytics data to academics who are in a position to take action,and through extensive engagement.Progress has also been made in improving institutional learning about the quality and interpretation of the available data,and hoe better data can be captured and made available. students and teachers are closest to the learning experience and best placed to take rapid, appropriate action in the light of learning analytics data, but managers and policymakers are able to take action at a much greater scale of impact. The process can appear messy, and it is easy to focus on disappointments. However, it is only through the detailed process of engagement and dialogue between analysts, stakeholders and the data that insight and organizational change are developed.  ",6,2,4,1
"1398","Zuckerberg is ploughing billions into 'personalised learning' – why?","Zuckerberg’s personalized learning plan is considered as a way to improve learning effectiveness. But there could be some disadvantages. Such as children only care about what they are interested in, or they don’t have a fixed hobby or their personal information is not protected properly. Although personalized learning could be a good way to improve study effectiveness, those flaws could have a bad effect to children’s study, this is something we don’t know.",5,3,2,2
"1399","Feature Selection","The complexity of the model will increase exponentially with the increase in the number of the features. So we must use some algorithms to simplify the features, retaining only a few features that are important to the model.",0,1,-1,5
"1400","Chapter 1: Social Network Data","Traditional data focuses on itself, but network data focuses on different data analysis methods and ways of thinking to guide different results.Network data is considered from a more holistic perspective, considering the connections between data. Network data analysts tend to see individuals nested within networks relationships with others.Network data sets are often used to describe the relationships between nodes.  ",0,0,0,4
"1401","RStudio Cheat Sheets","R cheat sheet provides the detailed information about the R panel.",0,1,-1,1
"1402","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","This reading can not be found.",0,0,0,5
"1403","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Learning Analytics (LA) is expected to become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance with the increase in available educational data. In this paper, the author explored the key dimensions of Learning Analytics, the critical problem zones, and some potential dangers to the beneficial exploitation of educational data.The paper proposed and discussed a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. The six dimensions of the proposed LA framework are:stakeholders, objectives, data, instruments, external constraints, and internal limitations.Each of the dimensions can be subdivided into several instantiations falling into that dimension. The main opportunities for LA as a domain are to unveil and contextualize so far hidden information out of the educational data and prepare it for the different stakeholders. The author proposed framework model in the paper which stressed the inherent connections between the six different dimensions and the impact of the analytics process on the end user and the data suppliers. If one of the parameters changes, the outcome and anticipated benefits will change. It is therefore our conviction that only the consideration of all six dimensions in the design process can lead to optimal exploitation of LA. LA has the potential for new insights into learning processes by making hitherto invisible patterns in the educational data visible to researchers and end users, and to enable development of new instruments for everyday educational practice. However, there are substantial uncertainties about the extent of impact LA will have on education and learning in general. The proposed framework model is motivated by the potential and opportunities that LA offers in its relevance for educational development and opportunities to personalize learning.",7,9,-2,1
"1404","The Big Five and Visualisations of Team Work Activity","Visualization could be a very useful tool to improve effectiveness. There’s a lot of factors need to be considered in teamwork. If we can use computer tools to provide visualization to help team member from social psychology level, that could help the team to improve their performance.",1,0,1,2
"1405","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This article includes qualitative observations, lessons learned, and future directions.",0,0,0,4
"1406","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Introducing the basic rule and theory of matrix factorization.",0,0,0,5
"1407","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","In order to discover the most efficient, practical methods from the data of online course, experts from CMU compare their method with existing methods and human engineered skill models on three Open Learning Initiative courses. From the deep analysis, they conclude that eEpipHANY is an efficient, practical and quick method which can used in actual online courses than human crafted models. It is a collection of data mining techniques for automatic discovery. Using techniques and application for evidence-based course is a critical research for a success future online education.",4,1,3,5
"1408","Using data mining to predict secondary school student performance","This study use Business Intelligence (BI)/Data Mining (DM) techniques to model and predict student achievement in Portugal of two core classes (i.e. Mathematics and Portuguese) in secondary education, with two different data sources: mark reports and questionnaires. The aim of the research is to predict student achievement and if possible to identify the key variables that affect educational success/failure. Three input setups (e.g. with and without the school period grades) and four DM algorithms (e.g. Decision Trees, Random Forest, Neural Net-works and Support Vector Machines) will be tested by using RMiner. The cross-validation of 10 folds is also used to access the predictive performances. From the results, the linear function methods (DT and RF) achieve a higher predictive accuracy than the nonlinear function methods (NN and SVM). It may be explained by a high number of irrelevant inputs. It has shown that student achievement is highly affected by previous performances, and slightly affected by number of absences, parent’s job and education, alcohol consumption.    ",1,0,1,3
"1409","Developing a generalizable detector of when students game the system","Some students are smart and like to game the system, trying to cut corners and get the best grades with the least effort. They can do so that they are very talented, but, the devil is a tall order, this road has not worked, only continue to enrich their own knowledge, to find a new way.",6,1,5,2
"1410","Big Data in Education","From this video I have understood how simply classifier models work.Sepcificly diagnostic mertics. We could apply this kind of methodology on various question by computing kappa get a accuracy rate.",0,0,0,5
"1411","Cross Validation","Cross validation is a solution proposed to ensure that every data can be used as efficiently as possible for a limited data set without overfitting. A simple method is to divide the data set into several identical subsets, and use each subset as the test set in turn, and the others as the training set. We can get an optimal model as long as the bias of each model is calculated and averaged.",0,3,-3,5
"1412","Hands-On Programming with R","The first three chapter provides the fundamental code and introduction  to  R, which is useful for novice to learn.",0,0,0,1
"1413","Principal Component Analysis explained visually","pca is a useful method in eliminating the dimensions in the dataset, which is helpful to find the most principal factors.",0,0,0,3
"1414","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Bowers has used hierarchical cluster analysis heatmap to cluster k-12 students, with elementary, middle, and high school cumulative grades as variables for clustering. He has also attempted to correlated clusters with categorical variables such as dropout, ACT taking status, gender, and district. He compared heatmaps produced from GPA of different grades. From the heatmap, it is easy to find how many cluster there are based on the different colors of GPA's. It is also easy to find correlation between clusters and variables such as dropout, ACT taking, gender, and district. The higher students' GPA's are, the less likely they will drop out and the more likely they will have taken ACT.",2,2,0,3
"1415","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article introduces concepts, data collection and processing, methods, and analysis surrounding social network analysis (SNA), meanwhile providing resources for further study and research. Although having used a small dataset of a class, the case has illustrated the whole process of SNA. The case shows how to carry out descriptive, exploratory data analysis, as well as potential explanatory analysis concerning relationship between actor position in the network and education outcomes. Through comparing the two sociographs for the first and second exams, we may find obvious difference in terms of density and transitivity. We may also compare pattern changes in factors like gender, study group, and performance by observing shapes associated with these factors. The further exploration of change patterns for each group via the parallel coordinate plot can illustrate overall changes from exam 1 to exam 2. A similar, but more complex, visualization tool is a loomchart. For now, the SNA technique has developed advanced methods to test statistical hypotheses, as mentioned by the article. This is good for exploration of more complicated relationship.",3,3,0,4
"1416","Why Students Should Own Their Educational Data","It is possible to use online learning data to promote individualistic learning for students, but this is possible constrained by some conditions. Of course, with education data covering each student, teachers can know a student's idiosyncratic learning styles and provide this student with tailored advice in terms of how to effectively grasp the stuff the teacher is teaching. But this is only possible when the class size is not too big so that the teacher has the time to analyze and interpret the meaning behind the data and communicate with students to confirm the teacher's understanding of the data. If the the class contains, say, 50 students, the teacher will end up getting herself or himself too busy with dealing with education data, deprived of time to think about how to improve her or his teaching itself. With a big class in hand, the teacher may have to leave each student analyzing her data by herself. When this occurs, we never know how effective a role data will play in boosting individualistic education.  ",1,0,1,2
"1417","Knowledge tracing: Modeling the acquisition of procedural knowledge","This article shows the working mechanisms of a Bayesian cognitive model used in an intelligence tutoring system. The model simultaneously interacts with the students in their process of taking exercises, calculating the probability of their having mastered the skills underlying each problem they have done and determining whether to let students pass or giving them more exercises for practice. This system has a high internal validity as well a high external validity. That is, they are applicable to tests where students do the work by themselves without interacting with the tutor. The advantage of this Bayesian system lies in its ability to incorporate previous empirical information, i.e., whether students have done the exercises wrongly or rightly in the prior problems, its ability to use individualized parameters for each student, and its ability to adopt slipping and guessing parameters.",6,4,2,3
"1418","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This essay is a good summary of the similarities and difference between educational data mining and learning analytics. They have a lot of similarities: Researchers in both areas learn machine learning concepts and attempt to explore patterns behind data in education. On the other hand, an essential difference lies in their purpose: Whereas data miners aim at data and techniques, learning analysts more focus on using data to help education practitioners to improve teaching. I agree with the authors' opinion that researchers in both areas should learn from each other and improve their respective research.",2,1,1,2
"1419","Evaluating Machine Learning Models","This article briefly summarizes the diagnostic measures for three types of algorithms in data mining, including classification, ranking, and regression. Each type has several different metrics which have different focuses and thus advantages and disadvantages. The article closes with caveats for problems with the data that may render the metrics problematic. The important thing in using theses measures is to realize each one's features and select appropriate one(s) for specific purposes.",0,5,-5,5
"1420","Why Is Measuring Learning So Difficult?","I agree that to measure learning is difficult, but this does not mean that it is impossible to give up measuring learning altogether. One difficulty lies with measuring learning process, but actually there are growth mixture models and a host of longitudinal models aimed to measure students' progression in terms of some education outcomes. Another effort has been made by Dr. Bowers in Teachers College who has managed to map students' overall academic information in heatmaps and Hilbert curves. More valuable, successful attempts will appear in the future. So, instead of complaining about futility of measuring learning, let us put more effort in devising effective means of measuring learning itself.",3,3,0,3
"1421","Saturday Morning Breakfast Cereal","This comic satirizes the current practice of forcing middle and high school students to learn math and then using standardized tests to examine their performance and punish those teachers who have not helped students to improve on such tests. The comic also implies that education policy makers may have confused correlation with causation. Entering engineering fields is correlated with being good at math, but may not be caused by that. The real cause may be interest and motivation which determine both entering into engineering career and good performance in math. This is shown in the comic where a child likes playing clocks because she likes engineering and you cannot force a child to enter engineering by forcing her to play with clocks.",4,1,3,2
"1422","The Data Wrangling Cheatsheet","This cheatsheet is very helpful, especially when it comes to dealing with data processing. Before viewing this cheatsheet, I only knew ""join"" and related methods to concatenate different datasets, but now I have the two powerful tools of tidyr and dplyr. The only thing is that I need to practice with the dozens of specific commands in the sheet before I can skillfully use them to process data.",2,0,2,1
"1423","Data wranglers: human interpreters to help close the feedback loop","The practices of hiring data wranglers to help interpret education data for education practitioners is inspiring. I was especially impressed by the fact that a wrangler wrote a 20-30-page report each month and helped administrators to interpret education data when the need arose. The data wranglers analyzed ranged from a small bar chart to education big data. I agree that such a job of data wrangling is very necessary for teachers and policy makers who may not know much about how to explore the meaning behind various types of data.",2,0,2,2
"1424","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article discusses both the dangers and potential of personalized learning. A main problem mentioned is the lack of a definition for this type of learning. Without a definition, it will be rather difficult to talk about the advantages and disadvantages of personalized learning. If it is defined as letting students choose whatever they like to learn, of course the learning outcome will probably not optimistic since students tend to learn only easy or interested stuff. Two issues arising in the comments of this article are worth discussion. First, motivation of learning may take a large weight in deciding the learning outcome. With low motivation, it will be not easy to help students learn what they do not like. For those students, the first thing be to increase motivation first. Second, personalized learning does not necessarily mean that they may get more attention from teachers, which however tend to decide the learning outcome. One on one study is available only to the elite, and teachers need to pay sufficient attention to students even when they are using personalized teaching style.",4,4,0,2
"1425","Feature Selection","This short introduction to feature selection discusses two main reasons why we want to carry out this process. One reason is for interpretation and insight (knowledge discovery), and the other is for solving the dimensionality curse problem.",0,1,-1,5
"1426","RStudio Cheat Sheets","The most useful information in this cheatsheet concerns shiny R and formats. I've known something about Rmarkdown before, but that is limited to basic commands and formats. This cheatsheet tells me how to produce tales in Rmarkdown and produce Latex format text. This is very useful to someone who may need to produce clean format of math equations in papers.",1,2,-1,1
"1427","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This articles gives a generic framework for learninganalytics which contains six dimensions, like data, stakeholders, and objective. The meaningfulness of this framework is that it connects relevant parties in education and illuminates how these parties are connected around the area of learning analytics. As mentioned by the authors, this framework is not intended to be perfect and applicable to every scenario in education, but that education practitioners may revise this framework and make it useful to their specific purposes.",2,0,2,2
"1428","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This is a comprehensive study on a MOOC course on recommendation system by the computer science department of University of Minnesota. PCA analysis is limited to Section 4.4 Preliminary Analyses where the authors explored reasons why students registered this course and found four factors with eigenvalues over 1. But the essay is not limited to PCA. It did many regression analyses, attempting to figure out variables significantly predicting outcomes such as  final grades and retention (five months after the course ended). The authors also compared face-to-face students and online students, with the former commonly prevailing on the outcomes they studied. Yet, the authors gave caveats that the small size of the former group of students might have made the results not statistically convincing. This article more than showed details of researching PCA or even MOOC courses. It also discussed interactions from students, the qualitative part. Some students applied what they learned to their businesses or work immediately out of a specific lesson. This shows the utility of this recommendation system course.",4,3,1,4
"1429","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article introduces an automatic way of finding out the Q matrix of item-skill correspondence. The new method is more complex than the currently popular LFA method, incorporating several machine learning algorithms such as matrix factorization, bag-of-words modeling, and clustering. The method also uses AFM or BKT method. I noticed two potential areas for further study: Add bag-of-words keyword information to expand the V-matrix, and explore whether AFM vs. BKT favors different search algorithms. These two areas are interesting. The first study may further automize the proposed method, making it possible to reduce participation from humans. The second study can provide suggestions as to which search algorithm needs which evaluation criterion.",3,2,1,5
"1430","Chapter 1: Social Network Data","This chapter focuses on basic concepts and issues around social network analysis (SNA). More specifically, emphasis is given to difference between conventional inferential statistics and descriptive statistics involving SNA. This chapter also describes SNA's data collection methods and scales of data measurement. An interesting topic lies in the Note section where the authors briefly discusses methods to test hypotheses using random sampling methods.",0,1,-1,4
"1431","Learning Analytics Dashboards","This article is a general introduction to the process of data visualization in education. It is helpful to know that this process starts from researchers having questions, with visualization itself beginning from sketching on a paper or blackboard before moving to visualization libraries like d3.js and Processing. Especially inspiring is the multiple realization of the difference between the two numbers, 37 and 75. To obtain a more detailed understanding of how to visualize data in learning analytics, we need to learn specific techniques.",1,0,1,2
"1432","Measurement and its Uses in Learning Analytics","For me who major in measurement and evaluation, this article has provided a systematic review of the theories and other relevant issues in psychometrics. This articles has done a brief yet comprehensive review of classical testing theory, IRT, CFA, DCM, GMM, and other models commonly used in measurement research. The value of this paper far extends the implied scope in the title ""learning analytics"": Anyone interested in psychometrics and intends to have a general understanding of this area will probably find this article a valuable reference and a good starting point. The author is justified in terms of reviewing concepts and theories in psychometrics for learning analytics researchers. After all, measurement is a prerequisite for any researcher intended to carry out an empirical study. To test a hypothesis which involves relationship between concepts, researchers first need to know how to operationalize these concepts before they may be able to empirically test their relationship.",2,0,2,5
"1433","Predictive Modelling in Teaching and Learning","This article is a general introduction to issues of predictive modeling in education. It refers to data collection, feature engineering, common algorithms, diagnostic measures of model evaluation, and challenges and opportunities for researchers in the area of predictive modeling. An inspiring categorization of data is time-based, state-based, and event-driven. This division can help us to better understand the difference of our data. A suggestion the authors gave on how to deal with missing data may be controversial. They suggested using common values (e.g., mean) or values of similar data points, but statisticians have warned against using such methods. They may narrow the standard deviation or have other problems. Instead, the missing values may be computed with appropriate algorithms if the missing patterns are completely random.",1,5,-4,5
"1434","Ethics and Learning Analytics: Charting the (Un)Charted","This article attempts to specify ethic principles for the newly emerged field of learning analytics. This effort is worthwhile and necessary since former ethic rules, although providing some insight for learning analytics, may be not applicable good enough. The introduction of the history of ethics for learning analytics is informative, allowing us to trace the history back to the Open University, the operation of which accumulates a large amount of data and makes it necessary to lay down rules concerning how to protect the data of the University's students. The article mentions ethic principles established by many different institutions and conferences, which means that for now there still lacks a popular set of rules acceptable to most, if not all, learning analytics researchers and practitioners. Anyhow, a good point of this article is that in the future interested organizations may refer to this article for inspiration when they need to establish their own ethic rules. Perhaps one day learning analytics institutions' leaders may sit together and produce a set of rules covering almost all possible uses of education data.",5,2,3,2
"1435","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The authors aim to promote explanatory modeling efforts in the area of educational data mining, an area long prevalent with predictive modeling attempts. The focus is on cognitive model discovery where researchers use Q-matrix (including KC's) and AFM to discover new KC's that have better fit than expert-defined KC's. The article mentions three models: DFA, LFA, and SimStuden (software). By comparing results to models only with expert efforts, the authors found that the automated cognitive models have better fits. The conclusion of this article is balanced. The authors emphasize the role of experts in exploring cognitive models, which they believe tends to make the derived models more interpretable, although another article in the reading of several weeks ago promotes totally automated modeling. For interpretability, the authors have included both understanding why and how: Why some variables should be included, and how the results can help to improve instructions. Of course, the authors also stress that both independent and dependent variables should correspond to constructs.",3,2,1,5
"1436","Statistical graphics: making information clear – and beautiful","The authors have revised a poor graph and represented it with R as an appealing graph illustrating information interesting to potential readers. The usefulness of this article is that it has spelled out principles in terms of purpose of the graph, revision guidelines, and guidelines for multiple graphs.",1,1,0,2
"1437","How to display data badly","Knowing how to produce poor-quality graphs helps us to notice bad practices and thus attempt to avoid these practices when we are drawing our own graphs. Some principles in this article are objective: Data density index, Perceptual distortion, and Data-ink ratio, whereas other rules may be subjective but insightful. Perhaps, I can summarize some of the author's rules with names like ""simplicity, consistency, clarity, efficiency, context, focus, sufficiency, label, and alternative"". These principles are similar to those in academic writing.",3,2,1,2
"1438","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This article clarifies the difference between the goal of discovery and communication in data visualization, with the former being the main goal of statisticians and the latter of Infovis experts. More specifically, statisticians prefer traditional graphical means, such as scatterplots, lines, and bars, to make comparisons, whereas Infovis people favor unique, creative design of graphs to catch audience's attention. The argument of the authors that statisticians should focus on making comparisons, presenting information, and discovering patterns from data is convincing, and this cogency of argument is reflected in the multitude of examples in the article. Many so-called ""best"" graphs from the Infovis world, although able to catch attention, are no use in giving much information about the data. Finally, the author's suggestion that experts from both fields should learn from each other is a helpful attempt to bridge the gap between the graphs from both groups.",4,0,4,2
"1439","Junkcharts Trifecta Checkup: The Definitive Guide","It is insightful for the author to divide poor quality graphics into categories according to differing combinations of three factors--questions, data, and visualization. The examples are illustrative to some extent, but may not be illuminating owing to lacking the context where these graphs appeared. By only looking at the graphs, we may find it difficult to find out what questions these graphs are aimed to answer, why the data are improper, or why the visual effect is poor. If the goals of the graph producers are different from understanding of the author, different judgment of their quality may arise.",0,5,-5,2
"1440","Cluster","One interesting point of this introduction is how to determine the number of clusters for a dataset. One is F-test, and the other is proportional reduction in error (PRE). It is good to have an applet to show the working mechanism of clustering, but it cannot be viewed on my computer.",2,1,1,1
"1441","Measurement and its Uses in Learning Analytics","In the first part the author clarifies what is psychological measurement and mention that it comprises some parts like defining a construct and specifying measurement instruments. Then in next part the author provides a bit more depth about measurement models and their uses in learning analytics and educational data mining. Finally, the author revisits the important subject of error and emphasis that practitioners should use with care.  ",1,1,0,5
"1442","Ethics and Learning Analytics: Charting the (Un)Charted","This chapter provides an overview of the development of our thinking by setting the context: why ethics is relevant firstly and establishing ethical principles in the broader context of the forces shaping higher education and the roles of data and evidence, Finally, the author concludes by mapping future issues for consideration.  ",0,0,0,2
"1443","Predictive Modelling in Teaching and Learning","The article describes some considerations when using predictive modelling, followed by the workflow of using predictive modelling in teaching and learning including like problem identification and data collection. Then the article lists some popular methods for build and evaluating models. Finally, the practice is discussed as well as some challenges and opportunities.",3,1,2,3
"1444","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The article reviews educational data mining efforts that have produced explanatory models and, in turn, can lead to improvements to learning outcomes and/or learning theory. Starting with cognitive models refinement and discovery, the article discusses some technologies applied in cognitive models. Then it describes how to move towards building explanatory models.",1,0,1,5
"1445","Junkcharts Trifecta Checkup: The Definitive Guide","This blog is a guidance on Junk Charts Trifecta Checkup, a general framework for data visualization criticism. The Trifecta Checkup involves three investigations: What is the question? What does the data say? What does the visual say? The author elaborates on eight types of critiques with an example from a prior post on Junk Charts.",0,3,-3,2
"1446","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social interactions between students plays an important role in undergraduate education. This article conducts descriptive analyses of the structure of the network and explores generative processes to build observed study networks. Starting with an introduction to network concepts, the author elaborates on their process of data collection and analysis and finally leads to a summary of their work.  ",2,0,2,4
"1447","Why Students Should Own Their Educational Data","This blog records the discussion between The Chronicle and Mr. Rose, who believes that technology can help to customize teaching materials by giving educators detailed data on students and the ability. There are many questions like what’s wrong with the idea of the average learner or how does that theory apply to learning and Mr. Rose have his answers.    ",1,1,0,2
"1448","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Testing Learning analytics and educational data mining: towards communication and collaboration",0,0,0,2
"1449","Evaluating Machine Learning Models","In this blog the author takes us to a tour of machine learning model evaluation focusing on two questions: How would one measure the success of a machine learning model? And how would we know when to stop and call it good? Starting with the basic workflow of machine learning, the author elaborates on performance evaluation metrics such as average accuracy, log-loss, and area under the curve.",2,0,2,5
"1450","Why Opting Out of Student Data Collection Isn’t the Solution","The author shows why opting out of student data collection isn’t the solution by answering three questions: How Data Collection Helps Students, When to Opt-Out and Why Opting Out Isn’t the Solution?",0,0,0,2
"1451","Saturday Morning Breakfast Cereal","This comic shoes the progress that a sociological discovery that most elite engineers were observed disassembling and reassembling clocks as children finally came into a policy to force all students do clock homework.",1,0,1,2
"1452","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article explains why Zuckerberg is ploughing billions into personalized learning. Starting with a brief introduction to personalized learning, the article tells the dangers of personalized learning and where personalized learning could help and finally sum up with a compromise approach.",0,1,-1,2
"1453","Feature Selection","I may take the online course later to learn Machine Learning",0,0,0,5
"1454","Chapter 1: Social Network Data","This is an introduction to social network methods including to a introduction to the difference about social network data, the nodes or actors part of network data, populations, samples, and boundaries and what ties or relations are to be measured for the selected nodes. The article also mentions the sampling ties.",0,0,0,4
"1455","RStudio Cheat Sheets","Useful cheat sheet for R Markdown function.",0,1,-1,1
"1456","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Internal limitations-information delivery. External Constaints:single occasion.E.g. kids temporature move up and down. Some parents send kids to the hospital because they don't know about the fluctuation. Another example is that my data is assignment grade. The higher the grade I have, I will be more confident. If I am sick in an exam and I got low grade, I will be really upset. This explains the internal limitations. The external constaints, if the learning materials or questions order are not always constant. There is big differences between reflection and prediction. GRE is a really complex instrument behind that. The temperature of the testing room, how frequent of the proctors' walk through.    ",1,4,-3,3
"1457","Cross Validation","Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation.",0,2,-2,5
"1458","Hands-On Programming with R","This is the website for “Hands-On Programming with R” which teach how to program in R with hands-on examples. Throughout this introduction you’ll learn how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools.",0,0,0,1
"1459","Principal Component Analysis explained visually","This is a visually demo of Principal component analysis (PCA), a technique used to emphasize variation and bring out strong patterns in a dataset. 2D and 3D examples are given and you can drag the points to see some adjusts.",1,1,0,3
"1460","Measurement and its Uses in Learning Analytics","ARTEMAS - The most interesting part of this article to me is the ""what are we measuring"" portion. There are so many variables that influence learning and it is important to understand the epistemology behind why we do what we do. The data backed claims of LA on the EPA triad will hopefully help us make insightful conclusions about how learning is improved.",1,0,1,2
"1461","Ethics and Learning Analytics: Charting the (Un)Charted","ARTEMAS - The interesting part about this article is the ethics and macro-principles behind learning analytics and the collection and subsequent use of big data. I personally don't see the use of data as a hindrance to my or a student's well-being. As long as people are aware that data is being collected, I don't see how it can hinder growth. Instead we should help people understand what data is and how it is being gathered and used so that they can make decisions (moral and ethical) about data for themselves.",2,1,1,2
"1462","Predictive Modelling in Teaching and Learning","ARTEMAS - As an ex-teacher I find this to be quite problematic. We are taught to always work from a backwards planning approach, so therefore there is very little need to predict anything really. We basically begin the year and the unit and the curriculum by detailing what we would like students to know after a given amount of time, then we try our best to get them there through the act of teaching and learning. I'm struggling to find where predictive analytics comes into play here.",3,2,1,2
"1463","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","ARTEMAS - Claims Analysis, an analysis of stances taken in the design and implementation of technologies is a unique way to turn clicks into constructs. In the book the Handbook of Learning Analytics, the authors try to meet the needs of a growing field by addressing the many challenges concerning LA. It analyzes a variety of techniques and approaches and also discusses the various problems persistent in the LA field. Finally, it also talks about the ethics of student information and the various measurements and use cases of Learning Analytics.",0,2,-2,2
"1464","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","ARTEMAS -",0,0,0,2
"1465","Junkcharts Trifecta Checkup: The Definitive Guide","ARTEMAS - Kind of like Tufte but not really. It basically talks about chart junk, or junk charts and gives three guiding principles for data visualization.   They are: What is the question? What does the data say? What does the visual say?   These three principles should then guide your visualization process.",1,2,-1,2
"1466","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","ARTEMAS - I am wondering how the author was able to gather all these data sources to then be able to cluster. Isn't all this data private? It is awesome that the  cluster model actually worked 80% and I'd actually want to look at the code itself. This is the name of the game right? Utilizing student data in a way that can aid student learning and drive effective decision making for teachers and administrators. In my other class, we spoke about ethics and data. I guess the question really is then, is true student improvement worth being flexible with one's ethics?",4,0,4,1
"1467","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","ARTEMAS - Again, I like the idea of social network analysis in that it shows us the logistics behind a classroom and how they all measure up and pair up with one another. However, social network analysis does not account for things like personality and why some students decide to sit with others. Maybe they instagrammed each other the class before? Does social network analysis account for this?",2,0,2,4
"1468","Why Students Should Own Their Educational Data","ARTEMAS - To me it's all about consent. I'm sure FB is using all my personal information and selling ad space to Kayak or Orbitz the next time I even google Las Vegas. But I understand that and have consented to that so what's the big deal? Should people own their own data? Of course. Should companies that utilize our data be more transparent about it? Of course.",0,0,0,2
"1469","Knowledge tracing: Modeling the acquisition of procedural knowledge","ARTEMAS - This academic paper discusses ways and methods to monitor a student's ability and progression in skills acclimation. Some things discussed here are: - memorization - recollection - inference making - critical thinking - use of prior knowledge   These are some ways that educators and data scientists can track student understanding of new skills and topics.",3,1,2,3
"1470","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","ARTEMAS - This article is quite interesting in that it differentiates the difference between EDM and LAK (learning analytics and knowledge). I think the key characteristic between the two is that LAK leverages more human judgment and emphasizes on it, while EDM emphasizes automation. One thing EDM seems to do better is the visualization piece, I am wondering if LAK can utilize visualization in their insights as well.",3,0,3,2
"1471","Evaluating Machine Learning Models","ARTEMAS - Yes, the biggest difficulty for me when I analyze data sets is which statistical model to use and also if I want to predict something which machine learning models to use. I have an understanding at this point about which models fit the data better. For example if the data set was comprised of mostly categorical data, then maybe a decision tree or chi-squared test would work. However if it was a continuous data set, then maybe other models would work. My way around this conundrum is to usually ask google to see what methods people have used before. Then once I understand what they have done, I try and insert my own data into those models to see what happens and try to interpret the results.",3,0,3,1
"1472","Why Opting Out of Student Data Collection Isn’t the Solution","ARTEMAS - Agree wholeheartedly on this topic. Data, if used responsibility, can only help us as educators make better decisions. Fine, we don't have to make decisions off of data, but we can surely be more informed when making decisions.  ",2,0,2,2
"1473","Why Is Measuring Learning So Difficult?","ARTEMAS - One word: humans. As a teacher, the thing that sets us apart from others is our understanding of humans and emotions and how they operate in a classroom environment. There are many factors that affect learning and academic performance. Maybe the child's parents got into a fight the night before a huge test? Maybe the child didn't have breakfast or dinner before school? These, and many other variables that we simply cannot account for is what makes measuring learning so difficult.",0,1,-1,1
"1474","Saturday Morning Breakfast Cereal","ARTEMAS - I was never really a comic book type of dude, and I only watched the Marvel series because I succumbed to the hype. Having said that, this is a great comic about feature engineering!",2,2,0,2
"1475","Zuckerberg is ploughing billions into 'personalised learning' – why?","ARTEMAS - AI and Machine Learning in education. Whoever gets there first wins. I think Mark is doing a great job at FB and he truly transformed the company into a marketing behemoth.  But education? Maybe google has the edge as most educators are using their platforms already. Noone is submitting their assignments via FB message, they are doing it through google.docs though!",2,0,2,2
"1476","Feature Selection","ARTEMAS - Feature selection. Knowledge discovery, it is useful to interpret the features of the data. Which variables and features matter for interpret-ability and insight. This is where the crux of the data analysis takes place I think. Feature engineer and/or feature selection makes models more meaningful, and tidying the data and engineering the data so that they fit these models and algorithms is the most important. Once of data is engineered, we can plug in the models and have better results. Curse of dimensionality, the more features you have the more data you need. Smaller features means less data is needed. ",3,0,3,5
"1477","Chapter 1: Social Network Data","ARTEMAS - The Social Network Data is interesting and we were able to do this with the HUDK4050 class with an activity that included nodes and K nearest neighbors. Euclidian distances is a unique way of clustering various entities.  The tough part about our social network data was the tidying part. I had to tidy the data of all the factors that were no important and also of all the students that were present in the class. Despite this, I do like the use of nodes and edges to represent how many shared classes each of us had.",2,0,2,4
"1478","RStudio Cheat Sheets","ARTEMAS - At first I found it quite difficult to read and understand the RStudio cheat sheets. But after having used R for a whole term, I'm getting more and more used to reading the cheat sheets and learning from them. Stack Overflow is a great option too.",1,3,-2,1
"1479","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","ARTEMAS - This one is tough as there are many variables that can influence why a person decides to enroll in college. It could be about money, about parental encouragement, peer encouragement, or whatever. Placing it strictly on an intelligent tutoring system can be problematic. But I assume if we want to know improvement in the SAT or ACT scores, intelligent tutoring systems can easily track this.",3,2,1,4
"1480","Translating Learning into Numbers: A Generic Framework for Learning Analytics","ARTEMAS - The nice thing about this article is that it describes some ways in which data is being: - collected- used- and implemented in the field of education today. Learning management systems already have a lot of student information, but what do they do with them? Governmental orgs have data as well, how will they use their insights on our data to improve our schools?",2,0,2,2
"1481","The Big Five and Visualisations of Team Work Activity","ARTEMAS - The Big 5 is a unique way of classifying participants in a teamwork activity. My only assumption here is that there could potentially be a lot of bias surrounding the analysis and that maybe some people might not consider the findings to be relevant or reflective of who they actually are.",0,1,-1,2
"1482","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ARTEMAS - I think recommender systems work as long as we have some prior information or data about the user. Let's say we found out that the user on coursera took an intro to r video class. Then it would be fair to assume that the next sequence in the learning process to for them to learn intermediate r. Therefore the recommendation system works in this situation.",5,0,5,4
"1483","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","ARTEMAS - This is interesting. I am wondering if certain edtech companies cater to certain skills. As a history teacher, some skills are more important than others when achieving mastery of the subject matter. I would assume that it's popular to gear towards the STEM disciplines when developing and mapping skills. Especially since these tests are more standardized than in other subjects. Artificial Intelligence is the buzz word apparently, and I suppose whoever wins the AI race wins the it all.",6,0,6,2
"1484","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","ARTEMAS - Somewhere in the internet abyss Deep Blue is celebrating in binary code. I wonder what Kasparov would think about this? Surely Elon would agree. Still don't want to ride in one of his cars though... I can assume the Youtube algorithms are checking my understanding of topics by documenting the amount of videos I watch per topic. They can then presumably use their ML models to suggest newer videos to me.",1,1,0,2
"1485","Using data mining to predict secondary school student performance","ARTEMAS - This could make sense, but where does all this prediction lead us but to the dead end of bias? We can surely predict scores based on household income, parental demographics, social demographics, and all other types of variables, but are we as data gatherers and analysts using our own inherent bias to try and predict the scores of students and their performance based on a societal construct?",1,3,-2,4
"1486","Developing a generalizable detector of when students game the system","ARTEMAS - This article about gamification is interesting. Partly because I find it fascinating as an ex-teacher that students would actually try to figure out ways to cheat the system instead of actually studying the academic material. Presumably studying the material (given to them) is a lot easier than trying to game the system and get away with it. The detector test is interesting in this sense that it tries to catch students that game the system, kind of like a virtual referee of sorts.",3,1,2,5
"1487","Big Data in Education","ARTEMAS - THIS ARTICLE WAS ENLIGHTENING IN VARIOUS WAYS",1,0,1,2
"1488","Cross Validation","ARTEMAS - One part I don't understand is how Cross Validation is a fundamental assumption of supervised learning. Taking some of the training data and use it to test the model. Cross validation is basically the amount of folds we do. The training and test set makes sense to me especially when you're dealing with regression analysis. What is difficult for me to understand is the higher order polynomial that the video is referring to. However the training set that acts like a test set makes sense. Which doesn't require the use of the test set. Take all the folds, and average the error to see how well we have done in the ML model. This should present a goodness of fit. The lowest error is the one we will go with.  ",3,4,-1,5
"1489","Hands-On Programming with R","ARTEMAS - I have this book downloaded onto my computer and basically it's about not only using R for data science but also discusses some of the ways R can be used a traditional scripting/coding language. Something like writing one's own functions and them applying them over a data set are taught. It's a great tool for new coders like me.",3,0,3,1
"1490","Principal Component Analysis explained visually","ARTEMAS - I find this website and source to be extremely useful. It looks kind of like a cluster analysis but in 3d form and really shows the viewer the differences between the types of cuisines and clusters. This person really followed Tufte!",2,0,2,2
"1491","The Data Wrangling Cheatsheet","Very Very useful. I referred back to this cheat sheet plenty of times in this semester.",1,1,0,1
"1492","How to display data badly","It's not on the syllabus nor the link could direct to this article.",0,0,0,4
"1493","Measurement and its Uses in Learning Analytics","The use of learning analytics tools is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices.  The Espistemology-Assessment-Pedagogy Traid and EPA provocations to provide actionable guidance for those developing learning analytics approaches and tools. Epistemology — What Are We Measuring? &amp; How are we measuring? We should keep in mind that what ""knowledge"" looks like within the analytic approach being developed, asking, What are we trying to measure? Pedagogy — Why is this Knowledge Important to Us?/Who is assessment/analytic for? We should consider who the target of the device is, whether it supports teachers, parents, students, or administrators in understanding some aspect of learning. Assessment — Where Does the Assessment Happen? When Does the Assessment, and Feedback, Occur?    ",2,0,2,2
"1494","Ethics and Learning Analytics: Charting the (Un)Charted","Learning analytics bring great benefits for education, however, it also come up with associated ethical issues. Benefits includes: -quality assurance and quality improvement -boosting retention rates -assessing and acting upon differential outcome -develop adaptive learning Although considerations of the ethical implications of learning analytics procedures, some ethical issue may be be raised: -data-proxy-induced hardship that disadvantage the embodied referent -conflict interests and claims of a range of stakeholders, such as students and institutions. Ethical issue may be raised during the process of -the location and interpretation of data -informed consent, privacy and de-identification of data -the management, classification and storage of data Six principle of the policy framework about students' data protection: -Learning analytics as moral practice -Students as agents -Student identity and performance as temporal dynamic constructs -Student success as a compley,multidimensional phenomenon -Transparency as important -Higher education cannot afford not to use data Six principle of student-centered learning analytics: -Use of aggregated, non-personalized data, students should be able to make informed opt in/out decisions -have full knowledge of which data is being collected and how it is used -personal data records are complete and up to data -surveillance of activities and the harvesting of data must not harm student progress -Algorithmic output should be subject to human review, and corrected if needed -provides context and time-specific, provisional incomplete pictures of students, and algorithms should be frequently reviewed and validated. Four principles guide for LA -personal information be used only in the context and purpose for it was provided -subsequent use of data should be reconcilable with the original context and purpose -data should be carefully collected and analyzed -data may be collected when the purpose/use of the collected data is made explicitly clear Question: How to provide adaptive learning and personalized assistance if use aggregated, non-personalized data?          ",10,4,6,2
"1495","Predictive Modelling in Teaching and Learning","Predictive modelling has become a core practice in both education data mining and learning analytics to predict student success as operationalized by academic achievement. predictive analysis in education: 1) measurement of learning 2) teaching 3) proxy metrics of value for administrations Before analyzing, -we need to make sure the sample represents the general population with minimum bias. -We need to generate accurate scenarios. Several factors make predictive modelling more difficult, including -sparse and noisy data -inference produced by predictive models may be involved in ethical or equitable issues Q: For the missing data, if the sample size is large, should we just delete the missing data? For the noisy data, is their a way to pre-scan the data quality? During analyzing: -identify the variables -multiple models created to predict same outcome -event-data is increasing important nowadays. It is complex data and request Feature engineering. Q: Gender, SES status, race as variables might cause bias, how to minimize the prediction model bias? Multiple models to predict the same variable is a great way, are there any other way? Things need to be pay attention: -remove highly correlated attributes otherwise it will cause over-emphasis on the repeated or correlated features. -deal with missing data, either remove or fill it in records by finding other similar records -choice appropriate learning algorithm 9 most commonly used algorithm in education data: 1. Liner Regression 2.Logistic Regression 3. Nearest Neighbours Classifiers 4. Decision Trees 5. Naive Bayes Classifiers 6. Bayesian Networks 7. Support Vector Machines 8. Neural Networks 9. Ensemble Methods Assess the quality of models: -k-fold cross validation -used the same manner as will be used in situ * The context of Learning analytics is highly interdisciplinary and requires not only computer scientist but also highly depends on experienced educator, psychologist and policy expert. Educational experience is important!! (Which I have <U+0001F601>)                    ",5,11,-6,3
"1496","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Two statistical modelling of educational data: Explanatory model and predictive models.  Predictive model: predict outcomes Explanatory model:identify interpretable causal relationships between constructs that can be either observed or inferred from the data. Although vast majority of researches focus on achieving predictive accuracy, developing explanatory models might benefits more about improve students learning outcomes. Cognitive model: They map knowledge component to problem steps or tasks on which student performance can be observed. They are important basis for the instructional design of automated tutors and improving the accuracy assessment of learning and knowledge. KC models (Q matrix) driving adaptive learning, and creation of new tasks to target the new skills. KC models refinement can result in instructional modifications and improved learning outcomes. Why explanatory models: 1. Start with ""clean"" independent variables that have either simple functions or map to clearly defined constructs. 2. Dependent variable maps to a well-defined construct. 3. Be characterized by fewer estimated parameters. Q:Does explanatory model have less biased comparing to predictive model because it basic descriptive analysis and tell about the truth.  ",3,2,1,5
"1497","Statistical graphics: making information clear – and beautiful","""There’s concern that investment in personalised learning may be a boost for Silicon Valley but a kick in the teeth for teachers."" Why? 1. Education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. 2. While learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. 3. Children’s preferences are not fixed – in fact they often change as immediate responses to the environment. I partially disagree with author's opinion about personalized learning. I do not think personalized learning is feeding children only the content they are interested in, however, it helps children learn everything they needed in the future in the way that they are good at. It is commonly known that there are auditory, visual and kinesthetic type of learners. Providing personalized learning could maximize their learning efficiency. Also, for the topic that children do not like, adaptive learning style is helpful to motivate students. I do agree with author's opinion that personalized learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment and it is something that takes time, conversation and collaboration, could not be done just by simply pouring millions of dollars into technology.",5,4,1,2
"1498","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","-Try not to cram into a single graph what can be better displayed in two or more. I've read Tufte's book, The Visual Display of Quantitative Information. It's an useful and interesting book talking about how to make effective and informative graph. Recommended everyone to read it. Why visual display important for data analysis? - Graphics are for the qualitative/descriptive -Graphics are for comparison -Graphics are for impact -Graphics should report the results of careful data analysis Statistical data visualization: not focused on visual appeal but on facilitation an understanding of patterns in an applied problem. Infographics: attractive, encourage the viewer to think about a particular dataset. Both important, different perspectives.    ",5,1,4,2
"1499","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. Three essential questions to keep in mind:  What is the QUESTION? What does the DATA say? What does the VISUAL say<U+FF1F>  How to make worthy data visualization? The Data should be relevant to the Question being addressed The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly.  Tufte's Book again! Highly recommend this book! Make trifecta graph!!  ",2,2,0,2
"1500","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This article demonstrates a novel application of hierarchical cluster analysis(HCA) in order to find pattern in disaggregated data that aid in data driven decision making by teachers and administrators. Through analyzing the patterns, it correctly identify more than 80% of students who dropped out. Thus, hierarchical cluster analysis is useful to identify schooling outcomes. ""Data driven decision making (3DM), has recently become a powerful means through which teachers and school leaders are able to gather together around student and school-level data to inform decision making and tailor instruction and resource allocation to students and classroom."" HCA: provide school leaders, researchers and policy makers a method to make better informed decisions in schools earlier, using data already collected on students. I like that by implementing the HCA(and heatmap), teachers and schools could make decision earlier and interrupt the decline in achievement early, before it results in future course failure.The main goal of the study is to present hierarchical cluster analysis (HCA) and visualization techniques(clustergram) as a useful method for the organization and pattern analysis of large sets of school and district data to aid data driven decision making.  Q: I am a little bit concerned about this analysis mainly cluster students by teachers assigned grade will not accurate enough to predict students drop our rate. If the HCA could optimize clustering based on different indicators? Will the bias occur when cluster students?",4,4,0,3
"1501","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Very interesting article about how social relationship influenced on learning outcomes. It provides me the insight of that these seems not directly related to learning variables also plays important roles that will affect learning which guide us about pedagogy, new teaching method &amp; new classroom setting etc. In the digital age, we might need to thinking about how internet and technology use affect learning. Student's position within communication and interaction networks is correlated with his/her performance. SNA aim to find the social pattern to refer same social influences. -understand homophily Important term: Degree centrality: the total number of connections a node has. To exam the equity or inequity in the number of ties between individuals. Data collection: more open-ended questions will smaller classes using pseudonym survey. Data management: Matrices are powerful way to store and represent social network data. (adjacency matrix and edgelist) R package for network: statnet suit,Rsiena, Igraph. Q: How to covert the social network visualization to statistical significance?      ",0,0,0,4
"1502","Why Students Should Own Their Educational Data","I watched this TedTalk four years ago when I was a student at Boston College studying Curriculum and Instruction. The video conveys the message that one size does not fit all. When I was in the C&amp;T Department, this video bring us the importance of differentiated instruction. It is interesting to see the Learning analytics and education data mining perspective about the same topic. Since no one will match exactly average of all dimensions, it is important to analyze individual patterns instead of aggregate data. *looking for personal patterns *personality research Whatever what kind of analysis is being done, the bottom line is that the user should own their data. This the default thing right now which is that everybody but the user owns their data.The third party who is responsible for protecting learner data.    ",2,0,2,2
"1503","Knowledge tracing: Modeling the acquisition of procedural knowledge","Very insightful article about how to model students' changing knowledge state during skill acquisition. Process of ""Knowledge Tracing"" could give instructor an estimate of the probability that the students has learned each role which helps to provide an individualized sequence of exercise and assistance. Assess the predictive validity of the model -correlate the actual accuracy and predicted accuracy estimates across goals. -compute mean error in prediction -compute the mean absolute error in prediction. step: 1. Internal validity 2.External Validity 3. Individual differences in learning and performance 4. Dynamic Estimation of Individual differences 5.Current assessment of knowledge tracing Q: How to come up with the coding rules? How to come up with the formulas in the article? How could we access this model? Is it a open resource? Is this model applicable for all filed of procedural knowledge, such as language learning, acquiring a math concept etc. I found that this article is hard to understand for people do not have machine learning background.  ",1,3,-2,3
"1504","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This article talks about the similarity and difference between Education Data Mining (EDM) and Learning Analytics and Knowledge(LAK) and their formal communication and collaboration between these two communities. Similarities: EDM and LAK both reflect the emergence of data-intensive approaches to education. They share the goals of improving education by improving assessment, how problems in education are understood, and how interventions are planned and selected.  Differences: EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment. EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners. It is much more typical in EDM research to see research which reduces phenomena to components and analyzing individual components and relationships between them. While LAK researchers typically place a stronger emphasis on attempting to understand systems as wholes, in their full complexity.  I feel a bit of confused why explicitly differentiate EDM and LAK since it share the common goals- to improve education and learning. I do not think the EDM and LAK should be intentionally separated/competitive and should collaborate to share research methods etc.",1,1,0,2
"1505","Evaluating Machine Learning Models","Reinforcement and detailed explanation of what we learned in class.This whole book seems really useful, will definitely save for later. *It is always better to train the model to directly optimize for the metric it will be evaluated on.    ",2,0,2,5
"1506","Why Opting Out of Student Data Collection Isn’t the Solution","Students data is essential and benefit to improve education. However, opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.",2,0,2,2
"1507","Why Is Measuring Learning So Difficult?","Learning is multi-dimensional and we need to simplify it to capture data. Learning is too contextual and idiosyncratic to measure. No reliable proxy indicators Measuring learning is actually measuring competency, and need new technology to measure the process/achievement multiple times.    ",0,0,0,1
"1508","Saturday Morning Breakfast Cereal","Very interesting cartoon. Science is not static!",0,1,-1,2
"1509","Data wranglers: human interpreters to help close the feedback loop","This paper talk about a programme of Human data Wrangler to analyze data related to learning to understand the practice of individual faculties/department and produce reports that summarise the key points and make actionable recommendations. This procedure is defined as Learning Analytic. Data wrangler requirement and roles- one component of a large, complex system of quality assurance and quality enhancement. -have an academic background close to the faculty they work with. -investigating data, generate charts and visualisations and produce their own charts. -building up relationships with key stakeholders to make valuable report -engage with faculty academics to support the use of data in action. -support delivery of Learning Design -facilitate Learning Design workshop and process of closing feedback loop. The article provide of several analysis about How Data Wranglers' report resulted in changed capacity to act on learning analytics data. limitations: not sufficient data, unevenness of the process across Faculties, poor data quality. Question: How to build the model for sophisticated analysis<U+FF1F> What is VLE/LMS model<U+FF1F>What is the different between top-down and bottom-up analytic strategy    ",6,5,1,1
"1510","Zuckerberg is ploughing billions into 'personalised learning' – why?","“There has been much hype about the potential for new technology or approaches to disrupt education and, not unreasonably, there’s concern that investment in personalized learning may be a boost for Silicon Valley but a kick in the teeth for teachers.” why? 1. Education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. 2.while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. 3. Children’s preferences are not fixed – in fact they often change as immediate responses to the environment.  I partially disagree author's opinion about personalized learning. Personalized learning is not only feeding children only the content they’re interested in, but teach children everything think need to know in the most appropriate way. As we all know, we have auditory, visual and kinesthetic type of learners, personalized learning helps to find the way to maximize study efficiency. Moreover, for the topic students are not interested in, personalized learning style might motivate students. I do agree with the author‘s opinion about personalised learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment and it takes time, conversation and collaboration, and cannot be realized by pouring millions of dollars into technology.",3,7,-4,2
"1511","Feature Selection","Covert the problem and feature from multi-dimensional to 2d which is easy to visualize and understand. Based on the curse of Dimensionality, it would be better if we only have few features and make the learning problem easier.",2,2,0,5
"1512","Chapter 1: Social Network Data","This article talks about the overall information, the terms analysis and measurement of social network data. It makes me have deeper understanding of assignment 2. It also talks about the application of statistics to social networks.  ",0,0,0,4
"1513","RStudio Cheat Sheets","Very useful link. However, seems a little bit confused for people who has little R background.  ",0,0,0,2
"1514","Translating Learning into Numbers: A Generic Framework for Learning Analytics","better test score = better understanding or better learning? Internal limitation: consent about this idea Could we judge students just by the data? External Constraints: what is students do not have grade? what about text anxiety that leads to low test score? Instruments:(how to operationalize?) appropriate algorithm? , analyze the correlation between test score and assignment score (way to assess students' understanding?),questionnaire about student data: (access to the data) teachers. school, research institute could access the data Objectives: reflection Stakeholders:(teachers? learners) teachers, learners &amp; school will benefit from this data analysis    ",5,1,4,3
"1515","The Big Five and Visualisations of Team Work Activity","This book is not on the syllabus and it's a 800+ pages book. It is impossible to finish before this semester. However, I already downloaded it and will read it in free time.",1,0,1,1
"1516","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This article is about a pilot study of an online MOOC course to gathering data for research. This course is the first class we are aware of that supplements student process and outcome data with both a survey of student background/intent and a subject matter mastery pretest/posttest to assess student learning outcomes Great research goals: 1. Do students in a face-to-face recommender systems course, who have access to MOOC resources, learn more than a comparable group of MOOC students who have access to recorded face-to-face instructional sessions? (very interesting questions!) 2. What demographic, background, and behavioral factors predict course completion,normalized subject matter learning gains, and course grades in this MOOC? 3. Do the MOOC students retain what they learned, when subject matter knowledge ismeasured 5 months after the end of the course? Do the face-to-face students retainmore of what they learned than the MOOC students do? Interesting result: -Only intention predicts completion,little else does. -Face to face students learned at least as much as online-only students and retention rate is at least the same. -Students at all incoming knowledge levels benefited similarly from the course as well as knowledge gain is not correlated signficantly with age, sex,student level etc. ***This is surprised to me because learning outcome is always associated with SES status,gender, race etc. If online learning platform will shorten the gap between students in different social classes, it will be a revolutionary indication    ",6,0,6,4
"1517","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Uncovering the right skills behind questions items is hard task that requires a comprehensive understanding of subject matter and cognitive factors to determine students' performance. This article introduces a ALS matrix factorization approach based on traditional Q-matrix approach that could predict accurate skills like expert. Q: A little bit confused about how data could measure human's thoughts? Does human set up the rules?",4,1,3,5
"1518","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article introduces a powerful model called eEPIPHANY that automatically determine which skills must be mastered for the successful completion of an online course which solve one of the big problem on making effective online courses since it is hard to find explicit associations between a necessary set of skills and course contents. By implementing the eEPIPHANY model, it carefully exploits correlations between various parts of student performance as well as in the text of assessment items. The accuracy is even higher than human-crafted skills models. Q: For these process that are involved with complex cognitive analysis, is it real possible that machine outperform the human? I found that it is hard for me to understand the very technical articles especially those articles about machine learning and algorithm etc. I will go back to these articles later when I understand machine learning and related stuffs better. (after learn more about R, engineering studio etc)",8,5,3,5
"1519","Developing a generalizable detector of when students game the system","This article is not in the syllabus.",0,0,0,1
"1520","Big Data in Education","Thanks for Ryan Baker for making this series of videos. I like his facial expression and gesture!! 1. Clustering:very detailed explanation of how we cluster data and choose selection of K 2. Q matrix: rows-items columns-skills -automatic model discovery -hand-development and refinement -hybrid approaches 3.prediction -classification, for categorical variable decision rules",2,0,2,5
"1521","Cross Validation","Try to find the representative training and testing data. Be generalized! cross validation data- a stand in for actual test data. Make more sense of cross validation after watching this video.",0,0,0,5
"1522","Hands-On Programming with R","Very useful book. Explicitly teaching code step by step. I am glad to read the first three chapters at the first week in order to have a overall concept of how R wroks and build confidence. I've got a Chinese version of this book and will finish the poker project with the book!",2,0,2,2
"1523","Principal Component Analysis explained visually","For me, the video explanation make sense for me better. I found that several useful link helping me understand PCA: https://www.youtube.com/watch?v=FgakZw6K1QQ https://www.youtube.com/watch?v=OowGKNgdowA",1,1,0,2
"1524","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This provides a new aspect and method for decision making based on data.",0,0,0,3
"1525","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This primer analyzed two study networks from a single classroom. It also discussed collection of both nodal and relational data, and we specifically focused on keeping surveys brief and simple to process.",0,0,0,4
"1526","Why Students Should Own Their Educational Data","Education data are a powerful tool that can help all with a stake in education, from families and educators",0,0,0,2
"1527","Knowledge tracing: Modeling the acquisition of procedural knowledge","This introduces useful ideas for knowledge tracing.",0,0,0,3
"1528","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.",0,0,0,2
"1529","Developing a generalizable detector of when students game the system","No access to this link",0,0,0,4
"1530","Evaluating Machine Learning Models","This paper introduces the machine-learning workflow, and then dives into evaluation metrics and model selection. It also focuses on hyperparameter tuning and A/B testing, which may benefit more seasoned machine-learning practitioners.",1,0,1,5
"1531","Why Opting Out of Student Data Collection Isn’t the Solution","After reading this one, I realized that opting-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.",1,0,1,2
"1532","Why Is Measuring Learning So Difficult?","After watching this video, I found that there are many difficulties for measuring learning.",0,0,0,4
"1533","Saturday Morning Breakfast Cereal","This interesting comic about big clock is instructive for me.",0,0,0,2
"1534","Data wranglers: human interpreters to help close the feedback loop","Data wrangling is a very useful and important idea for data mining.",0,0,0,2
"1535","Zuckerberg is ploughing billions into 'personalised learning' – why?","I realized that if personalised learning is conceived of as the means to adapt and customise a pupil’s learning according to their needs as well as teachers’ experience and school requirements, it holds promise. ",2,0,2,2
"1536","Feature Selection","This video explains the idea behind feature selection.",0,0,0,5
"1537","Chapter 1: Social Network Data","This chapter lets me understand that social network analysts do use a specialized language for describing the structure and contents of the sets of observations that they use. But, network data can also be described and understood using the ideas and concepts of more familiar methods, like cross-sectional survey research.",1,0,1,4
"1538","RStudio Cheat Sheets","This cheat sheet is very helpful, and I go back to this one many times this semester.",1,1,0,1
"1539","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","This is an interesting topic and method about predicting.",0,0,0,3
"1540","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This one discusses privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.",1,0,1,2
"1541","The Big Five and Visualisations of Team Work Activity","The visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.",2,0,2,2
"1542","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This one tested whether face-to-face students performed as well as the online-only students or better. And concluded that they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.",5,1,4,4
"1543","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","This is useful for my coding this semester.",0,0,0,1
"1544","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This paper introduces how can we automatically determine which skills must be mastered for the successful completion of an online course.",3,0,3,5
"1545","Using data mining to predict secondary school student performance","This one shows that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available.",2,0,2,3
"1546","Developing a generalizable detector of when students game the system","This paper shows how a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula.",0,0,0,5
"1547","Cross Validation","This video clearly shows how to do a cross validation without causing problems on the test set.",1,1,0,5
"1548","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Notes: I should have read this article at the beginning of the semester because most of the information covered in this article are closely connected to what we have learned in this semester. I am so glad that I can read about a real case in analyzing the education data for k-12 schools to help reform the education policies and access the students situation before deciding whether they should dropout or not. Having gone through all the assignments and got familiar with all the codes, I am now familiar with the charts mentioned in this article and all the analyzing methods the researchers have used. Although there are still a lot of questions needed to be answered in the future development of education data analysis, the current trend of development marks a bright future for this field.",3,1,2,2
"1549","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Notes: Living in an era when people cannot live without social media, I am so glad to see someone discussing about its influence on students' learning. It is interesting to see that the researchers analyze the relationship between students' connection with each other and their results in examinations. Also, the researchers are cautious enough to take the changes in relationship overtime into consideration. I think this study is of great value for both teachers and students. For teachers, they can help the students to form study groups which can help them achieve the best study results. For the students, with the help of this study,they can find the partners who can help them the most.",4,0,4,4
"1550","Why Students Should Own Their Educational Data","Notes: Just as is stated in this interview, ""It’s not that people don’t have particular habits and styles of learning."" it is that they do not have the data to find the relationship between their learning habits and their learning performance. Why students should own their learning data? I think the main reason would be that it is their privacy. Many schools in China like to send the students' exam grade directly to the students' parents. I think it is not a good way. Although letting the parents know how students are doing at school is good for them to help the students with their problems in learning, they have forgotten that these data are the students' privacy. While some of the students' data are shared with parents, students themselves sometimes do not have the access to their own educational data. It is the most irony thing.",3,1,2,2
"1551","Knowledge tracing: Modeling the acquisition of procedural knowledge","Notes: Sorry, I really want to read this article but I do not have Harvard key so I cannot get access to it.",0,1,-1,2
"1552","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Notes: I don't know why but I was requested to pay for this article.",0,0,0,2
"1553","Evaluating Machine Learning Models","Notes: This book is very informative. It introduces machine learning models in a very systematic way. From it, I learned different types of evaluation metrics, difference of offline and online evaluation mechanisms, hyperparameter search and online testing mechanisms. In chapter one, I read about the classification metrics, which I have learned in the class and once put into practice in analyzing the data. I also read about other metrics that I have never learned in statistics. The ranking metrics is a new thing for me. I have never learned it but after reading through this chapter, I know that it is related to binary classification. In chapter 2, I learned about the offline evaluation mechanisms and the difference between model validation and testing. In chapter 3, I learned about hyperparameter tuning. I have learned that it is the hardest one to handle in the realm of machine learning. Unfortunately, I could not understand the formula in this chapter. All in all, this book is very comprehensive. It contains a lot of information and has explained a lot of problems in detail.",1,2,-1,5
"1554","Why Is Measuring Learning So Difficult?","Notes: Learning for me, as is said by one of the speaker in this video, ""is a personal thing"". It is very difficult to measure and predict. Since people's motivation would change during time, the study result would also change. When I was in high school, I could always see some students who do not learn well. They usually do not complete the assignments and do badly in quizzes. However, some of these students have the ability to perform well in important exams such as final examination or even more important ones such as college entrance examination. If you try to build a metrics and predict their study result through their quiz results or through their previous learning performance.",2,2,0,3
"1555","Saturday Morning Breakfast Cereal","Notes: The comic is funny but can generate thoughts from readers. I have once imagined if education becomes politics what the world would be like. Asian countries probably would strive to death in achieving success of this competition. Sorry I don;t understand the clock thing, it must be a joke among the engineers.",2,2,0,2
"1556","The Data Wrangling Cheatsheet","Notes: This cheat sheet gave me much help in learning R language after class. When I first did some of the assignments, I totally had no idea of how to deal with all the problems, but when I read through this cheat sheet, it offered me hints and helped me manage to finish the problems. Overall, all the codes covered in this sheet teaches me how to convert, add, select or delete specific data in a dataset. Just as Professor Lang has mentioned in the class, R is a totally new language. Then this sheet acts as a very basic dictionary for a newbie like me to look up to when completing the assignment.",1,4,-3,1
"1557","Data wranglers: human interpreters to help close the feedback loop","Notes: I don't know why but I was requested to pay for this article.",0,0,0,2
"1558","Zuckerberg is ploughing billions into 'personalised learning' – why?","Notes: The personalized learning advocated by Mark Zuckerburg reminds me of the special education we have discussed in bilingual education. I believe that not only in bilingual education but also in other education programs, people have noticed that there are some students who have problems with study. It is not that they do not work hard enough nor they misbehave in the class, it is that they have difficulty in learning. These students, not being disabled, but are suffering from learning disabilities. Therefore, personalized learning should be provided because they could fully be aware of their learning conditions as well as their own problems through these data. Therefore, students should own their own learning data.",3,5,-2,2
"1559","Feature Selection","Notes: I watched this video and understood the importance of feature selection. It is a thing that people always ignore in data analysis. You may have a bunch of data but only a few would be useful for you. Then what would you do to pick out the useful data? Use feature selection. As is said by the speaker, when you include more features you actually include more data into analysis. These are all what I have learned through this video.",0,0,0,5
"1560","RStudio Cheat Sheets","Notes: This cheat sheet gave me much help in the first formative test. At that time I totally had no idea of how to deal with all the problems, but when I read through this cheat sheet, it offered me hints and helped me manage to finish half of the problems. Overall, all the codes covered in this sheet teaches me how to convert, add, select or delete specific data in a dataset. Just as Professor Lang has mentioned in the class, R is a totally new language. Then this sheet acts as a very basic dictionary for a newbie like me to look up to when completing the assignment.",1,4,-3,1
"1561","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Notes: I don't know why but I was requested to pay for this article.",0,0,0,2
"1562","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Notes: I don't know why but I was requested to pay for this article.",0,0,0,2
"1563","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Notes: This journal article introduces a research conducted by a group of people studying the effectiveness of an online assessment platform, eEPIPHANY. Following are the points that I have found really interesting and gave me inspirations. Firstly, I am amazed that the researchers could build so many models to analyze the effectiveness of this method. Before taking this course, I have never imagined how data would be used in the field of education. Although I am not an expert in data analysis, I could understand most of what they were doing and learn a lot through their process of analysis. Secondly, considering the conclusion they have got from the study, I think it may be a guideline for our future development in educational app or educational platform. What they have got from the study is that ""Our empirical study showed that eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. We also demonstrated that eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique"" (Matsuda &amp; el, 2015). This would give inspiration that if the developers of eEPHIPANY could combine text analysis technique with it, the method could be even more powerful than it is now. In conclusion, for a person who does not have much knowledge in data analysis, this journal article is quite difficult to understand. I have to admit that I have difficulty understanding some of the matrix they have mentioned in this article. However, after all, it is a great article and the analysis of this method is of great value for the future development of data analysis in the field of education.",6,1,5,2
"1564","Chapter 1: Social Network Data","Notes: Through reading Chapter 1, I have learned a lot about social network data, the ways to analyze data and the differences between social analyst and conventional analyst. Since I am not a student majors in statistics or anything else relating to this, I find this article a little bit difficult to understand but is of great novelty. Follow lists some of the parts that really interest me and I may also have some questions relating to these points. First is of course about the major difference that social network data has comparing to traditional forms of data. By reading through the first part of chapter one, I have learned that there are two major differences. One is that while traditional data focuses more on actors and their attributes, social network data focuses more on actors and the relations between them. This then leads to the second difference that social network data is more holistic which means it focuses more on the data as a whole rather than putting emphasis on the single numbers in the dataset. The second point that interests me is in the part called ""modality and levels of analysis"". In this part, it simply describes how social analysts analyze data. My understanding is that they analyze the data as a whole to examine the single data. That is to draw from the big picture to the small picture. This is different from conventional data analysis in that people used to draw from small pictures to the bigger ones. Finally is the various methods that are employed to build the ties and relations between data. I have learned how these ties and relations are being built. However, I still have one questions concerning the note at the end of this chapter. This part notes on the difference between statistics and social network data. Does it mean that social network data focuses more on analyzing the relationship between the data rather than the traditional way of data analysis which focuses on the mathematical meanings of the data?",3,2,1,4
"1565","Learning Analytics Dashboards","Notes: This article teaches us how to build a dashboard. It describes the steps in detail. It is very useful for me although I failed to complete building the dashboard myself in the class.",0,1,-1,2
"1566","Measurement and its Uses in Learning Analytics","Notes: This article acts as an introduction to the learning analytics. In this article I could find some terms that I have learned in other courses. For example, ""formative assessment"". Whether it is learning analytics or mobile learning, the theories are much the same and they are all for the benefit of the students as well as the educators. I have also found some of the codes and data analysis methods that we have put into practice in the class and I have further understanding of how they would facilitate the education data analysis after reading this article.",2,0,2,2
"1567","Predictive Modelling in Teaching and Learning","Notes: In this chapter, the authors introduced the predictive modeling in Teaching and Learning. I can connect all the methods mentioned in this article to what I have learned in the class. Therefore, this article acts as a tool for me to fully understand what I have learned in the class and the ways to put knowledge into practice. Following are the parts that I found most interesting. Firstly, the authors used most of the article to introduce in detail the procedure of predictive modeling. From problem identification to the evaluation of a model, I could fully understand each step with the detailed explanation. Secondly, at the end of the article, authors mentioned the challenges and opportunities for predictive modelling, about which I was very curious. While reading through that part of the article, I could sense that there are a lot of opportunities for predictive modelling to function in the field of education. Although there are still challenges and problems needing to be addressed, the future for predictive modelling in overall of brightness.",1,2,-1,2
"1568","Ethics and Learning Analytics: Charting the (Un)Charted","Notes: This chapter discussed about the issues concerning the ethics in learning analysis. Since these issues are usually overlooked by the public as well as the analysts, this article is of great importance in reminding people to pay attention. I think the authorities need the students consent before using their education data for research or other purpose. In this era, people value privacy a lot. Education data is students' personal information as well. As stated in the article, ""An increasing awareness of learning analytics as a means of doing something to the student without that student necessarily knowing triggered further exploration of issues around surveillance, student privacy and institutional accountability""(Prinsloo &amp; Slade, 2006), policies should be drawn up to protect the students' privacy. Besides that, concerning the ""further consideration"" part in this article, I want to point out that while increasingly more institutions are conducting learning analysis to help students in education, specific organizations should be established to deal with the issues concerning the authorization of the education data so as to protect the students' privacy. This may be a path that experts and people in education field should work on the most in the future. ",6,4,2,2
"1569","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Notes: This article introduces the models built for predicting students' performance in specific academic activities and the explanatory models developed from these predicting models to group the students by their performance. Following are some of the parts that I have found very interesting. Firstly, among the two predictive models evaluated by the researchers, I am particularly interested in SimStudent. It is said that the model can ""simulate features of novices' learning trajectories of which domain experts may not even be aware""(Liu &amp; Koedinger, 2017). I am fully aware of the fact that in reality students performance would vary a lot and is not easy to predict or to analyze in precise. However, this model would help the experts to notice what they might ignore. It actually acts as a tool to facilitate the study of the experts on the students. Secondly, considering the student grouping model, I am glad to see that it aims at improving the existing models. It is said that ""unlike other, more 'bottom-up' models of creating stereotyped groups of students, this method yielded student groups that are readily interpretable and potentially actionalble""(Liu &amp; Koedinger, 2017). This is a great progress in analyzing the students' performance for it jumps out of the existing frame that has been formed for decades. I believe that this method would be of great benefit for educational experts to analyze the students' academic performance and would yield new exciting results.",7,1,6,5
"1570","Statistical graphics: making information clear – and beautiful","Notes: Sorry but I cannot find this article on internet",0,0,0,2
"1571","How to display data badly","Notes: I love this article for two reasons. First the author wrote in a tone of humor. It is more interesting than other serious articles lecturing about what you should do in analyzing the data. Secondly, unlike other article which would keep telling people that what they should do, this article does well in providing examples of the wrong ones. You cannot expect a novice data analyst to do everything correctly in his first try. Therefore, instead of telling him what he should do, please tell him not to do something.",4,2,2,2
"1572","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Notes:  This article discusses about the role as well as importance of using graphs to illustrate and show the relationship of the data within the dataset. I totally agree with the author on the importance of the graphs. The graphs are essential in the field of statistics. They help show the clear relationship of the data and help to illustrate as well as predict the trend of development. Therefore, this article is of great importance and is worth reading.",5,0,5,2
"1573","Junkcharts Trifecta Checkup: The Definitive Guide","Notes: This blog article introduces 8 types of Trifecta Checkup framework. The author introduces them in graphs to clarify his idea. The graphs are clear and easy to understand. Each is with an example to illustrate his idea.",1,0,1,2
"1574","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","HCA, hierarchical cluster analysis is adopted to conduct pattern analysis for studying which group of students are most likely to drop out. It is particularly interesting in comparing individual longitudinal pattern with his/her cohort peers' patters. "" students are clustered hierarchically using the average linkage algorithm, while grades are clustered chronologically and by an ordered repeating pattern from core subjects to non-core subjects."" &; ### The HCA analysis adopted here, complements the conventional regression analysis, in presenting the disaggregated analysis, saying that the each single observation in the entire data set can be analyzed. Not providing the overall parameter estimates enabling inference to population, the HCA is more like a unique way of 'look inside' and 'look closer' to our sample, each students' entire longitudinal history of achievement. &;",4,1,3,3
"1575","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","SNA in classroom. Social network analysis and relational data are simple yet profound in conducting researches. First of all, it is fairly simple to conduct SNA, and the visualization of it enables quite easy and straightforward measurement. However, it does imply and provide profound hints way beyond these, providing clues to explore deeper and more detailed research questions. It is a good start to both understand the learning community and the questions researchers are interested in. I particularly think it is a good bridge of quantitative and qualitative study of learning community, instead of peer qualitative interviews/ observations, SNA visualization offers another way to both understand the community better and to extend to the analysis of learning. ### The social network analysis has many implementations in classroom analysis, and can be further explored in/as many problems. One potential question I am particularly interested in is 'ties as predictors of performance', which is quite intuitive in the sense that the closeness/tie between students are intuitively expected to be the predictor of study group formation or resources sharing, hence maybe a significant predictor of peer performance, which is an aspect can be further explored in education researches since we do value peer effect a lot and it implies a huge policy implication. &;",7,2,5,4
"1576","Why Students Should Own Their Educational Data","Contextualized profile? The contextualized profile of the performance for individual modelling?, does this profile function the same as human brain? in the sense that it predicts in which environment are the learners and predict the respective personality or any pattern accordingly? &; &;; &;L.Todd Rose refer to the education market as a non-functional market, there is not enough transparency, which links to his point that market should recognize the importance for individual learners to own their own data, while under the current circumstance, every company or institution is just trying to innovate on their own platform, and ""hoarding"" data because that's the business model they have to have under the current market of education innovation/ Ed-tech. &; &; &; &;; There is a shift in the kind of patterns that we look for. In stead of the expected level of population, which is average level, now more on personal patterns across all dimensions. &;",3,0,3,2
"1577","Knowledge tracing: Modeling the acquisition of procedural knowledge","Research: Modelling students' changing knowledge state during skill acquisition. Cognitive model building for skill acquisition. Associate each programming action with a single production rule, which enabled by the knowledge tracing process modeling students as an overlay of the production rules and the mastery-based curriculum structure. &; The correlation of of ln(slip weight), provides the variability of the models' prediction of test performance reflecting persisting differences among students in the slip parameter. Considering students' performance is different from predicting students' knowledge state, which is intuitive in the sense that although students acquired the underlying programming rules, they can get wrong in the quiz.",2,1,1,3
"1578","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Difference between Educational Data Mining and Learning Analytics: 1.EDM is in the tech field; LA is in educational field 2. EDM, automation and tech driven; LA use tech as a tool to enhance human judgement 3. EDM focuses more on individual learner; LA is more holistic",0,0,0,2
"1579","Evaluating Machine Learning Models","Evaluation Metrics for supervised learning models. Accuracy= correct predictions/ total data points. Precision = happy correct answers/ total items returned. Recall = happy correct answers/ total relevant items. AUC, area under ROC curve, shows how may correct positive classifications can be gained as you allow for more and more false positives. ROC provided nuanced details about the behaviours of the classifiers, but it's hard to compare ROC with each other quickly. F1 score = 2 precision *recall/ precision+recall &;",6,1,5,5
"1580","Why Is Measuring Learning So Difficult?","Reasons: 1. Learning is multi-dimentional, and it is being simplified too much for analyzing.&; 2. Learning is broad, it is too contextualized to be measured outside its context. 3. Learning in different fields differ, and the availability of tools that can be used to analyze learning also differ across different fields. 4. Learning is personal, and the structure is hard to define, and it is the behaviors that can be captured, not necessarily the progress we made in our brain. 5. The hard part is how to measure, to find reliable and simple proxies indicators to measure learning. Certain indicators can indicate understanding. 6. Learning is complex, a black box, having other cultural and social meanings embedded. 7. A measure of competence is not enough, but also to measure at different time points to draw the conclusion of learning. 8. Measurement, psychological construct or achievement? 9. Analytics, to reveal to the learner the connections that they are making, probably without aware it, reveal more about their connected learning, not just diagnosis. 10. Learning might be a collection of things that we don't understand, regarding measuring it, both over-simplication and complexation are problems. &; &; &; &; &;",4,5,-1,1
"1581","Saturday Morning Breakfast Cereal","Data Mining Bias. In statistics, there is one kind of Type 1 error, the data mining bias, regarding enforced data mining trying to find any correlation or even causality that is actually frauds. And as indicated in the comics, any compulsive finding can be easily manipulated in education policy or intervention, and it is like, what I personally call feeding the students the formula milk powder. SO definitely data scientists should be extra cautious on any conclusion or intervention they suggest, even the most authentic data can tell a fraud if there is bias embedded.",2,5,-3,1
"1582","The Data Wrangling Cheatsheet","Argument of a function is the same as a function call right?",1,0,1,1
"1583","Data wranglers: human interpreters to help close the feedback loop","Feedback loop. Closing the feedback loop to improve learning is at the heart of good learning analytic practice, which asks for high quality data, and also the need for and value of human meaning-making to interpret the data for the further step of transforming the data into actionable intelligence to truly achieve the effectiveness of feedback loop. And the sector of learning analytics is widely seen as entailing a feedback loop, where the actionable intelligence is produced from data related to learning, to understand leaning and fundamentally to work out the interventions aiming of improving learning. single-loop learning double-loop learning #Reason: A gap in knowledge and practice between the data about learning and the academics who need to be in a position to act to improve teaching provision: a gap that could easily widen as the quantity and complexity of data increases. #The role of data wranglers: they are not only to analyze the data, but to increase the familiarity of academics with the data sources, to build the learning analytics capacity as part of a Community of Practice.&; #Both bottoms-up and top-down for understanding learning and providing actionable intelligence: A bottom-up, grounded approach is necessary for sense making, saying that contextualization helps to understand; and meaningful engagement at the strategic, top-down level is also essential, especially regarding organizational changes that learning analytics aiming to achieve. &;; Human interpreters. 1. The need of multidisciplinary teams, when it comes to interpret the data, in which human interpreters play a key role, concluded from previous literature. 2. Sense-making and social processes are important, because of the complexity of the data we are dealing with, since learning itself is a complex and social process, and the action and intention to interpret the data definitely asks for the ability to contextualize it in understanding and analyzing it. &;",8,3,5,1
"1584","Zuckerberg is ploughing billions into 'personalised learning' – why?","How 'personalized' different from individual, learner-centered, or customized learning. Zuckerberg defines it as ""teachers 'working with students to customize instruction to meet the students' individual needs and interest' "", which I still don't think is too different from the prior proposed terminologies, and neither intuitive in understanding. While the underlying principles are using technology, algorithms to provide students with 'personalized' content based on their past behaviour and demonstrated interests. To me, this is as bias as only using historical data to predict stock exchange price, saying that technology is only focusing what the students presented previously, but teachers are more able to use contents and instructions to guide/encourage students to progress. The expectation from teachers, to a large extent, acts an active role in students' development and progress.&; ### It is not practical in using algorithm to predict what is appropriate for each student, in the sense that our education, to a large extent, is not just about personal development, but also more of peer competition. And the fact that the technology is offering what predicted to fit the students, might be complementary for teachers' reference, is definitely not enough in encouraging students to 'step out of their comfort zone'. &;",6,1,5,2
"1585","Feature Selection","Feature Selection, Knowledge Discovery, for interpretability and for insight: Only a few factors matter in prediction; something in 2D for students to understand, which is less considered in machine learning field than data mining. Curse of Dimensionality: adding features needs more data you have, amount of data = alpha power of N (features). The power of features help us to narrow down to a few features, which hopefully makes the learning process a lot easier. The goal is to use, in general, a bunch of features, and apply algorithm to adjust only a few features, to both understand the data well and have easier learning problems.",3,1,2,5
"1586","RStudio Cheat Sheets","It seems like a very useful resources, just I haven't played with R enough to practice everything.",2,0,2,1
"1587","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Validity and Reliability Is LA, in fact, more as support technology itself while most of the stakeholders actually use it solely to tell the whole story? Apart from guaranteeing the reliability of the data, the external validity of the conclusion draw from learning analytics seems to be an underlying vulnerability of LA? saying if its representativity is valid to draw conclusion on either learning patterns or a particular education intervention, targeting a student population on a rather large scale. If the answer is NO, then is it one of the reasons for L.Todd Rose to argue that education data should focus, more on individual learning, rather than the expected value of population?",1,0,1,2
"1588","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Results: Intention predicts completion. Student knowledge increased. Limited data suggests that face-to-face students learned at least as much as online-only students. Students at all incoming knowledge levels benefited similarly from the course. Students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge. Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest. Predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking. Among students who responded to a 5-month follow-up, most student learning gains were retained after 5 months. Programming students retained more than concepts students did; very limited data on face-to-face students suggests their retention is at least as high as that of online-only students. &;",6,5,1,4
"1589","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Skill Models for online courses for better evaluation and course refinement. ""Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course."" The limitation in interpretability lies in the fact that "" the obvious limitation of the current technique is its dependence on manual inspection."" The articles present the analysis for eEPIPHANY outperforming human-crafted skill models, "" eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction.""",9,3,6,5
"1590","Chapter 1: Social Network Data","Network data vs. conventional data Different from conventional data emphasizing actors and attributes, network data focus more on actors and relations, which leads to the composition of nodes and and edges in network data. &; ### One key point of the network data arose is that since we are interested in both the actors and finding the relations in between different actors, so when we design sample for addressing the population we are interested in, we normally cannot include single observations, with that being said, if one observation is selected, than relevant 'neighbors' and their relations should also be included in the data collection. &; &;",1,0,1,4
"1591","Learning Analytics Dashboards","Learning Analytics Dashboards. Dashboards are particularly good regarding visually present the learning traces, process of the learners, which is what learning analytics is essentially for. However, not all the data are good data, and having visualization just for the sake of it is not enough. Though it appears that it is the technique enables dashboard visualization, it is actually the goal set by the developper/evaluator that is important. What is the goal of developing the learning analytis dashboard, the very first step is to understand the goal, this paves the foundation for the actual execution afterwards. &; ### Having dashboard is good for learning analytics, either for analysis or for presenting the result for others. But it is not just done for the sake of it, though it is the case a lot of times. The chapter offered four guidance, regarding what kind of data can be visualized, who is the intended audience, what is the goal of visualization, and how can it be done. &; &; &;",8,0,8,2
"1592","Measurement and its Uses in Learning Analytics","Psychological Measurement 1. Composition: defining a construct; specifying a measurement model and developing a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome. 2. Construct &;&;&; - Construct is used interchangeably with latent variable, while trait is used to imply a construct that is stable over time. (e.g. tape measure provides a scale) &;&;&; - Psychological constructs, e.g. math ability and extraversion, equating the constructs to scores on instruments used to measure them. &;&;&; -We can infer an extremely partial list of constructs relevant to learning analytics from the instruments already developed to measure them. 3. Measurement Instruments &;&;&; -tests, questionnaires, having items or indicators. 4. Error &;&;&; - random error, unbiased,&; &;&;&; - systematic, biased 5. Models to use &;&;&; - Factor analysis &;&;&; -Latent class and latent mixture models &;&;&; -Item Response Theory 6. Explanation and/or Prediction Learning analytics has been described as a middle space between learning science and analytics, so the field may benefit from understanding the nuances of both perspectives. &; &; &; &; &;",2,5,-3,5
"1593","Predictive Modelling in Teaching and Learning","Predicting students' academic achievement. Predictive modelling in the educational domain. Different from explanatory modelling, which aims to provide explanations for the results and imply a causation, the predictive modelling intends to create a model predicting the values of new data based on observations. Based on the intuition that training data can be used to predict the value of new data. And the implementation of it in education including identifying students vulnerable in learning outcomes, etc. &; ### Workflow: 1. Problem Identification, 2. Data Collection, 3. Classification and Regression, 4. Feature Selection, 5.Model Building (Linear Regression, Logistic Regression, KNN, Decision Trees, Naive Bayes Classifiers, Bayesian Networks, Support Vector Machines, Neutral Networks, Ensemble Methods) 6. Model Evaluation &;",2,4,-2,3
"1594","Ethics and Learning Analytics: Charting the (Un)Charted","Ethics -Persuasive surveillance, the role and unintended consequences of algorithms. -ethics and privacy as crucial enablers within learning analytics. &;&;&; Is it inevitable, for people to realize the importance of the ethics only after a series of misconduct, or even catastrophic consequences? Just like in any other fields? As in Finance sector, the CFA certificate allocates a huge weight on the ethics, aiming to address the ethics in the finance field, and though the Edtech field can adopt some similar approaches, saying ""inventing"" some kind of certificate exam stressing the importance ethics, but comes to the real world practice, it is the transparency and the regulation of the market increases people's trust on the data users. But then comes to the question that, who and which entity has the entitlement to regulate? How can we deal with the monopoly of big corporation or any unwanted intervention of the state, or it is inevitably controversial and better than nothing? It appeals to me that the entitlement of drafting and mapping code of ethics even indicate some sort of sovereign and power relation in the field? &; &; &;",4,2,2,2
"1595","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The article argues that, while in the EDM field many of the researchers adopt predictive models and aspires to reach prediction accuracy, the field could benefit a lot in adopting explanatory models, in improving learning outcomes. Considering interpretability and actionability in producing explanatory models is important. Features of explanatory models, including starting with 'clean' independent variables, dependent variable maps to a well-defined construct, and is characterized by fewer estimated parameters. &;",3,0,3,5
"1596","Statistical graphics: making information clear – and beautiful","The article presented some of the key characteristics that a good graph should have, in the example of research regarding measles. When we present graphs, while we putting our faith in the graph for it to tell the story, we do need to be mindful to pick the perspective, add narration, to let the graph tell a good story in a clear way, if not comprehensive. It is just like human telling story, it is good to have a anecdotes to boost audience' interest but it needs to be a good anecdote, so does the graph, it should be relevant, clear, informative. We need to be clear of the purpose of having this graph, then to optimize the usage of it. ### The shift in making graphs. It is said in the article that there is shift from making graphs beautiful to making it clear, which is really good in the sense that graph is at the end of day, an instrument complementing to help better elaborate the arguments/facts which may be hard for audience to understand if they cannot visualize it, so it should be informative and clear at the first place. &;",17,1,16,2
"1597","How to display data badly","With an increasing use of data in both researches and practices, data display is not just for 'serious' usage and it is have been widely adopted in all kinds of scenarios and contexts. Though the article present the key characteristics we need to remember in a sarcastic tone of instructing how to make bad data display, yet essentially we want to have informative, clearly presented, relevant, easy-to-comprehend, accurate, data display. &; ### ""Chartjunk"" is a very interesting topic/issue raised in this article, saying that if we don't have many to be included in graph, instead of having our audience suspecting we don't really have much to show, we can fill the graph with nondata figurations, if we want to present data badly. This is something we really need to avoid, particularly in the sense that it is the time everyone talks about the data, and knows a little bit more about what to expect from a graph, than before. Graph is no longer an ornament, but actual information.",2,3,-1,2
"1598","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Clash or Synergy ""...our difficulties with some popular visualizations arose from an insufficient understanding—by ourselves and others—of the multiplicity of goals involved in data display."" This articles, after pointing out many of the Infovis not really abiding the statistical rules, also states that many of the times it is not really a clash but reflecting a different needs of constructor. While statisticians aim to provide accurate result for readers to draw conclusions, the data scientists more on the side of using infographics to attract the readers. Since both approach have their rationale and value, so there isn't necessarily clash of interests between the two, and synergy between the two could be expected to better exploit the value of each of them. &; ### As the article pointed that, many of the times, the statistics criticize the infovis not being statistically accurate/ acceptable, without communicating or trying to understand the incentives behind of having infovis. It is not really a question of who is right or wrong, but more of which is more appropriate in what kind of use? and both sides can benefit a lot of from understanding each other, and then we are back to the question that what is the visualization for and what we intends our audience to get out from that specific graph? Once we have that clear, we will be in a better place, balancing between statistical relevance and infovis' charisma. &; &;",9,6,3,2
"1599","Junkcharts Trifecta Checkup: The Definitive Guide","The criteria of criticism, as what the author think, should comes from three perspectives, good question, good data, good visual. And the author presents different examples regarding fulfilling or failing to fulfill the three criteria. Among which, I do think the Type QD is the easies to address, having good question, good and relevant data, so only the visual part need to be addressed. Then most of the case in real world, I FEEL that this is the least scenario happening, most of the difficult cases are, either the question being left out to address, or no good or relevant data is available. And these two questions, are not just about good/bad visualization, much more beyond that. What can we do to best address that? &; ### The author states three criteria, Q- question, D- data, V- visual, for elaboration what is a good visualization, and what is not. While good examples are presented, I do feel it is lacking real value in practice. Since most of the researchers, data scientists all want to to fulfill the three criteria, but many of the cases, especially for bad or no question, and bad data, it is more about research (project) design, and the availability of the data, which lies far beyond the visualization part.",11,7,4,2
"1600","Measurement and its Uses in Learning Analytics","The challenge of understanding how theory and analytics relate is to move “from clicks to constructs” in a principled way. Learning analytics are a specific incarnation of the bigger shift to an algorithmically pervaded society, and their wider impact on education needs careful consideration. In this chapter, we argue that by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Fundamentally then, we argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. We outline some key provocations in the development of learning analytic techniques, key questions to draw out the purpose and assumptions built into learning analytics. We suggest that using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.",0,0,0,2
"1601","Ethics and Learning Analytics: Charting the (Un)Charted","The challenge of understanding how theory and analytics relate is to move “from clicks to constructs” in a principled way. Learning analytics are a specific incarnation of the bigger shift to an algorithmically pervaded society, and their wider impact on education needs careful consideration. In this chapter, we argue that by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Fundamentally then, we argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. We outline some key provocations in the development of learning analytic techniques, key questions to draw out the purpose and assumptions built into learning analytics. We suggest that using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.",0,0,0,2
"1602","Predictive Modelling in Teaching and Learning","The challenge of understanding how theory and analytics relate is to move “from clicks to constructs” in a principled way. Learning analytics are a specific incarnation of the bigger shift to an algorithmically pervaded society, and their wider impact on education needs careful consideration. In this chapter, we argue that by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Fundamentally then, we argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. We outline some key provocations in the development of learning analytic techniques, key questions to draw out the purpose and assumptions built into learning analytics. We suggest that using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.",0,0,0,2
"1603","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The challenge of understanding how theory and analytics relate is to move “from clicks to constructs” in a principled way. Learning analytics are a specific incarnation of the bigger shift to an algorithmically pervaded society, and their wider impact on education needs careful consideration. In this chapter, we argue that by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Fundamentally then, we argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. We outline some key provocations in the development of learning analytic techniques, key questions to draw out the purpose and assumptions built into learning analytics. We suggest that using “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.",0,0,0,2
"1604","Statistical graphics: making information clear – and beautiful","http://www.stat.columbia.edu/~gelman/research/published/niemi.pdf     Improving figures requires two key decisions: --Who is your target audience? --What are you trying to show?      ",0,0,0,2
"1605","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","can't open",0,0,0,1
"1606","Junkcharts Trifecta Checkup: The Definitive Guide","helpful toolkit for chart makers   In putting this framework together, I aimed to make it simple to use and broadly applicable. The Trifecta Checkup involves only three investigations:   What is the QUESTION? What does the DATA say? What does the VISUAL say?    ",0,0,0,2
"1607","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","   This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators.   ",0,0,0,3
"1608","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","network concepts:     social network basics: actors and connections     network types:     - number of types of actors: unipartite bipartite     -nature of the ties: undirected directed     -binary value network level concept and measures     -density     -homophily         -social inflence         -social selection actor level variable     -degree     -closeness     -betweenness     -eigenvector  ",0,0,0,4
"1609","Why Students Should Own Their Educational Data","Rose not only wants educators to develop a personalized teaching approach for every individual student, but also for every individual student across different contexts we’re going to push for in my organization is you’ve got to have a third party who is responsible for protecting learner data. Then the student could have, say, a decade of data about the way that they’re learning.",1,0,1,2
"1610","Knowledge tracing: Modeling the acquisition of procedural knowledge","can't open",0,0,0,1
"1611","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","   a good review of EDM and LAK International Conference on Educational Data Mining     the International Educational Data Mining Society     Learning Analytics and Knowledge conference     Society for Learning Analytics (SoLAR -- http://www.solaresearch.org/)             ",1,0,1,2
"1612","Evaluating Machine Learning Models"," Learn the stages involved when developing a machine-learning model for use in a software application Understand the metrics used for supervised learning models, including classification, regression, and ranking Walk through evaluation mechanisms, such as hold?out validation, cross-validation, and bootstrapping Explore hyperparameter tuning in detail, and discover why it’s so difficult Learn the pitfalls of A/B testing, and examine a promising alternative: multi-armed bandits Get suggestions for further reading, as well as useful software packages ",1,2,-1,5
"1613","Why Opting Out of Student Data Collection Isn’t the Solution","It’s useful to analyze which purposes of student data collection are primary, for which permission is expected and implied when data is collected. primary use: administrative and educational purposes- no opt out secondary use: purpose unrelated to the educational and related activities Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.",1,0,1,2
"1614","Why Is Measuring Learning So Difficult?","why is measuring learning is so difficult?    - learning is multi-dimensional. we have to simplify it too much to capture data    -learning is too broad, too contextual    -learning is a personal thing    -no reliable simple proxy indicators    -learning is about growth, not performance    -learning is about either psychological constructs like self-efficacy or achievement   analytic should reveal to the learner even more possibilities for their own connected learning, rather than simply be a kind of diagnosis of what's happening now.  ",1,1,0,1
"1615","Saturday Morning Breakfast Cereal","the world may overreact to some unclear research findings. keep rational towards trends in our society",0,1,-1,2
"1616","Data wranglers: human interpreters to help close the feedback loop","can't open",0,0,0,1
"1617","Zuckerberg is ploughing billions into 'personalised learning' – why?","3 major flaws for PL: 1 education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. 2 while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. 3 children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher. In subcontracting out teaching to technology, the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced.   where could PL help: Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective.",5,5,0,2
"1618","Feature Selection","feature selection -knowledge discovery interpretability and insight -curse of dimensionality  ",0,0,0,5
"1619","Chapter 1: Social Network Data","""Network"" data (in their purest form) consist of a square array of measurements. Network data are defined by actors and by relations. Most commonly, network analysts will identify some population and conduct a census. he boundaries of the populations studied by network analysts are of two main types. Probably most commonly, the boundaries are those imposed or created by the actors themselves. Alternatively, a network analyst might take a more ""demographic"" or ""ecological"" approach to defining population boundaries.   Sampling ties: Full network methods Snowball methods Ego-centric networks (with alter connections) Ego-centric networks (ego only)  ",0,0,0,4
"1620","RStudio Cheat Sheets","a quick reference",0,0,0,5
"1621","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","can't open",0,0,0,1
"1622","The Big Five and Visualisations of Team Work Activity","active radar  interaction network  wattle tree ",0,0,0,2
"1623","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","interesting results:    Intention predicts completion; little else does.       Students at all incoming knowledge levels benefited similarly from the course.       Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest.       Predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking.     ",3,3,0,4
"1624","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","   Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.   ",8,1,7,5
"1625","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","   eEPIPHANY, to fully and automatically discover skill sets from online course data, which are the combination of the assessment item text data (i.e., problem and feedback text sentences for assessment items) and student learning interaction data. eEPIPHANY is a collection of data-mining techniques to automatically refine (or rebuild) a human-crafted set of skills, initially given by course designers and developers.    The most important goal of eEPIPHANY is to provide constructive feedback to online course designers and developers for iterative course improvement      ",1,1,0,5
"1626","Using data mining to predict secondary school student performance","   student achievement is highly affected by previous performances.     there are other relevant features, such as: school related (e.g. number of absences, reason to choose school, ex- tra educational school support), demographic (e.g. stu- dent’s age, parent’s job and education) and social (e.g. going out with friends, alcohol consumption) variables.       ",1,0,1,3
"1627","Developing a generalizable detector of when students game the system","   Within Cognitive Tutors, gaming the system consists of the following behaviors:   quickly and repeatedly asking for help until the tutor gives the student the correct answer (cf. Aleven 2001)   inputtinganswersquicklyandsystematically.Forinstance,systematicallyguessing numbers in order (1,2,3,4...) or clicking every checkbox within a set of multiple- choice answers, until the tutor identifies a correct answer and allows the student to advance.      ",2,0,2,5
"1628","Big Data in Education","can't open",0,0,0,1
"1629","Hands-On Programming with R","super helpful guide book for R users",1,0,1,2
"1630","Principal Component Analysis explained visually","Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize.",1,0,1,2
"1631","Measurement and its Uses in Learning Analytics","Note Through the provocations, we have drawn attention to the ways in which analytic approaches and artifacts subscribe to particular perspectives on learning: they implicitly make claims across the EPA triad, and the provocations drawn from them. Tools can be used in many ways, and should not be isolated from the context of use.",0,0,0,2
"1632","Ethics and Learning Analytics: Charting the (Un)Charted","Notes Through the provocations, we have drawn attention to the ways in which analytic approaches and artifacts subscribe to particular perspectives on learning: they implicitly make claims across the EPA triad and the provocations drawn from them.",0,0,0,2
"1633","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Note Tools can be used in many ways, and should not be isolated from their context of use.Interactional affordances are to some degree ""in the eye of the beholder."" We offer these provocations as a pragmatic tool for thinking, for designers, educators, researchers, and students — whether considering how one currently makes use of analytical tools, how one might do in the future, or indeed when designing new tools for new contexts.",1,0,1,2
"1634","Junkcharts Trifecta Checkup: The Definitive Guide","Note The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how I like to organize the thinking behind my critique pieces. The need for such a framework is clear. Opinion pieces on specific data graphics frequently come across as stream of conscience. Proclaiming a chart ""mind-blowing"" or ""worst of the century"" isn't worth much if the author cannot articulate why. The state of dataviz criticism has not progressed further than assembling a set of ""rules of thumb"".",4,4,0,2
"1635","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Notes The hierarchical cluster analysis and visualization method, detailed here as a clustergram, provides additional information about students that past regression analyses do not. While both types of methods provide information for identification of overall student outcomes prior to those outcomes, the clustergram displays the entire set of data analyzed for every case in the dataset, patterned in a way that aids overall interpretation. This is in stark contrast to regression analyses that aggregate data and report overall parameter estimates. Much like a medical x-ray, the clustergram provides a unique way to “look inside” each student’s entire history of achievement, and examine that history in context with other students who have performed in a similar manner through pattern analysis. The interpretation of these data patterns for 3DM is then aided through this type of pattern analysis, and helps point to possible areas and timing for future interventions.",2,3,-1,3
"1636","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Note Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. ",1,1,0,4
"1637","Why Students Should Own Their Educational Data","Note  It turns out your personality and your learning varies across contexts. Let’s just use aggression. Say you tend to be highly aggressive in classrooms where it’s new information and you have a male teacher. It’s that level of information. If we know that. That kind of data has been shown to be predictive of your behavior up to 10 years out. Which is not that surprising from a neurological perspective. Your brain is trying to predict its own environment. And you’ll know—given this—this, this, this is how you’ll behave.",0,1,-1,2
"1638","Evaluating Machine Learning Models","Notes  Learn the stages involved when developing a machine-learning model for use in a software application Understand the metrics used for supervised learning models, including classification, regression, and ranking Walk through evaluation mechanisms, such as hold?out validation, cross-validation, and bootstrapping Explore hyperparameter tuning in detail, and discover why it’s so difficult Learn the pitfalls of A/B testing, and examine a promising alternative: multi-armed bandits Get suggestions for further reading, as well as useful software packages ",1,2,-1,5
"1639","Why Opting Out of Student Data Collection Isn’t the Solution","Note Some “primary use” categories are obvious. In order for schools to function, they need basic information about students and parents. They need to record grades, know who is eligible for subsidized lunch, and who has special learning needs. Schools need to share data with vendors who operate cafeterias, school buses, and data storage systems for the school. In general, we might think about administrative and educational purposes as primary purposes of a school system where data collection is necessary, expected, and where it is not feasible to provide parents with choices because to do so would prevent the school from providing students with basic school educational services.",0,0,0,2
"1640","Zuckerberg is ploughing billions into 'personalised learning' – why?","Note Zuckerberg has a clear definition in his mind, however. For him, personalized learning is about teachers “working with students to customize instruction to meet the student’s individual needs and interests”. Although the Chan Zuckerberg Initiative’s Personalized Learning Platform is not part of Facebook, the underlying principles are the same: human work is replaced by technology, algorithms provide users with content based on an analysis of their past behavior and demonstrated interests. This is similar to how Facebook’s news feed works, and other commercial personalization models based on text and behavior analysis.",4,0,4,2
"1641","Feature Selection","Note Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in. Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.",0,0,0,5
"1642","Chapter 1: Social Network Data","Notes True interval level measures of the strength of many kinds of relationships are fairly easy to construct, with a little imagination and persistence. Asking respondents to report the details of the frequency or intensity of ties by survey or interview methods, however, can be rather unreliable -- particularly if the relationships being tracked are not highly salient and infrequent. Rather than asking whether two people communicate, one could count the number of email, phone, and inter-office mail deliveries between them. Rather than asking whether two nations trade with one another, look at statistics on balances of payments. In many cases, it is possible to construct interval level measures of relationship strength by using artifacts (e.g. statistics collected for other purposes) or observation.",1,0,1,4
"1643","The Big Five and Visualisations of Team Work Activity","Note These visualizations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.",2,0,2,2
"1644","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Note Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future direction",9,4,5,4
"1645","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Notes As the ITSs move from the labs to the classrooms, the next logical step may be to largely move the authoring efforts from highly specialized graduate students to domain experts (including teachers), but we are interested in investigating an intermediate step that consists in a comprehensive, flexible and usable framework for programmers and people skilled in knowledge-based systems. We are aware that our solution, based on generative models, may be justified only in well-defined domains and that some ill-defined tasks, such as design-based ones, may be challenging at best. However, there is no such tool available for the ITS community that is explicitly designed to facilitate the experimentation of different pedagogical approaches.",3,0,3,1
"1646","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Note How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. ",12,2,10,5
"1647","Using data mining to predict secondary school student performance","Note The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.",2,0,2,3
"1648","Developing a generalizable detector of when students game the system","Note Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.",1,0,1,5
"1649","Cross Validation","Notes I think there is a mistake in this video. Cross validation is (typically) not used to select the best model, and as such it doesn't pick the best one. Instead, it is used for evaluation and takes the average. ",2,0,2,5
"1650","Hands-On Programming with R","Note  Memorize (store) entire data sets Recall data values on demand Perform complex calculations with large amounts of data Do repetitive tasks without becoming careless or bored ",0,3,-3,1
"1651","Principal Component Analysis explained visually","Note With three dimensions, PCA is more useful, because it's hard to see through a cloud of data. In the example below, the original data are plotted in 3D, but you can project the data into 2D through a transformation no different than finding a camera angle: rotate the axes to find the best angle. To see the ""official"" PCA transformation, click the ""Show PCA"" button. The PCA transformation ensures that the horizontal axis PC1 has the most variation, the vertical axis PC2 the second-most, and a third axis PC3 the least. Obviously, PC3 is the one we drop.",2,3,-1,2
"1652","Video: Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult? As far as I am concerned, learning is a complex process which contains many components, such as human cognition, social and culture influence. Also, learning happens everywhere and any time. It is hard for people to actually capture the learning data. What people can do is to capture and record the behavior and outcomes of learning. However, the learning process in people’s head is really difficult to measure.",0,5,-5,1
"1653","Chapter 1","Dr. Knight and Dr. Shum offers us with insightful understandings of learning analytics. They put forward a triadic depiction of the relationship between elements of theory and practice in the development of learning analytic techniques, which is of great help to me. As learning is a complex process, there are a lot of implicit claims we should be aware of when doing the assessment. Dr. Knight and Shum raised six questions to better understand measurement. We measure what we value.",2,1,1,2
"1654","Chapter 4","As far as I am concerned, it is important for Learning Analytics researchers to keep the moral code in mind because learning analytics is a means of doing something to the student without that student necessarily knowing further exploration of issues around surveillance, student privacy and institutional accountability. In this process, the management, classification and storage of data all relate to the privacy of students. Since learning analytics is an immature discipline, there are a lot of ethical implications in the collection, analysis of student data to be considered. I am in favor with the idea that learning analytics researchers should accept the ethical principles before conducting research.",1,1,0,2
"1655","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Dr. Greller did an amazing job to provide us with the following figure.  The sis parameters in the picture are the six different dimensions in the analytics process. Since they are closely related, we should consider all of them in the design process.",0,0,0,1
"1656","Saturday Morning Breakfast Cereal - Clock","The comic about forcing students to assemble clocks is really funny. Actually, I think it reveals a case that educators use the educational data in a wrong way. In the first picture, the sociological discovery shows that 90% of elite engineers were observed disassembling and reassembling clocks as children, which contributes to the new “Assemble Clocks Program” in school. However, the school leaders ignore the fact that elite engineers assembling clocks in childhoods does not deduce the conclusion that children assembling clocks properly will surely become remarkable engineers. Since learning is a complex process, there are various factors to be considered when analyzing it. Learning happens everywhere and at any place, and most of the time, is unintentionally. When people become aware that their behavior is under surveillance, with potentially important consequences, their behavior may be distorted and the learning outcomes maybe counterproductive.",1,5,-4,2
"1657","Why Students Should Own Their Educational Data","Mr Rose believes that technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.” And professor Todd Rose brings an interesting notion to me—jagged profile, which indicates we cannot actually tell anything in population studies about any individual in a specific group. He argues that a lesson designed for average is designed for nobody (which I really doubted at first). In addition, Dr. Rose raises a question which worths thinking about: what’s is it that schools can do face to face that the online courses cannot. As far as I am concerned, the class interaction between students and teachers is one of the reasons that online courses cannot replace classroom teaching, With face-to-face interaction and communication, teachers can assess students’ level of understanding by observing their class performance and then adapt the lesson in time.",1,2,-1,2
"1658","Why Students Should Own Their Educational Data","Mr Rose believes that technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.” And professor Todd Rose brings an interesting notion to me—jagged profile, which indicates we cannot actually tell anything in population studies about any individual in a specific group. He argues that a lesson designed for average is designed for nobody (which I really doubted at first). In addition, Dr. Rose raises a question which worths thinking about: what’s is it that schools can do face to face that the online courses cannot. As far as I am concerned, the class interaction between students and teachers is one of the reasons that online courses cannot replace classroom teaching, With face-to-face interaction and communication, teachers can assess students’ level of understanding by observing their class performance and then adapt the lesson in time.",1,2,-1,2
"1659","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Prior to reading the article this week, I have no idea of the difference between Data Mining and Learning Analytics. I thought they are the same concept that refers to analyzing educational data in order to better assessment and problem-solving. However, Dr. Siemens and Baker shows us nuanced but significant distinctions between LAK and EDM. To conclude, there are there main differences:Type of discovery.EDM has a considerably greater focus on automated discovery, and LAK has a considerably greater focus on leveraging human judgment. 2. Type of adaption and personalizationEDM models are more often used as the basis of automated adaptation, conducted by a computer system.LAK models are more often designed to inform and empower instructors and learners. 3.Holistic and reductionistic frameworksThe “discovery with models” paradigm for EDM research discussed in is a clear example of this paradigm. By contrast, LAK researchers typically place a stronger emphasis on attempting to understand systems as wholes, in their full complexity. This article indeed offers me a better understanding about the similarity and difference between LAK and EDM.",4,0,4,2
"1660","The Learning Analytics Landscape: Tension Between Student Privacy and the Process of Data Mining","Quotes: Educational data mining (or learning analytics) is the process of collecting and analyzing a wide range of student data (and in great volume) in order to derive knowledge about learning habits and behaviors in order to personalize educational interventions to maximize student outcomes. Students often show little or no concern about sharing their personal data, especially in an environment of increased sharing through social media, which creates a landscape of ""digital promiscuity"" (Murphy,2014). Paul Prinsloo and Sharon Slade's framework of student learning. A need for a ""palette of 'privacy solutions'"" I strongly agree that providing people with notice, access, and the ability to control their data is key to facilitating some autonomy in a world where decisions are increasingly made about them with the use of personal data, automated processes, and clandestine rationales, and where people have minimal abilities to do anything about such decisions. (Daniel Solove)",2,1,1,2
"1661","Evaluating Machine Learning Models","Machine learning is a field full of technical terms, making it difficult for beginners to get started. One of the core tasks in building a machine learning model is to evaluate its performance. Machine Learning workflow ",0,1,-1,5
"1662","New technology “clouds” student data privacy","Just as technology delivers promising devices and applications to enhance learning, heightened privacy concerns call on schools and systems to become more involved and technology literate. This article provides us with a potential solution to the problem. Step 1 Designate a privacy official Step 2 Engage legal counsel Step 3 Get to know the laws Step 4 Adopt school community norms and policies Step 5 Implement workable processes Step 6 Leverage procurement Step 7 insist on professional development Step 8 Involve papernts Step 9 Data security must be a priority Step 10 Monitor and adjust I think it is a good framework to flow. But protecting students' education data privacy is complicated when actions are taken.",2,2,0,2
"1663","Why Opting Out of Student Data Collection Isn’t the Solution","Fair Information Privacy Principles (FIPPS), which form the basis of most privacy laws in the U.S. and around the world. Policymakers seeking to set privacy rules for students data need to consider both the privacy rights of parents and students and the expectations of parents that teachers and administrators have access to the data needed to make smart decisions about managing our educational system. Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system - not an opportunity to avoid resolution of education policy issues that affect all students. It is hard to make regulations on educational data, since they are crucial for school administrators to make reasonable policies and provide good educational products for students.",5,1,4,2
"1664","Why Is Measuring Learning So Difficult?","Why is measuring learning so difficult? As far as I am concerned, learning is a complex process which contains many components, such as human cognition, social and culture influence. Also, learning happens everywhere and any time. It is hard for people to actually capture the learning data. What people can do is to capture and record the behavior and outcomes of learning. However, the learning process in people’s head is really difficult to measure.",0,5,-5,1
"1665","Saturday Morning Breakfast Cereal","The comic about forcing students to assemble clocks is really funny. Actually, I think it reveals a case that educators use the educational data in a wrong way. In the first picture, the sociological discovery shows that 90% of elite engineers were observed disassembling and reassembling clocks as children, which contributes to the new “Assemble Clocks Program” in school. However, the school leaders ignore the fact that elite engineers assembling clocks in childhoods does not deduce the conclusion that children assembling clocks properly will surely become remarkable engineers. Since learning is a complex process, there are various factors to be considered when analyzing it. Learning happens everywhere and at any place, and most of the time, is unintentionally. When people become aware that their behavior is under surveillance, with potentially important consequences, their behavior may be distorted and the learning outcomes maybe counterproductive.",1,5,-4,2
"1666","The Data Wrangling Cheatsheet","The data wrangling function with dplyr and tidyr function in R is very useful. In this semester, I have almost use all of the functions in the cheat sheet. It help me to make the data more categorized and tidy.",2,1,1,1
"1667","Zuckerberg is ploughing billions into 'personalised learning' – why?","For Zuckerberg, personalized learning is about teachers ""working with students to customize instruction to meet the student's individual needs and interests"" There are three potential flaws of Zuckerberg's idea of personalized learning. First, by feeding children only the content they're interested in, we may end up with many specialists and few generalists. Second, student's lack of ability to compensate may mean they suffer as a result. Third, children's preferences are not fixed. In subcontracting out teaching to technology, the risk is that the valuable social contact between students, teachers and parents that's inherent to effective learning will be reduced. Speaking of personalized learning, we may think of a lot of advantages. For me, personalized learning means that teachers would modify the curriculum and teaching methods according to student's cognitive level and learning habits. In traditional classrooms, it is hard for teachers to pay specific attention to individuals and make personalized learning plan for them. They have to deliver the lesson on the average level. In this respect, technology could help a lot. With collecting and analyzing student's previous learning data, algorithm could provide them with a scientific learning plan. However, learning process is complicated. It is still a problem that whether technology could effectively detect and collect people's educational data. *adaptive study plan: adapts all topics to a learners' pace. customized study plan: provides a course modified according to the teacher's knowledge of what fits the students best. As Mike Sharples and other Open University colleagues write in their Innovating Pedagogy 2015 report, personalized learning combined with emotional analytics, personal inquiry, dynamic and stealth assessment could be a very powerful combination.      ",6,7,-1,2
"1668","Introduction to Feature selection for bioinformaticians using R, correlation matrix filters, PCA & backward selection","A relatively sophisticated way to do the correlation matrix analysis would be to perform a Principal Components Analysis. It is a multivariate technique that summarizes systematic patterns of variation in the data and is used for studying one table of observations and variables with the idea of transforming the observed variables into a set of new variables, the principal components, which are uncorrelated and explain the variation of the data.",0,0,0,5
"1669","Why open data matters in education","The advantage of open data: Open data increases the understanding of the disparity (in educational systems and the growth of students across the world) across different countries tremendously. Solution providers can better understand what works where and what does not works in what parts of the world. They can also understand and analyze the situations most amicable for creating a learning environment. Applications built on top of open data can be used to monitor among other things, the learning patterns of students, their performance patterns, teacher absenteeism, and on a larger scale regions that perform better and regions that perform poorly. This creates a better grip on the problem we are encountering as well as the scale of the problem.",8,3,5,2
"1670","Chapter 1: Social Network Data","""Conventional"" social science data consist of a rectangular array of measurements. ""Network"" data consist of a square array of measurements. Network data are defined by actors and by relations (or ""nodes"" and ""edges""). The nodes or actors part of network data would seem to be pretty straight-forward.",1,0,1,4
"1671","Microsoft and Knewton partner up to bring adaptive learning to publishers & schools","I think it is a win-win plan, since Microsoft will be able to enhance its product with an adaptive learning tool, and Knewton gains access to a vast distribution channel.",1,0,1,2
"1672","Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms - Boston College Law Review","The article examines several existing privacy regimes and explains why these approaches inadequately address current Big Data challenges. In  practice, Big Data encompasses three aspects of data magnification and manipulation. First, it refers to technology that maximizes computational power and algorithmic accuracy. Second, it describes types o analyses that draw on a range of tools to clean and compare data. Third, it promotes the belief that large data sets generate results with greater truth, objectivity, and accuracy. The article shows us several examples that make me realize by some unconscious behavior online, one may easily reveal his/ her information. As Big Data is versatile, dynamic and unpredictable, traditional notions of privacy that isolate certain categories of information - such as PII - to regulate collection, utilization, or disclosure are ill - suited to address these emerging risks.",2,5,-3,2
"1673","Text Mining, Big Data, Unstructured Data","Text Mining is a new terminology for me. It is to process unstructured (textual) information, extract meaningful numeric indices from the text, and, thus make the information contained in the text accessible to the various data mining algorithms.",0,0,0,1
"1674","The Quantified Student: An App That Predicts GPA","In a small experiment, researchers at Dartmouth College have shown that data automatically collected by an Android app can guess how students are spending their time- predicting their end-of-term grades with scary accuracy. How? A smartphone generally has Wi-fi, GPS to detect location, an accelerometer which detects motion and a microphone, which can pick up nearby sound. The phone also senses whether or not it's being charged or being used. It modeled several different behavior scenarios: 1) sleeping 2) physical activity 3) studying 4)partying Conclusion: Slightly more surprising, students tended to perform better when they buckled down towards the end of the semester. After the midterm, ""A"" students partied less, stayed at home more, and spent less time in conversation. But what's interesting is that this relationship held true whether they started out as relative extroverts or introverts. It wasn't the absolute time spent partying, in other words, it was the ability to prioritize that really counted. Also of note: students with better grades studied in louder locations. Were they benefiting from study groups? Maybe. The article also mentioned a terminology ""persuasive technology"". It means technology that is designed to change attitudes or behaviors of the users through persuasion and social influence, but not through coercion. I found this really interesting. People take mobile phone with them all day. Many data can be collected through this process. If these data could be used appropriately, apps could be made to improve people's lifestyle. However, data privacy is still a problem needed attention.",4,4,0,2
"1675","The ggvis R package - How to Work With The Grammar of Graphics - YouTube","the ggvis R package enables us to manage data in a visualized way. I like the function that classify data in different color. It is convenient and efficient for us to directly see the categories of data.",1,0,1,1
"1676","Passing the Privacy Test as Student Data Laws Take Effect","For SOPIPA, the Student Privacy Pledge, and most  state laws, the first key question is to determine whether a particular program or device is designed and marketed for use in schools. In my opinion, sometime it is hard to tell whether the information is identified or de-identified.",0,1,-1,2
"1677","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This paper compares the similarities and distinctions between two research communities: Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK). Given the overlaps in research interests, goals, and approaches between the EDM and LAK communities, the authors of this paper recommend increased and formal communication and collaboration between these communities. A formal relationship will allow each community to continue developing their specialized and distinct research methods and tools, while simultaneously increasing opportunities for collaborative research and sharing of research findings between the communities.This alliance would also strengthen our opportunities to influence non-academic research and practice. ",2,0,2,2
"1678","Hands-on programming with R","It is a lot of fun to read this book. Preliminary but easy to read. I would recommend it to students who are new to R.",2,0,2,2
"1679","Ethics and Learning Analytics: Charting the (Un)Charted","This chapter provides an overview of how our own thinking has developed alongside boarder developments in this field. This chapter maps how far the discourses surrounding the ethical implications of learning analytics have come, as well as some of the future considerations. The practical implementation of that understanding remains largely incomplete, but still wholly pertinent.",1,1,0,2
"1680","Theory and Learning Analytics","Through the provocations, we have drawn attention to the ways in which analytic approaches and artifacts subscribe to particular perspectives on learning: they implicitly make claims provocations drawn from them. Tools can be used in many ways, and should not pragmatic tool for thinking, for designers, educators, researchers, and students. The authors propose that it is productive to consider these provocations in order to reflect on the EPA claims being made through the deployment of a learning analytic tool within a given context. ",0,0,0,2
"1681","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The paper explores the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. The authors propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. The proposed framework model stresses the inherent connections between the six different dimensions and the impact of the analytics process on the end user and the data suppliers. This paper intends to inform about soft barriers and limitations of Learning Analytics. The authors identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. They also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples. The authors strongly suggest application developers and researchers not only make their technical environment known and open, but also describe the contextual environment and expectations from the users along the lines of the framework. They also suggest evaluating the growing number of LA application showcases and testing for consistency in the descriptive values of the model. ",7,6,1,1
"1682","Data wranglers: human interpreters to help close the feedback loop","Learning analytics is widely seen as entailing a feedback loop, and closing the loop to improve learning is at the heart of good learning analytics practice. This paper has presented an account of Data Wranglers and concludes the following: a) This approach is high cost in terms of time. b) The Data Wrangler process is not uniform. c) The issues of data quality unearthed through the Data Wrangler process shows the value of sense-making activity. d) Grounded approach is necessary for sense making. e) Substantial organisational change is hard.",1,1,0,1
"1683","Saturday Morning Breakfast Cereal - Women and Children","We should be careful when making causal inference. More importantly, we need to think it through before applying research findings to educational settings. What do we need all students to become engineers for? I believe that the education system should value diversity and encourage the students to develop their talents and interests.",2,0,2,2
"1684","rmarkdown-cheatsheet-2.0","This cheatsheet is very helpful and handy.",1,0,1,2
"1685","Network Analysis and Visualization with R and igraph","This tutorial covers basics of network analysis and visualization with the R package igraph. This workshop focuses on the R implementation of the the igraph library. This tutorial is very clear and informative.",1,0,1,4
"1686","Infovis and Statistical Graphics: Different Goals, Different Looks","One key difference between the two approaches is that Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods that have a similar look and feel across a wide range of applications. Another important difference is in the expected audience. Of all the visualizations discussed in this article, the Baby Name Wizard did the best at conveying information in an attractive, interesting, and open-ended way. The authors would like to broaden the communication between graphic designers, software designers, statisticians, and users of statistical methods. The purpose of this article is not to criticize but to explore the different goals that lead researchers in different fields to value different aspects of data visualization. The article suggests that to Infovis practitioners and statisticians alike, is to try not to cram into a single graph what can be better displayed in two or more.",7,1,6,2
"1687","Junk Charts Trifecta Checkup: The Definitive Guide - Junk Charts","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how I like to organize the thinking behind my critique pieces. The Trifecta Checkup involves only three investigations: question, data and visual. Ideally, the results of all three investigations are one and the same. The Trifecta Checkup framework establishes a taxonomy of dataviz critique and there are eight types of critiques.",2,2,0,2
"1688","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social relationships are a major aspect of the undergraduate experience. This study analyzed two study networks from a single classroom and discussed collection of both nodal and relational data. This article is intended as a first introduction to the power and complexity of educational research aims that might benefit from SNA.Networks are a relatively simple but powerful way of looking at the small and vital communities in every school and college. Empirical research of undergraduate learning communities is sparse, and instructors are thus limited to anecdotal evidence to inform decisions that may impact student relations. We hope this primer helps to guide educational researchers into a growing field that can help investigate classroom-scale hypotheses, and ultimately inform for better instruction.",2,2,0,4
"1689","Introduction to Social Network Methods:  Chapter 1: Social Network Data","The article talks about what is different about social network data. The first half of the design of the network data is about the populations, samples and boundaries of social network, as well as the modality and levels of analysis. The other half of the design of network data has to do with what ties or relations are to be measured for the selected nodes. The chapter then discusses the scales of measurement. This is an introduction to social network analysis.",1,0,1,4
"1690","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping Out and Hierarchical Cluster Analysis","The purpose of this study is to introduce hierarchical cluster analysis and pattern visualization methods from the data mining literature and demonstrate the method’s utility through one example, identification of student dropout from student K-12 longitudinal grades. In comparison to past methods of dropout identification, hierarchical cluster analysis of student grades for this dataset appears to be comparable to past methods. This study details the application of HCA and visualization of subject-specific teacher assigned grades. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8.",1,2,-1,3
"1691","Principal Component Analysis explained visually","Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize. This article went through a 2D example and a 3D example, and then landed on a 17D example. The visual presentation in the article is super illustrative.",2,0,2,2
"1692","Machine beats experts: Automatic discovery of skill models for data-driven online course refinement","The researchers found that eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction. The empirical study showed that eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. The paper also demonstrated that eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique. Creating effective online courses often requires intensive, iterativesystem engineering. Studying techniques for automatic skill model refinement and its application for evidence-based course refinement therefore is a critical research agenda for the successful future of online education.",8,1,7,5
"1693","Teaching recommender systems at large scale: evaluation and lessons learned from a hybrid MOOC","It is clear that massive, online, open courses attract a significant and diverse group of students, that they come to a course with different goals and intentions, and that those who persist leave with substantially more knowledge of the subject matter than they arrived with. Predicting course completion is hard, and predicting knowledge gains is even harder. The good news is that knowledge gains do not correlate significantly with age, sex, student level, or motivation for teaching the course. The factors that are predictive all relate to effort, prior courses, and baseline knowledge. The authors found that a successful and motivating activity was the generation of a class-specific dataset used for the assignments. They also assigned personal test data to each student for many of the programming assignments. They found the use of open source infrastructure for distributing course software was a big success.",6,1,5,4
"1694","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalised learning has major flaws, which brings with it all manner of complex issues involving children’s agency, power, collaboration and dialogue (or lack of them). But it also brings exciting prospects for the future.Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective. Other organisations combine user data with standard educational content, for example adaptive course-ware platforms.",2,3,-1,2
"1695","Predictive Modelling in Teaching and Learning","Predictive analytics are a group of techniques used to make inferences about uncertain future events. This chapter introduces the terms and workflow related to predictive modelling, with a particular emphasis on how these techniques are being applied in teaching and learning. It also discusses the steps that an educational data scientist must consider when engaging in the process, and a brief overview of the most popular techniques in the field. Three areas that could use investment in order to increase the impact that predictive modelling techniques can have: 1) supporting non-computer scientists in predictive modelling activities; 2) creating community-led educational data science challenge initiatives; 3) engaging in second order predictive modelling.",2,1,1,3
"1696","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The majority of educational data mining research has focused on achieving predictive accuracy, but the authors argue that the field could benefit from more focus on developing explanatory models. This chapter reviews examples of educational data mining efforts that have produced explanatory models and led to improvements to learning outcomes and/or learning theory. The chapter also summarizes some of the common characteristics of explanatory models, such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process. The authors argue for the importance of considering the interpretability and actionability of educational data mining efforts in producing more explanatory models. They have illustrated some ways in which concrete steps in the design of educational data modelling efforts can yield more explanatory models. The relationship between the fields of educational data mining, learning theory, and the practice of education could be greatly strengthened with increased attention to influence future learning outcomes.",3,0,3,5
"1697","Knowledge tracing: Modeling the acquisition of procedural knowledge","An executable cognitive model of Lisp programming skill consisted of a set of ideal production rules and formed the core of a successful intelligent programming tutor. The goal of the research was to implement a simple student modeling process that would allow the tutor to monitor the student's knowledge state and tailor the sequence of practice exercises to the student's needs. The resulting knowledge tracing process models the student as an overlay of the production rules and the mastery-based curriculum structure allows us to associate each programming action with a single production rule. A simple two-state learning model enables us to estimate the student's knowledge state from performance and predict performance from that knowledge state. Successive evaluations led us to (1) abandon an initial ideal student model and to model a sufficient set of rules, (2) to model differences in rule difficulty and (3) to model individual differences among students in learning and performance. The resulting model predicts student performance quite well and enables most students to reach a high level of task performance. It may be possible to improve on this level of performance and enable more students to reach mastery by manipulating incentive in testing, by providing additional procedural practice or by monitoring and remediating students' knowledge of key declarative concepts.",7,0,7,3
"1698","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Teacher-assigned grades matter: - predictive of overall student outcomes + to assess a student's ability to negotiate the school process      The main goal of this study is to present hierarchical cluster analysis (HCA) and visualization techniques as a useful method for the organization and pattern analysis of large sets of school and district data to aid data driven decision making (3DM).      (a useful and interesting means to visualize and assess an entire disaggregated data history pattern for a student in comparison with every other student’s data pattern in a sample.)     -    identifying student dropout        - provides an attractive avenue for identifying time points for early instructional intervention by exploring specific student grade cluster patterns.       ",0,1,-1,3
"1699","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social Network Analysis:    SNA aims to understand the determinants, structure, and consequences of relationships be- tween actors.    Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.  Uniqueness of SNA: the importance of relationships and emergent structure. Network analysis can give a baseline understanding of classroom net- work norms and illuminate major aspects of undergraduate learning.    Network Types: 1. unipartite (only one type of actor) 2. bipartite     Ties: 1. binary whether or not a relation exists 2. valued include additional quantitative information about the relation.       Social Network Data Collection    Egocentric studies focus on a sample of individuals (called “egos”) and the local social environment surrounding them without explicitly attempting to “connect the dots” in the network further. Census networks, some- times referred to as whole networks, collect data from an entire bounded population of actors,    Network measures 1. network density: a global metric that simply indicates how many ties are present.  2. homophily: a propensity for similar actors to be disproportionately connected in a relation of interest.    - happens in mutliple processes:     social selection and social influence. Social selection occurs when a relationship is more likely to occur due to two actors having the same attributes, while social influence occurs when individuals change their attributes to match those of their relational partners, due to influence from those partners.    Actor-level variable: centrality - measures of centrality 1. degree: the total number of connections a node has. examining the equity or inequity in the number of ties be- tween individuals and can be done by looking at the degree distribution, which shows the distribution of degrees over an entire network.  2. betweeness: whether actors serve as bridges in the shortest paths between two actors 3. closeness: how close one actor is to other actors on average, measured along geodesics. 4. eigenvector: Eigenvector centrality places importance on being connected to other well-connected individuals; having well-connected neighbors gives a higher eigenvector centrality than having the same number of neighbors who are less well connected.    Data Collection: Survey Timing of survey:    1. classroom descriptions consisting of a single network ---&gt;  as early as possible    2. longitudinal studies involving several collections ---&gt; at regular intervals or around important classroom events.                       ",3,1,2,4
"1700","Why Students Should Own Their Educational Data","the myth of average: population--&gt;individuals (x) wrong: not stable; too contextualized   --&gt;start by analyzing individual patterns instead of aggregate data  ",1,2,-1,3
"1701","Knowledge tracing: Modeling the acquisition of procedural knowledge","Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. ",2,0,2,3
"1702","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","  Comparison between EDM&amp; LAK   EDM: 1. tech field 2. machine learning 3. individual 4. automation   LAK: 1. educ field 2. text&amp; SNA 3. holistic 4. human judgement           ",0,0,0,2
"1703","Evaluating Machine Learning Models","   Classification is about predicting class labels given input data.    ",0,0,0,3
"1704","Why Is Measuring Learning So Difficult?","why is measuring learning so difficult? 1. simplify the learning process 2. learning is contextual 3. black box (social, psychological) 4. hard to find the reliable proxy 5. include growth? 6. what connections are learners making?",0,2,-2,1
"1705","Saturday Morning Breakfast Cereal","1. be cautious of the implication of a finding 2. correlation is not equal to causality 3. or an indicator cannot be the end 4. as an educator we have to look beyond the indicators can 5. think what is the origins of international trends",0,0,0,5
"1706","The Data Wrangling Cheatsheet","reshaping data: tidyr::gather( ) tidyr::separate( ) dplyr::select( )   Summarise data:  dplyr::summarise(.data, avg=mean())   Make new variables dplyr::mutate(.data)   Combine datasets dplyr::left_join dplyr::right_join dplyr::inner_join dplyr::full_join    ",0,0,0,1
"1707","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers:   - sense-making and social processes are important     because ""learning is a complex social activity.""   - Data Wranglers: to translate the theory described above into practice:     to act as human sense-makers, facilitating action on feedback from learners,     making better sense of what that feedback means and how the data can be improved (double     -loop learning), and helping to develop the Community of Practice around the use of learning analytics.    ",1,1,0,1
"1708","Zuckerberg is ploughing billions into 'personalised learning' – why?","The dangers of personalized learning:  First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists. Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result.    People are different, and learn differently too.algogenius, CC BY  Finally, children’s preferences are not fixed – in fact they often change as immediate responses to the environment.       ",2,4,-2,2
"1709","Feature Selection","Feature Selection -interpretability and insight - curse of dimensions",0,0,0,5
"1710","RStudio Cheat Sheets","The R Markdown Cheat Sheet  1. open a new .Rmd file 2. Write a document 3. Knit document to create report 4. Preview Output 5. Publish 6. Examine build log 7. Use output file",0,1,-1,1
"1711","Translating Learning into Numbers: A Generic Framework for Learning Analytics","       Dimension        V alues          Stakeholders        Data subjects: a group of learners. Data clients: tutor, discussion moderator.          Objective        Reflection: Analyse student interactions in a forum discussion, identify network connections between students, and identify isolated students to bring them back into the discussion.          Data        Protected dataset: Student interactions and posts in the discussion forum of the LMS. Relevant indicators: Posts published, posts replied to. Time scale: what time frame is applied to the analysis?          Instruments        Pedagogic theory: socio-constructivist, hypothesis is that active participants in a discussion show better learning outcomes. Technology: Social Network Analysis (SNA), statistics. Presentation: network diagram visualisation, stats table.          External limitations        Conventions: (1) Privacy: is the analysis in accordance with privacy arrangements, are the students properly informed? (2) Ethics: What are the dangers of abuse/misguided use of the data? Norms: Are there e.g., legal data protection or IPR issues related to this kind of use of student data?  Time scale: will the students still be able to benefit from the analytics outcome? Is the analysis post-hoc or just-in-time?          Internal limitations        Required competences: (1) Interpretation: Do the data clients have the necessary competences to interpret and act upon the results? Do they understand the visualisation or presentation of the information? (2) Critical thinking: Do they understand which data is represented and which data is absent? How will they use this information?       ",5,5,0,1
"1712","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","The main predictor of knowledge gain was effort expended in the course.     the main predictor of completion was intent to complete",1,0,1,4
"1713","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","eEPIPHANY: automatically discover skill sets (Q matrix) A matirix: a martix representing a chronological record of students' responses to assessment items.   Two Feature Extraction Strategies:     1. Matrix Factorization Strategy (MF)     2. Bag-of-Words Strategy (BoW)   Skill Model Construction        1. replace         2. append         3. split   Model Interpretation: the DoE Analysis",2,1,1,5
"1714","Learning Analytics Dashboards","Understand your goals--&gt; Acquire and  (Pre-) Process the data --&gt;Mapping Desig --&gt;Documentation --&gt;Add Interaction Techniques --&gt; Evaluate Continuously   Four main questions:         1. What kind of data can be visualized? - artefacts produced by students - social interactions - resources include consultation of documents - time spent - test and self-assessment results 2. For whom are the visualizations intended? 3. why: what is the goal of the visualization? 4. How can the data be visualized?     Which interaction techniques can be applied?     What tools, libraries, data formats, ..., can be used for the technical implementations?      What workflow and recipe can be used to develop the visualization.   - Static visualizations --&gt; provide answers to a limited number of questions that a user might have about a data set --&gt; the ability to reveal problems with the data itself (the way the data has been collected)           - Choose the visualization tools according to the contexts     . some techniques have been proven to work better than others             - pie charts not a good idea             - bar charts can be quite powerful             - coordinated graphs enable rich exploration             - 3D graphics often do not convey any additional information             - Scatterplots and parallel coordinates are good representations for depicting correlations.   - Documentation 1. rationale 2. alternative 3. evolution   - add interaction techniques -evaluate continuously",7,3,4,2
"1715","Measurement and its Uses in Learning Analytics","   1. the use of a learning analytics tool is always aligned with assessment regimes. theories are even more important when working with big data.   2. a certain kind of analytical tool--&gt; specific worldview &amp; learners   3. (1) assessment can be the driving force in how we understand what ""knowledge"" is   (2) assessment about pedagogy is influnence who we assess and ho (3) assessment and pedagogy are sometimes in tension, where the desire for summative assessment override pedagogically motivated formative feedback;  (4) drawing alignment between one’s epistemological view (of the nature of knowledge) and assessment or pedagogy practices is challenging — relationships between the three may be implied, but they are not entailed     Epistemology — What/How Are We Measuring?      Pedagogy — Why is this Knowledge Important to Us?          Pedagogy — Who is the Assessment/ Analytic For?      Assessment — Where Does the Assessment Happen?      Assessment — When Does the Assessment, and Feedback, Occur?                           ",1,1,0,2
"1716","Predictive Modelling in Teaching and Learning","PURPOSE of predictive modeling:     - create a model that will predict the values of new data based on observation.   Strong candidate problems for a successful predictive modelling approach: (1) quantifiable characteristics of the subject being modeled (2) a clear outcome of interest (3) the ability to intervene (4) a large data set (5) a recurring need less appropriate: sparse and noisy data   DATA COLLECTION     -  historical data is used to generate models of relationships between features     - powerful enabler: event-driven data   CLASSIFICATION AND REGRESSION     - classification algorithms: predict categorical values     - regression algorithms: predict numeric values   FEATURE SELECTION     - create features that correlate with the value to predict     - examine the correlation between features--&gt; remove or transform to eliminate the correlation     - the impact of missing data is heavily tied to the choice of learning algorithm   EVALUATING A MODEL common: k-fold cross validation    ",4,4,0,3
"1717","Ethics and Learning Analytics: Charting the (Un)Charted","current: frameworks, code of practices and conceptual mappings of ethical implications in learning analytics.   Future directions: 1. explore potential conflits between students' concerns, their right to pot-out, and the implications for the mandate of higher education to use student data to make interventions at an individual level. 2. balance research ethics and online datasets 3. balance optimism around AI -- risk of AI (discrimination)   Essential Elements: accountability, transparency, and regulatory frameworks",1,3,-2,2
"1718","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","  - predictive model     aim: find a combination of features that best predicts outcomes     assess: the accuracy of prediction   - explanatory model     important: connecting theories and practices          why a model fits the data well rather than it fits well characters of explanatory model (1) start with ""clean"" independent variables (2) the dependent variable maps to a well-defined construct (3) fewer estimated parameters     Focus on developing two models: 1. the statistical model         intelligent tutoring systems (VanLehn, 2006) based on observable features of students’ per- formance as they learn         an important basis for the instructional design of automated tutors and are important for accurate assessment of learning and knowledge. ---- provides a way for statistical models to make inferences about students’ underlying knowledge based on their observable performance on different problem steps        Q matrix   2. the cognitive model         representations of the knowledge space (facts, concepts, skills, et cetera) underlying a particular educational domain.           ",5,1,4,5
"1719","Statistical graphics: making information clear – and beautiful","Two key decisions: (1) who is your target audience? (2) what are you trying to show?   Guiding principles (1) avoid distracting elements (2) use informative color to visually associate elements (3) keep the figure simple   Guiding principles of creating small multiple plots (1) keep the x- and y- axes on the same scale (2) eliminate repetitive information (3) maintain consistency across plots",0,3,-3,2
"1720","How to display data badly","The aim of good data graphics is to display data accurately and clearly.   (a) showing data - rule 1 include all the data             measure: data density - rule 2 don't hide data              ( don't use a overabundance of chartjunk + choose a scale)                 measure: data-ink ratio   (b) showing data accurately - rule 3 visual metaphor - rule 4 the order of numbers+ mangitudes - rule 5 display the data in the context the essence of a graphic display is that a set of numbers have both magnitudes and an order are represented by an appropriate visual metaphor -- the magnitude and order of the metaphorical representation match the numbers. (space, time, ....) --&gt; carefully choose the interval   (c) showing data clearly - rule 6 don't change scales in Mid-Axis -rule 7 emphasize the important, not the trivial -rule 8 when doing comparison, start from the same base - rule 9 don't oder data in alphabetical way - rule 10 labelling     (1) Illegibly     (2) Incompletely     (3) Incorrectly     (4) Ambiguously - rule 11     (a) decimal places, not too many to be understandable     (b) dimensions     In conclusion, examine the data carefully enough to know what they have to say, and then let them say it with a minimum of adornment.      ",5,2,3,3
"1721","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","   (1) Statistical data visualization, which is focused not on visual appeal but on facilitating an understanding of patterns in an applied problem (recall the Discovery goals listed above), both in directing readers to specific information and allowing the readers to see for themselves.  (2) Infographics, which ideally should be attractive, grab one’s attention, tell a story and encourage the viewer to think about a particular dataset, both as individual measurements and as a representation of larger patterns (as in our Communication goals).    KEY difference:  Infovis: unique, distinctive displays+ want to draw attention to the graphics and subject matter Statistician: generic methods that have a similar look and feel across a wide range of applications+ viewers already shown interest and want structured information, often a carefully prepared argument   ",3,1,2,2
"1722","Junkcharts Trifecta Checkup: The Definitive Guide","The Trifecta Checkup:   What is the QUESTION? What does the DATA say? What does the VISUAL say? ",0,0,0,2
"1723","Big Data in Education 7.6 Knowledge Inference: Q-Matrix Knowledge Structure","Q-Matrix Also called KC (knowledge component) Model+ Skill-Item Mapping   How do we get a A-Matrix? 1. Automatic Model Discovery 2. Experts 3. Hybrid Approach   Model Evaluation 1. skills --&gt; items are connected 2. skills are connected   Strategies for Q-Matrix Refinement 1. Try to smooth learning curve 2. Look for skills with no apparent learning 3. Look for problems with unexpected error rates   Spikes in leanring curve: oftern 2 skills are treated as 1   AIC/BIC",5,2,3,5
"1724","Assignment 3","the two plots in assignment 3",0,1,-1,2
"1725","Big Data in Education 1.1 Introduction","1. Prediction:     Predict predictive variables from a set of the predictor variables 2. Structure Discovery     Structure and patterns in the data. No specific target. 3. Relationship 4. Discovery with models",0,0,0,5
"1726","Big Data in Education 2.2 Diagnostic Metrics Part 1","Metrics for classifiers   1. accuracy, also called agreement     -inter-rater reliability   BUT, accuracy does poorly when there is non-even assignment to catergories example, 92% kids always pass. Accuarcy 92%. --&gt; no information at all   2. Kappa, also Cohen's Kappa 0=at chance 1=perfect -1=perfectly inverse &gt;1 mess up somewhere &lt;1 model worse than chance 0&lt;kappa&lt;1 0.3-0.5 good enough to publish   no standard, Kappa is affected by the dataset    ",4,2,2,1
"1727","Big Data in Education 2.3 Diagnostic Metrics Part 2","ROC, when predicting something with two values THRESHOLD   --&gt; Four possibility 1. True positive     model=1, data=1 2. False positive     data=0, model=1 3. True negative     model=0, data=0 4. False negative     data=1, model=0   ROC curve X axis= Percent false positives (versus true negatives)     -&gt; False positives to the right Y axis=Percent true positive (versus false negative)     -&gt; True positives going up   dash line= chance model     A' A prime     z test to compare A primes     the test assumes independence     meaning across datasets     takes confidence into account   AUC   Precision and Recall Precision= TP/(TP+FP) the probability that a data point classified as true is actually true Recall= TP/(TP+FN) the probability that a data point that is actually true is classified as true",1,2,-1,5
"1728","Big Data in Education 2.4 Diagnostic Metrics: Correlation","Metrics for regressors 1. Linear correlation     sensitive to outliers measures   - r^2                   -MAD mean absolute Deviation                             very intepretable                   -Root Mean Squared Error (RMSE)                   -  BiC the lower the better                  -    AIC    ",1,2,-1,5
"1729","Big Data in Education 2.5 Cross-Validation and Over-Fitting","over-fitting, not fitting to signals, but noise     every model is over-fit in some fashion --&gt; assess generalizability         1. training set and test set         2. cross-validation                 k-fold (quicker)                 leave out one (more stable)                 variants: 1. flat 2. stratified 3. student-level   consider where to generalize and make sure cross-validate on that level                            ",2,0,2,5
"1730","cross validation","cross validation  ",0,0,0,5
"1731","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Data-Driven Decision Making (3DM) -  Hierarchical cluster analysis Problem: School lack an effective method to pattern and visually interpret disaggregated achievement data collected on students to help inform decision making. Goal: demonstrates a novel application of hierarchical cluster analysis and pattern visualization Data: every student in a cohort Method: the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district; compared to past methods of dropout identification as one example of the usefulness of the method.  Outcome: student dropout or taking a college entrance exam Result: Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns",1,4,-3,3
"1732","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social Interaction with students    Network Types. 1. the number of types of actors they contain. unipartite: only one type of actor bipartite: linking actors with the groups to which they belong 2. the nature of the ties they contain    undirected:  ties between actors are inherently bidirectional directed:  has an associated direction 3. Ties can also be binary or valued      ",0,0,0,4
"1733","Why Students Should Own Their Educational Data","Students are human subjects with different starting level and various at each skills. The population studies can not apply to individual in the group. learning style: can't apply to individuals at average aggregate data: draw inferences about a population from a sample; Personality research is contextualized. AI: user should own their data",0,0,0,4
"1734","Knowledge tracing: Modeling the acquisition of procedural knowledge","1. EDM and LAK appears along with the emergence of big data. 2. Similarity: goals of improving education by assessment; gain insight into organizational activities 3. Distinctions: - Discovery: have the exact opposite key and tool - Reduction: LAK on full complexity while EDM focus on individual components - Origins: LAK from semantic web, while EDM from educational software and student modeling - Adapation: LAK focus on human adaption, while EDM only on machine/automated adaption - Techniques: LAK is more like semantic/qualitative analysis; EDM: data mining models with quantitative analysis",2,1,1,2
"1735","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Future: the impact of data and analytics within education will be transformative at primary, secondary, and post-secondary levels in both area of LAK and ED. Common concern: the rapid development of analytics and data mining tools by commercial organizations that do not build off of either community’s expertise, algorithms, and research results.",1,1,0,2
"1736","Evaluating Machine Learning Models","A/B Testing Take away A/B Testing always pops out in Job Description when I did the job searching, so this part catch my eye. - Key points 1. Predominant method of online Test 2. Have two groups: control(A: old) and experiment(B: new) 3. Hypothesis Testing: “Does this new model lead to a statistically significant change in the key metric?”  4. Outcome: average value  ",1,0,1,5
"1737","Why Opting Out of Student Data Collection Isn’t the Solution","1. Violation of Fair Information Privacy Principles (FIPPS) 2. need to clarify the purposes of student data collection are primary, the expected and implied permission when data is collected.",1,0,1,2
"1738","Why Is Measuring Learning So Difficult?","learning is multidimensional thing simplify too much to capture data too contextual, knowledge is too bond trying to figure out what people know and what they can do: computer algorithm culture construct is really difficult to define measure define of ""measure"": no indicators that can be trusted, do know certain kind of thing to indicator of learning Culture, social implications, individual psychology things -- Complex: black box, multiple time points True Analytics: Reveal the connection the learner may or may not be aware of, should be beyond what is it now",1,2,-1,1
"1739","Saturday Morning Breakfast Cereal","Use of unlubricated policy from only a simple result of survey would distort the actual finding in given context. The application of policy or strategy should based on not just a statement, but need to consider the causal relationship and where does the statement come from. Data could be confused when looking from different angles.  ",0,1,-1,1
"1740","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers: academics who analyse data about student learning and prepare reports with actionable recommendations based on that data. Work with 4 main data sources: survey feedback; activity data; delivery data; aggregated completion activity of data wranglers: quality assurance and quality enhancement aim: improve the learning experience; desire for more data to be included in the reports Limitation: high cost in terms of time; process is not uniform; unearthed shows when sense-making activity; hard to keep substantial and sufficient engagement",2,2,0,1
"1741","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning: - Generally: modifying learning materials and teaching styles to accommodate the different ways pupils learn - MZ: teachers “working with students to customise instruction to meet the student’s individual needs and interests”.  Three major flows: 1. need acquire general knowledge other than professional knowledge and skills 2. Learners will lose the ability to compensate 3. Children is developing, preferences are not fixed  ",2,1,1,2
"1742","Feature Selection","- Knowledge Discovery Interpretability &amp; In sight - Curse of Dimensionality More variables(predictors) put in model, the more accurate the model is, while paying price to too many variables. e.g. Scree plot with elbow",0,1,-1,5
"1743","Chapter 1: Social Network Data","Relations: what ties or relations are to be measured for the selected nodes. sampling ties Method: 1. Full network: collect information about each actor's ties with all other actors 2. Snowball:begin with a focal actor or set of actors. 3. Ego-centric networks (with alter connections): begin with a selection of focal nodes (egos), and identify the nodes to which they are connected; then,determine which of the nodes identified in the first stage are connected to one another. 4.Ego-centric networks (ego only): focus on the individual, rather than on the network as a whole",0,0,0,4
"1744","RStudio Cheat Sheets","Narration and code to track your work Knit HTML echo: TRUE: display code in output Code Chunk: ```{r} ``` APA format table:     ```{r results = ""asis""} stargazer::stargazer(data, type = ""html"", title = ""Table with stargazer"") ```      ",1,0,1,1
"1745","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","- Problem: middle school is an important juncture for a student where he or she starts to be conscious about academic achievement and thinks about college attendance. - Reality: Indicative of a student’s choice to attend college: access to financial resources, family background, career aspirations and academic ability but they do not necessarily give sufficient actionable information to instructors or guidance counselors to intervene for individual students.  - Data: predict college attendance from the types of detectors, in the context of 3,747 students using the ASSISTment system in New England, producing detection that is both successful and potentially more actionable than previous approaches;  - Result: be able to distinguish between a student who will attend college and a student who will not attend college 68.6% of the time",1,1,0,3
"1746","Translating Learning into Numbers: A Generic Framework for Learning Analytics","1. Questions during research: tech: compatibility of datasets, algorithm and techniques soft(by human): ethical use, danger of abuse 2. Approach of framework for LA (Six critical dimensions): - Stakeholders:Data subjects/clients; Information flow between stakeholders (Instituion-Teachers-Students) - Objective: Reflection(critical self-evaluation of a data client); Prediction(intervention/adaptive services) - Data:Protected dataset(not accessible)/Relevant indicators/Time scale - Instruments: Pedagogic theory(reductive when apply to same dataset, result in different outcomes)/Technology/Presentation - External limitations: Conventions(Privacy, Ethics)-legal level/institutional level-Abuse problem/Time scale: data constituency - Internal limitations:Required competences(Interpretation/Critical thinking)          ",1,3,-2,1
"1747","The Big Five and Visualisations of Team Work Activity","   Topic: NLP Article: Natural Language Techniques for Intelligent Tutoring Systems Idea: Author propose an intelligent ChatBot system, based on instant messaging, for student on-line coaching in an English learning environment. TutorBot architecture - Language analysis - Ready reference material - Regular Conversation    3 main components or robots: (1) RRMBot (2) ClassifyBot (3) AIMLBot      ",0,0,0,3
"1748","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","   Evaluation of Online Course by comparing the one on Coursera and a flipped classroom instruction one.     Main predictor: effort expended in the course Outcome: knowledge retention Result: face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners);           ",4,1,3,4
"1749","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Problem/task: uncovering the right skills behind question items Goal: investigate means to assist experts for this task Method: by using a data driven, matrix factorization approach Study: The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and their performance when used in a linear model of skills assessment and item outcome prediction. Result:  1. a relatively similar pattern between the expert and the factorized mappings 2. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. ",5,0,5,5
"1750","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Research Questions: build a model to automatically determine which skills must be mastered to complete the online courses   Step: 1. Feature Extraction (Not Selection)    Matrix Factorization (MF) strategy Bag-of-Words (BoW) strategy Goal: generate a two-dimensional matrix, showing a mapping between assessment items and “skill candidates”  2. Model Construction Replace - Append - Split     ",2,1,1,5
"1751","Using data mining to predict secondary school student performance","Problem: lack of performance on Mathematics and the Portuguese language classes Goal: using BI/DM techniques to improve student performance in secondary school Data: student grades, demographic, social and school related features; binary/five-level classification and regression tasks for the problem classes Data collection method: school reports Model: Decision Trees, Random Forest, Neural Networks and Support Vector Machines Result: build a predictive model -  there are relevant features other than student past evaluations, like number of absences, parent’s job and education, alcohol consumption would influenced student achievement.",3,4,-1,3
"1752","Developing a generalizable detector of when students game the system","Game behavior of students Problem: students attempt to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly Goal: build a detector to accurately detect whether a student is gaming the system Criteria: accurately identifying which students game, accurately identifying when students game, increasing our knowledge about gaming, and generalizing beyond the original training context Method: Assess different models from previous paper",2,2,0,5
"1753","Big Data in Education","Classifiers Part I; Develop a model which can infer a single aspect of the data (predicted variable) from some combination of other aspects of the data Classification: categorical Labels with ""features"" Basic Idea: determine which features, in which combination, can predict the label   Good DM pkg for classification: RapidMiner SAS Enterprise Miner Weka KEEL ",1,0,1,5
"1754","Cross Validation","Goal: Find a predictive way to predict testing data, generalize to the real world Problem: over-fit, under-fit Assumptions: IID, independently and identically distributed: draw from the same distribution  ",0,1,-1,5
"1755","Evaluating Machine Learning Models - O'Reilly Media","Continue with A/B Testing: - Pitfalls 1. Randomized Splitting    do some A/A testing first, if tenable, move to A/B testing 2. Metric Select    Offline evaluation metrics are things like the classification, regression, and ranking metrics  3. Number of observations Reasonable value to preform the testing      ",1,2,-1,5
"1756","Measurement and its Uses in Learning Analytics","Notes Chapter 3: Measurement and its Uses in Learning Analytics  psychological measurement comprises the following: defining a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome. constructs  variables like physical length of an object are directly observed, or manifest, whereas a person’s mental states or psychological traits are only indirectly observed, or latent.   measurement instruments  Psychological measurement instruments are typically called tests or questionnaires (also surveys and inventories) and are made up of items or indicators   source of error  the measurement samples will have error resulting from the inherent non-repeatability, which is sometimes called random error and is unbiased   validity measurement models     factor analysis  Exploratory factor analysis (EFA) is used to determine the number of latent factors from data without strong theoretical assumptions and is commonly part of scale development. Confirmatory factor analysis (CFA) is a complementary set of techniques to test a theoretically proposed factor model by examining residuals between expected and observed correlations.   latent class and latent mixture models IRT  modelling individual person-item interactions rather than total test scores, as in classical test theory.   growth models  apply any time a latent trait is changing systematically between measurements. They can be applied to changing attitudes   ",3,6,-3,5
"1757","Ethics and Learning Analytics: Charting the (Un)Charted","Notes  SETTING THE CONTEXT: WHY ETHICS IS RELEVANT  Ethical implications around the collection, analysis, and use of student data should take cognizance of the potentially conflicting interests and claims of a range of stakeholders, such as students and institutions   ESTABLISHING ETHICAL PRINCIPLES: HOW FAR HAVE WE COME?  ethical issues  The location and interpretation of data Informed consent, privacy, and the de-identificationof data The management, classification, and storage of data   principles  Learning analytics as moral practice — focusing not only on what is effective, but on what is appropriate and morally necessary Students as agents — to be engaged as collaborators and not as mere recipients of interventions and services Student identity and performance as temporal dynamic constructs — recognizing that analytics provides a snapshot view of a learner at a particulartime and context Student success as a complex, multidimensional phenomenon Transparency as important — regarding the purposes for which data will be used, under what conditions, access to data, and the protection of an individual’s identity That higher education cannot afford not to use data   basis  The use of aggregated, non-personalized data is essential in delivering effective and appropriate teaching and learning, but students should be ableto make informed opt in/out decisions Students should have full(er) knowledge of which data is collected and how it is used Students should ensure that their personal data records are complete and up to date The surveillance of activities and the harvestingof data must not harm student progress Algorithmic output should be subject to (potential) Learning analytics essentially provides context and time-specific, provisional, incomplete pictures of students, and algorithms should be frequently reviewed and validated   RECENT DEVELOPMENTS IN ETHICAL FRAMEWORKS  Learning analytics is an ethical practice that should align with core organizational principles, such as open entry to undergraduate level study. The OU has a responsibility to all stakeholders to use and extract meaning from student data for the benefit of students where feasible. Students should not be wholly defined by their visible data or our interpretation of that data. This principle furthermore warns against stereotyping students and acknowledges those individuals who do not fit into typical patterns. The principle also makes it clear that members of staff may not have access to the full data set, which can seriously impact the reliability of the analysis. The purpose and the boundaries regarding the use of learning analytics should be well defined and visible. The University is transparent regarding data collection, and will provide students with the opportunity to update their own data at regular intervals. Students should be engaged as active agents in the implementation of learning analytics (e.g.,informed consent, personalized learning paths, interventions). Modelling and interventions based on analysis of data should be sound and free from bias. Adoption of learning analytics within the OU requires broad acceptance of the values and benefits (organizational culture) and the development of appropriate skills across the organization.     ",15,4,11,2
"1758","Predictive Modelling in Teaching and Learning","Notes  Predictive analytics are a group of techniques used to make inferences about uncertain future events it is important to distinguish predictive modelling from explanatory modelling.  In explanatory modelling, the goal is to use all available evidence to provide an explanation for a given outcome In predictive modelling, the purpose is to create a model that will predict the values (or class if the prediction does not deal with numeric data) of new data based on observations.   The intent of the predictive modelling activity is to set up a scenario that would accurately describe the outcomes of a given student assuming no new intervention. Depending on the algorithm used to build a predictive model, it can be beneficial to examine the correlation between features, and either remove highly correlated attributes (the multicollinearity problem in regressionanalyses), or apply a transformation to the features to eliminate the correlation Decision Trees (e.g., C4.5 algorithm) are repeated partitions of the data based on a series of single attribute “tests.” Each test is chosen algorithmically to maximize the purity of the classifications in each partition. An important consideration when putting predictive modelling into practice is the similarity between the data used for training the model and the data available when predictions need to be made. Often in the educational domain, predictive models are constructed using data from one or more time periods (e.g., semesters or years), and then applied to student data from the next time period. three areas that could use investment in order to increase the impact that predictive modelling techniques can have  Supporting non-computer scientists in predictive modelling activities. Creating community-led educational data science challenge initiatives Engaging in second order predictive modelling. In the context of learning analytics, we define second order predictive models as those that include historical knowledge as to the effects of andintervention in the model itself   ",1,2,-1,3
"1759","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Notes  Through manual inspection of the visualizations of a geometry dataset potential improvements to the best existing KC model at the time were identified Learning factors analysis (LFA; Cen et al., 2006) was developed to automate the data-driven method of KC model refinement to further alleviate demands on human time. An alternative automated approach uses a state-of-theart machine-learning agent, SimStudent, to discover cognitive models automatically without requiring existing ones inspecting the differences between the SimStudent model and the human-generated model revealed interpretable features that explained the advantages of the SimStudent model Both LFA and SimStudent are capable of producing cognitive model discoveries that not only significantly improve predictive accuracy but are readily interpretable and, thus, explanatory. Other modelling efforts, including a “human-in-theloop” component like Ordinal SPARFA-Tag, have yielded considerably more interpretable cognitive models than many alternative methods Explanatory modelling efforts tend to start with “clean” independent variables that have either simple functions or map to clearly defined constructs Another feature of explanatory models, one that relates most to actionability, is that the dependent variable maps to a well-defined construction Finally, explanatory models tend to be characterized by fewer estimated parameters (independent variables, or features). ",3,0,3,5
"1760","Statistical graphics: making information clear – and beautiful","notes  Our purpose in showing these examples is not to denigrate Excel or R, but rather to point out that using program defaults, while useful for exploratory data analysis, does not produce production quality figures. When producing quality figures, every decision needs to be made consciously and  with intent. Improving figures require two keys  Who is your target audience? What are you trying to show?   principles  avoid distracting elements use informative color to visually associate elements keep the figure simple and interpretable   ",1,1,0,2
"1761","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Notes  Looking at Infovis through statisticians’ eyes  statistical approach concentrates on what can be got out of the available data and the Infovis approach uses the data to draw attention to wider issues With presentation graphics you prepare some small number of graphs, which may be viewed by thousands, and with exploratory graphics you prepare thousands of graphs, which are viewed by one person, yourself   Understanding and dialogue rather than pure criticism  Statistical graphics are fine but they don’t always serve to communicate outside the academic/professional bubble. Infovis is much more popular than statistical graphics, and it behooves us to understand why   Sources for the two points of view Some goals involving the visual display of quantitative information  Discovery goals:  Giving an overview—a qualitative sense of what is in a dataset, checking assumptions,confirming known results, looking for distinct patterns. Conveying the sense of the scale and complexity of a dataset. Exploration: flexible displays to discover unexpected aspects of the data; small multiplesor, even better, interactive graphics to support making comparisons.   Communication goals:  Communication to self and others: displaying information from the dataset in a readilyunderstandable way Telling a story Attracting attention and stimulating interest     Static statistical graphics: timeless or simply old-fashioned  Two qualifications are needed here. First, it can take a lot of work to write clear prose, just as it can take a lot of work and a lot of practice to prepare clear graphs. Second, the vivid writing of a Martin Amis or T.S. Eliot can be fun in itself and also point the way forward   One key difference between the two approaches is that Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods that have a similar look and feel across a wide range of applications. Few statisticians are trying to develop anything new; they are using the standard well-tried tools. Infovis places a high value on creativity and difference, whereas statistics is centered on objectivity and replication. Another important difference is in the expected audience.  Statisticians assume that their viewers are already interested and want to provide structured information, often a carefully prepared argument. For statisticians, graphics are part of an explanation. Even exploratory analysis typically has a clear structure. In contrast, Infovis deisgners want to draw attention to theirgraphics and thus to the subject matter. For them, graphics are more of a door opener.   ",13,4,9,2
"1762","Junkcharts Trifecta Checkup: The Definitive Guide","Notes Windy Path      For the eight countries that got in (not automatically), track their paths to the World Cup. How many competitions did they have to play? For those countries that failed to qualify, track their paths to the point that they were stopped. How many competitions did they play? What is the structure of the qualification rounds? (These are organized regionally, in addition to certain playoffs across regions.) How many countries had a chance to win one of the eight spots? Within each competition, how many teams participated? Did the winner immediately qualify, or face yet another hurdle? Did the losers immediately disqualify, or were they offered another chance?    ",4,2,2,2
"1763","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","notes  Teacher-Assigned Grades as Useful Data in Schools Visualizing Data for 3DM in Schools  use of cross-sectional means and standard deviations for schools, classrooms and subgroups of students   Central Aim of the Study  adapt hierarchical cluster analysis and heatmaps for use with teacher assigned grades for data driven decision-making.   Sample and District Context Data Collection  The entire longitudinal grading histories of each student in the sample were recorded from the districts’ permanent paper file records, copies of report cards, from kindergarten through grade 12 in June of 2006   Hierarchical Cluster Analysis  supervised and unsupervised. Supervised clustering begins with a defined set of assumptions about the categorization of the data, while unsupervised clustering assumes nothing about the categorization and is designed to statistically discover the underlying structure patterns within the dataset Hierarchical clustering provides a way of organizing cases based on how similar the values for the list of variables are for each case.   Missing Data  Unlike many of the datasets described in the data mining literature above, education datasets that include all students from a school, cohort or district are notorious for issues with missing data   FINDINGS  An Example of Hierarchical Clustering: HCA using longitudinal grade histories K-12 subject-specific grade cluster patterns are informative in identifying student dropout Cluster analysis of course grades also provides an attractive avenue for identifying time points for early instructional intervention by exploring specific student grade cluster patterns.   The use of cluster analysis in much of the data mining literature has focused on the identification and classification of specific patterns in the data that will predict future participant outcomes ",0,3,-3,3
"1764","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Notes  SNA aims to understand the determinants, structure, and consequences of relationships between actors. In other words, SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationshipsbetween pairs of actors, and what, if any, the impacts are of these relationships on actors types   One way to categorize networks is by the number of types of actors they contain. Networks that consist of only one type of actor (e.g., students) are referred to as unipartite (or sometimes monopartite or one-mode).  Networks can also be categorized by the nature of the ties they contain.   data collection: Network data collection (and subsequent analyses) can be categorized, then, by whether it considers a static network, a cross-sectional realization of an implicitly dynamic network, or an explicitly dynamic network. The last of these may take the form of multiple cross-sectional snapshots or of some form of continuous data collection Network Level Concepts and Measures  The density of a network is a measurement of how many links are observed in a whole network divided by the total number of links that could exist if every actor were connected to every other actor. In a study network, a class exhibiting many complete triads may indicate a strong culture of group study compared with a class that exhibits comparatively few complete triads. One way to examine this would be a triad census—a simple count of how many different triad types exist in a network   Network Methods: Data Collection  We strongly suggest pilot studies with your survey, as scheduling a single high-value data collection as the first use of a survey instrument can be risky. Relational data collected in a closed-ended format such as lists, drop-down menus, or autocomplete forms can limit errors that come with open-ended data collection and are often easier to process   Data Management: Common practice is to use a combination of matrices, one (or more) containing nodal attributes and one (or more) containing relational data. A common form for the latter is called a sociomatrix or adjacency matrix; another is as an edgelist, a two column matrix with each row identifying a pair of nodes in a relationship. networks are a relatively simple but powerful way of looking at the small and vital communities in every school and college. Empirical research of undergraduate learning communities is sparse, and instructors are thus limited to anecdotal evidence to inform decisions that may impact student relations. ",3,5,-2,4
"1765","Why Students Should Own Their Educational Data","Notes  Mr. Rose believes that technology can help, by giving educators detailed data on students and the ability to customize teaching materials so “they truly can nurture the potential of every single individual.” Mr. Rose created a nonprofit organization called Center for Individual Opportunity (formerly Project Variability), which has supported research on what he calls the “science of the individual.” To me the real value of the MOOCs so far, is that it’s forced a conversation. what’s nice is it’s going to push schools and colleges to think about the value proposition. What is it you can do face to face that you can’t do online? the truly transformational potential of the technology [is hard for venture-backed companies] to do. There’s too much R&amp;D that has to be done.  market only works if you have a functional market. And education is decidedly not a functional market right now. There’s not enough transparency. ",5,1,4,2
"1766","Knowledge tracing: Modeling the acquisition of procedural knowledge","Notes unable to access the whole paper abstract  describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels. ",5,0,5,3
"1767","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Notes  collaboration between Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) similarities  definition both reflect the emergence of data-intensive approaches to education Both communities have the goal of improving the quality of analysis of large-scale educational data, to support both basic research and practice in education   distinctions     the authors of this paper recommend that the executive committees of SoLAR and IEDMS formalize approaches for dissemination of research and enacting cross-community ties. A formal relationship will allow each community to continue developing their specialized and distinct research methods and tools, while simultaneously increasing opportunities for collaborative research and sharing of research findings between the communities.   ",2,0,2,2
"1768","Evaluating Machine Learning Models","notes   orientation   The Machine Learning Workflow   Evaluation Metrics   Offline Evaluation Mechanisms     Hyperparameter Search   Online Testing Mechanisms      Evaluation Metrics   Classification Metrics     accuracy   Confusion Matrix   Per-Class Accuracy   Log-Loss   AUC     Ranking Metrics   Precision-Recall   Precision-Recall Curve and the F1 Score   NDCG     Regression Metrics     RMSE   Quantiles of Errors   “Almost Correct” Predictions     Caution: The Difference Between Training Metrics and Evaluation Metrics   Caution: Skewed Datasets—Imbalanced Classes, Outliers, and Rare Data       Offline Evaluation Mechanisms: Hold-Out Validation, Cross-Validation, and Bootstrapping   Unpacking the Prototyping Phase: Training, Validation, Model Selection   Why Not Just Collect More Data?   Hold-Out Validation   Cross-Validation   Bootstrap and Jackknife   Caution: The Difference Between Model Validation and Testing     Hyperparameter Tuning   Model Parameters Versus Hyperparameters   What Do Hyperparameters Do?   Hyperparameter Tuning Mechanism   Hyperparameter Tuning Algorithms   Grid Search   Random Search   Smart Hyperparameter Tuning     The Case for Nested Cross-Validation     The Pitfalls of A/B Testing   A/B Testing: What Is It?   Pitfalls of A/B Testing 1. Complete Separation of Experiences2. Which Metric?3. How Much Change Counts as Real Change?4. One-Sided or Two-Sided Test?5. How Many False Positives Are You Willing to Tolerate?6. How Many Observations Do You Need?7. Is the Distribution of the Metric Gaussian?8. Are the Variances Equal?9. What Does the p-Value Mean?10. Multiple Models, Multiple Hypotheses11. How Long to Run the Test?12. Catching Distribution Drift    ",1,2,-1,5
"1769","Why Opting Out of Student Data Collection Isn’t the Solution","notes  The first stop on the path to a basic understanding of education opt-outs begins with the Fair Information Privacy Principles, or FIPPS, which form the basis of most privacy laws in the U.S. and around the world. The FIPPS require data collectors to specify the purpose for which they are collecting data, and to seek informed consent for the collection and use of this data there is the use of data to understand how well students perform over time, how well a school system is serving different populations, and how well different educational strategies are succeeding. Encouraging individuals to opt-out prevents schools from getting an accurate picture of how good of an education is being provided for all students.  If primarily low-income students opt-out, or primarily high-income students opt-out, schools and policy makers would have a lack of knowledge and understanding about the challenges and barriers facing students of diverse backgrounds   providing individual parents with options that disrupt the ability of data to be used for essential educational purposes isn’t the best option. Legitimate education policy concerns need to be addressed by fixing these problems for all students, not just the minority who protest by opting out. Parents may legitimately seek to opt-out as one form of protest against policies and programs that need improvement. Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students. ",9,6,3,2
"1770","Why Is Measuring Learning So Difficult?","notes  simplify too much to collect data cultural background, hard to measure no reliable simple proxy indicators that we can trust ",1,1,0,1
"1771","Saturday Morning Breakfast Cereal","notes a sarcasm of current educational system  ",0,1,-1,2
"1772","Data wranglers: human interpreters to help close the feedback loop","notes  a programme of activity, where a group of ‘Data Wranglers’ were deployed to engage in sense-making activity with learning analytics data. context and role of data wranglers  sources  Survey feedback data from students, gathered at the end of their course. Activity data from the VLE/LMS (Moodle). Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums). Aggregated completion, pass rate and demographic data.     example evaluation  Feedback from stakeholders was generally positive, with respondents reporting that they valued the process, and its iterative, conversational nature in particular A less positive theme was the unevenness of the process across Faculties. Perhaps the largest issue was data quality. One serious misinterpretation of VLE/LMS activity data arose during the project, and the quality and resolution of the delivery data was perceived as a serious obstacle   conclusions  The Data Wrangler process is not uniform. It capitalises on the individual strengths of the Data Wranglers and the key stakeholders in the Faculties. The issues of data quality unearthed through the Data Wrangler process shows the value of sense-making activity. If it is nobody’sjob to make sense of the data, the risk is that the data do not make sense but nobody realises.   ",1,3,-2,1
"1773","Zuckerberg is ploughing billions into 'personalised learning' – why?","notes  Many in education would argue that personalised learning is what all good teachers do as a matter of course – modifying learning materials and teaching styles to accommodate the different ways pupils learn. Others see it as an antidote to top-down, centralised school bureaucracy, with the term “personalised” used interchangeably with individual, learner-centered or customised Zuckerberg has a clear definition in mind, however. For him, personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. Zuckerberg’s idea of personalised learning has three major flaws.  First, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists<U+3002> Second, while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. Their lack of ability to compensate may mean they suffer as a result. Finally, children’s preferences are not fixed – in fact they often change as immediate responses to the environment. To predict content relevant for children there needs to be sensitive, human-directed input – not automation. Otherwise we end up with what might be called de-personalised learning, and classrooms with little conversation between student and teacher. In subcontracting out teaching to technology, the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced.   Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective. Personalised learning by McGraw Hill allows educators to choose between the adaptive or customized study plans. The former adapts all topics to a learners’ pace, while the latter provides a course modified according to the teacher’s knowledge of what fits the students best. ",9,5,4,2
"1774","Feature Selection","notes  knowledge discovery  interpretability in sight   curse of dimensionality ",0,0,0,5
"1775","Chapter 1: Social Network Data","notes   On one hand, there really isn't anything about social network data that is all that unusual. Social network analysts do use a specialized language for describing the structure and contents of the sets of observations that they use. But, network data can also be described and understood using the ideas and concepts of more familiar methods, like cross-sectional survey research.   On the other hand, the data sets that social network analysts develop usually end up looking quite different from the conventional rectangular data array so familiar to survey researchers and statistical analysts. The differences are quite important because they lead us to look at our data in a different way -- and even lead us to think differently about how to apply statistics.  But a network analyst is also likely to look at the data structure in a second way: holistically While it is possible to describe network data as just a special form of conventional data (and it is), network analysts look at the data in some rather fundamentally different ways. Rather than thinking about how an actor's ties with other actors describes the attributes of ""ego,"" network analysts instead see a structure of connections, within which the actor is embedded. Actors are described by their relations, not by their attributes.-- holistically The major difference between conventional and network data is that conventional data focuses on actors and attributes Network data are defined by actors and by relations (or ""nodes"" and ""edges""). The nodes or actors part of network data would seem to be pretty straight-forward. Other empirical approaches in the social sciences also think in terms of cases or subjects or sample elements and the like. Survey research methods usually use a quite different approach to deciding which nodes to study. A list is made of all nodes (sometimes stratified or clustered), and individual elements are selected by probability methods. The logic of the method treats each individual as a separate ""replication"" that is, in a sense, interchangeable with any other. The boundaries of the populations studied by network analysts are of two main types. Probably most commonly, the boundaries are those imposed or created by the actors themselves. All the members of a classroom, organization, club, neighborhood, or community can constitute a population. These are naturally occurring clusters, or networks. So, in a sense, social network studies often draw the boundaries around a population that is known, a priori, to be a network Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal.""  Full network methods require that we collect information about each actor's ties with all other actors. In essence, this approach is taking a census of ties in a population of actors -- rather than a sample Snowball methods begin with a focal actor or set of actors. Each of these actors is asked to name some or all of their ties to other actors. When we collect social network data about certain kinds of relations among actors we are, in a sense, sampling from a population of possible relations. Usually our research question and theory indicate which of the kinds of relations among actors are the most relevant to our study, and we do not sample -- but rather select -- relations Binary measures of relations: By far the most common approach to scaling (assigning numbers to) relations is to simply distinguish between relations being absent (coded zero), and ties being present (coded one) Multiple-category nominal measures of relations: In collecting data we might ask our respondents to look at a list of other people and tell us: ""for each person on this list, select the category that describes your relationship with them the best: friend, lover, business relationship, kin, or no relationship.""  Grouped ordinal measures of relations: One of the earliest traditions in the study of social networks asked respondents to rate each of a set of others as ""liked"" ""disliked"" or ""neutral."" The result is a grouped ordinal scale Interval measures of relations: The most ""advanced"" level of measurement allows us to discriminate among the relations reported in ways that allow us to validly state that,  Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches. The distinction between the two approaches is not clear-cut. Mathematical approaches to network analysis tend to treat the data as ""deterministic."" That is, they tend to regard the measured relationships and relationship strengths as accurately reflecting the ""real"" or ""final"" or ""equilibrium"" status of the network. Mathematical types also tend to assume that the observations are not a ""sample"" of some larger population of possible observation there is little apparent difference between conventional statistical approaches and network approaches. Univariate, bi-variate, and even many multivariate descriptive statistical tools are commonly used in the describing, exploring, and modeling social network data   ",11,2,9,4
"1776","RStudio Cheat Sheets","notes main topic  workflow interactive documents embed code with knitr syntax parameters pandoc's markdown set render options with YAML create a reusable template table suggestions citations and bibliographies ",0,0,0,1
"1777","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","notes  Disengagement not only leads to negative attitudes about higher education, but also to poorer learning By contrast, students who have already made college plans when they are in middle school tend to be more likely to attend college in spite of challenges one of the major limitations to this past research is that it identifies changes in student engagement only through fairly strong indicators of disengagement, such as failing grades problem behaviors such as violence in school and non-attendance  all of the affect and behavior detectors performed better than chance. Detector goodness was somewhat lower than had been previously seen for Cognitive Tutor Algebra [cf. 6], but better than had been seen in other published models inferring student affect in an intelligent tutoring system solely from log files The probability of carelessness/slip is assessed contextually, and is different depending on the context of the student error. The probability estimate varies based on several features of the student action and the situation in which it occurs, including the speed of the action, and the student’s history of help-seeking from the tutor. The relationships seen between boredom and college enrollment, and gaming the system and college enrollment indicate that relatively weak indicators of disengagement are associated with lower probability of college enrollment. The finding further sheds light on behavioral factors the student experiences in classrooms (which are more frequently and in many ways more actionable than the behaviors which result in disciplinary referrals). Future endeavors in evaluating college attendance through data mining of interaction logs (pre-college) can further benefit from including additional possible interaction features in our model. ",8,9,-1,3
"1778","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Notes  critical dimensions of learning analytics  technically-focused research questions such as the compatibility of educational datasets, or the comparability and adequacy of algorithmic and technological approaches “softer” issues and problem areas that influence the acceptance and the impact of Learning Analytics.  questions of data ownership and openness ethical use and dangers of abuse demand for new key competences to interpret and act on LA results     design framework      ",0,3,-3,1
"1779","The Big Five and Visualisations of Team Work Activity","notes unable to access the whole book abstract  We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness. ",4,0,4,2
"1780","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","notes unable to download abstract   In the fall of 2013, we offered an open online Introduction to Recommender Systems through Coursera, while simultaneously offering a for-credit version of the course on-campus using the Coursera platform and a flipped classroom instruction model.   As the goal of offering this course was to experiment with this type of instruction, we performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course.   Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course.   Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge.   Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.  ",11,5,6,4
"1781","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Notes unable to access the whole paper abstract  Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed. ",8,1,7,5
"1782","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","notes  eEPIPHANY is a collection of data-mining techniques to automatically refine (or rebuild) a human-crafted set of skills, initially given by course designers and developers.  provide constructive feedback to online course designers and developers for iterative course improvement.   The contributions of this work are the following  A new problem formulation—We show how to integrate diversified information such as student performance and assessment item text data. A new algorithm—Our solution, the eEPIPHANY algorithm, is scalable and effective for practical use for large-scale online course engineering.  Evaluation—eEPIPHANY outperforms past competitors, including human experts, on several, real online course datasets.   SKILL MODEL FOR ONLINE COURSES  We assume that our target online courses have occasional lowstake assessments throughout the course—aka formative assessments—to assess students’ competency on target skills. We assume that each formative assessment has multiple assessment items (i.e., problems to answer), each of which is associated with one or more skills.   We hypothesize that two different types of feature-extraction strategies present pros and cons for our purposes With the lack of a predictive theory of parameter selection to compute the best skill model, eEPIPHANY exhaustively searches for the best skill model by comparing all possible skill models with different combinations of the following four parameters. The comparison is done by the model fit using the Bayesian Knowledge Tracing as a predictor for any strategy combination, the bigger the size of the model (i.e., the number of the clusters) the better the model. It can be also seen that the replace strategy is relatively better than other two skill-model construction strategies even only using the bag-of-words, eEPIPHANY always yields a better skill model than the default skill model that is hand-crafted by human experts the Matrix Factorization strategy efficiently discovers a latent skill model from the student learning data. On the other hand, the split strategy always resulted in producing an inferior skill model in our study; suggesting that the split strategy hardly improves on the human-crafted skill. The above observation also implies that eEPIPHANY can actually find a better skill model completely automatically without human interaction (which is what the replace strategy does) from real online course data eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction. eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique. ",26,8,18,5
"1783","Using data mining to predict secondary school student performance","notes  Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates.  In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious.   On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks.  four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management. ",5,2,3,3
"1784","Developing a generalizable detector of when students game the system","Notes  Some students, when working in interactive learning environments, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material Within cognitive tutors, gaming consists  quickly and repeatedly asking for help until the tutor gives the student the correct answer inputting answers quickly and systematically. For instance, systematically guessing numbers in order (1,2,3,4…) or clicking every checkbox within a set of multiple choice answers, until the tutor identifies a correct answer and allows the student to advance.   data  from a intelligent tutor lesson on scatter-plots, drawn from a Cognitive Tutor curriculum on middle school mathematics Quantitative field observations Pre-tests and post-tests for each lesson Detailed log-files of the students’ interactions with the tutor   the gaming detector   A combination of Fast Correlation-Based Filtering (Yu and Liu 2003) and Forward Selection (Ramsey and Schafer 1997) was used in order to efficiently search this space of models   Validation  whether a detector trained on a population of students within a specific lesson effectively detects harmful gaming in new students using that lesson whether a detector trained within a specific lesson (or set of lessons) effectively detects harmful gaming in new lessons   Behavioral analysis  harmful gaming is associated with consistently making many errors on a specific problem step                       ",5,6,-1,5
"1785","Big Data in Education","Notes  Types of EDM/LA method  Prediction  Classification Regression Latent Knowledge Estimation   Structure Discovery  Clustering Factor Analysis Domain Structure Discovery Network Analysis   Relationship mining  Association rule mining Correlation mining Sequential pattern mining Causal data mining   Distillation of data for human judgment Discovery with models   To build a regression model, you obtain a data setwhere you already know the answer – called the training label The basic idea of regression is to determine which features, in which combination, can predict the label’s value Decisions about strength of intervention can be made based on cost-benefit analysis One of the easiest measures of model goodness is accuracy, Also called agreement, when measuring inter-rater reliability Comparing Kappa values between two data sets, in a principled fashion, is highly difficult Informally, you can compare two data sets if the proportions of each category are “similar” MOOC: Due to what’s visible in the log files (access to resources rather than thinking processes made visible through complex activities) knowledge engineering: Where your model is created by a smart human being, rather than an exhaustive computer  Achieves higher construct validity than data mining Achieves comparable performance in data And can transfer better to new data in some cases, by capturing more general aspects of the construct   knowledge inference  Measuring what a student knows at a specifictime Measuring what relevant knowledgecomponents a student knows at a specific time   factor analysis  Addresses some of the limitations of BKT But doesn’t have all of the nice features of BKT Measures how much latent skill a student has,while they are learning  But expresses it in terms of probability ofcorrectness, the next time the skill is encountered No direct expression of the amount of latent skill,except this probability of correctness     Correlation Mining  Finding substantial linear correlations between variables Studying relationships between questionnaires on traditional motivational constructs (goal orientation, grit, interest) and student reasons for taking a MOOC   network analysis  Analysis of anything that can be seen as connections between nodes Nodes have connections to other nodes, referred to as ties or links   visualization should  Visualization Should…  Show the data Induce the viewer to think about the substance Avoid distorting what the data have to say Make large data sets coherent Encourage the eye to compare different pieces ofdata Reveal the data at several levels     Clustering  We picked starting values for the “centroids” of the clusters…  Usually chosen randomly Sometimes there are good reasons to start with specific initial values   Resultant Clusters  Lots of fast responses; also lots of viewing hintsafter making an incorrect response     ",10,10,0,5
"1786","Cross Validation","notes  use a model that is complex enough to fit the data without causing problems on the test set ",1,2,-1,5
"1787","Hands-On Programming with R","Notes  R will repeat a short vector to do element-wise operations with two vectors of uneven lengths When you link functions together, R will resolve them from the innermost operation to the outermost By default, sample builds a sample without replacement  One side effect of this behavior is that each draw depends on the draws that come before it. In the real world, however, when you roll a pair of dice, each die is independent of the other. can use Replacement = True   An attribute is a piece of information that you can attach to an atomic vector (or any R object). The attribute won’t affect any of the values in the object, and it will not appear when you display your object. You can think of an attribute as “metadata”; it is just a convenient place to put information associated with an object. R will normally ignore this metadata, but some R functions will check for specific attributes. These functions may use the attributes to do special things with the data. R always uses the same rules to coerce data to a single type. If character strings are present, everything will be coerced to a character string. Otherwise, logicalsare coerced to numerics. Data frames are the two-dimensional version of a list. They are far and away the most useful storage structure for data analysis, and they provide an ideal way to store an entire deck of cards. You can think of a data frame as R’s equivalent to the Excel spreadsheet because it stores data in a similar format. ",2,6,-4,1
"1788","Principal Component Analysis explained visually","notes  Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize. PCA is useful for eliminating dimensions. Below, we've plotted the data along a pair of lines: one composed of the x-values and another of the y-values. With three dimensions, PCA is more useful, because it's hard to see through a cloud of data. In the example below, the original data are plotted in 3D, but you can project the data into 2D through a transformation no different than finding a camera angle: rotate the axes to find the best angle.  ",3,4,-1,2
"1789","Measurement and its Uses in Learning Analytics","MEASUREMENTS, MODELS AND INSTRUMENTS IN LA.",0,0,0,5
"1790","Ethics and Learning Analytics: Charting the (Un)Charted","This talks about the divelopment of LA",0,0,0,2
"1791","Predictive Modelling in Teaching and Learning"," Different algorithms exist for building predictive models. Linear Regression, Logistic Regression, Nearest Neighbours Classifiers, Decision Trees, Naive Bayes Classifiers, Bayesian Networks, Support Vector Machines, Neural Networks, Ensemble Methods. Challenges: Supporting non-computer scientists in predictive modeling activities. Especially for policy makers.; Engaging in second-order predictive medelling, second order predictive models as those that include historical knowledge as to the effects of and intervention in the model itself.  ",2,2,0,3
"1792","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data"," 2 goals: Build a predictive (To find a combination of features that best predict outcomes, important about accuracy in predicting data) or explanatory model (Ientify interpretable causual relationships between constructs that can be either observed or inferredfrom the data). Aruguments: Field could be benefit from more focus on devloping explanatory models. Commen characteristics of explanatory models: having parameters that mao to interpretable constructs; involving human input early stage; overall few parameters.big ",2,0,2,5
"1793","Statistical graphics: making information clear – and beautiful","The best visualization of the data could follow each principles: Color choice, relevent components; simple to interprested.    ",1,0,1,2
"1794","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","; 1. Seeking for a chart that could more engaging audiences with question, demands, data arguments and more. ",0,0,0,2
"1795","Junkcharts Trifecta Checkup: The Definitive Guide","A good visual chart should clearly show the question and result of the question. (so the pick and choose process should be taken more seriously)",2,0,2,2
"1796","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Hierarchical cluster analysis used to predict dropouts rate. Cluster analysis also used to find the patterns can predict results.",0,1,-1,3
"1797","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","How Network Analysis can provide alot information. (seen alot already in research type papers)  ",0,0,0,4
"1798","Why Students Should Own Their Educational Data","Why individual achievement and differences are important. The ""average"" report is not effecient",1,0,1,4
"1799","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper also talks about LA in practical use (case)  ",0,0,0,2
"1800","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","The overall focus on education data mining and LA, should lead to a broarder focus and use; yay",2,0,2,4
"1801","Evaluating Machine Learning Models"," Evaluation metrics are tied to machine learning tasks. There are different metrics for the tasks of classification, regression, ranking, clustering, topic modeling, etc. Some metrics, such as precision-recall, are useful for multiple tasks. Classification, regression, and ranking are examples of supervised learning, which constitutes a majority of machine learning applications.   Classification metrics: Predicting class labels given input data. ; Accuracy simply measures how often the classifier makes the correct prediction.; A confusion matrix (or confusion table) shows a more detailed breakdown of correct and incorrect classifications for each class.; A variation of accuracy is the average per-class accuracy—the average of the accuracy for each class. Accuracy is an example of what’s known as a micro-average, and average per-class accuracy is a macro-average.; Log-loss, or logarithmic loss, gets into the finer details of a classifier.; AUC stands for area under the curve.; ",3,5,-2,5
"1802","Why Opting Out of Student Data Collection Isn’t the Solution","“Although the accuracy or effectiveness of this data is sometimes debated, assessing performance through data analysis is often an essential step in order to improve education and address areas of concern.”",0,0,0,3
"1803","Why Is Measuring Learning So Difficult?","Learning is complicated; Many dimensions and effective components Also personaly oriented, privacy and such.    ",0,1,-1,2
"1804","Saturday Morning Breakfast Cereal","1. Education is important in many ways, socially, politically and economically. 2. Data can be understand in different ways.  ",0,0,0,2
"1805","Data wranglers: human interpreters to help close the feedback loop","The author thinks the quantity and understanding of the data from institutions can be improved when the right LA skill of schloars and researchers are etter.",2,0,2,2
"1806","Zuckerberg is ploughing billions into 'personalised learning' – why?"," Is personalised learning the way to maximize students learning?  Definitions: Teachers working with students to customize instruction to meet the student’s individual needs and interests. Similarity with FB: underlying principles are the same: human work is replaced by technology, algorithms provide users with content based on an analysis of their past behavior and demonstrated interests. This is similar to how Facebook’s news feed works.  Dangers: 1. Not fulfill the needs of general education to students (only feeding them with what they want); 2.studnets might lack of ability to compensate may mean they suffer as a result.; 3. the risk is that the valuable social contact between students, teachers and parents that’s inherent to effective learning will be reduced. Where to go: requires developing the strategies which can marry the needs of children and teachers in education. ",5,3,2,2
"1807","Feature Selection","The curse of Dimensionality says that the amount of data that you need grows exponentially in the number of features that you have. ",0,0,0,1
"1808","Chapter 1: Social Network Data","Social network data 1. Nodes, populations, sample, boundaries.. Most important for me: the connections and solidity within and among each components.  ",1,0,1,4
"1809","RStudio Cheat Sheets","Learning how to use the cheatsheet",0,0,0,1
"1810","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","1. The ASSISTment system that predict college enrollment rate. Could be used for my another research. The 68.6% accuracy is need to be improved. But also dependt on which dimensions.",1,0,1,3
"1811","Translating Learning into Numbers: A Generic Framework for Learning Analytics","learning analytics can use to better understanding and predicting personal learning needs and performance.   In the article, the author explores the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data.    The author discuss and set the framework of LA that could be helpful for educators. There are 6 dimensions need to be considered carefully during the LA process: stakeholders, objective, data(protested data set), instruments, external limitations, internal limitations.    But also mentioned the limitations of LA in education settings. “One of the major questions in LA is the relation with theories of learning, teaching, cognition and knowledge”     ",1,7,-6,2
"1812","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC"," Reasons to experiment with MOOC education for at least three reasons: (1) to explore how it may affect future University education, (2) to explore how MOOC instruction affects department visibility and reputation worldwide, and (3) to better understand the effort involved, technology, and teaching methods.  “Predicting course completion is hard—about the only precourse factor that we found to be highly predictive is an intention, and even this predictive power is probably dominated by the fact that those who do not intend to complete usually do not.” There might not be a pattern in your research. ",1,0,1,4
"1813","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","1. There are discoved patterns from matrix. 2. Differences should be analysed in different ways.",0,0,0,4
"1814","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","1.This paper talks about online learning. And the skills and componence of online learning. 2.",1,0,1,5
"1815","Using data mining to predict secondary school student performance","The BI(DM: data mining) techniques   four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) ",1,0,1,3
"1816","Developing a generalizable detector of when students game the system","; Students attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly.; 2. In the article, author present a detecting system that can see if the students are just “gaming the system.”   It’s hard to find the right classification factors in general, to be the determinators.    . From the full set of possible single-parameters, we selected a subset that fit the following two criteria: 1. Each single-parameter gaming detector was at least 60% as good as the best single-parameter detector found ( terms of linear correlation to the observed data). 2. If two parameters had a closer correlation than 0.7 to each other, only the better fitting single-parameter detector was used.   Criteria for an ideal detector of gaming behavior: an ideal detector should accurately identify a category (or categories) of behavior which is known to be associated with a meaningful difference in student experience or outcomes.; can predict not only which students engage in the behavior, but when they do so; n ideal detector not only detects student behaviors but can help researchers understand those behaviors better.      ",10,2,8,5
"1817","Big Data in Education","1.1 Problems: Much of the data that easily collectible was purely summative in nature; Getting data on learning processes and learner behaviors, requires too much quantitative observations or video recording or others. ; Software in class, could be distracting.      or variables. Fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable. ; 1.2 Feel like everything is explianed in Swirl. But this helps to increase the understanding of each pieces.   classifier: to determine which features, in which combination, can predict the label;  Step Regression: used for binary classification (0,1) Logistic Regression: Given a specific set of values of predict ; Big data in education 1.3:   classifier: to determine which features, in which combination, can predict the label;  Step Regression: used for binary classification (0,1) Logistic Regression: Given a specific set of values of predictor variables. Fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable. ; Feel like most of them are the same material in Swirl. But with better way of explain everything; Generating rules from Decision Tree  Create a decision tress; Take the best single path from root to leaf and mark the path a rule.; remove all data points classified by that rule from data set. ; go to step one; Take all remaining data points. ; Find the most common values for those data points ",5,6,-1,1
"1818","Cross Validation","Use a model that is complex enough to fix the data without causing problems in the test set.",1,2,-1,5
"1819","Hands-On Programming with R","The general ideas about are R, more like intro chapters in swirl",1,0,1,1
"1820","Principal Component Analysis explained visually","With three dimensions, PCA is more useful, because it's hard to see through a cloud of data. In the example below, the original data are plotted in 3D, but you can project the data into 2D through a transformation no different than finding a camera angle: rotate the axes to find the best angle. ",2,3,-1,2
"1821","Measurement and its Uses in Learning Analytics","Helpful introduction to educational and psychological measurement for practitioners in learning analytics and educational data mining!",0,0,0,2
"1822","Ethics and Learning Analytics: Charting the (Un)Charted","Data has great power. It tells us how the world works in a most persuasive way. In a data-driven world, learning analytics becomes a cutting-edge research topic. With a huge impact on education, learning analytics needs our considerations. In this chapter, the author suggests that we need to think about the provocations in order to reflect on the epistemology-assessment-pedagogy (EPA) claims being made through the deployment of a learning analytic too within a given context.",2,0,2,2
"1823","Predictive Modelling in Teaching and Learning","It is really interesting and effective to use big data to predict student performance, yet I’m concerned about the data ethics issues behind this. Is it ethical to use some sensitive features to make predictions of students?",0,1,-1,2
"1824","Junkcharts Trifecta Checkup: The Definitive Guide","The website page introduces Junk Charts Trifecta Checkup, a general framework of data visualization criticism. Three investigations are mentioned: What is the QUESTION? What does the DATA say? What does the VISUAL say? The checkup can be really useful, especially when we are organizing the thinking behind critique.",1,2,-1,2
"1825","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","The paper introduces the implementation of hierarchical cluster analysis and pattern visualization. It identifies student dropout from K-12 longitudinal grades. It is an excellent example of how we can utilize educational data, providing an interesting path of data driven decision-making (3DM) in educational settings, which is a hot topic during recent years.",2,1,1,3
"1826","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","In education, we cares about the relationship between students and the influence it brings. Social network analysis (SNA) is a perfect tool to figure out this. And such analysis can be used not only for students but also for teachers, teacher educators, and school administrators. Such implementation would benefit the whole education cycle.",2,0,2,4
"1827","Why Students Should Own Their Educational Data","This talk has updated my perspective of educational data. I agree with the professor that education should be customized. Students should not always be “compared to others.” Instead, they need to be treated as individuals. Educational data is a great solution to personalized learning.",1,0,1,2
"1828","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","As we mentioned at the beginning of this semester, Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately. There are According to Siemens &amp; Baker, there are five key distinctions between EDM and LA:Discovery: in EDM, researchers are interested in automated discovery, and leveraging human judgment is a tool for that; in LA it is quite the opposite, leveraging human judgement is the aim.Reduction and holism: EDM reduces systems to components and explores them and their relationships, while LA wants to understand whole systems.Origins: EDM is rooted in educational software and student modelling; in contrast, LA origins are related to the semantic web, “intelligent curriculum”, outcome prediction and systemic interventions.Adaption and personalization: EDM performs automated adaptation, whereas LA informs and empowers instructors and students.Techniques and methods: EDM employs more techniques and methods of classification, clustering, Bayesian modelling, relationship mining, discovery with models, and visualization; while LA focuses on social network analysis, sentiment analysis, influence analysis, discourse analysis, learner success prediction, concept analysis and sense-making models.There is no right or wrong for both these two methods. We should use either of them according to the context.",2,1,1,2
"1829","Evaluating Machine Learning Models","In this report, Alice introduces the model evaluation basics to us. Topics in the report include machine-learning workflow, evaluation metrics, model selection, hyperparameter tuning, and A/B testing. I believe by reading the book, one can get great help in his or her machine-learning journey.",1,0,1,5
"1830","Why Opting Out of Student Data Collection Isn’t the Solution","Interesting point, “Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students”",1,0,1,2
"1831","Why Is Measuring Learning So Difficult?","Measuring Learning can be difficult. From my point of view, there are three reasons: 1) Some results are not quantitive 2) Students have different backgrounds. Some of them make good scores but no progress; some of them make good progress but still bad scores. 3) It is hard for a single teacher to judge students by their performance. More teachers or more assessments might be a more compelling way, yet it is hard to realize.",4,4,0,1
"1832","Data wranglers: human interpreters to help close the feedback loop","Interesting discussion about data wranglers!",0,0,0,1
"1833","Zuckerberg is ploughing billions into 'personalised learning' – why?","Interesting! I like how the author summarized the three dangers of personalized learning: 1. Education include general knowledge. We need generalists in our society 2. Students should learn how to learn in a way that’s not suited to them, which will be good for their life-long learning 3. The preference of children is not fixed. It might be sensitive and hard to make predictions",4,2,2,2
"1834","Feature Selection"," I find on google useful info about feature selection: - Why don’t we give all the features to the ML algorithm and let it decide which feature is important? 1. Curse of dimensionality — Overfitting 2. Occam’s Razor 3. Garbage In Garbage out- What are the most popular feature selection algorithms:1. Pearson Correlation 2. Chi-Squared 3. Recursive Feature Elimination 4. Lasso: SelectFromModel 5. Tree-based: SelectFromModel",2,0,2,5
"1835","Chapter 1: Social Network Data","Social network data use a specialized language for describing the structure and contents of the sets and observations they use. The data sets it develops usually look different from the conventional rectangular data array. In this passage, the author mainly introduces the nodes (actors) and edges (relations) of the social network.",0,0,0,4
"1836","RStudio Cheat Sheets","Nice resource! Cheatsheets are our best friend! They make it much easier for us to use packages in RStudio!",3,0,3,1
"1837","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Never thought about predictions can be used in such a way. However, data privacy and bias might be a concern.",0,2,-2,2
"1838","Translating Learning into Numbers: A Generic Framework for Learning Analytics","L6-Excercise2 Which would pose problems for you to actually acquire the data you want? Biased data, messy data; The paper touches topics such as team member, social network analysis, team leader, activity radar, and software development project. The paper use the framework form the “Big 5” theory, which are Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.",2,2,0,2
"1839","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","The paper introduces a teaching recommender system. I know recommender system has been used in many entertainment apps and shopping apps like Amazon and TikTok, but I never thought that it could also be used in educational settings. I would like to know more by reading more paper on this topic.",5,0,5,2
"1840","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","This book discusses topics on student models, skills assessment, alternating least squares matrix factorization, latent skills, cognitive modeling, and so on. People always find it difficult to discover the latent skills by asking questions. Big data provides a good solution to this. By combining experts and factorized mappings, we can make good predictions.",4,1,3,5
"1841","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","It is always hard for one to decide which skills are the critical skills of an online course. To solve this problem, the authors use Q-matrix to develop a model to figure out. They also use the existing models (LFA) and human engineered skill models to evaluate their model. The results are very positive. Three aspects of advantages of the model are found: 1) performance 2) interpretability 3) speed",4,3,1,5
"1842","Using data mining to predict secondary school student performance","Student performance can be predicted by data mining. Through analysis, it is shown that students’ achievement is influenced by past evaluations, number of absences, parent’s job and education, alcohol consumption, and so on. It is really interesting and effective to use big data to predict student performance, yet I’m concerned about the data ethics issues behind this. Is it ethical to use features like parents’ job to make predictions of students?",1,1,0,3
"1843","Developing a generalizable detector of when students game the system","When studying with educational technology such as online courses or robot tutors, students love cheating the system to get good scores. For example, they will continue asking for help, or they will input answers quickly and systematically. This paper develops a detector to find the differences between cheating children and the real-learning children using latent response models and behavior detection. It can be really useful especial when students are using the system without supervision.",2,2,0,5
"1844","Cross Validation","Cross-validation is one of the techniques used to test the effectiveness of a machine learning model. It is also a resampling procedure used to evaluate a model if we have a limited data.",0,1,-1,5
"1845","Hands-On Programming with R","This book is very useful and hands-on, even for beginners. It introduces the very basics in r. Learners will get knowledge and skills of how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools.",1,0,1,1
"1846","Principal Component Analysis explained visually","This web page introduces Principal component analysis (PCA), a procedure that to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize.The author gives nice visualisation of 2D &amp; 3D examples. The passage also use a “eating in the UK” example to illustrate how data that more than 3 dimensions work in PCA.",3,0,3,2
"1847","Why Students Should Own Their Educational Data","Big data can work for the population but does not always work for the individual. Sometimes study can start with individual cases and then go to the population level keeping all its complexity. Deal with data with caution! It would be good if each student has her/his own profile containing info not only about the weakness but also the strength, for example good at comprehension by graphs. Then instructors know how to modify and cater to students' taste. Doubt: Whether it is appropriate to compare students to pilots? Though students differ in various aspects but most of them linger around the average I believe? But it is still justifiable to design learning materials for the minorities. Besides, the lecturer is talking about higher edu? In elementary or high school level, it can be hard to set standard to evaluate students' learning if there are difference in learning materials. Possible solutions might be to gauge individual learning experiences and not set students to standardized tests.; Enlightening moments:  “jagged profile”   Nobody is about average. Examples from pilots, we know that sometimes mean or median is not the population because everyone is individualized and are jagged. Jagged profile reveals the fact that the normal people is representing nobody.  “Because our science textbook assumes every kid is reading on grade level, we’re in trouble,” he said in the talk. “For her, science class is first and foremost a reading test, and it’s doubtful that we will ever see what she’s truly capable of.”      It turns out your personality and your learning varies across contexts.  Context is very important in most conditions. Our goal is to explore the full potentials of every student. Therefore, context should be the major consideration as opposed to generalization.",6,5,1,4
"1848","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Difference &amp; Similarities EDM (Educational Data Mining) &amp; LAK (Learning Analytics and Knowledge)   EDM  system/model-oriented; Simplizing the system and reaching a stage withou human intervention. automated discovery. LAK   human based; understanding the whole system; leveraging human judgement. **Form ; There is no right or wrong between LAK and EDM. It is the difference between the origins and method to realize the same goal-- better education for students.   Although the focus and concentration is not the same, they are complimentary.",3,1,2,2
"1849","Why Is Measuring Learning So Difficult?","Learning is a magic! Learning is multi-dimentional, broad.q data --simplified learning process learning is context-based(social culture) measure of learning/competence proxy indicators students competent beforehand",1,0,1,1
"1850","Saturday Morning Breakfast Cereal","Evaluation in learning? I read it twice and I found education is an interesting field to practice some goals or methods. Skills can be enhanced and put to place because skills are skills to itself. We can train workers to assemble a phone a thousand times in order that they are more skilled and faster doing the work. In contrast, education is not. We can to impress students and more importantly to inspire them. Reading fast is correlated with accumulated reading comprehension but merely training students to read fast clearly drive off-track. In the same tune, mere data or causal relationship do not work when detached from its context.   Practitioners and researchers are, more often than not, work seperately, however knowledge should be overlapping. It creates a gap between the original aim and the real action.",12,0,12,2
"1851","The Data Wrangling Cheatsheet","IMPORTANT SYNTAX: Gather: Gather(data = mydata             key= "" varikey""             value = ""varivalue"",             var1:var5/-var6) Transform a wide form into a long one. Put var1:var5 into a key--varikey, and the corresponding value appears under ""varivalue"". Spread: Spread (data = mydata,             key= ""varikey"",            value= ""varivalue""          )  Transform a long form into a wide form. Put the key into a long list and the values appearing in varivalue as the corresponding value below.   Separate: Separate one variable into two or more. seperate (data, C(""A"",""B"",""C""), SEP = ""_"")    %&gt;% works as a pipe and get inserted into the function as the first argument.  Streamline the working logic.    ; Links for more info: http://genomicsclass.github.io/book/pages/dplyr_tutorial.html https://rpubs.com/justmarkham/dplyr-tutorial https://blog.rstudio.com/2016/06/27/dplyr-0-5-0/  ",2,0,2,1
"1852","Data wranglers: human interpreters to help close the feedback loop","Data Wranglers Data Wrangler is a activator among database and teachers. Before the program, only few teachers make good use of database while data wranglers plays a role in between to deploy data and design special format relevant to each teacher, whereby teachers are getting familiar with the database and are able to get connected to the data (both quan and quali).    Bottom-up, grounded approach is necessary for sense-making.  Schools are subject to colonization if there are always up-bottom approach, which is only based on experience. Bottom-up approach is triggered by needs-- students' behavior, students' needs. Sometimes there are paradoxes and grounded research are vital to further investigation. Analysis do not have to be statistics. Simple graph can also show hints and insights. (e.g. evaluation, enjoyment in studying); Enlightening moments:     It is important to note that all the data are available to academics directly, via various dashboards and online facilities. The role of the Data Wrangler is not only to analyse the data, but to increase the familiarity of academics with the data sources, to build learning analytics capacity as part of a Community of Practice.  Just like online courses and resources, they are not being made good use of. It is in the       This is as expected in a capacity- building exercise: the process must start from people’s existing expertise, and if capacity building is required, this expertise will of necessity be lacking.       ",5,1,4,1
"1853","RStudio Cheat Sheets","Markdown: opposite to Markup, used in R markdown to make the text more readable. heading: # code:  ```   ```  ",1,0,1,1
"1854","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Algorithm ---efficient but wait Learning Analytic researches, containing human learning process and various human-related elements, is an complex and intricate , which calls for patience and caution. It is destined to come with double sides. More data, more opportunities with more vulnerabilities.--privacy Therefore it is vital to prepare a well-rounded template for reference. Number should not be just numbers. Numeric data contains vast info but also is a simplified version, stripped of background and other qualitative data. Despite flaws, researches are still valuable in providing precious information. Technology does not stop wheeling on in spite of crowds of fear. So should education learning analytic.  ; Six dimensions of the proposed LA frame work: Stakeholders (data clients &amp; data subjectives)     Objective (reflection)     Data (protected database; relevant indicators; time scale)     Instruments (Pedagogic theory; Technology; Presentation)     External Limitations (Conventions: Privacy &amp; Ethics)     Internal Limitations (Required competences: Interpretation &amp; Critical Thinking)",3,8,-5,1
"1855","Measurement and its Uses in Learning Analytics","; ITR: Item Response Theory modelling individual person-item interactions purpose: to describe the items by item parameters and the examinees by examinee parameters in such a way that we can predict probabilitstically the response of any examinee to any item, even if similar examinees have never taken similar items before.",0,0,0,5
"1856","Ethics and Learning Analytics: Charting the (Un)Charted","Privacy The debate surrounding privacy and surveillance of students information is heated. There is no agreement on to what extent should  privacy be protected. Personally speaking, I believe that more power, more responsibilities. Data is weapon, with which man with kindness can harness wild grass while man with selfishness can make a profit. I personally believe that data analyst should stick to these moral code. Endowed with power and access, restrictions and responsibilities come with the territory. However, moral is not a solid means to guard against fortune-seekers. But laws and contracts are. On the other hand, laws and contracts should not only set limits on the practitioners but also should set the line between the public and the practitioners so that data wranglers wanting to explore data and make good use data can ""freely"" apply what they have learned to schools and families rather than hesitate.  ",2,4,-2,2
"1857","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","    The central purpose of this study is to introduce hierarchical cluster analysis and pattern visualization methods from the data mining literature and demonstrate the method’s utility through one example, identification of student dropout from student K-12 longitudinal grades.     ",0,1,-1,3
"1858","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","they conduct descriptive analyses of the structure of the network of co-studying relationships. they explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. they also cover practical issues, such as the unique aspects of human subjects review for network studies. their aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.",2,1,1,4
"1859","Why Students Should Own Their Educational Data","looks like an interview. the prof expressed his idea about the question. well it is a little bit tricky and everyone deserve to remain their own opinions.",2,0,2,2
"1860","Knowledge tracing: Modeling the acquisition of procedural knowledge","i cannot open it, either. i have tried several times but i still do not know why. it seems that i was blocked. ",0,1,-1,1
"1861","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This interesting paper addresses a valid area of concern. The overall conclusion reached by the authors, that the two disciplinary areas of educational data mining (EDM) and learning analytics and knowledge (LAK) should collaborate more, is certainly true. These two areas are parts of a whole that were created by looking at the same thing from different perspectives.",0,1,-1,2
"1862","Developing a generalizable detector of when students game the system","oops. i cannot access to this article.",0,0,0,2
"1863","Evaluating Machine Learning Models","after reading this report, I learned the stages involved when developing a machine-learning model for use in a software application and understood the metrics used for supervised learning models, including classification, regression, and ranking. super helpful!",2,1,1,5
"1864","Why Opting Out of Student Data Collection Isn’t the Solution","this paper mainly talks about how privacy principles help people think about students' data.",0,0,0,2
"1865","Saturday Morning Breakfast Cereal","The reporter has been exaggerated. And certain reaction has been taken in school. Students need to focus more on clock repair so that art class is cancelled, which is regarded as a wish action. After this internationalized, in order to not to lose, education spending increases and kids also need to spend 6 hours doing clock homework (xenophobia becomes the first drive). But it did not meet up with the primary goal. People think they do not do enough rather than reflecting their beginning.",2,1,1,2
"1866","Zuckerberg is ploughing billions into 'personalised learning' – why?","personal learning? yes or not? that is a question. well at the present, I think it is better to stay with uniform learning.",2,0,2,2
"1867","Feature Selection","i really love the Youtube videos! they are super fun. this one is about the Machine Learning.",3,0,3,2
"1868","Chapter 1: Social Network Data","On one hand, there really isn't anything about social network data that is all that unusual. Social network analysts do use a specialized language for describing the structure and contents of the sets of observations that they use. But, network data can also be described and understood using the ideas and concepts of more familiar methods, like cross-sectional survey research.On the other hand, the data sets that social network analysts develop usually end up looking quite different from the conventional rectangular data array so familiar to survey researchers and statistical analysts. The differences are quite important because they lead us to look at our data in a different way -- and even lead us to think differently about how to apply statistics.""Conventional"" social science data consist of a rectangular array of measurements. The rows of the array are the cases, or subjects, or observations. The columns consist of scores (quantitative or qualitative) on attributes, or variables, or measures. A simple example is shown as figure 1.1.  Each cell of the array then describes the score of some actor (row) on some attribute (column). In some cases, there may be a third dimension to these arrays, representing panels of observations or multiple groups.",3,1,2,4
"1869","RStudio Cheat Sheets","They are useful Rstudio Cheat sheets! awesome! very useful! i have already download all of them!   ",2,1,1,1
"1870","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","even cannot open this link. click it twice, no website linked.",0,0,0,1
"1871","The Big Five and Visualisations of Team Work Activity","they have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. they evaluated these visualisations in the context of a semester long software development project course. they give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. they conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.",4,0,4,2
"1872","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.",8,1,7,5
"1873","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","I found the evaluation methods in this paper most useful! they compared their method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that their method outperforms human-engineered skill models, skill models discovered  are interpretable, and remarkably faster than existing methods. ",6,0,6,5
"1874","Using data mining to predict secondary school student performance","The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.",4,1,3,3
"1875","Developing a generalizable detector of when students game the system","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.",4,1,3,5
"1876","Cross Validation","the video is very clear and easy to understand. super interesting!",3,0,3,2
"1877","Junkcharts Trifecta Checkup: The Definitive Guide","Checkup question:  What is the QUESTION? What does the DATA say? What does the VISUAL say? ",0,0,0,2
"1878","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Cluster modeling and cluster analysis are great tools for decision making. These tool correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. However, I think the ethical issue behind using student’s performance as well as other data to label and recognize students need to be carefully considered.",3,0,3,3
"1879","Why Students Should Own Their Educational Data","The TEDx talk is truly inspiring. The education is more standardized in China; Students barely have selective course until college. I think the jagged profile of all the students is the reason why more students do not enjoy school. I really hope this system will change. The next step for education should be personalized and adaptative learning.",2,0,2,2
"1880","Knowledge tracing: Modeling the acquisition of procedural knowledge","It ask me to login to access the article.",0,0,0,3
"1881","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","At the beginning of the class, I also confused between the term “Learning Analytics” and “Educational Data Mining.” This article helps me understand the difference and similarities between these two terms. EDM was defined as an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to understand better students, and the settings which they learn in. LAK was defined as the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding  and  optimizing  learning  and  the  environments  in  which it occurs. LAK is more holistic and has a considerably greater focus on leveraging human judgment. LAK models are more often designed to inform and empower instructors and learners. Other differences are clearly stated in the Table 1 in this article. ",2,1,1,2
"1882","Evaluating Machine Learning Models","Measuring the success of machine learning algorithms can be hard. I agree with Alice that creating measurable metrics is very important and should be considered early. Main reason is because you might be using a model that has no defined way of knowing its effectiveness. If for example we want a model to recommend products based on search history, we can use accuracy rate as a metric to know when the model is mature enough for deployment. It will also give a clear picture of how effective the model is.",5,1,4,5
"1883","Why Opting Out of Student Data Collection Isn’t the Solution","Fair Information Privacy Principles require collectors to specify the purpose and seek consent. The consent is implied if the purpose is obvious and the primary reason.  Some primary uses are obvious like for school functions. Other uses like improving students’ performance are tricky, and students can opt-out for data collection.  However, opt-out of data collection will lower the accuracy of analysis and only protect the privacy of the student who opt-out. Opt-out is not the solution for protecting student’s data privacy. Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.",6,1,5,2
"1884","Why Is Measuring Learning So Difficult?","Measuring Learning is difficult because learning is multi-dimensional and difficult to define “Leaning” and “Measure.” We can measure the behavioral patterns or outputs, but we cannot measure personal growth.  And when measuring learning, there are other factors to consider like culture and social impact. The example of an expert in physics taking intro to physics at MIT is very interesting. In my opinion, the most common ways of measuring learning are exams, assessments and scores.  But in this case, those people get perfect scores but doesn’t mean they learned anything. The indicator of learning is not as simple as a score.",3,2,1,5
"1885","Saturday Morning Breakfast Cereal","Very interesting yet sarcastic comic. In my opinion, human insight is still very important in the big data era. The misunderstood correlation will result in bias.  But machine could not fix that with human supervision.",0,2,-2,2
"1886","Data wranglers: human interpreters to help close the feedback loop","Human Data Wranglers responsible for making sense of a range of data sources related to learning. This article shows that human meaning-makers is vital in the learning analytics process.",0,0,0,1
"1887","Zuckerberg is ploughing billions into 'personalised learning' – why?","Personalized learning is important, but this article also points out some flaws in Zuckerberg’s idea. First, general knowledge is necessary. Second, people need the ability to compensate. Third, since children change preference frequently-caution for depersonalized learning!",2,1,1,2
"1888","Feature Selection","Helpful video and explained feature selection. Feature selection is very useful and can avoid too many variables being used.",0,0,0,5
"1889","RStudio Cheat Sheets","It is a great website that collects all the useful cheat sheets for R (I also saw python). I will save this website for future use. It will be very helpful.",2,1,1,1
"1890","The Big Five and Visualisations of Team Work Activity","I agree with the idea of how visualization can help groups improve effectiveness, as it can give a clear picture of performance. Some times numbers don’t make enough impact where as a visualization can. One point of the Big five that I agree with strongly is Team Orientation. I believe when working in groups the overall goal is to win as an individual but excel as a group. Making decisions that benefit the team will ultimately increase effectiveness.",9,0,9,2
"1891","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","This is my first note of Zotero. However, I cannot get access to the full article. From the preview, the author use matrix factorization to assist experts for skill definition and mapping of items to skills. And it turned out the factorization approach is better than the experts’ Q-matrix approach.",2,0,2,5
"1892","Developing a generalizable detector of when students game the system","I think it is great that more and more development is happening in detecting cheating in a educational scenario. Students should not be credited the same way compared to a person who did not cheat. Having ways to detect these behavior will minimize this problem. It reminds me of my college where we have cameras that can flag students who are suspicious.",1,4,-3,3
"1893","Big Data in Education","The link don't work?",1,0,1,4
"1894","Cross Validation","This video is a great explanation of cross-validation. I also found this Chinese explanation. https://zhuanlan.zhihu.com/p/24825503 It lists different approaches.",1,0,1,5
"1895","Hands-On Programming with R","O’Reilly’s Hands-on Programming with R is a great book for people who are not familiar with R before. In the first three chapters, it taught me the basics of R steps by steps. Very detail, clearly and easy to understand. I haven’t finished reading the rest chapters but I will do that later!   ",2,0,2,2
"1896","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This article combines 3DM and the usefulness of teacher-assigned grades using a novel form of data mining, patterning and visualization known has hierarchical cluster analysis (HCA), to provide school leaders, researchers and policy makers a method to make better informed decisions in schools earlier, using dataalready collected on students.",1,0,1,3
"1897","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","INTRODUCTION TO THE CASE STUDY Network Concepts Social Network Basics Network Types Network Data Collection Network Level Concepts and Measures Network Methods: Data Collection  ",0,0,0,4
"1898","Why Students Should Own Their Educational Data","I believe the most effective teaching/learning approach, based on extensive research, remains the self-paced, individually guided strategy (ie, the apprentice or tutoring model). However, that model is too expensive and impractical for all but the 1%. Maybe with enough data and design, the model can be replicated through technology, at which point, no more teachers.",1,0,1,2
"1899","Knowledge tracing: Modeling the acquisition of procedural knowledge","ACT-R theory of skill knowledge assumes a fundamental distinction between declarative knowledge and procedural knowledge, assuming that skill knowledge is encoded initially in declarative form through experiences Procedural knowledge, in contrast, is goal-oriented and mediates problemsolving behavior. Both declarative and procedural knowledge are strengthened so that performance grows more rapid and reliable.",4,0,4,3
"1900","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","This interesting paper addresses a valid area of concern. The overall conclusion reached by the authors, that the two disciplinary areas of educational data mining (EDM) and learning analytics and knowledge (LAK) should collaborate more, is certainly true. These two areas are parts of a whole that were created by looking at the same thing from different perspectives. However, it seems to me that the authors are perhaps a little behind the times. There are multiple examples extant in the scientific literature and news media that describe the use of analytics for a variety of purposes, including assisting leaders in making better decisions. It is laudable that the authors believe that, to the extent EDM and LAK can jointly articulate quality standards for research in this area, it may be possible to more effectively communicate these standards to the wider community of tool developers, analytics practitioners, and the broader research community. The research and methods from these two disciplines are certainly valuable in the educational field. They deserve a place among the approaches available to assist educational leaders in the creation of better educational opportunities for all. However, the individual disciplinary areas need to be organized to more closely align with each other. That will make it easier to work on articulating quality standards outside these areas, hopefully under the umbrella of a more broadly based organization such as the ACM.",4,1,3,2
"1901","Evaluating Machine Learning Models"," Learn the stages involved when developing a machine-learning model for use in a software application Understand the metrics used for supervised learning models, including classification, regression, and ranking Walk through evaluation mechanisms, such as hold?out validation, cross-validation, and bootstrapping Explore hyperparameter tuning in detail, and discover why it’s so difficult Learn the pitfalls of A/B testing, and examine a promising alternative: multi-armed bandits Get suggestions for further reading, as well as useful software packages ",1,2,-1,5
"1902","Why Is Measuring Learning So Difficult?","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.",0,1,-1,2
"1903","Saturday Morning Breakfast Cereal","So cool! Students learn math and then using standardized tests to examine their performance and punish those teachers who have not helped students to improve on such tests. Ironic!",1,2,-1,3
"1904","Data wranglers: human interpreters to help close the feedback loop","This article cover topic that people need to interpret the data, engaging in sense-making activities to mediate the information in ways that enable intelligent action. Also, they need to connect data wranglers/analysts with the practitioners that could benefit from the data. Open University example where it is being done.  ",1,0,1,1
"1905","Zuckerberg is ploughing billions into 'personalised learning' – why?","The dangers of personalised learning Where personalised learning could help A compromise approach  ",0,1,-1,2
"1906","Feature Selection","knowledge discovery interpretability &amp; insight curse of dimensionality",0,0,0,5
"1907","Translating Learning into Numbers: A Generic Framework for Learning Analytics","The key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.",6,5,1,2
"1908","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Tracking students through the online course. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.",6,3,3,4
"1909","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability",11,1,10,5
"1910","Learning Analytics Dashboards","Visualization has the potential to be more precise and revealing than conventional statistical computations . Because static visualizations usually lead to more questions, adding dynamic interaction techniques to the visualization can lead to meaningful visualization tools that encourage exploratory data analysis. We need to get to know the problem domain, the data set, the intended end-users of the tool, the typical tasks they should be able to perform, and so on.",2,2,0,2
"1911","Measurement and its Uses in Learning Analytics","By design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes. Also, by deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners.   “claims analysis” — analysis of the implicit or explicit stances taken in the design and deploying of technologies — is a productive human-centred method to address these key questions, and we offer some examples of the method applied to those provocations.",0,0,0,2
"1912","Predictive Modelling in Teaching and Learning","Linear Regression predicts a continuous numeric output from a linear combination of attributes. Logistic Regression predicts the odds of two or more outcomes, allowing for categorical predictions. Nearest Neighbours Classifiers use only the closest labelled data points in the training dataset to determine the appropriate predicted labels for new data. Decision Trees are repeated partitions of the data based on a series of single attribute “tests.” Each test is chosen algorithmically to maximize the purity of the classifications in each partition. Naïve Bayes Classifiers assume the statistical independence of each attribute given the classification, and provide probabilistic interpretations of classifications. Bayesian Networks feature manually constructed graphical models and provide probabilistic interpretations of classifications. Support Vector Machines use a high dimensional data projection in order to find a hyperplane of greatest separation between the various classes. Neural Networks are biologically inspired algorithms that propagate data input through a series of sparsely interconnected layers of computational nodes (neurons) to produce an output.  Ensemble Methods use a voting pool of either homogeneous or heterogeneous classifiers. ",2,3,-1,3
"1913","Ethics and Learning Analytics: Charting the (Un)Charted","This chapter provides an overview of how our own thinking has developed and maps our journey against broader developments in the field. Against a backdrop of technological advances and increasing concerns around pervasive surveillance and the role and unintended consequences of algorithms, the development of research in learning analytics as an ethical and moral practice provides a rich picture of fears and realities. More importantly, we begin to see ethics and privacy as crucial enablers within learning analytics.  The chapter briefly locates ethics in learning analytics in the broader context of the forces shaping higher education and the roles of data and evidence before tracking our personal research journey, highlighting current work in the field, and concluding by mapping future issues for consideration.",2,2,0,2
"1914","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Predictive models aim to find a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data. Explanatory models seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. ",1,0,1,5
"1915","Statistical graphics: making information clear – and beautiful","Use informative colour to visually associate elements. Keep the figure simple (and therefore interpretable). Keep the x- and y-axes on the same scale. Eliminate repetitive information. Maintain consistency across plots.",0,0,0,2
"1916","How to display data badly","The understanding of how to produce poor-quality graphs helps us to notice bad practices and help us to avoid in doing the similar project.",0,1,-1,2
"1917","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Infovis prizes unique, distinctive displays, while statisticians are always trying to develop generic methods for all works of life. Another difference lies in the expected audience.Infovis wants to draw attention to their graphics and then to the subject matter. ",2,1,1,2
"1918","Junkcharts Trifecta Checkup: The Definitive Guide","If you use the Trifecta Checkup framework, every critique you produce for a particular chart falls into one of these types:  The trifecta:the chart has no weaknesses The singles: Type Q, failing for a poorly defined objective Type D, failing to illuminate the question Doubles: Type QD, providing in vain effort Type QV, failing to bring out the key features of the data Triple: Type QDV:  nothing is right      ",1,8,-7,2
"1919","Measurement and its Uses in Learning Analytics","This paper kind of combines measurement and learning analytics together. It greatly enlightens me to look into educational from an interdisciplinary perspective to gain a full picture of students' learning and performance.",3,0,3,2
"1920","Ethics and Learning Analytics: Charting the (Un)Charted","This handbook introduces some basic ideas of learning analytics. The most important argument in the first chapter is that the authors believe that by design- or else by accident- the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices.",0,0,0,2
"1921","Predictive Modelling in Teaching and Learning","Modeling teaching and learning is kind of hard in real practice. This handbook provides us with some basic ideas of modeling and give lots of insights.",0,1,-1,2
"1922","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","This paper primarily talks about the idea that by design — or else by accident — the use of a learning analytics tool is always aligned with assessment regimes, which are in turn grounded in epistemological assumptions and pedagogical practices. Fundamentally then, the authors argue that deploying a given learning analytics tool expresses a commitment to a particular educational worldview, designed to nurture particular kinds of learners. They outline some key provocations in the development of learning analytic techniques, key questions to draw out the purpose and assumptions built into learning analytics.",0,0,0,2
"1923","Statistical graphics: making information clear – and beautiful","Visualization plays an important role in presenting education data, because it helps people understand the data better and possibly easier to find the patterns for the data. In class, I have learnt ggplot as a very tool to present data. I should explore more!",2,0,2,2
"1924","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how I like to organize the thinking behind my critique pieces. From this website, I can have a deeper insight into what kind of visualization I may need in order to present my data clearly.",2,2,0,2
"1925","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This paper introduces a new application of hierarchical cluster analysis and pattern visualization in educational fields in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. This paper is quite interesting!",1,0,1,3
"1926","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This paper introduces basic concepts in SNA, along with methods for data collection, data processing and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. This paper is interesting and show us the potential to apply SNA in educational fields.",0,0,0,4
"1927","Why Students Should Own Their Educational Data","This report generally talks about that every student should have their own personal educational data, so that teachers and educators can better tailor their own teaching. The idea is similar to personalized learning, and this article also suggests that we can make full use of modern technology to track students' learning.",2,0,2,2
"1928","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","EDM and LAK are kind of two popular research areas in recent years. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.",1,0,1,2
"1929","Evaluating Machine Learning Models","Machine learning is popular recent days. ""Evaluating Machine Learning Models"" is a very good book for me to learn basics of machine learning. In the book, the first part of books focus on developing machine-learning models for use in a software application. For the latter parts, the book talks about the metrics and standards to evaluate the models.",2,0,2,5
"1930","Why Opting Out of Student Data Collection Isn’t the Solution","This article talks about the use of education data collection and discusses why opts-out of data being collected is not a good solution for students.",1,0,1,2
"1931","Why Is Measuring Learning So Difficult?","Measuring learning is quite complex and hard in real practice. This video shows us why it is hard.",0,3,-3,1
"1932","Saturday Morning Breakfast Cereal","This cartoon is very interesting, and it profoundly show the basic idea of causation. The order of causation, or the independent and dependent variables of a causal relationship cannot be reversed. Sometimes, researchers may overlook or have some misconceptions about this fact.",2,1,1,2
"1933","Zuckerberg is ploughing billions into 'personalised learning' – why?","This report talked about a news that Zuckerberg may setup a project aiming to improve personalized learning for school students. This article has also discussed the advantages and disadvantages of personalized learning.",0,0,0,2
"1934","Chapter 1: Social Network Data","This chapter introduces some basic terminologies in social network analysis, which is quite helpful for beginners.",0,0,0,4
"1935","RStudio Cheat Sheets","This is a very useful website, because I can quickly find many useful R functions in this cheatsheet. It would definitely aid in my coding for future use.",0,0,0,1
"1936","Translating Learning into Numbers: A Generic Framework for Learning Analytics","In this paper, the authors explored key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. The paper proposes a generic design framework that can act as a useful guide for setting up LA services in support of educational practice and learner guidance.",2,4,-2,1
"1937","The Big Five and Visualisations of Team Work Activity","This paper created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.",4,0,4,2
"1938","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This paper talks about the influence of an open online Introduction to Recommender Systems on students learning. The authors have performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent, and designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course. Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.",11,4,7,4
"1939","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","This paper investigates the means to assist experts to map skills to tasks by using a data driven, matrix factorization approach. This topic is particularly interesting to me, because I am in the major of measurement and assessment. In my field, it is the common case to predefine a Qmatrix before conducting an assessment and then estimate students' profile skills. But the Qmatrix may include elements of errors.This paper enlightens me combine it to my major to make more advancements.",2,1,1,5
"1940","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","In this paper, the authors have developed an innovative method to discover skill models from the data of online courses. The method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. The method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, they compares their method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) their method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) their method is remarkably faster than existing methods. I feel really inspired by the methods, because it can be potentially combined with my program of measurement and evaluation.",11,1,10,5
"1941","Using data mining to predict secondary school student performance","This paper talks about using data mining techniques to predict secondary school students' performance. The paper is quite interesting, and the authors tested how different models and inputs may influence the prediction of academic performance.",1,0,1,3
"1942","Developing a generalizable detector of when students game the system","The researchers in this paper presented a system that can accurately detect whether a student is gaming the system instead of learning materials, within a Cognitive Tutor mathematics curricula. In addition, their detector can distinguish between two types of gaming. This paper is interesting, because it can provide teachers and educators a perspective and assessment way to monitor students' learning and performance.",1,0,1,5
"1943","Cross Validation","This video is showing us the basic idea of cross validation. For example, the train and test data sets.",0,0,0,5
"1944","Hands-On Programming with R","This book is kind of the ""Bible"" in learning R. I have read parts of the books before. I really love this book! But also, the best way to learn R is to code by myself without the book.",2,0,2,2
"1945","Principal Component Analysis explained visually","This is a very useful website to learn PCA, because it interactively visualize the basic ideas of PCA. With this website, it is much easier for me to understand PCA and the mechanisms behind.",1,0,1,2
"1946","Measurement and its Uses in Learning Analytics","Repetitive article Learning in higher education is increasingly supported through online learning environment allowing to track, analyze, and support learner behavior. So, basically, Learning Analytics use static and dynamic information about learners and learning environments, assessing, eliciting, and analyzing them, for real-time modeling, prediction and optimization of learning processes, learning environments, and educational decision-making. Hence, learning analytics aim at better understanding and supporting student learning by offering personalized learning environments as well as providing just-in-time feedback. In times of growing and increasingly heterogeneous students, learning analytics are considered as effective means to early identify students at risk and thus reduce academic failure and attrition.",5,2,3,1
"1947","Ethics and Learning Analytics: Charting the (Un)Charted","Repetitive article Learning in higher education is increasingly supported through online learning environment allowing to track, analyze, and support learner behavior. So, basically, Learning Analytics use static and dynamic information about learners and learning environments, assessing, eliciting, and analyzing them, for real-time modeling, prediction and optimization of learning processes, learning environments, and educational decision-making. Hence, learning analytics aim at better understanding and supporting student learning by offering personalized learning environments as well as providing just-in-time feedback. In times of growing and increasingly heterogeneous students, learning analytics are considered as effective means to early identify students at risk and thus reduce academic failure and attrition.",5,2,3,1
"1948","Predictive Modelling in Teaching and Learning","Learning in higher education is increasingly supported through online learning environment allowing to track, analyze, and support learner behavior. So, basically, Learning Analytics use static and dynamic information about learners and learning environments, assessing, eliciting, and analyzing them, for real-time modeling, prediction and optimization of learning processes, learning environments, and educational decision-making. Hence, learning analytics aim at better understanding and supporting student learning by offering personalized learning environments as well as providing just-in-time feedback. In times of growing and increasingly heterogeneous students, learning analytics are considered as effective means to early identify students at risk and thus reduce academic failure and attrition.",5,2,3,1
"1949","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Repetitive article Learning in higher education is increasingly supported through online learning environment allowing to track, analyze, and support learner behavior. So, basically, Learning Analytics use static and dynamic information about learners and learning environments, assessing, eliciting, and analyzing them, for real-time modeling, prediction and optimization of learning processes, learning environments, and educational decision-making. Hence, learning analytics aim at better understanding and supporting student learning by offering personalized learning environments as well as providing just-in-time feedback. In times of growing and increasingly heterogeneous students, learning analytics are considered as effective means to early identify students at risk and thus reduce academic failure and attrition.",5,2,3,1
"1950","Statistical graphics: making information clear – and beautiful","I don't know why I can't open this article. :(",0,0,0,2
"1951","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","I don't know why I can't open this article. :(",0,0,0,2
"1952","Junkcharts Trifecta Checkup: The Definitive Guide","As we know, good visualizations should not only accurately reflect the data but also unveil underlying structures and reveal patterns of distribution, clusters, anomalies and correlations, in a format that is clear and easy to read and understand. The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. In putting the framework together, we need to make it simple to use and broadly applicable. The Trifecta Checkup involves only three investigations:  What is the QUESTION? What does the DATA say? What does the VISUAL say? ",2,2,0,2
"1953","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","I don't know why I can't open this article. :(",0,0,0,2
"1954","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Some people may concern about privacy issues. However, according to my classmate Susan's note, “It has almost become normal for developers to ship apps that require social media registration, that request unnecessary permissions such as microphone access and location data, and that demand access to all of a user’s contacts.” Student social life and social organizations can be shared with the government. Because of the downloading of the application, they had already agreed to share the information with the public. So, the real click-to-agree problem may not be that individuals fail in their duty. It may, instead, that individuals who heavily depend on Google, Facebook or Twitter is not in a position to negotiate with the online contracts.",2,4,-2,4
"1955","Why Students Should Own Their Educational Data","For a long period of time, we have thought we could understand individuals by studying groups of people and patterns in the population. So every time we say we are studying this application of learning, what we are really saying is there are groups of people, and we look for statistical patterns in the people. But we can’t actually tell anything in population studies about any individual in that group.We have to draw inferences about a population from a sample because we couldn’t get the population data. When we start talking about the ability to create some kind of personalized learning, we have to be able to model the individual.Hopefully, nowadays, there is a shift that we start to analyze individual patterns instead of aggregate data. For example, cancer research. They have a combination of big data and the moral imperative of trying to treat individuals with cancer.",0,2,-2,2
"1956","Knowledge tracing: Modeling the acquisition of procedural knowledge","DO NOT HAVE ACCESS",0,0,0,2
"1957","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address the growing interest in data and analytics in education. The EDM and LAK communities are defined in relatively similar ways. The International Educational Data Mining Society defines EDM as follows: “Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.” The Society for Learning Analytics Research defines Learning Analytics as: “… the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.” EDM and LAK both reflect the emergence of data-intensive approaches to education. LAK and EDM share the goals of improving education by improving assessment, how problems in education are understood, and how interventions are planned and selected.  ",1,2,-1,2
"1958","Evaluating Machine Learning Models","Model Evaluation is an integral part of the model development process. It helps us to find the best model that represents our data and how well the chosen model will work in the future. Evaluating model performance with the data used for training is not acceptable in data science because it can easily generate overoptimistic and overfitted models. There are two methods of evaluating models in data science, Hold-Out and Cross-Validation. To avoid overfitting, both methods use a test set (not seen by the model) to evaluate model performance. Hold-Out: In this method, the mostly large dataset is randomly divided to three subsets:  Training set is a subset of the dataset used to build predictive models. Validation set is a subset of the dataset used to assess the performance of model built in the training phase. It provides a test platform for fine tuning model's parameters and selecting the best-performing model. Not all modeling algorithms need a validation set. Test set or unseen examples is a subset of the dataset to assess the likely future performance of a model. If a model fit to the training set much better than it fits the test set, overfitting is probably the cause. ",6,0,6,5
"1959","Why Opting Out of Student Data Collection Isn’t the Solution","In order for schools to function, they need basic information about students and parents. They need to record grades, know who is eligible for subsidized lunch, and who has special learning needs. Schools need to share data with vendors who operate cafeterias, school buses, and data storage systems for the school. In general, we might think about administrative and educational purposes as primary purposes of a school system where data collection is necessary, expected, and where it is not feasible to provide parents with choices because to do so would prevent the school from providing students with basic school educational services.Thus, personal information and course performance should be collected in order to maintain the educational function of a university. The demographic information collected already when students apply to the university. Although some students may not want to share their own academic records, the data still needs to be shared as a student. For example, they need to share their assignment and transcript, otherwise, they cannot use the platform, such as Canvas.",0,0,0,2
"1960","Why Is Measuring Learning So Difficult?","It’s hard to measure learning because it’s too broad and we need to simplify it. Moreover, learning is a personal thing. Nobody can do learning for us. If we decide not to tell our motivation or our condition to actually make other people attain what’s going on, it is really hard to define and measure. We cannot just draw conclusion from other studies since there are so many other factors might affect student achievement, such as curriculum design or instructional strategies. Learning is a long-term process. To clearly understand the essential distinction between learnings, we should trace back to the history, politics, economics, cultures and ethics to fully understand and pursuit the significance behind different education style.",2,2,0,2
"1961","Saturday Morning Breakfast Cereal","To be honest, I can’t quite understand the comic. I noticed that the professor mentions that “Japanese children are breaking and reassembling clocks 12% better than our children” and “Chinese missiles can reach Washington in 2.7 minutes”. There are many popular stereotypes of East Asian education among Westerners. For example, students heavily rely on rote learning, which associates with poor learning outcomes and superficial understanding. Students will practice a lot without fully understanding the teaching content. However, East Asian students indeed have good academic performance, especially in science and mathematics. I think the reason why a seemingly anachronistic teaching style cultivate high-achieving students is that repetitive learning by East Asians are not equate with rote learning, and they believe that repeated practice is one of the important ways to understand. Through repeated practice and recitation, students can gain insight into the concept behind the learning content",5,2,3,2
"1962","Data wranglers: human interpreters to help close the feedback loop","I don't know why I can't open this article. :(",0,0,0,2
"1963","Zuckerberg is ploughing billions into 'personalised learning' – why?","For Zuckerberg, personalised learning is about teachers “working with students to customise instruction to meet the student’s individual needs and interests”. Personalised learning has three major flaws:(1) Education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge. By feeding children only the content they’re interested in, we may end up with many specialists and few generalists.(2) While learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. (3) Children’s preferences are not fixed.     ",2,2,0,2
"1964","Feature Selection","Feature Selection is the process where we automatically or manually select those features which contribute most to our prediction variable or output in which we are interested in. Having irrelevant features in our data can decrease the accuracy of the models and make our model learn based on irrelevant features.The reason why Feature Selection is important is that Feature Selection methods helps us to reduce the dimensions without much loss of the total information. It also helps to make sense of the features and its importance.",0,1,-1,5
"1965","Chapter 1: Social Network Data","Social network analysis is more a branch of ""mathematical"" sociology than of ""statistical or quantitative analysis,"" though social network analysts most certainly practice both approaches. The distinction between the two approaches is not clear-cut.  Mathematical approaches to network analysis tend to treat the data as ""deterministic."" That is, they tend to regard the measured relationships and relationship strengths as accurately reflecting the ""real"" or ""final"" or ""equilibrium"" status of the network. Mathematical types also tend to assume that the observations are not a ""sample"" of some larger population of possible observations; rather, the observations are usually regarded as the population of interest. Statistical analysts tend to regard the particular scores on relationship strengths as stochastic or probabilistic realizations of an underlying true tendency or probability distribution of relationship strengths. Statistical analysts also tend to think of a particular set of network data as a ""sample"" of a larger class or population of such networks or network elements -- and have a concern for the results of the current study would be reproduced in the ""next"" study of similar samples. ",3,1,2,4
"1966","RStudio Cheat Sheets","The cheat sheets make my life much easier throughout the whole semester. It is easy for me to use some of my favorite packages.",1,1,0,1
"1967","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Case Study I found from the Internet:  Temple University uses predictive analytics to help predict which students are in danger of dropping out. Austin Peay State University uses a course recommendation system called Degree Compass (modeled after Netflix, Amazon, and Pandora) to help students select courses. Colorado Technical University uses an adaptive learning technology called intellipath to assess what students know, anticipates what they do not, and presents information that will help them meet course learning goals as quickly as they can. ",1,1,0,3
"1968","Translating Learning into Numbers: A Generic Framework for Learning Analytics","I remember that Tom Stella, an assistant superintendent of Everett Public Schools in Massachusetts, once said: ""The fewer places I have to go to get assessment data, the better."" I totally agree with his opinion. Nowadays, there are lots of technology platforms over there for me to track my study progress (for example, different professors would ask us to use their preferred platforms to learn new stuff.) and they are kind of isolating each other. I think I could definitely benefit from learning analytics (LA) since it stores all my data and provides me a clearer path to what I need to be learned based on my data, as well as creating recommendation subjects based on the understanding of my strengths and weakness. However, privacy is always a significant concern. I think the company needs to clearly identify ""who can touch the data"" and ""who owns the data"" to prohibit using data for advertising purposes.",8,3,5,2
"1969","The Big Five and Visualisations of Team Work Activity","the “Big Five” components of teamwork:  Team Leadership: ability to direct and coordinate other team members’ activities, assess team performance, assign tasks, develop team knowledge and skills, motivate team members, plan and organize, and establish a positive atmosphere. Mutual performance monitoring: ability to develop common understandings of the team environment and apply appropriate task strategies to accurately monitor teammate performance. Backup behavior: ability to anticipate other team members’ needs through accurate knowledge about their responsibilities. Includes the ability to shift workload among members to achieve balance during high periods of workload or pressure. Adaptability: ability to adjust strategies based on information gathered from the environment through the use of backup behavior and reallocation of intra-team resources. Altering a course of action or team repertoire in response to changing conditions (internal or external). Team orientation: propensity to take others’ behavior into account during group interaction and belief in importance of team goal over individual members’ goals. ",0,0,0,2
"1970","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","With the growing number of students in the classroom and the switch to online environments, instructors are beginning to integrate collaborative learning approaches in the classroom. However, many times in large collaborative environments and large social networks, students are overwhelmed by the amount of available information; it is often challenging to select the most appropriate sources of information. I think a promising way to deal with this challenge and enhance social interaction in collaborative learning environments is by introducing recommender systems.",1,1,0,4
"1971","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Linear models of skills are familiar to most teachers. The success of linear models and factorization methods raises the question of whether these methods could also be successful in deriving Q-matrices that maps items to skills. A few studies have shown that a mapping can, indeed, be derived from data. However, only very distinct topics like French and mathematics can yield adequate mapping. Recent work by Lan et al. combine a factor analysis framework, named SPARFA, with Bayesian techniques to uncover skills behind task and to label these skills from tags and from the question item texts.",7,0,7,5
"1972","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","The article showed that eEPIPHANY is an efficient, practical, and quick method to automatically discover skill models from online course data without human interaction. Moreover, the empirical study in the article showed that eEPIPHANY always finds skill models that are better than human-crafted skill models used in actual online courses. eEPIPHANY-crafted skill models have reasonable interpretability with the added help of the text analysis technique. Creating effective online courses often requires intensive, iterative system engineering. Studying techniques for automatic skill model refinement and its application for evidence-based course refinement therefore is a critical research agenda for the successful future of online education",8,1,7,5
"1973","Using data mining to predict secondary school student performance","I remember that I had once been labeled as ""more likely to fail"" in one course when I was at Syracuse University because I was stopped by illness from the exam at that time. I didn't receive an email doubting my abilities, instead, they sent me an email to ask me to see my advisor and professor because they found that I was off track. I think the message to me was carefully crafted and warm so that I was not discouraged or alarmed. I think predictive analytics would be a useful tool for students if it applies to students in a correct way. The three main reasons colleges are employing the predictive tool are:* to identify students most in need of advising services* to develop adaptive learning courseware that personalized learning* to manage enrollment<U+2028>",3,3,0,2
"1974","Developing a generalizable detector of when students game the system","Detector - detect when students “game the system”  accurately detects which students game the system Detecting When Students Game the System makes predictions about when students game the system, which are difficult to directly validate, but which have been used to drive learning interventions which improve student learning expands our knowledge about the behavioral construct of “gaming the system” can generalize between contexts  It is worth noting that many of the same issues apply in general to the problems of modeling user behavior and strategies. Detectors of user behavior and strategies should focus on behaviors which are associated with differences in user experience and outcomes. A detector of a category of user behavior should not just identify that a behavior has occurred, but when it occurs – as in the example presented within the paper, this task may be facilitated by using hierarchical modeling frameworks that make predictions at multiple grain-sizes. Detectors of user behavior and strategies will be more useful if:  they can help identify why users engage in the studied behaviors and strategies they can effectively generalize to different sub-domains within an overall system they can capture important behaviors, identifies when they occur, promotes understanding of the behaviors, and is general – regardless of what domain the behavior occurs within.  ",1,2,-1,5
"1975","Big Data in Education","I don't know why I can't open this article. :(",0,0,0,2
"1976","Cross Validation","Cross-validation is a technique that is used for the assessment of how the results of statistical analysis generalize to an independent data set. Cross-validation is largely used in settings where the target is prediction and it is necessary to estimate the accuracy of the performance of a predictive model. The prime reason for the use of cross-validation rather than conventional validation is that there is not enough data available for partitioning them into separate training and test sets (as in conventional validation). This results in a loss of testing and modeling capability.",2,1,1,5
"1977","Hands-On Programming with R","My HUDM 5026 Introduction to Data Analysis and Graphics in R course textbook. From this book, I learn how to program by diving into the R language, and then use my newfound skills to solve practical data science problems. Also, with this book, I know how to load data, assemble and disassemble data objects, navigate R's environment system, write my own functions, and use all of R's programming tools. This book is very helpful for beginner's and guide beginners to R with some engaging programming examples. Highly recommend!",2,1,1,1
"1978","Principal Component Analysis explained visually","Principal Component Analysis (PCA) is a dimension-reduction tool that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set. PCA finds the principal components of data. It is often useful to measure data in terms of its principal components rather than on a normal x-y axis. PCA are the directions where there is the most variance, the directions where the data is most spread out.",0,0,0,5
"1979","The Chinese learner – a question of style","Since the book Battle Hymn of the Tiger Mother was published in 2011, it has aroused anxious responses and triggered furious cultural conflicts. Likewise, in 2015, BBC produced a documentary film named Are Our Kids Tough Enough? which generated a controversial discussion about the difference between Chinese and American learning styles. Consistent with the American educational philosophy and educational ideology, the American teaching model is a student-centered model that emphasizes communication and interaction. In this model, the educational purpose emphasizes not the accumulation and acquisition of basic knowledge, but the cultivation of students’ innovation ability and independent consciousness. Education in China is built on the basis of knowledge imparting, with teachers as the center, students being regarded as passive information receivers, and learning content determined by the college entrance examination. Under this model, China’s educational objectives highlight the importance of basic knowledge, and classroom teaching focuses on the transmission and inculcation of knowledge, as well as the cultivation of students’ respect and acceptance of authority, mastery and inheritance of knowledge. The choice of teaching method is compatible with the teaching mode. Classroom teaching in the United States are generally pay attention to interaction, pay attention to training students’ self-learning and collaborative learning consciousness and ability, adopt the teaching methods in addition to the direct teaching method, case teaching, group discussion and group learning, more important is in the form of inquiry learning method, namely “inquiry learning” and “based on the study of the problem,”. In the classroom teaching of our country, influenced by the hierarchical concept of teachers and students as well as the teacher-centered model in the traditional culture for a long time, it generally adopts the indoctrination teaching that emphasizes the imparting of basic knowledge, pays attention to the research of teachers’ teaching methods, and ignores the expansion of students’ learning methods to different degrees. Moreover, US parents tend to conform to their children’s personalities and interests and give them the choice, allowing their children freely to develop their individuality, creativity and curiosity. However, what Americans are trying to convey to their children is the opposite of Chinese culture. The hierarchy between teachers/parents/elders and students in Chinese culture makes Chinese education have different set of rules about obedience and self-discipline comparing to US education. In contrast to be a “good child” in China, most American children are brought up with a strong sense of individuality and criticism, learning how to make their own decisions, how to find meaning and pleasure in life by themselves, and selectively ignoring so-called “authorities” or rules. This phenomenon clearly has deep historical roots. ",8,5,3,2
"1980","Why Students Should Own Their Educational Data","1. average VS individual",0,0,0,3
"1981","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","   1. EDM research which leverages human judgment in many cases does so to provide labels for classification, while LAK research which uses automated discovery often does so in the service of informing humans who make final decisions.  2. EDM models are more often used as the basis of automated adaptation, conducted by a computer system such as an intelligent tutoring system. By contrast, LAK models are more often designed to inform and empower instructors and learners.  3. EDM research to see research which reduces phenomena to components and analyzing individual components and relationships between them. LAK researchers typically place a stronger emphasis on attempting to understand systems as wholes, in their full complexity.    ",1,0,1,2
"1982","Why Is Measuring Learning So Difficult?","1. multi-dimensional 2. from practices, participate --- contexual, idiosyncratic 3. personal, construct --- but can see result of interaction 4. when students teach something to each other --- (P2P mode 42 coding school) 5. measure competence --- come in competence &amp; when course finish 6. measuring learning - psychological constructs psychometric achievement 7. doorway! what else is possible! --- LA! 8. coalescing of factors",0,0,0,1
"1983","Saturday Morning Breakfast Cereal","data is persuasive cause &amp; effect could be upside down should find the real &amp; deepest connection heavy impact on policy decisions but what matters is the brain behind... crazy program..",0,0,0,2
"1984","The Data Wrangling Cheatsheet","dplyr: 1. Syntax           2. Reshaping Data           3. Subset Observations           4. Subset Variables           5. Summarise Data           6. Make New Variables           7. Group Data (?)           8. Combine Data Sets (?)",0,0,0,1
"1985","Data wranglers: human interpreters to help close the feedback loop","    CASE OF DATA WRANGLING   This is not a straightforward process: some academic staff may be resistant to what they perceive as the metrics agenda. However, engaging with learning analytics can steer the agenda towards richer conceptions of learning than a nai¨ve quantitative view might imply    Learning Design can provide an account of pedagogical intent that can provide useful context for interpreting learning analytics, and learning analytics can provide particularly useful insight to underpin the process of Learning Design   ",2,0,2,1
"1986","Zuckerberg is ploughing billions into 'personalised learning' – why?","three major flaws:  1, education has always been about acquiring knowledge and skills relevant to a profession, but also about acquiring general knowledge.  2,while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating. 3,children’s preferences are not fixed – in fact they often change as immediate responses to the environment   Motivation is crucial for effective learning, and personalised learning gives children a sense of ownership and relevance, while personalised assessments are regarded as effective.  ",4,1,3,2
"1987","Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms - Boston College Law Review","Note!",0,0,0,4
"1988","The R Markdown Cheat sheet","code chunk:```[r]```   inline code   what is shiny?",1,0,1,1
"1989","K-Means Clustering","Use:We begin with two centroids. These are computed by splitting all points on the variable (dimension) with greatest range (or some other measure of spread). The split separates points above the mean (or some other measure of location) on this variable from those below the mean. Centroids are then computed for each group by averaging coordinates of its members. Then we do an entire k-means cycle (assignments plus iterations). After convergence, we move to computing three centroids. Again, we split the cluster having the largest range on a variable into two clusters (one above and one below the mean on this variable). New centroids are computed and another k-means cycle is performed. We continue this process until we reach the desired number (k)of centroids. Limitation:Starting with arbitrary random centroids is a relatively poor method",1,4,-3,1
"1990","Feature Selection - Georgia Tech - Machine Learning","1. human being     - knowledge discovery          interpretability: people ignore in machine learning field (data-mining field less ignore)         insight      - curse &amp; dimensionality          feature selection 2. machine &amp; machine learning algorithms       important features!!!",0,1,-1,5
"1991","Big Data in Education 7.1 Clustering","1. decide how many clusters we want 2. centroids: random -- voronoi diagram -- re fit -- convergence 3. run several times...   k should be 3 rather than 5.. ?",0,1,-1,1
"1992","Chapter 12","    As for what can be incorporated into a dashboard,    Artefacts produced by learners, including blog posts, shared documents, software, and other artefacts that would often end up in a student project portfolio.    Social interaction, including speech in face-to-face group work, blog comments, Twitter or discussion forum interactions.    Resource use can include consultation of documents (manuals, web pages, slides), views of videos, et cetera. Techniques like software trackers and eye-tracking can provide detailed information  used and how.        Time spent can be useful for teachers to identify students at risk and for students to compare their own efforts with those of their peers.    Test and self-assessment results can provide an indication of learning progress.             ",3,1,2,4
"1993","Junk Charts Trifecta Checkup: The Definitive Guide","The Question occupies the top corner because any data visualization project needs a worthy cause. I'd like the Question to be well-posed, and interesting; the former focuses the search for appropriate data while the latter ensures an engaged audience. The Data should be relevant to the Question being addressed. Relevance can often be augmented by reducing noise, removing errors or transformations. The Visual elements should represent the Data in a clear, concise manner, addressing the Question directly.   0. The trifecta 1. The singles 1a. Type Q   definition  1b. Type D    data 1c. Type V    confusion 2. Doubles 2a. Type QD    2b. Type QV 2c. Type DV 3. Triple (Type QDV)",4,2,2,2
"1994","Big Data in Education 7.2 Validation and Selection","distortion (mean squared deviation) distance cross-validation -- centres chosen --- penalize model",0,2,-2,1
"1995","Big Data in Education 7.6 Knowledge Inference: Q-Matrix Knowledge Structure","1. automatic model discovery:conjunctive &amp; compensatory 2. hand-development &amp; refinement",0,0,0,5
"1996","Introduction to Social Network Methods:  Chapter 1: Social Network Data","1. nodes &amp; edges   2. Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal."" Statistical analysts deal with the same issues as ""hierarchical"" or ""nested"" designs.       3. full network methods snowball methods ego-centric networks (with after connections) ego-centric networks (ego only)       4. If we do not know what relations to examine, how might we decide? There are a number of conceptual approaches that might be of assistance. Systems theory, for example, suggests two domains: material and informational. Many interesting areas of work such as network correlation, multi-dimensional scaling and clustering, and role algebras have been developed to work with multi-relational data.   5. Binary measures of relations Multiple-category nominal measures of relations Grouped ordinal measures of relations Full-rank ordinal measures of relations Interval measures of relations     5. Social network data are, as we have pointed out, easily represented as arrays of numbers -- just like other types of sociological data. Algorithms from statistics are commonly used to describe characteristics of individual observations (e.g. the median tie strength of actor X with all other actors in the network) and the network as a whole (e.g. the mean of all tie strengths among all actors in the network). Statistical algorithms are very heavily used in assessing the degree of similarity among actors, and if finding patterns in network data (e.g. factor analysis, cluster analysis, multi-dimensional scaling). Even the tools of predictive modeling are commonly applied to network data (e.g. correlation and regression).",3,1,2,4
"1997","Cluster","1.After each assignment, we need to update the assigned centroid by adding in the coordinates of the new point (a simple calculation). Assigning all points to a set of successively updated centroids constitutes one iteration of the k-means algorithm   2.we need to know k to find clusters and we need to identify clusters to determine k. Hartigan's procedure gives us a lever. At each stage of Hartigan's method, we compute the sum-of-squares within groups over all variables (sum of squared deviations of each point from its centroid on every dimension). This sum of squares should decline as we add new clusters; indeed, it would be zero if we made every point a cluster. So we look for the reduction in sum of squares at each step and stop adding clusters when this reduction is negligible.   ... look for a proportional reduction in error (PRE) of about .4 or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares.   3.separating convex clusters    ",2,2,0,1
"1998","Chapter 5","predictive modelling: the purpose is to create a model that will predict the values   explanatory modelling: the intent of these explanations is generally to be causal   The largest methodological difference between the two modelling approaches is in how they address the issue of generalizability     Linear Regression Logistic Regression Nearest Neighbours Classifiers Decision Trees Naïve Bayes Classifiers Bayesian Networks Support Vector Machines Neural Networks Ensemble Methods",1,2,-1,3
"1999","Big Data in Education 1.1 Introduction","type of edm/la method: 1, prediction -classification -regression -latent knowledge estimation 2, structure discovery -clustering -factor analysis -domain structure discovery -network analysis 3, relationship mining -association rule mining -correlation mining -",0,1,-1,5
"2000","Cross Validation","Generalize representative from the same distribution fundamental assumption   take some of the training data   fold   sheep????? use some of the data as test set   pick the average one  ",0,0,0,5
"2001","Big Data in Education 2.2 Diagnostic Metrics Part 1","accuracy: poor when non-even assignment to categories   Kappa: 0 maybe agreement is at chance 1 maybe perfect -1 maybe perfectly inverse &gt;1 maybe somewhere mess up &lt;0 super bad, rare 0&lt;Kappa&lt;1 hard to say  ",3,4,-1,1
"2002","Big Data in Education 2.5 Cross-Validation and Over-Fitting","over-fitting: both noise and signal reduce? simple     K-fold better than leave-out-one   flat cross validation   v.s. stratified cross-validation",1,0,1,5
"2003","Big Data in Education 2.4 Diagnostic Metrics: Correlation","linear correlation   physics -- 0.8 is weak education -- 0.3 is good     MAD RMSE low MAD/RMSE is good high correlation is good   AIC BIC  ",3,2,1,5
"2004","Big Data in Education 2.3  Diagnostic Metrics Part 2","ROC: 1, 2 values 2, out put real value   threshold   A'   complication   AUC",0,0,0,5
"2005","Measurement and its Uses in Learning Analytics","Psychological measurement:  Defining a construct Specifying a measurement model and a reliable instrument Analyzing error Framing a valid argument for uses of outcome    Reliability: consistency of scores   Validity: degree to which evidence and theory support interpretations   “When adapting an instrument or, especially, part of an instrument for new purposes, practitioners should be mindful of whether these new uses merit new validation arguments.”   “A model is identifiable if its parameters can be unambiguously learned given sufficient data.” “While an explanatory model can be used to make predictions - and an error-free explanatory model would make perfect predictions - a predictive model is not necessarily explanatory.” ",3,1,2,5
"2006","Ethics and Learning Analytics: Charting the (Un)Charted","??? Data-proxy-induced hardship: when the detail obtained from the dat-proxy comes to disadvantage its embodied referent in some way.   Educational triage:  Respecing student autonomy Ensuring long-term sustainability of the institution Beneficence (always act in the student’s best interest) Non-maleficence (inflicting the least harm possible to reach a beneficial outcome) Maintain a sense of distributive justice    Threats of LA:  Ethical and data privacy issues Over-analysis Lack of generalizability of results ",1,5,-4,2
"2007","Predictive Modelling in Teaching and Learning","Did not read it",0,0,0,5
"2008","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Did not read it",0,0,0,5
"2009","Statistical graphics: making information clear – and beautiful","Did not read it",0,0,0,5
"2010","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Did not read it",0,0,0,5
"2011","Junkcharts Trifecta Checkup: The Definitive Guide","Did not read it",0,0,0,5
"2012","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Did not read it",0,0,0,5
"2013","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Did not read it",0,0,0,5
"2014","Why Students Should Own Their Educational Data","“If the walled-garden approach of companies wins in the short term, then we can’t really exploit the new science of the individual.”   MOOC companies know that data is important, but they’re hoarding it.   Desired: 3rd party who is responsible for protecting learner data.   Video  Average = no one “If you design learning environments for average, odds are they’re designed for nobody.” Jagged learning profile. Average hurts everyone:  Talent/strength becomes a liability because educational environment doesn’t challenge them.  Weakness get spotlight and obscures talent/strength   Ban the average in our classrooms. Design educational tools to the edges, not to the average. <U+2192> “Adjustable seats for learning.” ",3,5,-2,2
"2015","Knowledge tracing: Modeling the acquisition of procedural knowledge","Did not read it",0,0,0,5
"2016","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Argues for increased communication and collaboration between Educational Data Mining (EDM) &amp; Learning Analytics and Knowledge (LAK) communities.",0,0,0,2
"2017","Evaluating Machine Learning Models","Did not read it",0,0,0,5
"2018","Why Opting Out of Student Data Collection Isn’t the Solution","Did not read it",0,0,0,5
"2019","Why Is Measuring Learning So Difficult?","Did not read it",0,0,0,5
"2020","Saturday Morning Breakfast Cereal","I subscribed to this. Great satire of philosophy/religion/science/politics/sociology/psychology.",1,0,1,2
"2021","Data wranglers: human interpreters to help close the feedback loop","“The role of the Data Wrangler is is not only to analyse the date, but to increase the familiarity of academics with the data sources , to build learning analytics capacity as part of a Community of Practice.”   “This ongoing conversation about data — between those who capture and curate it and those who can do something about it — is key to the double-loop learning aspect of the process.”   “The issues of the data quality unearthed through the Data Wrangler process shows the value of sense-making activity. If it is nobody’s job to make sense of the data, the risk is that the data do not make sense but nobody realises.”",0,1,-1,1
"2022","Zuckerberg is ploughing billions into 'personalised learning' – why?","Did not read it",0,0,0,5
"2023","Feature Selection","Did not read it",0,0,0,5
"2024","Chapter 1: Social Network Data","Did not read it",0,0,0,5
"2025","RStudio Cheat Sheets","Did not read it",0,0,0,5
"2026","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Did not read it",0,0,0,5
"2027","Translating Learning into Numbers: A Generic Framework for Learning Analytics","9/24/19 Comment: As student, can't access data &amp; tools related to prediction. Can see whole class's performance on assessments, but cannot access data from each individual's assessment. cannot access prof/dept/uni ""birds eye"" views of class, dept, student body, etc.   Summary: Data mining is more comparable to observational data gathering than to intrusive collection via direct methods.     45 Table 1 can be used as a checklist when designing a purposeful LA process    Main opportunity for LA as a domain: to unveil and contextualize so far hidden information out of the educational data and prepare it for the different stakeholders.   LA datasets create a new set of challenges for research and practice:  A lack of common dataset formats The need for version control and a common reference system to distinguish and point to different datasets Methods to anonymize and preprocess according privacy &amp; legal protection A standardized documentation so that others can make proper use of it Data policies that regulate how users can use and share    In most natural settings, users “pollute” databases by producing erroneous or incomplete datasets. For example, teachers set up “test students” or “test accounts” in LMS systems.   Data collection often leads to “enmeshed identities”. A dataset cannot typically distinguish between a single individual and a shared presence in the learning space (group work on a single device).   LA designers and developers need to be aware that any algorithm or method they apply is reductive by nature and in that it simplifies reality to a manageable set of variables.   The ethic principle of “informed consent” is very much under threat.   To use LA to its full potential, integration of available institutional datasets needs to happen   It is one of the principal pitfalls of statistical prediction that it can only predict average behavior not outliers. A such, LA provides no means of predicting exceptions to a rule, or exceptions to the exception rule.     It is not yet clear to what extent LA will lead to more personalized learning experiences rather than merely clustering people into behavioristic “learner models”.   Real dangers that extended and organized collection of learner data will empower HEIs (higher ed institutions), companies, or governments to increase manipulative control over students, employees, and citizens, thereby abusing LA as a means to reinforce segregation, peer pressure, and conformism rather than to help construct a needs-driven learning society.",6,3,3,1
"2028","The Big Five and Visualisations of Team Work Activity","Did not read it",0,0,0,5
"2029","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","Did not read it",0,0,0,5
"2030","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Did not read it",0,0,0,5
"2031","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Did not read it",0,0,0,5
"2032","Using data mining to predict secondary school student performance","Did not read it",0,0,0,5
"2033","Developing a generalizable detector of when students game the system","Did not read it",0,0,0,5
"2034","Big Data in Education","Did not read it",0,0,0,5
"2035","Cross Validation","Did not read it",0,0,0,5
"2036","Hands-On Programming with R","Did not read it",0,0,0,5
"2037","Principal Component Analysis explained visually","Did not read it",0,0,0,5
"2038","Measurement and its Uses in Learning Analytics","The article theory and learning analytics is a good source to dig deeper into some relative knowledge of my major. In addition, the EPA, epistemology, assessment, pedagogy triangle is very very interesting.",2,0,2,2
"2039","Ethics and Learning Analytics: Charting the (Un)Charted","    Ethics and Learning Analytics: Charting the (Un)Charted by Paul and Sharon are a good source to learn and relate what we learned or will learn from the class. ethics, artificial intelligence, big data are discussed.                                        ",2,0,2,2
"2040","Predictive Modelling in Teaching and Learning","Wow Porf. Lang is one of the editor. That is amazing. This article Predictive Modelling in Teaching and Learning provides numerous illuminating points and detailed explanation about predictive modeling, machine learning, model evaluation and so on. Overall, I learned a lot and it is informative paper.",2,0,2,5
"2041","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Ran Liu and Kenneth R. Koedinger in Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data discussed numerous important points including explanatory models, model interpretability, educational data mining, which is the same as our course, closing the loop and cognitive models with details and clear explanations. I learned a lot.  ",2,0,2,5
"2042","Statistical graphics: making information clear – and beautiful","This article is the same as the infovis and statistical....   Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion) by Gelman and Unwin is the most interesting article so far especially because of the figures displayed in this article.The figure, data visualization, of 2009 weather in NYC is clear and very impressive. The decision tree: O-C Divide is also cute.",3,0,3,2
"2043","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion) by Gelman and Unwin is the most interesting article so far especially because of the figures displayed in this article.The figure, data visualization, of 2009 weather in NYC is clear and very impressive. The decision tree: O-C Divide is also cute.",3,0,3,2
"2044","Junkcharts Trifecta Checkup: The Definitive Guide","It is a good source with clear details and different catogories",2,0,2,5
"2045","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","The author Bowers who wrote Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis gave us a clear view of multivariate analysis, data analysis, decision making, dropouts and so on. There are a lot of great pictures which made it easier to understand the concepts. and the formulas in the appendix made this paper more reliable and professional.",3,1,2,3
"2046","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research contributed by Daniel Z. Grunspan, Benjamin L. Wiggins, and Steven M. Goodreau is a very good article. In this paper, social network basics, network types, network data collection, network level concepts and measures, actor-Level variables, network methods: Data Collection, timing of Survey Administration, Data Management and so on are discussed. There are also many good exampls such as example of nodal attributes held in a matrix, a small sociomatrix, General measurements taken from study networks of the first two exams, Degree distribution from the study networks of the first two exams, Results from a permutation correlation test between degree and betweenness centrality and student exam performance.",2,0,2,4
"2047","Why Students Should Own Their Educational Data","Mr. Jeffrey Young discussed about that why students should own their educational data from TED talk. It really attracted me because I am a student and I want to learn more about the statement. I found it very creative and cool that there was a Q&amp;A part at the end, and it explained points clearly, maybe it is because it is a TED talk. In addition, the comments part is interesting and it is a good place to learn more based on the article.",3,0,3,2
"2048","Knowledge tracing: Modeling the acquisition of procedural knowledge","Knowledge tracing: Modeling the acquisition of procedural knowledge - could not access",0,0,0,3
"2049","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","   Learning Analytics and Educational Data Mining: Towards Communication and Collaborationby Siemens and Baker provided a great overview of the Educational data mining and learning analytics, which is super closely related to the course and my major. The table of brief comparison of the two fields are good and clear.   ",4,0,4,2
"2050","Evaluating Machine Learning Models","Evaluating Machine Learning Models by Alice Zheng is really informative and clear in explanation and description. The picture of Machine learning model development and evaluation workflow is very clear and help readers to understand the concepts above easier and clearer. In addition, Evaluation Metrics, Offline Evaluation Mechanisms, Hyperparameter Search and Online Testing Mechanisms are mentioned with good supporting details and strong main points.",7,0,7,5
"2051","Why Opting Out of Student Data Collection Isn’t the Solution","The short article: Why Opting Out of Student Data Collection Isn’t the Solution by Brenda Leong and Jules Polonetsky is very good and enlightening. how data collection helps students and opt out are talked with great explanation and details.",2,0,2,2
"2052","Why Is Measuring Learning So Difficult?","This video starts with talks from several professional people related to education and they pointed out several key points with their detailed clarification. As later, there are more and more valued ideas shared.",0,2,-2,4
"2053","Saturday Morning Breakfast Cereal","This one is super cute and informative",2,0,2,2
"2054","Data wranglers: human interpreters to help close the feedback loop","  This short paper from the Open University named, Data wranglers: human interpreters to help close the feedback loop is very illuminating and amazing. By the way, it was my first time saw the Open University. The illustrations to support the main points are very clear. For example, Situation before Data Wrangler in place: users make little use of available data sources, Situation when Data Wrangler starts work: Data Wrangler presents data from all sources to all users, Situation when Data Wrangler work is mature: many users make more use of data sources directly and Proportion of students on selected courses who report that they ‘enjoy learning through’ different media are very clear and good to understand.  ",8,0,8,1
"2055","Zuckerberg is ploughing billions into 'personalised learning' – why?","This short article written by Jean Cote named: Zuckerberg is ploughing billions into ‘personalised learning’ – why?. At first, the title is very attractive because it is a question sentence, which would lead readers to find answers in the article. the dangers of personalized learning and reasons of personalized as well as a compromise approach are discussed with good supporting details.",4,1,3,2
"2056","Feature Selection","The short video Feature Selection - Georgia Tech - Machine Learning, which is from Udacity is easy to understand. It's amazing that it's easier and clearer to understand after learning something by video.",2,0,2,2
"2057","Chapter 1: Social Network Data","Robert and Mark wrote a lot of great information about the social network data. At first, there is a introduction about the differences about social network data. Then they discussed the nodes, populations, samples, and boundaries, modality and levels of analysis. Afterwards, relations including sampling ties and multiple relations are also mentioned with detailed explanations. Moreover, scales of measurement and the note on statistics and social network data are also informative. There are some good examples such as example of rectangular data array and example of square array of network data.",2,0,2,4
"2058","RStudio Cheat Sheets","This R Markdown cheat sheet is very useful. It is a very good source.",2,1,1,1
"2059","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","did not find the paper",0,0,0,1
"2060","Translating Learning into Numbers: A Generic Framework for Learning Analytics","could not access",0,0,0,2
"2061","The Big Five and Visualisations of Team Work Activity","The Big Five and Visualisations of Team Work Activity by Judy Kay, Nicolas Maisonneuve, Kalina Yacef and Peter Reimann talks about Team Member Social Network Analysis Team Leader Activity Radar Software Development Project. Those information is very detailed and good for learning.",2,0,2,2
"2062","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","could not access",0,0,0,2
"2063","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","In A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices, Michel and Rhouma introduced the student models, skills assessment, alternating least squares matrix factorization, latent skills and cognitive modeling, which was really informative and enlightening.",3,0,3,5
"2064","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement by Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos from International Educational Data Mining Society, Paper presented at the International Conference on Educational Data Mining is super related to the course which is exactly educational data mining. There are a lot of good points are discussed include but not limited to the Online Courses, Skills, Automation, Models, Data, Formative Evaluation, Correlation, Comparative Analysis. Overall, it's really informative and I learned a lot.      ",3,1,2,5
"2065","Using data mining to predict secondary school student performance","Using data mining to predict secondary school student performance written by Cortez, Paulo, Silva, Alice Maria Gonçalves is very good to learn about business intelligence in education, Classification and regression, Decision trees and Random forest, etc. it broaden my horizon and I found it very informative.    ",1,1,0,3
"2066","Developing a generalizable detector of when students game the system","could not get the article except for the abstract.",0,0,0,2
"2067","Big Data in Education","These two videos published by Columbia Learn were really informative and easy to understand. clustering, validation and selection are explained in a very good way.",1,0,1,1
"2068","Cross Validation","This video about cross validation from Udacity is very clear and easy to understand. by the way I heard ""Charles"", which is really surprising though. The description is very good as well as the explanation.",3,0,3,2
"2069","Hands-On Programming with R","This book: Hands-On Programming with R by Garrett Grolemund is super clear to follow it to learn R as a beginner like me. There are a lot of details and step by step instructions and even possible error messages occur. I really learned a lot from this book. And I found that R or another programming languages are related to statistics very closely because I saw some concepts like the expected value from my statistics course.",4,1,3,1
"2070","Principal Component Analysis explained visually","The examples are really clear. Great visualizations make it much easier to understand principal component analysis",3,0,3,2
"2071","Measurement and its Uses in Learning Analytics","an introduction to educational and psychological measurement for practitioners in learning analytics and educational data mining. Psychological measurement could have high-stakes results, Comprise of  1. Construct , still need comparison to a measure like  tape measure; we can sense the difference in length but need a construct; with trait! For example, we can quantify the difference in two lengths by subtracting one measurement from the other.   Relevent instrument for LA that has already developed : intelligence (e.g., the Stanford–Binet Intelligence Scale), scholastic aptitude (e.g., that SAT test), academic achievement (numerous examples include both large-scale tests and course exams), personality (e.g., the “big five” factor model; Digman, 1990), achievement-goal orientation (e.g., Midgley et al., 2000), achievement emotions (Pekrun, Goetz, Frenzel, Barchfeld, &amp; Perry, 2011), grit (Duck- worth, Peterson, Matthews, &amp; Kelly, 2007), self-theories of intelligence and fixed/growth mindset (Dweck, 2000; Yeager &amp; Dweck, 2012), intrinsic motivation (Deci &amp; Ryan, 1985; Guay, Vallerand, &amp; Blanchard, 2000), self-regulated learning and self-efficacy (e.g., Pintrich &amp; De Groot, 1990), learning power (Bucking- ham Shum &amp; Deakin Crick, 2012; Crick, Broadfoot, &amp; Claxton, 2004), and crowd-sourced learning ability (Milligan &amp; Griffin, 2016).   People’s responses to an instriument may not be always faithfully reflect. Statistical models allow us to think of items, indicators, or tests as random samples of a latent variable. The inherent non-repeatedity results in possible error   I read that we could use a lot of measurement model in learning analytics, then why do we still need learning analytics if we can just focus on   Learning analytics could play a role of middle space for learning science and analytics, predictive models and explanatory model, minimizing errors, to know how to handle errors and uncertainty.  ",3,4,-1,5
"2072","Ethics and Learning Analytics: Charting the (Un)Charted","It is an overview of of how our own thinking has developed and maps our journey against broader developments in the field. Against a backdrop of technological advances and increasing concerns around pervasive surveillance and the role and unintended consequences of algorithms, the development of research in learning analytics as an ethical and moral practice provides a rich picture of fears and realities. More importantly, we begin to see ethics and privacy as crucial enablers within learning analytics. Ethical issues were grouped within the three broads: The location and interpretation of data Informed consent, privacy, and the de-identifi- cation of data The management, classification, and storage of data  ",1,2,-1,2
"2073","Predictive Modelling in Teaching and Learning","This article describes the process, practice, and challenges of using predictive modelling in teaching and learning. In both the elds of educational data mining (EDM) and learning analytics (LA) predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic achievement. In this chapter, we provide a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process, and a brief overview of the most popular techniques in the eld. The ethical problem is always the biggest obstacle to la researchers and practitioners.",3,1,2,3
"2074","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","In the statistical modelling of educational data, approaches vary depending on whether the goal is to build a predictive or an explanatory model. Predictive models aim to nd a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data. Explanatory models seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. The vast majority of educational data mining research has focused on achieving pre- dictive accuracy, but we argue that the eld could bene t from more focus on developing explanatory models. We review examples of educational data mining efforts that have pro- duced explanatory models and led to improvements to learning outcomes and/or learning theory. We also summarize some of the common characteristics of explanatory models, such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process.  Learning analytics could play a role of middle space for learning science and analytics, predictive models and explanatory model, minimizing errors, to know how to handle errors and uncertainty.",2,2,0,5
"2075","Statistical graphics: making information clear – and beautiful","To convey the idea and to understand the art of achieving graphical excellence and in turn appreciate the beauty with which these graphs are able to represent the data; we will learn and try to understand the following fundamental graphical designs and visualize and see just how good and fascinating graphical designs can be: 1. Data Maps2. Time Series3. Space Time Narrative Designs4. Relational Graphics",2,0,2,2
"2076","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","The importance of graphical displays in statistical practice has been recognizedsporadically in the statistical literature over the past century, with wider awarenessfollowing Tukey’s Exploratory Data Analysis (1977) and Tufte’s books in the succeedingdecades. But statistical graphics still occupies an awkward in-between position: Withinstatistics, exploratory and graphical methods represent a minor subfield and are not wellintegrated with larger themes of modeling and inference. Outside of statistics,infographics (also called information visualization or Infovis) is huge, but the",0,1,-1,2
"2077","Junkcharts Trifecta Checkup: The Definitive Guide","The Junk Charts Trifecta Checkup is a general framework for data visualization criticism. It captures how I like to organize the thinking behind my critique pieces. The need for such a framework is clear. Opinion pieces on specific data graphics frequently come across as stream of conscience. Proclaiming a chart ""mind-blowing"" or ""worst of the century"" isn't worth much if the author cannot articulate why. The state of dataviz criticism has not progressed further than assembling a set of ""rules of thumb"".",4,4,0,2
"2078","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)",1,3,-2,3
"2079","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.",4,1,3,4
"2080","Why Students Should Own Their Educational Data","Pre-reading ?I don’t see any reason why student shouldn’t own their educational data.  Research value : research on individual pattern brings more chance of breakthrough Learning style theory comes from analyzing a population and trying to parse out different ways of learning over a population. But when you apply it to one individual it doesn’t hold. You can’t start with averages, it doesn’t work. When we start talking about the ability to create some kind of personalized learning, you have to be able to model the individual.  You can never learn individual truly from a certain pattern: we actually cannot tell anything in a population study Student should own the data, third party should get involved to supervise the process   I agree with his opinion that truly transformational potential of the technology [is hard for venture-backed companies] to do. Whenever there’s economic or political interest involved, there’s always a discriminated bar which was not full access to learning subjects. And the transformation took place only when the beneficiaries no longer belong to a small group of entities.  ",2,1,1,2
"2081","Knowledge tracing: Modeling the acquisition of procedural knowledge","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called the ideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.",6,0,6,3
"2082","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Edm: looks at and develop methods that gather unique types of data coming from educational data setting La: the measurement collection, analysis and reporting data about learners and their context Distinction: Edm: machine learning side automated, reductionist(PCA) La: leverage  human judgement analysis , wholistic  ",1,0,1,2
"2083","Why Opting Out of Student Data Collection Isn’t the Solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust",2,0,2,2
"2084","Why Is Measuring Learning So Difficult?","citing the evidence for countering the theory of learning style, which generates patterns from population not individuals, thus if we want to measure every individual learning, this could be really hard from the perspectives of following scale labor of work ethic technology biological diversity",1,1,0,2
"2085","Saturday Morning Breakfast Cereal","fun comics!",1,0,1,2
"2086","Data wranglers: human interpreters to help close the feedback loop","Learning analytics :“the necessity of closing the feedback loop through appropriate interventions unmistakable”. A mutidisplinary team humans in interpreting the data, engaging in sense-making activities to mediate the information in ways that enable intelligent action   Problem:large scale of data need centralization and administrative process Goal : facilitate feedback from learner; making better sense of what that feedback means and how the data can be improved Data source: survey, activity aggregated pass rate, mode delivery Data wrangle(learning analytics specialist help connect teahcers instructor better understand the data  ",2,0,2,1
"2087","Zuckerberg is ploughing billions into 'personalised learning' – why?","for more dominance? besides have a good social reputation is another investment worth trying. this is the trend of every big mega company today, to reach out their services to every industry, trying to share the cake created by the previous explorer. They either crash them down with more money to burn playing monetary games or acquiring the explorers and make full use of them.  ",2,2,0,2
"2088","Feature Selection","Getting a large volume of data could be either an advantage or a dreadful thing depending on what methods you are using to utilize the data. A machine learning method feature selection helps zoom in the ""features"" that are most relevant to the research questions. it often happens before cross validation, supervised and unsupervised learning",0,1,-1,5
"2089","Chapter 1: Social Network Data","the application of social network analysis helps a lot in exploring not just the relationships between student student, teacher and teacher in class; but also the ones outside classroom. In class it could used to analyze the dominance or the flow within the formal learning environment, teacher centered or student centered ? how social emotional learning happened under what types of social network model? etc.",0,0,0,2
"2090","RStudio Cheat Sheets","It is easy!",1,0,1,2
"2091","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Framework 1.knowing who your stakeholders are 2.building up your objectives, 3.look at the data you want to gather (open or close) 4.choose instruments to implement research 5.deal with limitations from both external and internal sides  ",0,1,-1,1
"2092","The Big Five and Visualisations of Team Work Activity","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.",4,0,4,2
"2093","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","the good thing for this recommendation system is that when you have no idea what to learn, it automated and save the searching process. however the recommendation may always be the case that you cannot always learn what you needed due to the unique characteristics of different subject matter. surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course. Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories. The main predictor of knowledge gain was effort expended in the course. Students also had significant knowledge retention after the course. Both of these results are limited to the sample of students who chose to complete our knowledge tests. Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion was intent to complete. Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge. Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers). This article also includes our qualitative observations, lessons learned, and future directions.",13,4,9,4
"2094","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance.The skills definition, and the mapping of item to skills, require the involvement of experts.",3,1,2,5
"2095","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]",17,2,15,5
"2096","Using data mining to predict secondary school student performance","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid theeducation domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school relatedfeatures) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networksand Support Vector Machines) and three inputselections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.",5,2,3,3
"2097","Developing a generalizable detector of when students game the system","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.",4,1,3,5
"2098","Big Data in Education","This study,through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts ofstudents from a school district (n=188), demonstrates a novel application of hierarchical clusteranalysis and pattern visualization in which all data points collected on every student in a cohort can bepatterned, visualized and interpreted. Additionally, as a proof-of-concept study, overall schooling outcomes, such as studentdropout or taking a college entrance exam, are identified from the data patterns and compared to pastmethods of dropout identification as one example of the usefulness of the method. Hierarchicalcluster analysis correctly identified over 80% of the students who dropped out using the entire studentgrade history patterns from either K-12 or K-8.",1,1,0,3
"2099","Cross Validation","in order to better train our model and get more accurate result, getting a optimal training set and testing set is important. for the training set represents the general pattern of the population while testing set represent the most possible and similar to future data. Cross validation seems to be the a good choice when building these two sets",3,0,3,5
"2100","Hands-On Programming with R","This is a nice book that we also use in hudm 5026",1,0,1,1
"2101","Principal Component Analysis explained visually","PCA one of the feature extraction methods, not simply subseting the original dataset but a process of dimensionality reduction by which an initial set of raw data is reduced to more manageable groups for processing. A characteristic of these large data sets is a large number of variables that require a lot of computing resources to process. The new data set is representing the old with new ""mutant"" features.",0,0,0,1
"2102","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","It is a great paper that gives an example of unsupervised clustering, which is to ""statistically discover the underlying structure patterns within the dataset (Kohonen, 1997), a procedure well suited to discovering the underlying patterns within student data in education."" And particularly, hierarchical cluster analysis is used here. A few highlights in the techniques the authors used:  Average linkage was used to deal with missing data.  Cluster analysis, cluster tree, and heatmap are combined to create the final visualization, clustergram.  Since each student has a grade for every subject every year, the data is more like trends of vectors rather than isolated sample points in high-dimensional space. Therefore,they used uncentered correlation function as the distance measure, which examines the similarity of trends of student grade patterns over time.   ",3,1,2,3
"2103","Data wranglers: human interpreters to help close the feedback loop","A programme of human Data Wranglers is introduced by the paper. Goal of the programme: produce reports with actionable recommendations and further drive systematic improvement through single- and double-loop learning (with learning analytics). Context: Open University, a large distance teaching/online university. Who are Data Wranglers: a group of academics who analyze data about student learning and prepare reports with actionable recommendations. Cases:  Visualize visits to Moodle resources (forum, Wiki, Pages, Quiz) Survey students' enjoyment with reading print, reading text online, audio listening, and viewing AV. Validate whether students focus more on assessed learning activities than optional activities. Exploring the relationship between students' feedback on courses and the course ""design"".  However, from the existing examples, the authors found no improvements in the learning experience of the students, but only positive feedbacks from Faculty members and stakeholders. Such finding is not surprising for me since too many factors exist in a university and every single student have different preference in learning style, course design, etc.",4,0,4,1
"2104","Feature Selection","Feature selection is useful for both human beings and machines (machine learning). For human beings, we need feature selection for knowledge discovery. Among many features we keep observing, there might be only a few of them are meaningful (having the predictive power, etc.). Meanwhile, with only a few features, human beings can interpret observations and build up understandings of them more easily. For machine learning, it is also very important to reduce features (dimensions) because the needed data points increase exponentially (2^N, with the number of dimensions. This is called the Curse of Dimensionality.",0,0,0,1
"2105","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","At present, school personnel lack an effective way to model and visualize the classified achievement data collected by students to help make decisions.Overall educational outcomes, such as dropouts or college entrance examinations, can be identified from data patterns and compared with past methods of dropout identification as an example of method effectiveness.",1,3,-2,3
"2106","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","This article mainly talks about that it is possible to inform educators in a unique way and to improve educational reform. Social interactions is one of the major part that worth further study. I found out this are is vary attractive to me given the fact the relationship  between human being the most difficult things to be study and once we success, many human behaviors can be explained by this study.",3,1,2,2
"2107","Why Students Should Own Their Educational Data","By the form of Q and , this article mainly talks about the reasons that why students should have their own education data. Although most people believe that average is the most broadcasting and logical way to express knowledge, this form of education already lost its advantages, since average is only good for deliver basic knowledge at the age that most people even can not access to education.",2,1,1,2
"2108","Evaluating Machine Learning Models","This book mainly Describe machine learning workflows, and then evaluate metrics and model selection in depth. Many useful test are included.",0,0,0,5
"2109","Why Is Measuring Learning So Difficult?","Very good video.",1,0,1,1
"2110","Saturday Morning Breakfast Cereal","Interesting comic and I like this way.",1,0,1,2
"2111","The Data Wrangling Cheatsheet","Very useful useful cheat sheet to arrange cross table, and I already employ many useful method base on this cheat sheet in my 5026 final project. s",0,2,-2,1
"2112","Zuckerberg is ploughing billions into 'personalised learning' – why?","This article mainly takes about personalised learning and this idea is introduced by Zuckerberg, the founder of Facebook. By his definition, personalised learning is a process that teachers are working with students to customise instruction to meet the student’s individual needs and interests. However, his idea exist three major major flaws, which the rest of the article mainly takes about to against Zuckbrberg's idea. ",2,1,1,2
"2113","RStudio Cheat Sheets","Very useful cheat sheet that contain many useful function.",0,1,-1,1
"2114","Translating Learning into Numbers: A Generic Framework for Learning Analytics","; I like the part that discuss privacy and ethical issues since when pure science already dominated our life today, conflict must exist. To respect human nature, or bow to logical thick is a problem that we should keep discuss as the development of science.",3,2,1,2
"2115","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","This article mainly talks about an innovative method to answer how can we identify which skills must be mastered for the successful completion of an online courses. This is an interesting topic to study, since personal I never finish any online course successfully before.",4,0,4,5
"2116","Chapter 1: Social Network Data","This passage is mainly talking about the application of statistics in the area of social network. Many useful methods and examples are included in this passage, ranging from ""Example of square array of network data"" to ""Snowball methods"". All these examples and methods make me rethink the role of statistic as the flourishing of date, we can define more relationship trough analysis ways.",1,0,1,4
"2117","Learning Analytics Dashboards","Very useful website that can provide many functional resource. Thanks for sharing.",1,0,1,1
"2118","Measurement and its Uses in Learning Analytics","This s a vary interesting and inspiring passage about Psychological measurement. The idea of epistemology-assessment-pedagogy is a very functional method which I believe may used in my future study. Each section that used to explain these three ideas gives detailed information and suggestions of these methods. Like what this passage mentioned at the very end"" Tools can be used in many ways, and should not be isolated. ",1,1,0,2
"2119","Predictive Modelling in Teaching and Learning"," Process, practice, and challenges of using predictive modelling in teaching and learning are mainly talk about in this article. Very useful case for people who show interests in this area. ",0,0,0,3
"2120","Ethics and Learning Analytics: Charting the (Un)Charted","Considering relevant ethical issues should be take into account when we do our job. How far have we come is a good question that we all should be aware of.",1,0,1,2
"2121","How to display data badly","Great example that I should avoid. To clearly deliver the results of our chosen is also an important steps.",2,0,2,2
"2122","Junkcharts Trifecta Checkup: The Definitive Guide","I learn a lot about how to set the frame of my data though this article. Various of structures and categories are mentioned throughout this whole article. The three investigations also help to better clean and refine my data when I deal with a data contains so many unnecessary variables and information.",2,0,2,4
"2123","Measurement and its Uses in Learning Analytics","As a student’s major in educational measurements, I feel very familiar with the topics mentioned this article. It is interesting learning how the subject of measurement and learning analytics are different but complimentary. While measurement is explanatory, LA is predictive. I am willing to see more usage of measurements in the field of LA.",1,0,1,2
"2124","Ethics and Learning Analytics: Charting the (Un)Charted","This paper introduces how our own thinking has developed alongside broader developments in the field. The future of higher education is digital, distributed, and data-driven, and the paper discussed learning analysis and some future consideration. To explore potential conflicts between students’ concerns, more further research is needed. And there is also increasing concern balancing optimism around AI, machine learning and big data.",0,3,-3,2
"2125","Predictive Modelling in Teaching and Learning","The article introduces epistemology, pedagogy, assessment. All of these tools should be used in many ways. And tools should not be isolated from the context of use. It is productive to consider these provocations to reflect on the EPA claims that being through the deployment of a learning analytic tool with a given context.",0,0,0,2
"2126","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","This article illustrates a way of dividing models built for education data analysis, explanatory model and predictive model, and why the former is even more important than the latter. Although there are more predictive models generated. The article points out that explanatory models seek to identify interpretable constructs that are causally related to the outcome, and often have parameters that map to interpretable constructs, have fewer parameters overall, and involve human input early in the model development process.",0,0,0,5
"2127","Statistical graphics: making information clear – and beautiful","In this paper, the author described what is a good statistical graph based on statistical software such as R, and how to create a multilayer interactive graphics. I used to think that the graphs created by the software are adequate, but now I realize plotting of a graph should depend more on what the researchers would want to convey to the readers instead of the limitation of the software.  ",2,2,0,2
"2128","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","This paper introduces a wide-ranging discussion among graphics designers, statisticians, and users of statistical methods. Statisticians assume that their audiences are interested in and want to provide structured information. However, for graphics designers, they want to draw attention to graphics, and thus to the subject matter. This shows both groups use interactivity.",0,0,0,2
"2129","Junkcharts Trifecta Checkup: The Definitive Guide","This framework is interesting; it separates data visualization into three parts, Q: question, D: data, V: visual. The question is at the top corner, because data visualization needs a worthy cause. The data is relevant to the question addressed, and it includes reducing noise, removing errors or transformations. The Visual represents the data in a clear concise manner, addressing the question directly.",3,2,1,2
"2130","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","This study is an excellent example of how clustering method can be used in education context. This study designs a hierarchical cluster analysis (HCA) to analyze teacher-assigned grades to predict some student’s overall outcomes. It has some benefits that the traditional logistic model is not able to provide. It is also initiative in that it excavates the usefulness of teacher-assigned grades, which includes more aspects of the students’ performance aside from academic performance, thus, useful in predicting students overall overcome.",2,0,2,3
"2131","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","Networks are a simple but great wary to look at the small and vital communities in schools and universities. Network analysis need concepts and measurements in many standard types of data analyses. It’s hard to interpret density measurements when we are lack of comparable data of similar networks. The author analyzed two network in one classroom, and focused on keeping surveys brief and easy to process.",1,2,-1,4
"2132","Why Students Should Own Their Educational Data","I agree with the opinion that students should own their educational data. Most educations focus on average level of students, but students are different from each other, they are specific individuals. Students are good at different areas, and have different talents, so they should get their educational data and get their appropriate education. I’ve seen many students have to learn something they are not good at or not interested in, and they would waste their time on meaningless learning. Maybe online learning is a solution, because we are always lack of teachers, online education can personalize education and also provide good-quality education.  ",3,2,1,2
"2133","Knowledge tracing: Modeling the acquisition of procedural knowledge","Couldn't open this article because don't have the access to log in the website.",0,0,0,1
"2134","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","EDM and LAK both represent the emergence of data-intensive ways of education. Both communities have the same goal, which is improving the quality of analysis of large-scale educational data, to support both basic research and practice in education. However, EDM has a considerably greater focus on automated discovery, but LAK has a considerably greater focus on leveraging human judgment. ",1,0,1,2
"2135","Evaluating Machine Learning Models","Although the mean target of machine learning is to teach machine to learn something, it’s more important to figure out if the machine is learning the right thing. That’s why we need to evaluate the machine learning model. We need some data to train the model, and we also need some data to evaluate the model. If the model remembers all data during training, it doesn’t mean the model is good, maybe it’s overtraining. We need to evaluate the model to figure out if the model can work well.  ",4,0,4,5
"2136","Why Opting Out of Student Data Collection Isn’t the Solution","It’s obvious that data collection can help students. Schools need basic information about students and their parents. And schools need to record students’ grade, and know more about their students. And schools need to share data with people who work in cafeterias, school buses. Opting out is not the solution, critics who don’t trust vendors with data may call for opt-out rights. Parents who object to the number and type of tests given to students call for opt-outs.",2,2,0,2
"2137","Why Is Measuring Learning So Difficult?","Social network analyst uses a specialized language to describe the structure and content of their observations. Network data can be described with the ideas and concepts of familiar methods. Network data consist of a squared array of measurement. The difference between conventional data and network data is network data focuses on actors and relations, but conventional data focuses on actors and attributes.",0,0,0,4
"2138","Saturday Morning Breakfast Cereal","This is a very interesting and thought-provoking comic which reveal the dangerous result if a scholar fails to differentiate causal effect with simple correlation. In the comics, the media and public has misinterpreted the scholar's finding that playing with clock will lead one to become an engineer and invested a lot of money and resources into it until they found that this is ridiculous.  Besides I feel that there is a sense if ambiguity in the sociological research, because there will be more flexibility the responding and interpreting the sociological research, therefore, we need to be very careful about the result we published.",1,4,-3,2
"2139","Data wranglers: human interpreters to help close the feedback loop","It’s very important to close the feedback loop to improve learning. The evaluation if the paper is being used to report future Data Wrangler activity. The Data Wrangler work is embedded in institutional processes, with engagement at the most senior level as well as with individual academics.",2,0,2,1
"2140","Zuckerberg is ploughing billions into 'personalised learning' – why?","This news talked about the potential of the ""personalized learning"" triggered by the news that Facebook CEO Zuckerberg's generous investment in the area. Zuckerberg's definition of ""personalized learning"" is ""teachers working with students to customize instruction to meet the student's individual needs and interests."" In the article, both the benefits and problems with the concept of ""personalized learning"" were listed, and the optimal use of ""personalized learning"" by several big educational company is also mentioned. The article argues that while talking about personalized learning, we often think about the benefits it would bring, such as more flexibility, triggers pupils' interest to learn, promote teaching efficiency, avoid school bureaucracy, etc, but we seldom consider the downside of it. For example, ""personalized learning"" would discourage the students from learning more general knowledge, which is useful, but they seem ""uninterested"" in; the students might getting too used to all the materials serving for their convenience and lost the ability to adapt the environment.However, from my point of view, these shortcomings listed by the authors are not that rigorous. The general knowledge can still be gain by the students if the course requirements are designed wisely. For the second point, I don't think people's adaptability would degenerate with the progress of technology. It just changed the context which we need to adapt ourselves to. But I do agree that there is something about traditional school that is irreplaceable, for example, the real connection between teachers and students and accompany and communication among the peers. We need to be careful with what the technology could substitute and what cannot. ",11,3,8,2
"2141","Feature Selection","In this video, the instructor explains two reasons why we need to do feature selection. The first reason is that fewer features in the data would facilitate the interpretability and insight of the research due to human cognition process; the second reason is due to the Curse of Dimensionality. Curse of Dimensionality means the need for the number of data will grow exponentially when more features are involved, which results in consuming a lot more resources and time. Therefore, it is important to use some algorithm to select the most important features when there are too many features.",0,0,0,5
"2142","Chapter 1: Social Network Data","Social network analyst uses a specialized language to describe the structure and content of their observations. Network data can be described with the ideas and concepts of familiar methods. Network data consist of a squared array of measurement. The difference between conventional data and network data is network data focuses on actors and relations, but conventional data focuses on actors and attributes.",0,0,0,4
"2143","RStudio Cheat Sheets","I found this resource very useful, I already added it to the bookmark. I already used the tips in the R markdown and data import cheat sheet. Thanks!!!  ",1,1,0,1
"2144","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","This study used a web-based tutoring system for middle school mathematics to predict their college enrollment. The system assesses a student’s knowledge while assisting them in learning, providing teachers with detailed reports on the skills each student knows. Using criterion including student’s knowledge feature, behaviors feature, it helps to dig more internal controllable factors that can influence a students’ college enrollment :ability and engagement.",1,0,1,3
"2145","Translating Learning into Numbers: A Generic Framework for Learning Analytics","This article gives a general introduction on learning analytics including why the needs for learning analytics emerged, a framework of learning analytics, what does each component of the framework represent, and some potential problems that might raise along with it. It is a great handbook for whoever is interested in the LA industry.",1,1,0,2
"2146","The Big Five and Visualisations of Team Work Activity","In this reading, the researchers established a novel way of data visualizing group activity using a software development course as an example, with the help of two group communication software (Wiki and Ticket system). The three main components of the visualization are Activity Radar, interaction Network, and Wattle Tree. The three components capture different perspectives of group activity, such as the level of participation of each team member, the relationship and flow between each team member, and the member’s activity, respectively. The function of each graphical visualization or the combination of the functions could help evaluate the teamwork in line with the theory of Big Five components of teamwork. I think this research has let me know the infinite possibility of data usage. Data visualization can not only capture and present many physical and concrete substances but also vague things in our world, such as human relationships.",0,0,0,2
"2147","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","This article introduces MOOC to implement teaching recommending system, and tests whether taking the recommender system course gives students an impression of the quality of the department. And the result shows that follow-up survey takers were quite similar to the larger body of recommender systems students.",4,0,4,4
"2148","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","This paper demonstrate that Using the matrix factorization approach actually have better prediction result than expert's Q matrix. If well-master this approach, we would save a lot of time and resources.",1,0,1,5
"2149","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","If we want to build effective online course, we need intensive, iterative system engineering. It is a critical research agenda for the successful future of online education to study techniques for automatic skill model refinement and its application for evidence-based course refinement. It is quite challenging to define a set of skills to be learned and have individual skills associated with particular part of course contents when designing and implementing large-scale online courses .",5,1,4,5
"2150","Using data mining to predict secondary school student performance","Education is important for our society. The author uses BI/DM techniques to analyst the education domain, using past school grades, demographic, social and other school related data. The author tried four model, decision trees, random forest, neural networks and support vector machines. I think the author didn’t need to use decision tree actually, because random forest is also used, the main idea of analysis of RF and DT are the same, and RF has more trained decision trees, so using DT is meaningless, only RF is enough.",2,1,1,3
"2151","Big Data in Education","The link to this book cannot work.",1,0,1,2
"2152","Cross Validation","The video is well-explained, and I learned that a Cross Validation is a strategy we used with the training set to test the goodness of fit of the model. The way to do the cross validation is first, split the training data into folds; then training on every combination of the folds and used the leaving out one fold as a fake test set; and last but not least average all the errors, and pick the lowest error.  ",1,4,-3,5
"2153","Hands-On Programming with R","This is a very useful tool, including all the basics knowledge we need to know about R in a very clear structure. I have added to my bookmark already. Thanks!  ",1,0,1,2
